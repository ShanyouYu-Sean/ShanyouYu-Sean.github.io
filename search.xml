<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[spring aop源码解析]]></title>
      <url>/2020/11/27/spring-2/</url>
      <content type="html"><![CDATA[<p>转自  <a href="https://mp.weixin.qq.com/s/kxbdat_T0io6xEnD48HK-g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/kxbdat_T0io6xEnD48HK-g</a>  略有改动</p>
<h2 id="EnableAspectJAutoProxy注解"><a href="#EnableAspectJAutoProxy注解" class="headerlink" title="@EnableAspectJAutoProxy注解"></a>@EnableAspectJAutoProxy注解</h2><p>为了开启AOP功能，使用了一个@EnableAspectJAutoProxy</p>
<pre><code class="java">
@Import(AspectJAutoProxyRegistrar.class)
public @interface EnableAspectJAutoProxy {
    //proxyTargetClass属性，默认false，尝试采用JDK动态代理织入增强(如果当前类没有实现接口则还是会使用CGLIB)；如果设为true，则强制采用CGLIB动态代理织入增强
    boolean proxyTargetClass() default false;
    //通过aop框架暴露该代理对象，aopContext能够访问。为了解决类内部方法之间调用时无法增强的问题
    boolean exposeProxy() default false;
}
</code></pre>
<p>进入这个注解可以查看到这个注解的2个属性，除此之外可以看到这个注解使用@Import注解引入了一个配置类</p>
<pre><code class="java">
class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar {
    AspectJAutoProxyRegistrar() {
    }

    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
               //注册一个AOP代理实现的Bean，往下看          AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);
        AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class);
        if (enableAspectJAutoProxy != null) {
            if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) {
                AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);
            }

            if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) {
                AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);
            }
        }

    }
}
</code></pre>
<p>registerAspectJAnnotationAutoProxyCreatorIfNecessary方法的主要功能是注册或者升级AnnotationAwareAspectJAutoProxyCreator类</p>
<p>这个类在AOP中非常的重要，它的主要功能就是根据@Point注解定义的切点来自动代理与表达式匹配的类。<br>下面看一个这个实现的逻辑</p>
<pre><code class="java">private static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) {
        Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;); //如果已存在这个bean
        if (registry.containsBeanDefinition(&quot;org.springframework.aop.config.internalAutoProxyCreator&quot;)) {
            BeanDefinition apcDefinition = registry.getBeanDefinition(&quot;org.springframework.aop.config.internalAutoProxyCreator&quot;);
            //判断优先级，如果优先级较高则替换原先的bean
            if (!cls.getName().equals(apcDefinition.getBeanClassName())) {
                int currentPriority = findPriorityForClass(apcDefinition.getBeanClassName());
                int requiredPriority = findPriorityForClass(cls);
                if (currentPriority &lt; requiredPriority) {
                    apcDefinition.setBeanClassName(cls.getName());
                }
            }

            return null;
        } else {
            //注册AnnotationAwareAspectJAutoProxyCreator到容器中，此类负责基于注解的AOP动态代理实现
            RootBeanDefinition beanDefinition = new RootBeanDefinition(cls);
            beanDefinition.setSource(source);
            beanDefinition.getPropertyValues().add(&quot;order&quot;, -2147483648);
            beanDefinition.setRole(2);
            registry.registerBeanDefinition(&quot;org.springframework.aop.config.internalAutoProxyCreator&quot;, beanDefinition);
            return beanDefinition;
        }
    }
</code></pre>
<p>看一下AnnotationAwareAspectJAutoProxyCreator的类图：</p>
<p><img src="https://i.loli.net/2020/11/28/ovaKkMhsONZqiHE.png" alt="image.png"></p>
<p>观察类图可知，AnnotationAwareAspectJAutoProxyCreator这个类间接实现了BeanPostProcessor接口。还记得我们之前在对SpringIOC的源码进行解析时提到过，Spring在实例化Bean的前后会分别调用方法postProcessBeforeInstantiation和postProcessAfterInstantiation<br>而AOP的整体逻辑就是通过这两个方法来实现的</p>
<h2 id="postProcessBeforeInstantiation"><a href="#postProcessBeforeInstantiation" class="headerlink" title="postProcessBeforeInstantiation"></a>postProcessBeforeInstantiation</h2><p>首先看一下这个postProcessBeforeInstantiation方法，它是在bean实例化之前调用的，主要是针对切面类。这个方法不在AnnotationAwareAspectJAutoProxyCreator这个类中，而是在其父类AbstractAutoProxyCreator中</p>
<pre><code class="java">
public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException {
    Object cacheKey = getCacheKey(beanClass, beanName);

    if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) {
      if (this.advisedBeans.containsKey(cacheKey)) {
        return null;
      }
     //加载所有增强
      if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) {
        this.advisedBeans.put(cacheKey, Boolean.FALSE);
        return null;
      }
    }

    TargetSource targetSource = getCustomTargetSource(beanClass, beanName);
    if (targetSource != null) {
      if (StringUtils.hasLength(beanName)) {
        this.targetSourcedBeans.add(beanName);
      }
      Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource);
      Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource);
      this.proxyTypes.put(cacheKey, proxy.getClass());
      return proxy;
    }

    return null;
  }
</code></pre>
<h2 id="加载增强"><a href="#加载增强" class="headerlink" title="加载增强"></a>加载增强</h2><p>上方代码中最重要的一个方法就是shouldSkip方法了，这个方法被AspectJAwareAdvisorAutoProxyCreator所重载</p>
<pre><code class="java">protected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) {

    //查找所有标识了@Aspect注解的类，这里是重点，接着往下看
    List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();
    for (Advisor advisor : candidateAdvisors) {
        if (advisor instanceof AspectJPointcutAdvisor) {
            if (((AbstractAspectJAdvice) advisor.getAdvice()).getAspectName().equals(beanName)) {
                return true;
            }
        }
    }
    return super.shouldSkip(beanClass, beanName);
    }


    protected List&lt;Advisor&gt; findCandidateAdvisors() {
        return this.advisorRetrievalHelper.findAdvisorBeans();
    }

    protected List&lt;Advisor&gt; findCandidateAdvisors() {
        List&lt;Advisor&gt; advisors = super.findCandidateAdvisors();
        //buildAspectJAdvisors是重点
           advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors());
        return advisors;
    }
</code></pre>
<p>一个长方法buildAspectJAdvisors</p>
<pre><code class="java">
public List&lt;Advisor&gt; buildAspectJAdvisors() {
    //所有Aspect类的名称集合
    List&lt;String&gt; aspectNames = this.aspectBeanNames;
    if (aspectNames == null) {
        synchronized (this) {
            aspectNames = this.aspectBeanNames;
            //这个双重检查是不是在学习安全的单例模式的时候见过
            if (aspectNames == null) {
                List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;();
                aspectNames = new LinkedList&lt;String&gt;();
                //获取所有Bean名称
                String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(
                        this.beanFactory, Object.class, true, false);
                for (String beanName : beanNames) {
                    //判断是否符合条件，比如说有时会排除一些类，不让这些类注入进Spring
                    if (!isEligibleBean(beanName)) {
                        continue;
                    }
                    // 必须注意，bean会提前暴露，并被Spring容器缓存，但是这时还不能织入。
                    Class&lt;?&gt; beanType = this.beanFactory.getType(beanName);
                    if (beanType == null) {
                        continue;
                    }
                    //判断Bean的Class上是否标识@Aspect注解
                    if (this.advisorFactory.isAspect(beanType)) {
                        aspectNames.add(beanName);
                        AspectMetadata amd = new AspectMetadata(beanType, beanName);
                        if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) {
                            MetadataAwareAspectInstanceFactory factory =
                                    new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName);
                            //解析封装为Advisor返回
                            //下一步说，重点的重点
                            List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory);
                            if (this.beanFactory.isSingleton(beanName)) {
                                //将解析的Bean名称及类上的增强缓存起来,每个Bean只解析一次
                                this.advisorsCache.put(beanName, classAdvisors);
                            }
                            else {
                                this.aspectFactoryCache.put(beanName, factory);
                            }
                            advisors.addAll(classAdvisors);
                        }
                        else {
                            if (this.beanFactory.isSingleton(beanName)) {
                                throw new IllegalArgumentException(&quot;Bean with name &#39;&quot; + beanName +
                                        &quot;&#39; is a singleton, but aspect instantiation model is not singleton&quot;);
                            }
                            MetadataAwareAspectInstanceFactory factory =
                                    new PrototypeAspectInstanceFactory(this.beanFactory, beanName);
                            this.aspectFactoryCache.put(beanName, factory);
                            advisors.addAll(this.advisorFactory.getAdvisors(factory));
                        }
                    }
                }

                this.aspectBeanNames = aspectNames;
                return advisors;
            }
        }
    }

    if (aspectNames.isEmpty()) {
        return Collections.emptyList();
    }
    List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;();
    for (String aspectName : aspectNames) {
        //从缓存中获取当前Bean的切面实例，如果不为空，则指明当前Bean的Class标识了@Aspect，且有切面方法
        List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName);
        if (cachedAdvisors != null) {
            advisors.addAll(cachedAdvisors);
        }
        else {
            MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName);
            advisors.addAll(this.advisorFactory.getAdvisors(factory));
        }
    }
    return advisors;
}
</code></pre>
<p>这个方法可以概括为：</p>
<ul>
<li>找到所有BeanName</li>
<li>根据BeanName筛选出被@Aspect注解的类</li>
<li>针对类中被Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class注解的方法，先按上边的注解顺序排序后按方法名称排序，每一个方法对应一个Advisor。</li>
</ul>
<p>生成增强<br>advisorFactory.getAdvisors方法会从@Aspect标识的类上获取@Before，@Pointcut等注解的信息及其标识的方法的信息，生成增强</p>
<pre><code class="java">
public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) {
    Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();
    String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName();
    //校验类的合法性相关
    validate(aspectClass);

    MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory =
            new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory);

    List&lt;Advisor&gt; advisors = new LinkedList&lt;Advisor&gt;();
    //获取这个类所有的增强方法
    for (Method method : getAdvisorMethods(aspectClass)) {
        //生成增强实例
        Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName);
        if (advisor != null) {
            advisors.add(advisor);
        }
    }

    if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) {
        Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory);
        advisors.add(0, instantiationAdvisor);
    }

    for (Field field : aspectClass.getDeclaredFields()) {
        Advisor advisor = getDeclareParentsAdvisor(field);
        if (advisor != null) {
            advisors.add(advisor);
        }
    }

    return advisors;
}

//获取类的的方法
private List&lt;Method&gt; getAdvisorMethods(Class&lt;?&gt; aspectClass) {
    final List&lt;Method&gt; methods = new LinkedList&lt;Method&gt;();
    ReflectionUtils.doWithMethods(aspectClass, new ReflectionUtils.MethodCallback() {
        @Override
        public void doWith(Method method) throws IllegalArgumentException {
                //在@Aspect标识的类内部排除@Pointcut标识之外的所有方法，得到的方法集合包括继承自父类的方法，包括继承自Object的方法
            if (AnnotationUtils.getAnnotation(method, Pointcut.class) == null) {
                methods.add(method);
            }
        }
    });
    //对得到的所有方法排序，
    //如果方法标识了切面注解，则按@Around, @Before, @After, @AfterReturning, @AfterThrowing的顺序排序
    //如果没有标识这些注解，则按方法名称的字符串排序,
    //有注解的方法排在无注解的方法之前
    //最后的排序应该是这样的Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class。。。
    Collections.sort(methods, METHOD_COMPARATOR);
    return methods;
}
</code></pre>
<p>调用生成增强实例的方法</p>
<pre><code class="java">
public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory,
        int declarationOrderInAspect, String aspectName) {
    //再次校验类的合法性
    validate(aspectInstanceFactory.getAspectMetadata().getAspectClass());
    //切点表达式的包装类里面包含这些东西：execution(public * cn.shiyujun.service.IOCService.hollo(..))
    AspectJExpressionPointcut expressionPointcut = getPointcut(
            candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass());
    if (expressionPointcut == null) {
        return null;
    }
    //根据方法、切点、AOP实例工厂、类名、序号生成切面实例，详细代码往下看
    return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod,
            this, aspectInstanceFactory, declarationOrderInAspect, aspectName);
}

private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class&lt;?&gt; candidateAspectClass) {
    //查询方法上的切面注解，根据注解生成相应类型的AspectJAnnotation,在调用AspectJAnnotation的构造函数的同时
    //根据注解value或pointcut属性得到切点表达式，有argNames则设置参数名称
    AspectJAnnotation&lt;?&gt; aspectJAnnotation =
            AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod);
    //过滤那些不含@Before, @Around, @After, @AfterReturning, @AfterThrowing注解的方法
    if (aspectJAnnotation == null) {
        return null;
    }
    //生成带表达式的切面切入点，设置其切入点表达式
    AspectJExpressionPointcut ajexp =
            new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class&lt;?&gt;[0]);
    ajexp.setExpression(aspectJAnnotation.getPointcutExpression());
    ajexp.setBeanFactory(this.beanFactory);
    return ajexp;
}
</code></pre>
<p>InstantiationModelAwarePointcutAdvisorImpl的构造方法</p>
<pre><code class="java">
public InstantiationModelAwarePointcutAdvisorImpl(AspectJExpressionPointcut declaredPointcut,
      Method aspectJAdviceMethod, AspectJAdvisorFactory aspectJAdvisorFactory,
      MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) {

    this.declaredPointcut = declaredPointcut;
    this.declaringClass = aspectJAdviceMethod.getDeclaringClass();
    this.methodName = aspectJAdviceMethod.getName();
    this.parameterTypes = aspectJAdviceMethod.getParameterTypes();
    this.aspectJAdviceMethod = aspectJAdviceMethod;
    this.aspectJAdvisorFactory = aspectJAdvisorFactory;
    this.aspectInstanceFactory = aspectInstanceFactory;
    this.declarationOrder = declarationOrder;
    this.aspectName = aspectName;

    if (aspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) {
      Pointcut preInstantiationPointcut = Pointcuts.union(
          aspectInstanceFactory.getAspectMetadata().getPerClausePointcut(), this.declaredPointcut);

      this.pointcut = new PerTargetInstantiationModelPointcut(
          this.declaredPointcut, preInstantiationPointcut, aspectInstanceFactory);
      this.lazy = true;
    }
    else {
      this.pointcut = this.declaredPointcut;
      this.lazy = false;
            //重点在这里
      this.instantiatedAdvice = instantiateAdvice(this.declaredPointcut);
    }
  }

    private Advice instantiateAdvice(AspectJExpressionPointcut pointcut) {
    //再往下看
    Advice advice = this.aspectJAdvisorFactory.getAdvice(this.aspectJAdviceMethod, pointcut,
        this.aspectInstanceFactory, this.declarationOrder, this.aspectName);
    return (advice != null ? advice : EMPTY_ADVICE);
  }
</code></pre>
<p>生成增强</p>
<pre><code class="java">
public class ReflectiveAspectJAdvisorFactory extends AbstractAspectJAdvisorFactory implements Serializable {

    public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut,
            MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) {

        Class&lt;?&gt; candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();
        //又是一次校验
        validate(candidateAspectClass);

        AspectJAnnotation&lt;?&gt; aspectJAnnotation =
                AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod);
        if (aspectJAnnotation == null) {
            return null;
        }

        if (!isAspect(candidateAspectClass)) {
            throw new AopConfigException(&quot;Advice must be declared inside an aspect type: &quot; +
                    &quot;Offending method &#39;&quot; + candidateAdviceMethod + &quot;&#39; in class [&quot; +
                    candidateAspectClass.getName() + &quot;]&quot;);
        }

        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Found AspectJ method: &quot; + candidateAdviceMethod);
        }

        AbstractAspectJAdvice springAdvice;
        //根据注解类型生成不同的通知实例
        switch (aspectJAnnotation.getAnnotationType()) {
            case AtBefore:
                springAdvice = new AspectJMethodBeforeAdvice(
                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
                break;
            case AtAfter:
                springAdvice = new AspectJAfterAdvice(
                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
                break;
            case AtAfterReturning:
                springAdvice = new AspectJAfterReturningAdvice(
                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
                AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation();
                if (StringUtils.hasText(afterReturningAnnotation.returning())) {
                    springAdvice.setReturningName(afterReturningAnnotation.returning());
                }
                break;
            case AtAfterThrowing:
                springAdvice = new AspectJAfterThrowingAdvice(
                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
                AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation();
                if (StringUtils.hasText(afterThrowingAnnotation.throwing())) {
                    springAdvice.setThrowingName(afterThrowingAnnotation.throwing());
                }
                break;
            case AtAround:
                springAdvice = new AspectJAroundAdvice(
                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
                break;
            case AtPointcut:
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Processing pointcut &#39;&quot; + candidateAdviceMethod.getName() + &quot;&#39;&quot;);
                }
                return null;
            default:
                throw new UnsupportedOperationException(
                        &quot;Unsupported advice type on method: &quot; + candidateAdviceMethod);
        }

        //设置通知方法所属的类
        springAdvice.setAspectName(aspectName);
        //设置通知的序号,同一个类中有多个切面注解标识的方法时,按上方说的排序规则来排序，
        //其序号就是此方法在列表中的序号，第一个就是0
        springAdvice.setDeclarationOrder(declarationOrder);
        //获取通知方法的所有参数
        String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod);
        //将通知方法上的参数设置到通知中
        if (argNames != null) {
            springAdvice.setArgumentNamesFromStringArray(argNames);
        }
        //计算参数绑定工作，此方法详解请接着往下看
        springAdvice.calculateArgumentBindings();
        return springAdvice;
    }
}
</code></pre>
<p>校验方法参数并绑定</p>
<pre><code class="java">public synchronized final void calculateArgumentBindings() {
    if (this.argumentsIntrospected || this.parameterTypes.length == 0) {
        return;
    }

    int numUnboundArgs = this.parameterTypes.length;
    Class&lt;?&gt;[] parameterTypes = this.aspectJAdviceMethod.getParameterTypes();
    //切面注解标识的方法第一个参数要求是JoinPoint,或StaticPart，若是@Around注解则也可以是ProceedingJoinPoint
    if (maybeBindJoinPoint(parameterTypes[0]) || maybeBindProceedingJoinPoint(parameterTypes[0])) {
        numUnboundArgs--;
    }
    else if (maybeBindJoinPointStaticPart(parameterTypes[0])) {
        numUnboundArgs--;
    }

    if (numUnboundArgs &gt; 0) {
    //绑定属性
        bindArgumentsByName(numUnboundArgs);
    }

    this.argumentsIntrospected = true;
}
private void bindArgumentsByName(int numArgumentsExpectingToBind) {
    if (this.argumentNames == null) { //获取方法参数的名称
        this.argumentNames = createParameterNameDiscoverer().getParameterNames(this.aspectJAdviceMethod);
    }
    if (this.argumentNames != null) {
        // 往下看
        bindExplicitArguments(numArgumentsExpectingToBind);
    }
    else {
        throw new IllegalStateException(&quot;Advice method [&quot; + this.aspectJAdviceMethod.getName() + &quot;] &quot; +
                &quot;requires &quot; + numArgumentsExpectingToBind + &quot; arguments to be bound by name, but &quot; +
                &quot;the argument names were not specified and could not be discovered.&quot;);
    }
}

private void bindExplicitArguments(int numArgumentsLeftToBind) {
    //此属性用来存储方法未绑定的参数名称，及参数的序号
    this.argumentBindings = new HashMap&lt;String, Integer&gt;();

    int numExpectedArgumentNames = this.aspectJAdviceMethod.getParameterTypes().length;
    if (this.argumentNames.length != numExpectedArgumentNames) {
        throw new IllegalStateException(&quot;Expecting to find &quot; + numExpectedArgumentNames +
                &quot; arguments to bind by name in advice, but actually found &quot; +
                this.argumentNames.length + &quot; arguments.&quot;);
    }

    // So we match in number...,argumentIndexOffset代表第一个未绑定参数的顺序 
    int argumentIndexOffset = this.parameterTypes.length - numArgumentsLeftToBind;
    for (int i = argumentIndexOffset; i &lt; this.argumentNames.length; i++) {
        //存储未绑定的参数名称及其顺序的映射关系
        this.argumentBindings.put(this.argumentNames[i], i);
    }

    // Check that returning and throwing were in the argument names list if
    // specified, and find the discovered argument types.
    //如果是@AfterReturning注解的returningName 有值，验证，解析，同时得到定义返回值的类型
    if (this.returningName != null) {
        if (!this.argumentBindings.containsKey(this.returningName)) {
            throw new IllegalStateException(&quot;Returning argument name &#39;&quot; + this.returningName +
                    &quot;&#39; was not bound in advice arguments&quot;);
        }
        else {
            Integer index = this.argumentBindings.get(this.returningName);
            this.discoveredReturningType = this.aspectJAdviceMethod.getParameterTypes()[index];
            this.discoveredReturningGenericType = this.aspectJAdviceMethod.getGenericParameterTypes()[index];
        }
    }
    //如果是@AfterThrowing注解的throwingName 有值，验证，解析，同时得到抛出异常的类型
    if (this.throwingName != null) {
        if (!this.argumentBindings.containsKey(this.throwingName)) {
            throw new IllegalStateException(&quot;Throwing argument name &#39;&quot; + this.throwingName +
                    &quot;&#39; was not bound in advice arguments&quot;);
        }
        else {
            Integer index = this.argumentBindings.get(this.throwingName);
            this.discoveredThrowingType = this.aspectJAdviceMethod.getParameterTypes()[index];
        }
    }

    // configure the pointcut expression accordingly.
    configurePointcutParameters(argumentIndexOffset);
}

private void configurePointcutParameters(int argumentIndexOffset) {
    int numParametersToRemove = argumentIndexOffset;
    if (this.returningName != null) {
        numParametersToRemove++;
    }
    if (this.throwingName != null) {
        numParametersToRemove++;
    }
    String[] pointcutParameterNames = new String[this.argumentNames.length - numParametersToRemove];
    Class&lt;?&gt;[] pointcutParameterTypes = new Class&lt;?&gt;[pointcutParameterNames.length];
    Class&lt;?&gt;[] methodParameterTypes = this.aspectJAdviceMethod.getParameterTypes();

    int index = 0;
    for (int i = 0; i &lt; this.argumentNames.length; i++) {
        if (i &lt; argumentIndexOffset) {
            continue;
        }
        if (this.argumentNames[i].equals(this.returningName) ||
            this.argumentNames[i].equals(this.throwingName)) {
            continue;
        }
        pointcutParameterNames[index] = this.argumentNames[i];
        pointcutParameterTypes[index] = methodParameterTypes[i];
        index++;
    }
    //剩余的未绑定的参数会赋值给AspectJExpressionPointcut(表达式形式的切入点)的属性，以备后续使用
    this.pointcut.setParameterNames(pointcutParameterNames);
    this.pointcut.setParameterTypes(pointcutParameterTypes);
}
</code></pre>
<h2 id="postProcessAfterInitialization"><a href="#postProcessAfterInitialization" class="headerlink" title="postProcessAfterInitialization"></a>postProcessAfterInitialization</h2><p>这个方法是在bean实例化之后调用的，它是适用于所有需要被代理的类的</p>
<pre><code class="java">public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
    if (bean != null) {
        Object cacheKey = getCacheKey(bean.getClass(), beanName);
        if (!this.earlyProxyReferences.contains(cacheKey)) {
        //往下看
            return wrapIfNecessary(bean, beanName, cacheKey);
        }
    }
    return bean;
}

protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {
//如果已经处理过
    if (beanName != null &amp;&amp; this.targetSourcedBeans.contains(beanName)) {
        return bean;
    }
    //如果当前类是增强类
    if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {
        return bean;
    }
    //查看类是否是基础设施类，或者是否被排除
    if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) {
        this.advisedBeans.put(cacheKey, Boolean.FALSE);
        return bean;
    }

    //校验此类是否应该被代理，获取这个类的增强
    Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);
    //如果获取到了增强则需要针对增强创建代理
    if (specificInterceptors != DO_NOT_PROXY) {
        this.advisedBeans.put(cacheKey, Boolean.TRUE);
        //创建代理
        Object proxy = createProxy(
                bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));
        this.proxyTypes.put(cacheKey, proxy.getClass());
        return proxy;
    }

    this.advisedBeans.put(cacheKey, Boolean.FALSE);
    return bean;
}
</code></pre>
<p>上方这段代理一共有两个重点，getAdvicesAndAdvisorsForBean和createProxy这两个方法</p>
<p>获取增强</p>
<pre><code class="java">
protected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, TargetSource targetSource) {
//往下看
    List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName);
    if (advisors.isEmpty()) {
        return DO_NOT_PROXY;
    }
    return advisors.toArray();
}

protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) {
    //获取容器中的所有增强
    List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();
    //验证beanClass是否该被代理，如果应该，则返回适用于这个bean的增强
    List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);
    extendAdvisors(eligibleAdvisors);
    if (!eligibleAdvisors.isEmpty()) {
        eligibleAdvisors = sortAdvisors(eligibleAdvisors);
    }
    return eligibleAdvisors;
}
</code></pre>
<p>上方这个获取增强又分成了2部分，获取全部和根据全部处理bean相关的</p>
<p>获取全部增强</p>
<pre><code class="java">protected List&lt;Advisor&gt; findCandidateAdvisors() {
    // 调用父类的方法加载配置文件中的AOP声明（注解与XML都存在的时候）
    List&lt;Advisor&gt; advisors = super.findCandidateAdvisors();
        //往下看
        if (this.aspectJAdvisorsBuilder != null) {
      advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors());
    }
    return advisors;
  }
</code></pre>
<p>下面的方法就是获取所有的增强的代码实现了，方法比较长，不过主要逻辑很少。</p>
<ul>
<li>获取所有beanName </li>
<li>找出所有标记Aspect注解的类 </li>
<li>对标记Aspect的类提取增强器</li>
</ul>
<pre><code class="java">
public List&lt;Advisor&gt; buildAspectJAdvisors() {
    List&lt;String&gt; aspectNames = this.aspectBeanNames;

    if (aspectNames == null) {
      synchronized (this) {
        aspectNames = this.aspectBeanNames;
        if (aspectNames == null) {
          List&lt;Advisor&gt; advisors = new LinkedList&lt;&gt;();
          aspectNames = new LinkedList&lt;&gt;();
                    //获取所有的bean
          String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(
              this.beanFactory, Object.class, true, false);
          for (String beanName : beanNames) {
                      //校验不合法的类，Spring的一个扩展点，可以从子类中做排除切面的操作
            if (!isEligibleBean(beanName)) {
              continue;
            }
            //获取bean的类型
            Class&lt;?&gt; beanType = this.beanFactory.getType(beanName);
            if (beanType == null) {
              continue;
            }
                        //是否带有Aspect注解
            if (this.advisorFactory.isAspect(beanType)) {
              aspectNames.add(beanName);
              AspectMetadata amd = new AspectMetadata(beanType, beanName);
              if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) {
                MetadataAwareAspectInstanceFactory factory =
                    new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName);
                                        //解析所有的增强方法，下面说
                List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory);
                if (this.beanFactory.isSingleton(beanName)) {
                  this.advisorsCache.put(beanName, classAdvisors);
                }
                else {
                  this.aspectFactoryCache.put(beanName, factory);
                }
                advisors.addAll(classAdvisors);
              }
              else {
                if (this.beanFactory.isSingleton(beanName)) {
                  throw new IllegalArgumentException(&quot;Bean with name &#39;&quot; + beanName +
                      &quot;&#39; is a singleton, but aspect instantiation model is not singleton&quot;);
                }
                MetadataAwareAspectInstanceFactory factory =
                    new PrototypeAspectInstanceFactory(this.beanFactory, beanName);
                this.aspectFactoryCache.put(beanName, factory);
                advisors.addAll(this.advisorFactory.getAdvisors(factory));
              }
            }
          }
          this.aspectBeanNames = aspectNames;
          return advisors;
        }
      }
    }

    if (aspectNames.isEmpty()) {
      return Collections.emptyList();
    }
    List&lt;Advisor&gt; advisors = new LinkedList&lt;&gt;();
    for (String aspectName : aspectNames) {
      List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName);
      if (cachedAdvisors != null) {
        advisors.addAll(cachedAdvisors);
      }
      else {
        MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName);
        advisors.addAll(this.advisorFactory.getAdvisors(factory));
      }
    }
    return advisors;
  }
</code></pre>
<p>接下来就是各个增强器的获取方法的实现</p>
<pre><code class="java">
public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) {
        //获取所有Aspect类、类名称、并校验
    Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();
    String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName();
    validate(aspectClass);


    MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory =
        new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory);

    List&lt;Advisor&gt; advisors = new LinkedList&lt;&gt;();
        //取出类的所有方法
    for (Method method : getAdvisorMethods(aspectClass)) {
            //获取增强方法，往下看
      Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName);
      if (advisor != null) {
        advisors.add(advisor);
      }
    }

    // 如果需要增强且配置了延迟增强则在第一个位置添加同步实例化增强方法
    if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) {
      Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory);
      advisors.add(0, instantiationAdvisor);
    }

    // 获取属性中配置DeclareParents注解的增强
    for (Field field : aspectClass.getDeclaredFields()) {
      Advisor advisor = getDeclareParentsAdvisor(field);
      if (advisor != null) {
        advisors.add(advisor);
      }
    }

    return advisors;
  }
</code></pre>
<p>普通增强的获取</p>
<pre><code class="java">public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory,
      int declarationOrderInAspect, String aspectName) {

    validate(aspectInstanceFactory.getAspectMetadata().getAspectClass());
        //获取切点
    AspectJExpressionPointcut expressionPointcut = getPointcut(
        candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass());
    if (expressionPointcut == null) {
      return null;
    }
        //根据切点生成增强
    return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod,
        this, aspectInstanceFactory, declarationOrderInAspect, aspectName);
  }
</code></pre>
<p>上方代码又分为了两部分，先看一下切点信息的获取</p>
<pre><code class="java">
public InstantiationModelAwarePointcutAdvisorImpl(AspectJExpressionPointcut declaredPointcut,
    Method aspectJAdviceMethod, AspectJAdvisorFactory aspectJAdvisorFactory,
    MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) {

  this.declaredPointcut = declaredPointcut;
  this.declaringClass = aspectJAdviceMethod.getDeclaringClass();
  this.methodName = aspectJAdviceMethod.getName();
  this.parameterTypes = aspectJAdviceMethod.getParameterTypes();
  this.aspectJAdviceMethod = aspectJAdviceMethod;
  this.aspectJAdvisorFactory = aspectJAdvisorFactory;
  this.aspectInstanceFactory = aspectInstanceFactory;
  this.declarationOrder = declarationOrder;
  this.aspectName = aspectName;

  if (aspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) {
    Pointcut preInstantiationPointcut = Pointcuts.union(
        aspectInstanceFactory.getAspectMetadata().getPerClausePointcut(), this.declaredPointcut);
    this.pointcut = new PerTargetInstantiationModelPointcut(
        this.declaredPointcut, preInstantiationPointcut, aspectInstanceFactory);
    this.lazy = true;
  }
  else {
    this.pointcut = this.declaredPointcut;
    this.lazy = false;
           //初始化对应的增强器，重点
    this.instantiatedAdvice = instantiateAdvice(this.declaredPointcut);
  }
}
</code></pre>
<p>到这里之后获取所有的增强这个流程就快要完毕了</p>
<pre><code class="java">private Advice instantiateAdvice(AspectJExpressionPointcut pointcut) {
        //往下看
    Advice advice = this.aspectJAdvisorFactory.getAdvice(this.aspectJAdviceMethod, pointcut,
        this.aspectInstanceFactory, this.declarationOrder, this.aspectName);
    return (advice != null ? advice : EMPTY_ADVICE);
  }

public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut,
      MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) {

    Class&lt;?&gt; candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();
    validate(candidateAspectClass);

    AspectJAnnotation&lt;?&gt; aspectJAnnotation =
        AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod);
    if (aspectJAnnotation == null) {
      return null;
    }

    if (!isAspect(candidateAspectClass)) {
      throw new AopConfigException(&quot;Advice must be declared inside an aspect type: &quot; +
          &quot;Offending method &#39;&quot; + candidateAdviceMethod + &quot;&#39; in class [&quot; +
          candidateAspectClass.getName() + &quot;]&quot;);
    }

    if (logger.isDebugEnabled()) {
      logger.debug(&quot;Found AspectJ method: &quot; + candidateAdviceMethod);
    }

    AbstractAspectJAdvice springAdvice;
        //根据不同的注解类型封装不同的增强器
    switch (aspectJAnnotation.getAnnotationType()) {
      case AtBefore:
        springAdvice = new AspectJMethodBeforeAdvice(
            candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
        break;
      case AtAfter:
        springAdvice = new AspectJAfterAdvice(
            candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
        break;
      case AtAfterReturning:
        springAdvice = new AspectJAfterReturningAdvice(
            candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
        AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation();
        if (StringUtils.hasText(afterReturningAnnotation.returning())) {
          springAdvice.setReturningName(afterReturningAnnotation.returning());
        }
        break;
      case AtAfterThrowing:
        springAdvice = new AspectJAfterThrowingAdvice(
            candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
        AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation();
        if (StringUtils.hasText(afterThrowingAnnotation.throwing())) {
          springAdvice.setThrowingName(afterThrowingAnnotation.throwing());
        }
        break;
      case AtAround:
        springAdvice = new AspectJAroundAdvice(
            candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);
        break;
      case AtPointcut:
        if (logger.isDebugEnabled()) {
          logger.debug(&quot;Processing pointcut &#39;&quot; + candidateAdviceMethod.getName() + &quot;&#39;&quot;);
        }
        return null;
      default:
        throw new UnsupportedOperationException(
            &quot;Unsupported advice type on method: &quot; + candidateAdviceMethod);
    }

    springAdvice.setAspectName(aspectName);
    springAdvice.setDeclarationOrder(declarationOrder);
    String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod);
    if (argNames != null) {
      springAdvice.setArgumentNamesFromStringArray(argNames);
    }
    springAdvice.calculateArgumentBindings();
    return springAdvice;
  }
</code></pre>
<p>获取匹配增强<br>经过上方的长篇大论，我们终于完成了所有的增强器的解析，还记得刚才的方法走到哪了么</p>
<pre><code class="java">protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) {
   //获取全部增强
  List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();
  List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);
  extendAdvisors(eligibleAdvisors);
  if (!eligibleAdvisors.isEmpty()) {
    eligibleAdvisors = sortAdvisors(eligibleAdvisors);
  }
  return eligibleAdvisors;
}
</code></pre>
<p>接下来看看怎么为当前的Bean匹配自己的增强吧</p>
<pre><code class="java">protected List&lt;Advisor&gt; findAdvisorsThatCanApply(
      List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) {

    ProxyCreationContext.setCurrentProxiedBeanName(beanName);
    try {
        //往下看
      return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass);
    }
    finally {
      ProxyCreationContext.setCurrentProxiedBeanName(null);
    }
  }

    public static List&lt;Advisor&gt; findAdvisorsThatCanApply(List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; clazz) {
        if (candidateAdvisors.isEmpty()) {
            return candidateAdvisors;
        }
        List&lt;Advisor&gt; eligibleAdvisors = new LinkedList&lt;Advisor&gt;();
        for (Advisor candidate : candidateAdvisors) {
            //处理引介增强，重点，再往下看
            if (candidate instanceof IntroductionAdvisor &amp;&amp; canApply(candidate, clazz)) {
                eligibleAdvisors.add(candidate);
            }
        }
        boolean hasIntroductions = !eligibleAdvisors.isEmpty();
        for (Advisor candidate : candidateAdvisors) {
            if (candidate instanceof IntroductionAdvisor) {
                continue;
            }
            //对普通bean的处理
            if (canApply(candidate, clazz, hasIntroductions)) {
                eligibleAdvisors.add(candidate);
            }
        }
        return eligibleAdvisors;
    }
</code></pre>
<p>引介增强与普通bean的处理最后都是进的同一个方法，只不过是引介增强的第三个参数默认使用的false</p>
<pre><code class="java">
public static boolean canApply(Advisor advisor, Class&lt;?&gt; targetClass, boolean hasIntroductions) {
    //如果存在排除的配置
    if (advisor instanceof IntroductionAdvisor) {
        return ((IntroductionAdvisor) advisor).getClassFilter().matches(targetClass);
    }
    else if (advisor instanceof PointcutAdvisor) {
        PointcutAdvisor pca = (PointcutAdvisor) advisor;
        //往下看
        return canApply(pca.getPointcut(), targetClass, hasIntroductions);
    }
    else {
        return true;
    }
}

public static boolean canApply(Pointcut pc, Class&lt;?&gt; targetClass, boolean hasIntroductions) {
    Assert.notNull(pc, &quot;Pointcut must not be null&quot;);
    //切点上是否存在排除类的配置
    if (!pc.getClassFilter().matches(targetClass)) {
        return false;
    }
    //验证注解的作用域是否可以作用于方法上
    MethodMatcher methodMatcher = pc.getMethodMatcher();
    if (methodMatcher == MethodMatcher.TRUE) {  
        return true;
    }

    IntroductionAwareMethodMatcher introductionAwareMethodMatcher = null;
    if (methodMatcher instanceof IntroductionAwareMethodMatcher) {
        introductionAwareMethodMatcher = (IntroductionAwareMethodMatcher) methodMatcher;
    }

    Set&lt;Class&lt;?&gt;&gt; classes = new LinkedHashSet&lt;Class&lt;?&gt;&gt;(ClassUtils.getAllInterfacesForClassAsSet(targetClass));
    classes.add(targetClass);
    for (Class&lt;?&gt; clazz : classes) {
        Method[] methods = ReflectionUtils.getAllDeclaredMethods(clazz);
        for (Method method : methods) {
            //获取类所实现的所有接口和所有类层级的方法，循环验证
            if ((introductionAwareMethodMatcher != null &amp;&amp;
                    introductionAwareMethodMatcher.matches(method, targetClass, hasIntroductions)) ||
                    methodMatcher.matches(method, targetClass)) {
                return true;
            }
        }
    }

    return false;
}
</code></pre>
<p>现在所有的bean对应的增强都已经获取到了，那么就可以根据类的所有增强数组创建代理</p>
<p>创建代理<br>回到最上方开始获取增强的地方，当增强获取到之后就可以执行下面这个操作了</p>
<pre><code class="java">
protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName,
      @Nullable Object[] specificInterceptors, TargetSource targetSource) {

    if (this.beanFactory instanceof ConfigurableListableBeanFactory) {
      AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);
    }

    ProxyFactory proxyFactory = new ProxyFactory();
        使用proxyFactory对象copy当前类中的相关属性
    proxyFactory.copyFrom(this);
        //判断是否使用Cglib动态代理
    if (!proxyFactory.isProxyTargetClass()) {
          //如果配置开启使用则直接设置开启
      if (shouldProxyTargetClass(beanClass, beanName)) {
        proxyFactory.setProxyTargetClass(true);
      }
      else {
            //如果没有配置开启则判断bean是否有合适的接口使用JDK的动态代理（JDK动态代理必须是带有接口的类，如果类没有实现任何接口则只能使用Cglib动态代理）
            //关于代理的基础知识可以参考我的另一篇文章：https://mp.weixin.qq.com/s/1DRmvuky5_NMRcH-toTLqQ
        evaluateProxyInterfaces(beanClass, proxyFactory);
      }
    }
        //添加所有增强
    Advisor[] advisors = buildAdvisors(beanName, specificInterceptors);
    proxyFactory.addAdvisors(advisors);
        //设置要代理的类
    proxyFactory.setTargetSource(targetSource);
        //Spring的一个扩展点，默认实现为空。留给我们在需要对代理进行特殊操作的时候实现
    customizeProxyFactory(proxyFactory);
    proxyFactory.setFrozen(this.freezeProxy);
    if (advisorsPreFiltered()) {
      proxyFactory.setPreFiltered(true);
    }
        //使用代理工厂获取代理对象
    return proxyFactory.getProxy(getProxyClassLoader());
  }
</code></pre>
<p>获取代理对象</p>
<pre><code class="java">public Object getProxy(@Nullable ClassLoader classLoader) {
    return createAopProxy().getProxy(classLoader);
  }
protected final synchronized AopProxy createAopProxy() {
    if (!this.active) {
      activate();
    }
    return getAopProxyFactory().createAopProxy(this);
  }
public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException {
    if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) {
      Class&lt;?&gt; targetClass = config.getTargetClass();
      if (targetClass == null) {
        throw new AopConfigException(&quot;TargetSource cannot determine target class: &quot; +
            &quot;Either an interface or a target is required for proxy creation.&quot;);
      }
      if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {
        return new JdkDynamicAopProxy(config);
      }
      return new ObjenesisCglibAopProxy(config);
    }
    else {
      return new JdkDynamicAopProxy(config);
    }
  }
</code></pre>
<p>增强何时调用？<br>代理创建出来了，那么我们的前置增强、后置增强、环绕增强等是如何在代理中体现的呢，对代理模式还不熟悉的同学一定要先看一下这篇文章呦：<a href="https://mp.weixin.qq.com/s/1DRmvuky5_NMRcH-toTLqQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/1DRmvuky5_NMRcH-toTLqQ</a><br>这里就简单看一下JDK动态代理的实现吧</p>
<pre><code class="java">public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    MethodInvocation invocation;
    Object oldProxy = null;
    boolean setProxyContext = false;

    TargetSource targetSource = this.advised.targetSource;
    Object target = null;

    try {
            //equals方法处理
      if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) {
        return equals(args[0]);
      }
            //hash代码处理
      else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) {
        return hashCode();
      }
      else if (method.getDeclaringClass() == DecoratingProxy.class) {
        return AopProxyUtils.ultimateTargetClass(this.advised);
      }
      else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp;
          method.getDeclaringClass().isAssignableFrom(Advised.class)) {
        // Service invocations on ProxyConfig with the proxy config...
        return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);
      }

      Object retVal;
            //如果配置内部方法调用的增强
      if (this.advised.exposeProxy) {
        oldProxy = AopContext.setCurrentProxy(proxy);
        setProxyContext = true;
      }

      target = targetSource.getTarget();
      Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null);

      // 获取当前方法的拦截器链
      List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);

      if (chain.isEmpty()) {
                //如果没有拦截器直接调用切点方法
        Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
        retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);
      }
      else {
        invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);
                //执行拦截器链，重点，往下看
        retVal = invocation.proceed();
      }

      Class&lt;?&gt; returnType = method.getReturnType();
            //返回结果
      if (retVal != null &amp;&amp; retVal == target &amp;&amp;
          returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp;
          !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {
        retVal = proxy;
      }
      else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) {
        throw new AopInvocationException(
            &quot;Null return value from advice does not match primitive return type for: &quot; + method);
      }
      return retVal;
    }
    finally {
      if (target != null &amp;&amp; !targetSource.isStatic()) {
        targetSource.releaseTarget(target);
      }
      if (setProxyContext) {
        AopContext.setCurrentProxy(oldProxy);
      }
    }
  }
</code></pre>
<p>看完上方的代码，可以猜到，所有的增强都在这个拦截器里面了，那么这个拦截器又是如何实现的呢</p>
<pre><code class="java">public Object proceed() throws Throwable {
    //  执行完所有的增强后执行切点方法
    if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) {
      return invokeJoinpoint();
    }
        //获取下一个要执行的拦截器
    Object interceptorOrInterceptionAdvice =
        this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);
    if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) {
      InterceptorAndDynamicMethodMatcher dm =
          (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;
      if (dm.methodMatcher.matches(this.method, this.targetClass, this.arguments)) {
        return dm.interceptor.invoke(this);
      }
      else {
        // Dynamic matching failed.
        // Skip this interceptor and invoke the next in the chain.
        return proceed();
      }
    }
    else {
      // It&#39;s an interceptor, so we just invoke it: The pointcut will have
      // been evaluated statically before this object was constructed.
      return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);
    }
  }
</code></pre>
<p>至此SpringAOP的源码解析已经完成</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spring如何实现AOP？，您可以这样说：</p>
<ul>
<li>AnnotationAwareAspectJAutoProxyCreator是AOP核心处理类</li>
<li>AnnotationAwareAspectJAutoProxyCreator实现了BeanProcessor，其中postProcessAfterInitialization是核心方法。</li>
<li>核心实现分为2步<ul>
<li>getAdvicesAndAdvisorsForBean获取当前bean匹配的增强器<ul>
<li>找所有增强器，也就是所有@Aspect注解的Bean</li>
<li>找匹配的增强器，也就是根据@Before，@After等注解上的表达式，与当前bean进行匹配，暴露匹配上的。</li>
<li>对匹配的增强器进行扩展和排序，就是按照@Order或者PriorityOrdered的getOrder的数据值进行排序，越小的越靠前。</li>
</ul>
</li>
<li>createProxy为当前bean创建代理,createProxy有2种创建方法，JDK代理或CGLIB<ul>
<li>如果设置了proxyTargetClass=true，一定是CGLIB代理</li>
<li>如果proxyTargetClass=false，目标对象实现了接口，走JDK代理</li>
<li>如果没有实现接口，走CGLIB代理</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spring ioc源码解析]]></title>
      <url>/2020/11/26/spring-1/</url>
      <content type="html"><![CDATA[<p>网上资料很多也很杂，这玩意我在公司开过session专门讲过，也算是比较了解，这里不啰嗦，直接用springboot的源码结合网上的资料总结下。</p>
<pre><code class="java">public static void main(String[] args) {
    SpringApplication.run(xxx.class, args);
  }
</code></pre>
<h2 id="构造器"><a href="#构造器" class="headerlink" title="构造器"></a>构造器</h2><p>略过一些，直接先点击构造方法</p>
<pre><code class="java">public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) {
        // resourceLoader 属性，资源加载器。
        this.resourceLoader = resourceLoader;
        Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;);
        // 被@configuration标记过的类
        this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));
        // 推断当前环境是哪种Web环境，详见下面
        this.webApplicationType = deduceWebApplicationType();
        // 注意下面这两个方法，他们都调用的事getSpringFactoriesInstances
        // 所以这里拿到的东西都是从SpringFactories里加载的
        // 同时，这里SpringFactoriesLoader会把SpringFactories里的内容加载到其内部的cache里
        // 方便以后获取
        // 创建ApplicationContextInitializer实例，详见下面
        setInitializers((Collection) getSpringFactoriesInstances(
                ApplicationContextInitializer.class));
        // 初始化 listeners 属性
        setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
        this.mainApplicationClass = deduceMainApplicationClass();
}

// 加载REACTIVE容器还是SERVLET容器或者是default容器
private WebApplicationType deduceWebApplicationType() {
        if (ClassUtils.isPresent(REACTIVE_WEB_ENVIRONMENT_CLASS, null)
                &amp;&amp; !ClassUtils.isPresent(MVC_WEB_ENVIRONMENT_CLASS, null)
                &amp;&amp; !ClassUtils.isPresent(JERSEY_WEB_ENVIRONMENT_CLASS, null)) {
            return WebApplicationType.REACTIVE;
        }
        for (String className : WEB_ENVIRONMENT_CLASSES) {
            if (!ClassUtils.isPresent(className, null)) {
                return WebApplicationType.NONE;
            }
        }
        return WebApplicationType.SERVLET;
}

/**
     * 获得指定类型的数组
     * @param type
     * @param &lt;T&gt;
     * @return
     */
    private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) {
        return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] {});
    }

    private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type,
            Class&lt;?&gt;[] parameterTypes, Object... args) {
        ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
        // Use names and ensure unique to protect against duplicates
        // 加载在 `META-INF/spring.factories` 里的类名的数组
        // 在 META-INF/spring.factories 文件中，会以 KEY-VALUE 的格式，配置每个类对应的实现类们， 这里只拿keys
        // 这都是一些spring boot启动需要加载的组建
        Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(
                SpringFactoriesLoader.loadFactoryNames(type, classLoader));
        // 创建对象们
        List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes,
                classLoader, args, names);
        // 进行排序
        AnnotationAwareOrderComparator.sort(instances);
        return instances;
    }
</code></pre>
<p>关于ApplicationContextInitializer和ApplicationListener，上两张图：</p>
<p><img src="https://i.loli.net/2020/11/26/GdLHePKMFSRvZXp.png" alt="image.png"></p>
<p><img src="https://i.loli.net/2020/11/26/K3pgr5xJLijvkP4.png" alt="image.png"></p>
<p>这个构造器最主要就是准备了ApplicationContextInitializer和ApplicationListener，为接下来的run做准备</p>
<hr>
<p>说一下listener，因为用的比ApplicationContext少。</p>
<p>ApplicationEvent以及Listener是Spring为我们提供的一个事件监听、订阅的实现，内部实现原理是观察者设计模式，设计初衷也是为了系统业务逻辑之间的解耦，提高可扩展性以及可维护性。事件发布者并不需要考虑谁去监听，监听具体的实现内容是什么，发布者的工作只是为了发布事件而已。</p>
<p>好处是可以实现异步的事件发布和监听。</p>
<p>创建事件 ApplicationEvent</p>
<pre><code class="java">@Getter
public class PushOrderEvent extends ApplicationEvent {

    private String orderNo;

    private Long userId;

    public PushOrderEvent(Object source, String orderNo,Long userId) {
        super(source);
        this.orderNo = orderNo;
        this.userId = userId;
    }
}
</code></pre>
<p>创建监听器 ApplicationListener</p>
<p>实现接口方式</p>
<pre><code class="java">@Slf4j
@Component
public class PushOrderListener implements ApplicationListener&lt;PushOrderEvent&gt; {


    @Override
    public void onApplicationEvent(PushOrderEvent event) {

        log.info(&quot;{}用户下了一个订单{}&quot;, event.getUserId(), event.getOrderNo());
    }
}
</code></pre>
<p>注解方式</p>
<pre><code class="java">@Slf4j
@Component
public class AnnotationPushOrderListener {

    @EventListener
    public void handler(PushOrderEvent event) {

        log.info(&quot;{}用户下了一个订单{}&quot;, event.getUserId(), event.getOrderNo());
    }

}
</code></pre>
<p>发布事件</p>
<pre><code class="java">@Slf4j
@RestController
@RequestMapping(&quot;order&quot;)
public class OrderController {

    @Autowired
    private ApplicationEventPublisher publisher;

    @PostMapping(&quot;push&quot;)
    public ResponseEntity pushOrder() {
        String orderNo = UUID.randomUUID().toString();

        // 发布事件
        publisher.publishEvent(new PushOrderEvent(this, orderNo, 666666L));

        return ResponseEntity.ok(orderNo);
    }

}
</code></pre>
<hr>
<h2 id="run方法"><a href="#run方法" class="headerlink" title="run方法"></a>run方法</h2><hr>
<p>先说一下需要了解的一些概念，便于后文理解</p>
<p>BeanPostProcessor</p>
<p>BeanPostProcessor 接口定义了一个你可以自己实现的回调方法，来实现你自己的实例化逻辑、依赖解决逻辑等，如果你想要在Spring完成对象实例化、配置、初始化之后实现自己的业务逻辑，你可以补充实现一个或多个BeanPostProcessor的实现。</p>
<p>BeanPostProcessor有两个方法：</p>
<pre><code class="java">public interface BeanPostProcessor {

    /**
     * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean
     * initialization callbacks (like InitializingBean&#39;s {@code afterPropertiesSet}
     * or a custom init-method). The bean will already be populated with property values.
     * The returned bean instance may be a wrapper around the original.
     * @param bean bean的实例
     * @param beanName bean的name
     * @return 返回处理过后的bean,可以是最初的Bean或者是包装后的Bean；
     * 如果返回null，后续的BeanPostProcessor不会被执行
     * @throws org.springframework.beans.BeansException in case of errors
     * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet
     */
    Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException;

    /**
     * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean
     * initialization callbacks (like InitializingBean&#39;s {@code afterPropertiesSet}
     * or a custom init-method). The bean will already be populated with property values.
     * The returned bean instance may be a wrapper around the original.
     * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean
     * instance and the objects created by the FactoryBean (as of Spring 2.0). The
     * post-processor can decide whether to apply to either the FactoryBean or created
     * objects or both through corresponding {@code bean instanceof FactoryBean} checks.
     * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a
     * {@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation} method,
     * in contrast to all other BeanPostProcessor callbacks.
     * @param bean bean的实例
     * @param beanName bean的name
     * @return 返回处理过后的bean,可以是最初的Bean或者是包装后的Bean；
     * 如果返回null，后续的BeanPostProcessor不会被执行
     * {@code null}, no subsequent BeanPostProcessors will be invoked
     * @throws org.springframework.beans.BeansException in case of errors
     * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet
     * @see org.springframework.beans.factory.FactoryBean
     */
    Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;

}
</code></pre>
<p>我们可以看到注释postProcessBeforeInitialization方法是在所有的bean的InitializingBean的afterPropertiesSet方法之前执行而postProcessAfterInitialization方法则是在所有的bean的InitializingBean的afterPropertiesSet方法之后执行的。</p>
<p>BeanFactoryProcessor</p>
<p>BeanFactoryPostProcessor的定义和BeanPostProcessor相似，有一个最主要的不同是：BeanFactoryPostProcessor可以对bean的配置信息进行操作；更确切的说Spring IOC容器允许BeanFactoryPostProcessor读取配置信息并且能够在容器实例化任何其他bean（所有的实现了BeanFactoryPostProcessor接口的类）之前改变配置信息</p>
<pre><code class="java"> */
public interface BeanFactoryPostProcessor {

    /**
     * Modify the application context&#39;s internal bean factory after its standard
     * initialization. All bean definitions will have been loaded, but no beans
     * will have been instantiated yet. This allows for overriding or adding
     * properties even to eager-initializing beans.
     * @param beanFactory the bean factory used by the application context
     * @throws org.springframework.beans.BeansException in case of errors
     */
    void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;

}
</code></pre>
<p>我们可以看到注释中写到的：postProcessBeanFactory可以在BeanFactory完成实例化后修改容器内部的BeanFactory。这时候所有的bean都被加载，但是没有bean被初始化。这就允许BeanFactoryPOSTProcessor重写或者添加配置，甚至可以提前初始化bean。</p>
<hr>
<p>开始正题run():</p>
<pre><code class="java">/**
     * Run the Spring application, creating and refreshing a new
     * {@link ApplicationContext}.
     * @param args the application arguments (usually passed from a Java main method)
     * @return a running {@link ApplicationContext}
     */
    // 可变个数参数args即是我们整个应用程序的入口main方法的参数，在我们的例子中，参数个数为零。
    // SpringApplication对象的run方法创建并刷新ApplicationContext
    public ConfigurableApplicationContext run(String... args) {
        // StopWatch是来自org.springframework.util的工具类，可以用来方便的记录程序的运行时间。
        StopWatch stopWatch = new StopWatch();
        stopWatch.start();
        ConfigurableApplicationContext context = null;
        Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;();
        // 设置headless模式, 没啥用，不关心
        configureHeadlessProperty();
        // 这个RunListener是在SpringApplication对象的run方法执行到不同的阶段时，发布相应的event给SpringApplication对象的成员变量listeners中记录的事件监听器。
        SpringApplicationRunListeners listeners = getRunListeners(args);
        listeners.starting();
        try {
            // 正常没有args
            ApplicationArguments applicationArguments = new DefaultApplicationArguments(
                    args);
            // 准备environment，详见下文
            ConfigurableEnvironment environment = prepareEnvironment(listeners,
                    applicationArguments);
            // 在environment中将需要ignore的bean设为true
            configureIgnoreBeanInfo(environment);
            Banner printedBanner = printBanner(environment);
            // 通过反射去初始化ApplicationContext，并实例化了其三个属性：
            // 1、reader（AnnotatedBeanDefinitionReader）
            // 2、scanner（ClassPathBeanDefinitionScanner）
            // 3、beanFactory（DefaultListableBeanFactory）
            context = createApplicationContext();
            // 把ExceptionReporter加载一遍
            exceptionReporters = getSpringFactoriesInstances(
                    SpringBootExceptionReporter.class,
                    new Class[] { ConfigurableApplicationContext.class }, context);
            // 准备Context，详见下文
            prepareContext(context, environment, listeners, applicationArguments,
                    printedBanner);
            // 最重要的部分，详见下文
            refreshContext(context);
            afterRefresh(context, applicationArguments);
            stopWatch.stop();
            if (this.logStartupInfo) {
                new StartupInfoLogger(this.mainApplicationClass)
                        .logStarted(getApplicationLog(), stopWatch);
            }
            listeners.started(context);
            callRunners(context, applicationArguments);
        }
        catch (Throwable ex) {
            handleRunFailure(context, ex, exceptionReporters, listeners);
            throw new IllegalStateException(ex);
        }

        try {
            listeners.running(context);
        }
        catch (Throwable ex) {
            handleRunFailure(context, ex, exceptionReporters, null);
            throw new IllegalStateException(ex);
        }
        return context;
    }
</code></pre>
<pre><code class="java">// 准备环境
private ConfigurableEnvironment prepareEnvironment(
        SpringApplicationRunListeners listeners,
        ApplicationArguments applicationArguments) {
    // Create and configure the environment 创建和配置环境

    // 获取或创建环境
    // Environment接口是Spring对当前程序运行期间的环境的封装。主要提供了两大功能：profile和property(父接口PropertyResolver提供)
    ConfigurableEnvironment environment = getOrCreateEnvironment();
    // 配置环境：配置PropertySources和activeProfiles
    configureEnvironment(environment, applicationArguments.getSourceArgs());
    // listeners环境准备(就是广播ApplicationEnvironmentPreparedEvent事件)
    listeners.environmentPrepared(environment);
    // 将环境绑定到SpringApplication
    bindToSpringApplication(environment);
    // 如果是非web环境，将环境转换成StandardEnvironment
    if (this.webApplicationType == WebApplicationType.NONE) {
        environment = new EnvironmentConverter(getClassLoader())
                .convertToStandardEnvironmentIfNecessary(environment);
    }
    // 配置PropertySources对它自己的递归依赖
    ConfigurationPropertySources.attach(environment);
    return environment;
}
</code></pre>
<pre><code class="java">// 准备Context
private void prepareContext(ConfigurableApplicationContext context,
            ConfigurableEnvironment environment, SpringApplicationRunListeners listeners,
            ApplicationArguments applicationArguments, Banner printedBanner) {
        // 设置上下文的environment
        context.setEnvironment(environment);
        // 应用上下文后处理，一般不会处理啥
        postProcessApplicationContext(context);
        // 在context refresh之前，对其应用ApplicationContextInitializer，详见下文
        applyInitializers(context);
        // 一个空的实现
        listeners.contextPrepared(context);
        // 打印启动日志和启动应用的Profile
        if (this.logStartupInfo) {
            logStartupInfo(context.getParent() == null);
            logStartupProfileInfo(context);
        }

        // Add boot specific singleton beans
        // 向beanFactory注册一个单例bean：命令行参数bean（正常实现没有）
        context.getBeanFactory().registerSingleton(&quot;springApplicationArguments&quot;,
                applicationArguments);
        if (printedBanner != null) {
            // 向beanFactory注册一个单例bean：banner bean
            context.getBeanFactory().registerSingleton(&quot;springBootBanner&quot;, printedBanner);
        }

        // Load the sources
        // 获取全部资源，其实就一个：SpringApplication的primarySources（主类）属性
        Set&lt;Object&gt; sources = getAllSources();
        Assert.notEmpty(sources, &quot;Sources must not be empty&quot;);
        // 实例化了BeanDefinitionLoader，并调用AnnotatedBeanDefinitionReader#doRegisterBean，并将主类的BeanDefinition注册到context中的beanFactory的BeanDefinitionMap中
        load(context, sources.toArray(new Object[0]));
        // 向上下文中添加ApplicationListener，并广播ApplicationPreparedEvent事件
        listeners.contextLoaded(context);
    }

/**
 * Apply any {@link ApplicationContextInitializer}s to the context before it is
 * refreshed.
 * @param context the configured ApplicationContext (not refreshed yet)
 * @see ConfigurableApplicationContext#refresh()
 */
// 一共6个initializer，他们的initialize方法都被调用
// 1、DelegatingApplicationContextInitializer：如果配置了context.initializer.classes，获取其值（逗号分隔的initializer列表字符串），转换成class列表
// 根据classes列表进行实例化获取initializer实例列表，再对每个initializer实例调用initialize方法。
// 2、ContextIdApplicationContextInitializer：设置application id：从environment中获取spring.application.name配置项的值，并把设置成application id
// 若没有配置spring.application.name，则取默认值application；将application id封装成ContextId对象，注册到beanFactory中。
// 3、ConfigurationWarningsApplicationContextInitializer：向上下文注册了一个BeanFactoryPostProcessor：ConfigurationWarningsPostProcessor实例
// 4、ServerPortInfoApplicationContextInitializer：向上下文注册了一个ApplicationListener：ServerPortInfoApplicationContextInitializer对象自己
// 5、SharedMetadataReaderFactoryContextInitializer：向context注册了一个BeanFactoryPostProcessor：CachingMetadataReaderFactoryPostProcessor实例。
// 6、ConditionEvaluationReportLoggingListener：向上下文注册了一个ApplicationListener：ConditionEvaluationReportListener实例；
// 从beanFactory中获取名为autoConfigurationReport的bean赋值给自己的属性report
@SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })
protected void applyInitializers(ConfigurableApplicationContext context) {
    for (ApplicationContextInitializer initializer : getInitializers()) {
        // 解析当前initializer实现的ApplicationContextInitializer的泛型参数
        Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(
                initializer.getClass(), ApplicationContextInitializer.class);
        // 断言context是否是requiredType的实例
        Assert.isInstanceOf(requiredType, context, &quot;Unable to call initializer.&quot;);
        // 向context应用初始化器
        initializer.initialize(context);
    }
}
</code></pre>
<p>把refreshContext(context)拿出来单独说，他实际上是调用了AbstractApplicationContext#refresh</p>
<pre><code class="java">    @Override
    public void refresh() throws BeansException, IllegalStateException {
        synchronized (this.startupShutdownMonitor) {
            // Prepare this context for refreshing.
            // 两步：
            // 1、initPropertySources() 默认空实现
            // 2、getEnvironment().validateRequiredProperties(); 默认没有RequiredProperties
            prepareRefresh();

            // Tell the subclass to refresh the internal bean factory.
            // 给BeanFactory设了一个ID叫application
            ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

            // Prepare the bean factory for use in this context.
            // 详见下文
            prepareBeanFactory(beanFactory);

            try {
                // Allows post-processing of the bean factory in context subclasses.
                // 默认没有实现，如果是web项目的话，会注册web-specific scopes (&quot;request&quot;, &quot;session&quot;, &quot;globalSession&quot;)和web-specific environment beans (&quot;contextParameters&quot;, &quot;contextAttributes&quot;)
                postProcessBeanFactory(beanFactory);

                // Invoke factory processors registered as beans in the context.
                // 处理BeanFactoryPostProcessors，会注册bean，实例化bean，并调用其方法
                // 调用的是invokeBeanFactoryPostProcessors，详见下文
                invokeBeanFactoryPostProcessors(beanFactory);

                // Register bean processors that intercept bean creation.
                // 处理beanpostprocessor，会注册bean，实例化bean，以供bean创建的时候使用，详见下文
                registerBeanPostProcessors(beanFactory);

                // Initialize message source for this context.
                // 针对于国际化问题的MessageSource，这里略过，不是很重要
                initMessageSource();

                // Initialize event multicaster for this context.
                // 初始化事件监听多路广播器
                // 没有的话就注册一个simpleApplicationEventMulticaster就是用来发布事件用的。
                initApplicationEventMulticaster();

                // Initialize other special beans in specific context subclasses.
                // 空方法
                onRefresh();

                // Check for listener beans and register them.
                // 注册监听器
                registerListeners();

                // Instantiate all remaining (non-lazy-init) singletons.
                // 实例化所有剩余的非懒加载单例 bean。
                // 除了一些内部的 bean、实现了 BeanFactoryPostProcessor 接口的 bean、实现了 BeanPostProcessor 接口的 bean，
                // 其他的非懒加载单例 bean 都会在这个方法中被实例化，并且 BeanPostProcessor 的触发也是在这个方法中。
                // 详见下文
                finishBeanFactoryInitialization(beanFactory);

                // Last step: publish corresponding event.
                // 详见下文
                finishRefresh();
            }

            catch (BeansException ex) {
                if (logger.isWarnEnabled()) {
                    logger.warn(&quot;Exception encountered during context initialization - &quot; +
                            &quot;cancelling refresh attempt: &quot; + ex);
                }

                // Destroy already created singletons to avoid dangling resources.
                destroyBeans();

                // Reset &#39;active&#39; flag.
                cancelRefresh(ex);

                // Propagate exception to caller.
                throw ex;
            }

            finally {
                // Reset common introspection caches in Spring&#39;s core, since we
                // might not ever need metadata for singleton beans anymore...
                resetCommonCaches();
            }
        }
    }
</code></pre>
<pre><code class="java">
    /**
     * Configure the factory&#39;s standard context characteristics,
     * such as the context&#39;s ClassLoader and post-processors.
     * @param beanFactory the BeanFactory to configure
     */
    protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) {
        // Tell the internal bean factory to use the context&#39;s class loader etc.
        // 默认是appclassloader
        beanFactory.setBeanClassLoader(getClassLoader());
        // 注册语言解析器，就可以对SPEL进行解析了
        beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));
        // 为beanFactory增加了一个默认的propertyEditor，这个主要是对bean的属性等设置管理的一个工具
        beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment()));

        // Configure the bean factory with context callbacks.
        // 添加BeanPostProcessor--ApplicationContextAwareProcessor
        // ApplicationContextAwareProcessor：让Application contexts自动注册他潜在依赖的bean factory，默认不会启用，后面给ignore了
        beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));
        // 设置了几个忽略自动装配的接口
        beanFactory.ignoreDependencyInterface(EnvironmentAware.class);
        beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);
        beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);
        beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);
        beanFactory.ignoreDependencyInterface(MessageSourceAware.class);
        beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);

        // BeanFactory interface not registered as resolvable type in a plain factory.
        // MessageSource registered (and found for autowiring) as a bean.
        // 设置了几个自动装配的特殊规则
        beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);
        beanFactory.registerResolvableDependency(ResourceLoader.class, this);
        beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);
        beanFactory.registerResolvableDependency(ApplicationContext.class, this);

        // Register early post-processor for detecting inner beans as ApplicationListeners.
        beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));

        // Detect a LoadTimeWeaver and prepare for weaving, if found.
        // 增加对AspectJ的支持
        if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {
            beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));
            // Set a temporary ClassLoader for type matching.
            beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));
        }

        // Register default environment beans.
        // 添加默认的系统环境bean
        if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) {
            beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment());
        }
        if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) {
            beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties());
        }
        if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) {
            beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment());
        }
    }
</code></pre>
<pre><code class="java">public static void invokeBeanFactoryPostProcessors(
        ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) {

    // Invoke BeanDefinitionRegistryPostProcessors first, if any.
    Set&lt;String&gt; processedBeans = new HashSet&lt;String&gt;();

    // 1.判断beanFactory是否为BeanDefinitionRegistry，beanFactory为DefaultListableBeanFactory,
    // 而DefaultListableBeanFactory实现了BeanDefinitionRegistry接口，因此这边为true
    if (beanFactory instanceof BeanDefinitionRegistry) {
        BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;
        // 用于存放普通的BeanFactoryPostProcessor
        List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new LinkedList&lt;BeanFactoryPostProcessor&gt;();
        // 用于存放BeanDefinitionRegistryPostProcessor
        List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new LinkedList&lt;BeanDefinitionRegistryPostProcessor&gt;();

        // 2.首先处理入参中的beanFactoryPostProcessors
        // 遍历所有的beanFactoryPostProcessors, 将BeanDefinitionRegistryPostProcessor和普通BeanFactoryPostProcessor区分开
        for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) {
            if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) {
                // 2.1 如果是BeanDefinitionRegistryPostProcessor
                BeanDefinitionRegistryPostProcessor registryProcessor =
                        (BeanDefinitionRegistryPostProcessor) postProcessor;
                // 2.1.1 直接执行BeanDefinitionRegistryPostProcessor接口的postProcessBeanDefinitionRegistry方法（一般是在BeanFactory里注册或修改BeanDefinition）
                registryProcessor.postProcessBeanDefinitionRegistry(registry);
                // 2.1.2 添加到registryProcessors(用于最后执行postProcessBeanFactory方法)
                registryProcessors.add(registryProcessor);
            } else {
                // 2.2 否则，只是普通的BeanFactoryPostProcessor
                // 2.2.1 添加到regularPostProcessors(用于最后执行postProcessBeanFactory方法)
                regularPostProcessors.add(postProcessor);
            }
        }

        // Do not initialize FactoryBeans here: We need to leave all regular beans
        // uninitialized to let the bean factory post-processors apply to them!
        // Separate between BeanDefinitionRegistryPostProcessors that implement
        // PriorityOrdered, Ordered, and the rest.
        // 用于保存本次要执行的BeanDefinitionRegistryPostProcessor
        List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;BeanDefinitionRegistryPostProcessor&gt;();

        // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.
        // 3.再处理bean factory里的BeanDefinitionRegistryPostProcessor
        // 调用所有实现PriorityOrdered接口的BeanDefinitionRegistryPostProcessor实现类
        // 3.1 找出所有实现BeanDefinitionRegistryPostProcessor接口的Bean的beanName
        String[] postProcessorNames =
                beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
        // 3.2 遍历postProcessorNames
        for (String ppName : postProcessorNames) {
            // 3.3 校验是否实现了PriorityOrdered接口
            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {
                // 3.4 获取ppName对应的bean实例, 添加到currentRegistryProcessors中,
                // beanFactory.getBean: 这边getBean方法会触发创建ppName对应的bean对象, 目前暂不深入解析
                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
                // 3.5 将要被执行的加入processedBeans，避免后续重复执行
                processedBeans.add(ppName);
            }
        }
        // 3.6 进行排序(根据是否实现PriorityOrdered、Ordered接口和order值来排序)
        sortPostProcessors(currentRegistryProcessors, beanFactory);
        // 3.7 添加到registryProcessors(用于最后执行postProcessBeanFactory方法)
        registryProcessors.addAll(currentRegistryProcessors);
        // 3.8 遍历currentRegistryProcessors, 执行postProcessBeanDefinitionRegistry方法
        // **这里划重点** 因为这里会执行spring中最重要的一个beanfactory后置加载器：ConfigurationClassPostProcessor
        // 做什么的我在后文说
        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
        // 3.9 执行完毕后, 清空currentRegistryProcessors
        currentRegistryProcessors.clear();

        // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.
        // 4.调用所有实现了Ordered接口的BeanDefinitionRegistryPostProcessor实现类（过程跟上面的步骤3基本一样）
        // 4.1 找出所有实现BeanDefinitionRegistryPostProcessor接口的类, 这边重复查找是因为执行完上面的BeanDefinitionRegistryPostProcessor,
        // 可能会新增了其他的BeanDefinitionRegistryPostProcessor, 因此需要重新查找
        postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
        for (String ppName : postProcessorNames) {
            // 校验是否实现了Ordered接口，并且还未执行过
            if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) {
                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
                processedBeans.add(ppName);
            }
        }
        sortPostProcessors(currentRegistryProcessors, beanFactory);
        registryProcessors.addAll(currentRegistryProcessors);
        // 4.2 遍历currentRegistryProcessors, 执行postProcessBeanDefinitionRegistry方法
        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
        currentRegistryProcessors.clear();

        // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.
        // 5.最后, 调用所有剩下的BeanDefinitionRegistryPostProcessors
        boolean reiterate = true;
        while (reiterate) {
            reiterate = false;
            // 5.1 找出所有实现BeanDefinitionRegistryPostProcessor接口的类
            postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
            for (String ppName : postProcessorNames) {
                // 5.2 跳过已经执行过的
                if (!processedBeans.contains(ppName)) {
                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
                    processedBeans.add(ppName);
                    // 5.3 如果有BeanDefinitionRegistryPostProcessor被执行, 则有可能会产生新的BeanDefinitionRegistryPostProcessor,
                    // 因此这边将reiterate赋值为true, 代表需要再循环查找一次
                    reiterate = true;
                }
            }
            sortPostProcessors(currentRegistryProcessors, beanFactory);
            registryProcessors.addAll(currentRegistryProcessors);
            // 5.4 遍历currentRegistryProcessors, 执行postProcessBeanDefinitionRegistry方法
            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
            currentRegistryProcessors.clear();
        }

        // Now, invoke the postProcessBeanFactory callback of all processors handled so far.
        // 6.调用所有BeanDefinitionRegistryPostProcessor的postProcessBeanFactory方法(BeanDefinitionRegistryPostProcessor继承自BeanFactoryPostProcessor)
        invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);
        // 7.最后, 调用入参beanFactoryPostProcessors中的普通BeanFactoryPostProcessor的postProcessBeanFactory方法
        invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);
    } else {
        // Invoke factory processors registered with the context instance.
        invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);
    }

    // 到这里 , 入参beanFactoryPostProcessors和容器中的所有BeanDefinitionRegistryPostProcessor已经全部处理完毕,
    // 下面开始处理容器中的所有BeanFactoryPostProcessor

    // Do not initialize FactoryBeans here: We need to leave all regular beans
    // uninitialized to let the bean factory post-processors apply to them!
    // 8.找出所有实现BeanFactoryPostProcessor接口的类
    String[] postProcessorNames =v
            beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);

    // Separate between BeanFactoryPostProcessors that implement PriorityOrdered,
    // Ordered, and the rest.
    // 用于存放实现了PriorityOrdered接口的BeanFactoryPostProcessor
    List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;();
    // 用于存放实现了Ordered接口的BeanFactoryPostProcessor的beanName
    List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;();
    // 用于存放普通BeanFactoryPostProcessor的beanName
    List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;();
    // 8.1 遍历postProcessorNames, 将BeanFactoryPostProcessor按实现PriorityOrdered、实现Ordered接口、普通三种区分开
    for (String ppName : postProcessorNames) {
        // 8.2 跳过已经执行过的
        if (processedBeans.contains(ppName)) {
            // skip - already processed in first phase above
        } else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {
            // 8.3 添加实现了PriorityOrdered接口的BeanFactoryPostProcessor
            priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));
        } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {
            // 8.4 添加实现了Ordered接口的BeanFactoryPostProcessor的beanName
            orderedPostProcessorNames.add(ppName);
        } else {
            // 8.5 添加剩下的普通BeanFactoryPostProcessor的beanName
            nonOrderedPostProcessorNames.add(ppName);
        }
    }

    // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered.
    // 9.调用所有实现PriorityOrdered接口的BeanFactoryPostProcessor
    // 9.1 对priorityOrderedPostProcessors排序
    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);
    // 9.2 遍历priorityOrderedPostProcessors, 执行postProcessBeanFactory方法
    invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);

    // Next, invoke the BeanFactoryPostProcessors that implement Ordered.
    // 10.调用所有实现Ordered接口的BeanFactoryPostProcessor
    List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;();
    for (String postProcessorName : orderedPostProcessorNames) {
        // 10.1 获取postProcessorName对应的bean实例, 添加到orderedPostProcessors, 准备执行
        orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));
    }
    // 10.2 对orderedPostProcessors排序
    sortPostProcessors(orderedPostProcessors, beanFactory);
    // 10.3 遍历orderedPostProcessors, 执行postProcessBeanFactory方法
    invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);

    // Finally, invoke all other BeanFactoryPostProcessors.
    // 11.调用所有剩下的BeanFactoryPostProcessor
    List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;();
    for (String postProcessorName : nonOrderedPostProcessorNames) {
        // 11.1 获取postProcessorName对应的bean实例, 添加到nonOrderedPostProcessors, 准备执行
        nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));
    }
    // 11.2 遍历nonOrderedPostProcessors, 执行postProcessBeanFactory方法
    invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);

    // Clear cached merged bean definitions since the post-processors might have
    // modified the original metadata, e.g. replacing placeholders in values...
    // 12.清除元数据缓存（mergedBeanDefinitions、allBeanNamesByType、singletonBeanNamesByType），
    // 因为后处理器可能已经修改了原始元数据，例如， 替换值中的占位符...
    beanFactory.clearMetadataCache();
}
</code></pre>
<p>这里要单独把ConfigurationClassPostProcessor拿出来说一下，这是一个BeanFactory的后置处理器，因此它的主要功能是参与BeanFactory的建造，在这个类中，会解析加了@Configuration的配置类，还会解析@ComponentScan、@ComponentScans注解扫描的包，以及解析@Import等注解。</p>
<p>这里我们直接看它所调用的主要方法</p>
<pre><code class="java">public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) {
    List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;();
    // 获取现有的BeanDefinitionName，此时应该只有主类，和一些AnnotationProcessor，listener
    String[] candidateNames = registry.getBeanDefinitionNames();

    for (String beanName : candidateNames) {
        BeanDefinition beanDef = registry.getBeanDefinition(beanName);
        if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) ||
                ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) {
            // log 日志
        }
        // checkConfigurationClassCandidate()会判断一个是否是一个配置类,并为BeanDefinition设置属性为lite或者full。
        // 在这儿为BeanDefinition设置lite和full属性值是为了后面在使用
        // 如果加了@Configuration，那么对应的BeanDefinition为full;
        // 如果加了@Bean,@Component,@ComponentScan,@Import,@ImportResource这些注解，则为lite。
        // lite和full均表示这个BeanDefinition对应的类是一个配置类
        // 尽管如此，因为这里是对上文的candidate进行一个过滤
        // 所以一般这里过滤后只剩一个主类
        else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) {
            configCandidates.add(new BeanDefinitionHolder(beanDef, beanName));
        }
    }
    // ... 省略部分代码
    SingletonBeanRegistry sbr = null;
    if (registry instanceof SingletonBeanRegistry) {
        sbr = (SingletonBeanRegistry) registry;
        if (!this.localBeanNameGeneratorSet) {
            // beanName的生成器，因为后面会扫描出所有加入到spring容器中class，然后把这些class
            // 解析成BeanDefinition类，此时需要利用BeanNameGenerator为这些BeanDefinition生成beanName
            BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR);
            if (generator != null) {
                this.componentScanBeanNameGenerator = generator;
                this.importBeanNameGenerator = generator;
            }
        }
    }
    // ... 省略部分代码

    // 解析所有加了@Configuration注解的类
    ConfigurationClassParser parser = new ConfigurationClassParser(
            this.metadataReaderFactory, this.problemReporter, this.environment,
            this.resourceLoader, this.componentScanBeanNameGenerator, registry);

    Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates);
    Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size());
    do {
        // 解析配置类，在此处会解析配置类上的注解(ComponentScan扫描出的类，@Import注册的类，以及@Bean方法定义的类)
        // 注意：这一步只会将加了@Configuration注解以及通过@ComponentScan注解扫描的类才会加入到BeanDefinitionMap中
        // 通过其他注解(例如@Import、@Bean)的方式，在parse()方法这一步并不会将其解析为BeanDefinition放入到BeanDefinitionMap中，而是先解析成ConfigurationClass类
        // 真正放入到map中是在下面的this.reader.loadBeanDefinitions()方法中实现的
        // 而且这里不会为bean解析依赖，即BeanDefinition的dependsOn属性是空的
        // 详见下文
        parser.parse(candidates);
        parser.validate();

        Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses());
        configClasses.removeAll(alreadyParsed);

        // Read the model and create bean definitions based on its content
        if (this.reader == null) {
            this.reader = new ConfigurationClassBeanDefinitionReader(
                    registry, this.sourceExtractor, this.resourceLoader, this.environment,
                    this.importBeanNameGenerator, parser.getImportRegistry());
        }
        // 将上一步parser解析出的ConfigurationClass类加载成BeanDefinition
        // 实际上经过上一步的parse()后，解析出来的bean已经放入到BeanDefinition中了，但是由于这些bean可能会引入新的bean，例如实现了ImportBeanDefinitionRegistrar或者ImportSelector接口的bean，或者bean中存在被@Bean注解的方法
        // 因此需要执行一次loadBeanDefinition()，这样就会执行ImportBeanDefinitionRegistrar或者ImportSelector接口的方法或者@Bean注释的方法
        // 实际上是执行loadBeanDefinitionsForConfigurationClass方法，见下文
        this.reader.loadBeanDefinitions(configClasses);
        alreadyParsed.addAll(configClasses);

        candidates.clear();
        // 这里判断registry.getBeanDefinitionCount() &gt; candidateNames.length的目的是为了知道reader.loadBeanDefinitions(configClasses)这一步有没有向BeanDefinitionMap中添加新的BeanDefinition
        // 实际上就是看配置类(例如AppConfig类会向BeanDefinitionMap中添加bean)
        // 如果有，registry.getBeanDefinitionCount()就会大于candidateNames.length
        // 这样就需要再次遍历新加入的BeanDefinition，并判断这些bean是否已经被解析过了，如果未解析，需要重新进行解析
        // 这里的AppConfig类向容器中添加的bean，实际上在parser.parse()这一步已经全部被解析了
        // 所以为什么还需要做这个判断，在processConfigBeanDefinitions的过程中, 有可能会动态添加beanDefinition到beanDefinitionMap, 这样就会导致两次的数量不一致
        if (registry.getBeanDefinitionCount() &gt; candidateNames.length) {
            String[] newCandidateNames = registry.getBeanDefinitionNames();
            Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames));
            Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;();
            for (ConfigurationClass configurationClass : alreadyParsed) {
                alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());
            }
            // 如果有未解析的类，则将其添加到candidates中，这样candidates不为空，就会进入到下一次的while的循环中
            for (String candidateName : newCandidateNames) {
                if (!oldCandidateNames.contains(candidateName)) {
                    BeanDefinition bd = registry.getBeanDefinition(candidateName);
                    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;
                            !alreadyParsedClasses.contains(bd.getBeanClassName())) {
                        candidates.add(new BeanDefinitionHolder(bd, candidateName));
                    }
                }
            }
            candidateNames = newCandidateNames;
        }
    }
    while (!candidates.isEmpty());

    // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes
    if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) {
        sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());
    }

    if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) {
        ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();
    }
}
</code></pre>
<pre><code class="java">
public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) {
    this.deferredImportSelectors = new LinkedList&lt;&gt;();
    // 根据BeanDefinition类型的不同，调用parse()不同的重载方法
    // 实际上最终都是调用doProcessConfigurationClass()方法
    for (BeanDefinitionHolder holder : configCandidates) {
        BeanDefinition bd = holder.getBeanDefinition();
        try {
            if (bd instanceof AnnotatedBeanDefinition) {
                parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName());
            }else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) {
                parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName());
            }else {
                parse(bd.getBeanClassName(), holder.getBeanName());
            }
        }
    }
    // 处理延迟importSelector
    // 也是真正处理spring的AutoConfiguration的方法
    // 详见下文
    processDeferredImportSelectors();
}
</code></pre>
<pre><code class="java">protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)
        throws IOException {

    // 1、首先处理内部类，处理内部类时，最终还是调用doProcessConfigurationClass()方法
    processMemberClasses(configClass, sourceClass);
    // 2、处理属性资源文件，加了@PropertySource注解
    for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(
            sourceClass.getMetadata(), PropertySources.class,
            org.springframework.context.annotation.PropertySource.class)) {
        if (this.environment instanceof ConfigurableEnvironment) {
            processPropertySource(propertySource);
        }
    }
    // 3、处理@ComponentScan或者@ComponentScans注解
    // 3.1 先找出类上的@ComponentScan和@ComponentScans注解的所有属性(例如basePackages等属性值)
    Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(
            sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);
    if (!componentScans.isEmpty() &amp;&amp;
            !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) {
        for (AnnotationAttributes componentScan : componentScans) {
            // 3.2 解析@ComponentScan和@ComponentScans配置的扫描的包所包含的类
            // 比如 basePackages = com.tiantang.study, 那么在这一步会扫描出这个包及子包下的class，然后将其解析成BeanDefinition
            // (BeanDefinition可以理解为等价于BeanDefinitionHolder)
            Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions =
                    this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName());
            // 3.3 通过上一步扫描包com.tiantang.com下的类，有可能扫描出来的bean中可能也添加了ComponentScan或者ComponentScans注解.
            //所以这里需要循环遍历一次，进行递归(parse)，继续解析，直到解析出的类上没有ComponentScan和ComponentScans
            // (这时3.1这一步解析出componentScans为空列表，不会进入到if语句，递归终止)
            for (BeanDefinitionHolder holder : scannedBeanDefinitions) {
                BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();
                if (bdCand == null) {
                    bdCand = holder.getBeanDefinition();
                }
                // 同样，这里会调用ConfigurationClassUtils.checkConfigurationClassCandidate()方法来判断类是否是一个配置类
                if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) {
                    parse(bdCand.getBeanClassName(), holder.getBeanName());
                }
            }
        }
    }
    // 4.处理Import注解注册的bean，这一步只会将import注册的bean变为ConfigurationClass,不会变成BeanDefinition
    // 而是在loadBeanDefinitions()方法中变成BeanDefinition，再放入到BeanDefinitionMap中
    // 这里划重点
    // @import那里用到过？看这里
    // ···
    //  @Import(EnableConfigurationPropertiesImportSelector.class)
    //  public @interface EnableConfigurationProperties
    // ···
    // 也就是说，所有需要springboot自动装配的AutoConfiguration类，其实都是被@Import标注过的类
    // ！！但是，因为进到这个方法的时候，configCandidates是主类，除非在我们的主类的classpath下我们显示的声明了@import
    // 否则这个方法只会把标注有@EnableAutoConfiguration的引入到deferredimport里供后面真正处理的时候使用（即主类）
    // 当然后面调用processDeferredImportSelectors方法时，还是会重新进入这个方法
    processImports(configClass, sourceClass, getImports(sourceClass), true);

    // 5.处理@ImportResource注解引入的配置文件
    AnnotationAttributes importResource =
            AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);
    if (importResource != null) {
        String[] resources = importResource.getStringArray(&quot;locations&quot;);
        Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;);
        for (String resource : resources) {
            String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);
            configClass.addImportedResource(resolvedResource, readerClass);
        }
    }
    // 处理加了@Bean注解的方法
    Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);
    for (MethodMetadata methodMetadata : beanMethods) {
        configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));
    }
    // ... 省略部分代码
    // No superclass -&gt; processing is complete
    return null;
}
</code></pre>
<pre><code class="java">// 来了，真正处理spring boot的AutoConfiguration的方法来了
    private void processDeferredImportSelectors() {
        // deferredImports就是我们刚刚处理过的主类
        // Import注解的值是EnableAutoConfigurationImportSelector.class
        List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors;
        this.deferredImportSelectors = null;
        if (deferredImports == null) {
            return;
        }

        deferredImports.sort(DEFERRED_IMPORT_COMPARATOR);
        Map&lt;Object, DeferredImportSelectorGrouping&gt; groupings = new LinkedHashMap&lt;&gt;();
        Map&lt;AnnotationMetadata, ConfigurationClass&gt; configurationClasses = new HashMap&lt;&gt;();
        for (DeferredImportSelectorHolder deferredImport : deferredImports) {
            //以EnableAutoConfiguration注解为例，其Import注解的值为EnableAutoConfigurationImportSelector.class，
            //那么此处就是在调用EnableAutoConfigurationImportSelector的selectImports方法，返回了一个字符串数组
            //这里就是org.springframework.boot.autoconfigure.AutoConfigurationImportSelector$AutoConfigurationGroup
            Class&lt;? extends Group&gt; group = deferredImport.getImportSelector().getImportGroup();
            // 包装一个grouping，里面有beanfactory，bean classloader
            DeferredImportSelectorGrouping grouping = groupings.computeIfAbsent(
                    (group != null ? group : deferredImport),
                    key -&gt; new DeferredImportSelectorGrouping(createGroup(group)));
            // 把上面的deferredImports加进来
            grouping.add(deferredImport);
            configurationClasses.put(deferredImport.getConfigurationClass().getMetadata(),
                    deferredImport.getConfigurationClass());
        }
        for (DeferredImportSelectorGrouping grouping : groupings.values()) {
            // 这里划重点，这个getImports()得单独拿出来说
            // 详见下文
            grouping.getImports().forEach(entry -&gt; {
                ConfigurationClass configurationClass = configurationClasses.get(entry.getMetadata());
                try {
                    // 这个前文提到过了，用于把这些自动配置类加载到ConfigurationClass中
                    processImports(configurationClass, asSourceClass(configurationClass),
                            asSourceClasses(entry.getImportClassName()), false);
                }
                catch (BeanDefinitionStoreException ex) {
                    throw ex;
                }
                catch (Throwable ex) {
                    throw new BeanDefinitionStoreException(
                            &quot;Failed to process import candidates for configuration class [&quot; +
                            configurationClass.getMetadata().getClassName() + &quot;]&quot;, ex);
                }
            });
        }
    }
</code></pre>
<pre><code class="java">public Iterable&lt;Group.Entry&gt; getImports() {
        for (DeferredImportSelectorHolder deferredImport : this.deferredImports) {
            // getImports调用了AutoConfigurationImportSelector#process方法
            this.group.process(deferredImport.getConfigurationClass().getMetadata(),
                    deferredImport.getImportSelector());
        }
        return this.group.selectImports();
    }
</code></pre>
<pre><code class="java">public void process(AnnotationMetadata annotationMetadata,
                DeferredImportSelector deferredImportSelector) {
        // process再调用selectImports方法
        String[] imports = deferredImportSelector.selectImports(annotationMetadata);
        for (String importClassName : imports) {
            this.entries.put(importClassName, annotationMetadata);
        }
    }

public String[] selectImports(AnnotationMetadata annotationMetadata) {
        if (!isEnabled(annotationMetadata)) {
            return NO_IMPORTS;
        }
        AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader
                .loadMetadata(this.beanClassLoader);
        AnnotationAttributes attributes = getAttributes(annotationMetadata);
        // 重点在这里了selectImports通过AnnotationMetadata去拿真正需要自动加载的类
        List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata,
                attributes);
        // 删除重复的
        configurations = removeDuplicates(configurations);
        // 删除exclude的
        Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes);
        checkExcludedClasses(configurations, exclusions);
        configurations.removeAll(exclusions);
        // filter一下那些有condition注解的
        configurations = filter(configurations, autoConfigurationMetadata);
        fireAutoConfigurationImportEvents(configurations, exclusions);
        return StringUtils.toStringArray(configurations);
    }

protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata,
            AnnotationAttributes attributes) {
        // 到这里，我们终于进来了，去SpringFactoriesLoader里去拿configurations
        // 因为之前在最开始构造器阶段SpringFactoriesLoader就已经加载过了，这里就直接从cache里拿出来了
        List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(
                getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader());
        Assert.notEmpty(configurations,
                &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot;
                        + &quot;are using a custom packaging, make sure that file is correct.&quot;);
        return configurations;
    }
</code></pre>
<pre><code class="java">private void loadBeanDefinitionsForConfigurationClass(
        ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) {
    // 省略部分代码 ... 

    // 如果一个bean是通过@Import(ImportSelector)的方式添加到容器中的，那么此时configClass.isImported()返回的是true
    // 而且configClass的importedBy属性里面存储的就是需要注册为bean的类
    if (configClass.isImported()) {
        registerBeanDefinitionForImportedConfigurationClass(configClass);
    }
    // 判断当前的bean中是否含有@Bean注解的方法，如果有，需要把这些方法产生的bean放入到BeanDefinitionMap当中
    for (BeanMethod beanMethod : configClass.getBeanMethods()) {
        loadBeanDefinitionsForBeanMethod(beanMethod);
    }
    loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());
    // 如果bean上存在@Import注解，且import的是一个实现了ImportBeanDefinitionRegistrar接口,则执行ImportBeanDefinitionRegistrar的registerBeanDefinitions()方法
    loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());
}
</code></pre>
<pre><code class="java">public static void registerBeanPostProcessors(
        ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) {

    // 1.找出所有实现BeanPostProcessor接口的类
    String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);

    // Register BeanPostProcessorChecker that logs an info message when
    // a bean is created during BeanPostProcessor instantiation, i.e. when
    // a bean is not eligible for getting processed by all BeanPostProcessors.
    // BeanPostProcessor的目标计数
    int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;
    // 2.添加BeanPostProcessorChecker(主要用于记录信息)到beanFactory中
    beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));

    // Separate between BeanPostProcessors that implement PriorityOrdered,
    // Ordered, and the rest.
    // 3.定义不同的变量用于区分: 实现PriorityOrdered接口的BeanPostProcessor、实现Ordered接口的BeanPostProcessor、普通BeanPostProcessor
    // 3.1 priorityOrderedPostProcessors: 用于存放实现PriorityOrdered接口的BeanPostProcessor
    List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;();
    // 3.2 internalPostProcessors: 用于存放Spring内部的BeanPostProcessor
    List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;();
    // 3.3 orderedPostProcessorNames: 用于存放实现Ordered接口的BeanPostProcessor的beanName
    List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;();
    // 3.4 nonOrderedPostProcessorNames: 用于存放普通BeanPostProcessor的beanName
    List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;();
    // 4.遍历postProcessorNames, 将BeanPostProcessors按3.1 - 3.4定义的变量区分开
    for (String ppName : postProcessorNames) {
        if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {
            // 4.1 如果ppName对应的Bean实例实现了PriorityOrdered接口, 则拿到ppName对应的Bean实例并添加到priorityOrderedPostProcessors
            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
            priorityOrderedPostProcessors.add(pp);
            if (pp instanceof MergedBeanDefinitionPostProcessor) {
                // 4.2 如果ppName对应的Bean实例也实现了MergedBeanDefinitionPostProcessor接口,
                // 则将ppName对应的Bean实例添加到internalPostProcessors
                internalPostProcessors.add(pp);
            }
        }
        else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {
            // 4.3 如果ppName对应的Bean实例没有实现PriorityOrdered接口, 但是实现了Ordered接口, 则将ppName添加到orderedPostProcessorNames
            orderedPostProcessorNames.add(ppName);
        }
        else {
            // 4.4 否则, 将ppName添加到nonOrderedPostProcessorNames
            nonOrderedPostProcessorNames.add(ppName);
        }
    }

    // First, register the BeanPostProcessors that implement PriorityOrdered.
    // 5.首先, 注册实现PriorityOrdered接口的BeanPostProcessors
    // 5.1 对priorityOrderedPostProcessors进行排序
    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);
    // 5.2 注册priorityOrderedPostProcessors
    registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);

    // Next, register the BeanPostProcessors that implement Ordered.
    // 6.接下来, 注册实现Ordered接口的BeanPostProcessors
    List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;();
    for (String ppName : orderedPostProcessorNames) {
        // 6.1 拿到ppName对应的BeanPostProcessor实例对象
        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
        // 6.2 将ppName对应的BeanPostProcessor实例对象添加到orderedPostProcessors, 准备执行注册
        orderedPostProcessors.add(pp);
        if (pp instanceof MergedBeanDefinitionPostProcessor) {
            // 6.3 如果ppName对应的Bean实例也实现了MergedBeanDefinitionPostProcessor接口,
            // 则将ppName对应的Bean实例添加到internalPostProcessors
            internalPostProcessors.add(pp);
        }
    }
    // 6.4 对orderedPostProcessors进行排序
    sortPostProcessors(orderedPostProcessors, beanFactory);
    // 6.5 注册orderedPostProcessors
    registerBeanPostProcessors(beanFactory, orderedPostProcessors);

    // Now, register all regular BeanPostProcessors.
    // 7.注册所有常规的BeanPostProcessors（过程与6类似）
    List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;();
    for (String ppName : nonOrderedPostProcessorNames) {
        BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);
        nonOrderedPostProcessors.add(pp);
        if (pp instanceof MergedBeanDefinitionPostProcessor) {
            internalPostProcessors.add(pp);
        }
    }
    registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);

    // Finally, re-register all internal BeanPostProcessors.
    // 8.最后, 重新注册所有内部BeanPostProcessors（相当于内部的BeanPostProcessor会被移到处理器链的末尾）
    // 8.1 对internalPostProcessors进行排序
    sortPostProcessors(internalPostProcessors, beanFactory);
    // 8.2注册internalPostProcessors
    registerBeanPostProcessors(beanFactory, internalPostProcessors);

    // Re-register post-processor for detecting inner beans as ApplicationListeners,
    // moving it to the end of the processor chain (for picking up proxies etc).
    // 9.重新注册ApplicationListenerDetector（跟8类似，主要是为了移动到处理器链的末尾）
    beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));
}
</code></pre>
<pre><code class="java">protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {
    // Initialize conversion service for this context.
    // 1.初始化此上下文的转换服务
    if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp;
            beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) {
        beanFactory.setConversionService(
                beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));
    }
    // Register a default embedded value resolver if no bean post-processor
    // (such as a PropertyPlaceholderConfigurer bean) registered any before:
    // at this point, primarily for resolution in annotation attribute values.
    // 2.如果beanFactory之前没有注册嵌入值解析器，则注册默认的嵌入值解析器：主要用于注解属性值的解析。
    if (!beanFactory.hasEmbeddedValueResolver()) {
        beanFactory.addEmbeddedValueResolver(new StringValueResolver() {
            @Override
            public String resolveStringValue(String strVal) {
                return getEnvironment().resolvePlaceholders(strVal);
            }
        });
    }
    // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early.
    // 3.初始化LoadTimeWeaverAware Bean实例对象
    // 尽早初始化LoadTimeWeaverAware bean，以便尽早注册它们的转换器。
    String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);
    for (String weaverAwareName : weaverAwareNames) {
        getBean(weaverAwareName);
    }
    // Stop using the temporary ClassLoader for type matching.
    // 禁止使用临时类加载器进行类型匹配
    beanFactory.setTempClassLoader(null);
    // Allow for caching all bean definition metadata, not expecting further changes.
    // 4.冻结所有bean定义，注册的bean定义不会被修改或进一步后处理，因为马上要创建 Bean 实例对象了
    beanFactory.freezeConfiguration();
    // Instantiate all remaining (non-lazy-init) singletons.
    // 5.实例化所有剩余（非懒加载）单例对象
    beanFactory.preInstantiateSingletons();
}
</code></pre>
<pre><code class="java">@Override
public void preInstantiateSingletons() throws BeansException {
    if (this.logger.isDebugEnabled()) {
        this.logger.debug(&quot;Pre-instantiating singletons in &quot; + this);
    }
    // Iterate over a copy to allow for init methods which in turn register new bean definitions.
    // While this may not be part of the regular factory bootstrap, it does otherwise work fine.
    // 1.创建beanDefinitionNames的副本beanNames用于后续的遍历，以允许init等方法注册新的bean定义
    List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames);
    // Trigger initialization of all non-lazy singleton beans...
    // 2.遍历beanNames，触发所有非懒加载单例bean的初始化
    for (String beanName : beanNames) {
        // 3.获取beanName对应的MergedBeanDefinition
        // 实际就调用了getMergedBeanDefinition，详见下文
        RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);
        // 4.bd对应的Bean实例：不是抽象类 &amp;&amp; 是单例 &amp;&amp; 不是懒加载
        if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) {
            // 5.判断beanName对应的bean是否为FactoryBean
            if (isFactoryBean(beanName)) {
                // 5.1 通过beanName获取FactoryBean实例
                // 通过getBean(&amp;beanName)拿到的是FactoryBean本身；通过getBean(beanName)拿到的是FactoryBean创建的Bean实例
                final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName);
                // 5.2 判断这个FactoryBean是否希望急切的初始化
                boolean isEagerInit;
                if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) {
                    isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() {
                        @Override
                        public Boolean run() {
                            return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit();
                        }
                    }, getAccessControlContext());
                } else {
                    isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;
                            ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit());
                }
                if (isEagerInit) {
                    // 5.3 如果希望急切的初始化，则通过beanName获取bean实例
                    getBean(beanName);
                }
            } else {
                // 6.如果beanName对应的bean不是FactoryBean，只是普通Bean，通过beanName获取bean实例
                // 调用dogetbean
                getBean(beanName);
            }
        }
    }
    // Trigger post-initialization callback for all applicable beans...
    // 7.遍历beanNames，触发所有SmartInitializingSingleton的后初始化回调
    for (String beanName : beanNames) {
        // 7.1 拿到beanName对应的bean实例
        Object singletonInstance = getSingleton(beanName);
        // 7.2 判断singletonInstance是否实现了SmartInitializingSingleton接口
        if (singletonInstance instanceof SmartInitializingSingleton) {
            final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;
            // 7.3 触发SmartInitializingSingleton实现类的afterSingletonsInstantiated方法
            if (System.getSecurityManager() != null) {
                AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() {
                    @Override
                    public Object run() {
                        smartSingleton.afterSingletonsInstantiated();
                        return null;
                    }
                }, getAccessControlContext());
            } else {
                smartSingleton.afterSingletonsInstantiated();
            }
        }
    }
}
</code></pre>
<hr>
<p>一些需要知道的知识</p>
<h4 id="MergedBeanDefinition"><a href="#MergedBeanDefinition" class="headerlink" title="MergedBeanDefinition"></a>MergedBeanDefinition</h4><p>在之后的内容你可能会频繁的见到 “MergedBeanDefinition” 这个词，因此这边先稍微讲解一下，有助于你更好的理解。</p>
<p>MergedBeanDefinition：这个词其实不是一个官方词，但是很接近，该词主要是用来表示 “合并的 bean 定义”，因为每次都写 “合并的 bean 定义” 有点太绕口，因此我在之后的注释或解析中或统一使用 MergedBeanDefinition 来表示 “合并的 bean 定义”。</p>
<p>之所以称之为 “合并的”，是因为存在 “子定义” 和 “父定义” 的情况。对于一个 bean 定义来说，可能存在以下几种情况：</p>
<p>该 BeanDefinition 存在 “父定义”：首先使用 “父定义” 的参数构建一个 RootBeanDefinition，然后再使用该 BeanDefinition 的参数来进行覆盖。<br>该 BeanDefinition 不存在 “父定义”，并且该 BeanDefinition 的类型是 RootBeanDefinition：直接返回该 RootBeanDefinition 的一个克隆。<br>该 BeanDefinition 不存在 “父定义”，但是该 BeanDefinition 的类型不是 RootBeanDefinition：使用该 BeanDefinition 的参数构建一个 RootBeanDefinition。<br>之所以区分出2和3，是因为通常 BeanDefinition 在之前加载到 BeanFactory 中的时候，通常是被封装成 GenericBeanDefinition 或 ScannedGenericBeanDefinition，但是从这边之后 bean 的后续流程处理都是针对 RootBeanDefinition，因此在这边会统一将 BeanDefinition 转换成 RootBeanDefinition。</p>
<h4 id="FactoryBean"><a href="#FactoryBean" class="headerlink" title="FactoryBean"></a>FactoryBean</h4><p>一般情况下，Spring 通过反射机制利用 bean 的 class 属性指定实现类来实例化 bean。而 FactoryBean 是一种特殊的 bean，它是个工厂 bean，可以自己创建 bean 实例，如果一个类实现了 FactoryBean 接口，则该类可以自己定义创建实例对象的方法，只需要实现它的 getObject() 方法。</p>
<p>注：很多中间件都利用 FactoryBean 来进行扩展。</p>
<p>例如以下例子：</p>
<pre><code class="java">public class AppleFactoryBean implements FactoryBean&lt;Apple&gt; {
    @Override
    public Apple getObject() throws Exception {
        Apple apple = new Apple();
        apple.setName(&quot;bigApple&quot;);
        return apple;
    }
    @Override
    public Class&lt;?&gt; getObjectType() {
        return Apple.class;
    }
    @Override
    public boolean isSingleton() {
        return true;
    }
}
</code></pre>
<p>为了区分 “FactoryBean” 和 “FactoryBean 创建的 bean 实例”，Spring 使用了 “&amp;” 前缀。假设我们的 beanName 为 apple，则 getBean(“apple”) 获得的是 AppleFactoryBean 通过 getObject() 方法创建的 bean 实例；而 getBean(“&amp;apple”) 获得的是 AppleFactoryBean 本身。</p>
<hr>
<pre><code class="java">protected RootBeanDefinition getMergedBeanDefinition(
        String beanName, BeanDefinition bd, BeanDefinition containingBd)
        throws BeanDefinitionStoreException {
    // 1.加锁再进行操作
    synchronized (this.mergedBeanDefinitions) {
        // 用于存储bd的MergedBeanDefinition，也就是该方法的结果
        RootBeanDefinition mbd = null;
        // Check with full lock now in order to enforce the same merged instance.
        if (containingBd == null) {
            // 2.检查beanName对应的MergedBeanDefinition是否存在于缓存中
            mbd = this.mergedBeanDefinitions.get(beanName);
        }
        // 3.如果beanName对应的MergedBeanDefinition不存在于缓存中
        if (mbd == null) {
            if (bd.getParentName() == null) {
                // 4.如果bd的parentName为空，代表bd没有父定义，无需与父定义进行合并操作，
                // 也就是bd的MergedBeanDefinition就是bd本身（可能需要转成RootBeanDefinition）
                // Use copy of given root bean definition.
                if (bd instanceof RootBeanDefinition) {
                    // 4.1 如果bd的类型为RootBeanDefinition，则bd的MergedBeanDefinition就是bd本身，则直接克隆一个副本
                    mbd = ((RootBeanDefinition) bd).cloneBeanDefinition();
                } else {
                    // 4.2 否则，将bd作为参数，构建一个RootBeanDefinition。
                    // 正常使用下，BeanDefinition在被加载后是GenericBeanDefinition或ScannedGenericBeanDefinition
                    mbd = new RootBeanDefinition(bd);
                }
            } else {
                // 5.否则，bd存在父定义，需要与父定义合并
                // Child bean definition: needs to be merged with parent.
                BeanDefinition pbd;
                try {
                    // 5.1 获取父定义的beanName
                    String parentBeanName = transformedBeanName(bd.getParentName());
                    // 5.2 如果父定义的beanName与该bean的beanName不同
                    if (!beanName.equals(parentBeanName)) {
                        // 5.3 获取父定义的MergedBeanDefinition（因为父定义也可能有父定义，也就是bd的爷爷定义...）
                        pbd = getMergedBeanDefinition(parentBeanName);
                    } else {
                        // 5.4 如果父定义的beanName与bd的beanName相同，则拿到父BeanFactory，
                        // 只有在存在父BeanFactory的情况下，才允许父定义beanName与自己相同，否则就是将自己设置为父定义
                        BeanFactory parent = getParentBeanFactory();
                        if (parent instanceof ConfigurableBeanFactory) {
                            // 5.5 如果父BeanFactory是ConfigurableBeanFactory，则通过父BeanFactory获取父定义的MergedBeanDefinition
                            pbd = ((ConfigurableBeanFactory) parent).getMergedBeanDefinition(parentBeanName);
                        } else {
                            // 5.6 如果父BeanFactory不是ConfigurableBeanFactory，则抛异常
                            throw new NoSuchBeanDefinitionException(parentBeanName,
                                    &quot;Parent name &#39;&quot; + parentBeanName + &quot;&#39; is equal to bean name &#39;&quot; + beanName +
                                            &quot;&#39;: cannot be resolved without an AbstractBeanFactory parent&quot;);
                        }
                    }
                } catch (NoSuchBeanDefinitionException ex) {
                    throw new BeanDefinitionStoreException(bd.getResourceDescription(), beanName,
                            &quot;Could not resolve parent bean definition &#39;&quot; + bd.getParentName() + &quot;&#39;&quot;, ex);
                }
                // Deep copy with overridden values.
                // 5.7 使用父定义pbd构建一个新的RootBeanDefinition对象（深拷贝）
                mbd = new RootBeanDefinition(pbd);
                // 5.8 使用bd覆盖父定义
                mbd.overrideFrom(bd);
            }
            // Set default singleton scope, if not configured before.
            // 6.如果没有配置scope，则设置成默认的singleton
            if (!StringUtils.hasLength(mbd.getScope())) {
                mbd.setScope(RootBeanDefinition.SCOPE_SINGLETON);
            }
            // A bean contained in a non-singleton bean cannot be a singleton itself.
            // Let&#39;s correct this on the fly here, since this might be the result of
            // parent-child merging for the outer bean, in which case the original inner bean
            // definition will not have inherited the merged outer bean&#39;s singleton status.
            // 7.如果containingBd不为空 &amp;&amp; containingBd不为singleton &amp;&amp; mbd为singleton，则将mdb的scope设置为containingBd的scope
            if (containingBd != null &amp;&amp; !containingBd.isSingleton() &amp;&amp; mbd.isSingleton()) {
                mbd.setScope(containingBd.getScope());
            }
            // Cache the merged bean definition for the time being
            // (it might still get re-merged later on in order to pick up metadata changes)
            // 8.将beanName与mbd放到mergedBeanDefinitions缓存，以便之后可以直接使用
            if (containingBd == null &amp;&amp; isCacheBeanMetadata()) {
                this.mergedBeanDefinitions.put(beanName, mbd);
            }
        }
        // 9.返回MergedBeanDefinition
        return mbd;
    }
}
</code></pre>
<hr>
<p>这边引入了一个 “父 BeanFactory” 的概念，稍微解释下。</p>
<p>父 BeanFactory</p>
<p>在 Spring 中可能存在多个 BeanFactory，多个 BeanFactory 可能存在 “父工厂” 与 “子工厂” 的关系。最常见的例子就是：Spring MVC 的 BeanFactory 和 Spring 的 BeanFactory，通常情况下，Spring 的 BeanFactory 是 “父工厂”，Spring MVC 的 BeanFactory 是 “子工厂”，在 Spring 中，子工厂可以使用父工厂的 BeanDefinition，因而，如果在当前 BeanFactory 中找不到，而又存在父工厂，则会去父工厂中查找。</p>
<hr>
<pre><code class="java">public boolean isFactoryBean(String name) throws NoSuchBeanDefinitionException {
    // 1.拿到真正的beanName（去掉&amp;前缀、解析别名）
    String beanName = transformedBeanName(name);
    // 2.尝试从缓存获取Bean实例对象
    Object beanInstance = getSingleton(beanName, false);
    if (beanInstance != null) {
        // 3.beanInstance存在，则直接判断类型是否为FactoryBean
        return (beanInstance instanceof FactoryBean);
    } else if (containsSingleton(beanName)) {
        // 4.如果beanInstance为null，并且beanName在单例对象缓存中，则代表beanName对应的单例对象为空对象，返回false
        // null instance registered
        return false;
    }
    // No singleton instance found -&gt; check bean definition.
    if (!containsBeanDefinition(beanName) &amp;&amp; getParentBeanFactory() instanceof ConfigurableBeanFactory) {
        // 5.如果缓存中不存在此beanName &amp;&amp; 父beanFactory是ConfigurableBeanFactory，则调用父BeanFactory判断是否为FactoryBean
        // No bean definition found in this factory -&gt; delegate to parent.
        return ((ConfigurableBeanFactory) getParentBeanFactory()).isFactoryBean(name);
    }
    // 6.通过MergedBeanDefinition来检查beanName对应的Bean是否为FactoryBean
    return isFactoryBean(beanName, getMergedLocalBeanDefinition(beanName));
}
</code></pre>
<pre><code class="java">protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType,
                          @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException {

    // 如果这个 name 是 FactoryBean 的beanName (&amp;+beanName),就删除&amp; , 返回beanName ,传入的name也可以是别名,也需要做转换
    // 注意 beanName 和 name 变量的区别,beanName是经过处理的,经过处理的beanName就直接对应singletonObjects中的key
    final String beanName = transformedBeanName(name);
    Object bean;

    // Eagerly check singleton cache for manually registered singletons.
    // 根据beanName尝试从singletonObjects获取Bean
    // 获取不到则再尝试从earlySingletonObjects,singletonFactories 从获取Bean
    // 这段代码和解决循环依赖有关
    Object sharedInstance = getSingleton(beanName);
    // 第一次进入sharedInstance肯定为null
    if (sharedInstance != null &amp;&amp; args == null) {
        if (logger.isTraceEnabled()) {
            if (isSingletonCurrentlyInCreation(beanName)) {
                logger.trace(&quot;Returning eagerly cached instance of singleton bean &#39;&quot; + beanName +
                        &quot;&#39; that is not fully initialized yet - a consequence of a circular reference&quot;);
            } else {
                logger.trace(&quot;Returning cached instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);
            }
        }
        // 如果sharedInstance不为null,也就是非第一次进入
        // 为什么要调用 getObjectForBeanInstance 方法,判断当前Bean是不是FactoryBean,如果是,那么要不要调用getObject方法
        // 因为传入的name变量如果是(&amp;+beanName),那么beanName变量就是(beanName),也就是说,程序在这里要返回FactoryBean
        // 如果传入的name变量(beanName),那么beanName变量也是(beanName),但是,之前获取的sharedInstance可能是FactoryBean,需要通过sharedInstance来获取对应的Bean
        // 如果传入的name变量(beanName),那么beanName变量也是(beanName),获取的sharedInstance就是对应的Bean的话,就直接返回Bean
        bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);
    } else {
        // Fail if we&#39;re already creating this bean instance:
        // We&#39;re assumably within a circular reference.
        // 判断是否循环依赖
        if (isPrototypeCurrentlyInCreation(beanName)) {
            throw new BeanCurrentlyInCreationException(beanName);
        }

        // Check if bean definition exists in this factory.
        // 获取父BeanFactory,一般情况下,父BeanFactory为null,如果存在父BeanFactory,就先去父级容器去查找
        BeanFactory parentBeanFactory = getParentBeanFactory();
        if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) {
            // Not found -&gt; check parent.
            String nameToLookup = originalBeanName(name);
            if (parentBeanFactory instanceof AbstractBeanFactory) {
                return ((AbstractBeanFactory) parentBeanFactory).doGetBean(
                        nameToLookup, requiredType, args, typeCheckOnly);
            } else if (args != null) {
                // Delegation to parent with explicit args.
                return (T) parentBeanFactory.getBean(nameToLookup, args);
            } else if (requiredType != null) {
                // No args -&gt; delegate to standard getBean method.
                return parentBeanFactory.getBean(nameToLookup, requiredType);
            } else {
                return (T) parentBeanFactory.getBean(nameToLookup);
            }
        }

        // 创建的Bean是否需要进行类型验证,一般情况下都不需要
        if (!typeCheckOnly) {
            // 标记 bean 已经被创建
            markBeanAsCreated(beanName);
        }

        try {
            // 获取其父类Bean定义,子类合并父类公共属性
            final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);
            checkMergedBeanDefinition(mbd, beanName, args);

            // Guarantee initialization of beans that the current bean depends on.
            // 获取当前Bean依赖的Bean的名称 ,@DependsOn
            String[] dependsOn = mbd.getDependsOn();
            if (dependsOn != null) {
                for (String dep : dependsOn) {
                    if (isDependent(beanName, dep)) {
                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                                &quot;Circular depends-on relationship between &#39;&quot; + beanName + &quot;&#39; and &#39;&quot; + dep + &quot;&#39;&quot;);
                    }
                    // 如果当前Bean依赖其他Bean,把被依赖Bean注册给当前Bean
                    registerDependentBean(dep, beanName);
                    try {
                        // 先去创建所依赖的Bean
                        getBean(dep);
                    } catch (NoSuchBeanDefinitionException ex) {
                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                                &quot;&#39;&quot; + beanName + &quot;&#39; depends on missing bean &#39;&quot; + dep + &quot;&#39;&quot;, ex);
                    }
                }
            }

            // Create bean instance.
            if (mbd.isSingleton()) {
                // 创建单例Bean
                sharedInstance = getSingleton(beanName, () -&gt; {
                    try {
                        return createBean(beanName, mbd, args);
                    } catch (BeansException ex) {
                        // Explicitly remove instance from singleton cache: It might have been put there
                        // eagerly by the creation process, to allow for circular reference resolution.
                        // Also remove any beans that received a temporary reference to the bean.
                        destroySingleton(beanName);
                        throw ex;
                    }
                });
                bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);
            } else if (mbd.isPrototype()) {
                // It&#39;s a prototype -&gt; create a new instance.
                // 创建prototype Bean,每次都会创建一个新的对象
                Object prototypeInstance = null;
                try {
                    // 回调beforePrototypeCreation方法，注册当前创建的原型对象
                    beforePrototypeCreation(beanName);
                    // 创建对象
                    prototypeInstance = createBean(beanName, mbd, args);
                } finally {
                    // 回调 afterPrototypeCreation 方法，告诉容器该Bean的原型对象不再创建
                    afterPrototypeCreation(beanName);
                }
                bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);
            } else {
                // 如果既不是单例Bean,也不是prototype,则获取其Scope
                String scopeName = mbd.getScope();
                final Scope scope = this.scopes.get(scopeName);
                if (scope == null) {
                    throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + scopeName + &quot;&#39;&quot;);
                }
                try {
                    // 创建对象
                    Object scopedInstance = scope.get(beanName, () -&gt; {
                        beforePrototypeCreation(beanName);
                        try {
                            return createBean(beanName, mbd, args);
                        } finally {
                            afterPrototypeCreation(beanName);
                        }
                    });
                    bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);
                } catch (IllegalStateException ex) {
                    throw new BeanCreationException(beanName,
                            &quot;Scope &#39;&quot; + scopeName + &quot;&#39; is not active for the current thread; consider &quot; +
                                    &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;,
                            ex);
                }
            }
        } catch (BeansException ex) {
            cleanupAfterBeanCreationFailure(beanName);
            throw ex;
        }
    }

    // Check if required type matches the type of the actual bean instance.
    // 对创建的Bean进行类型检查
    if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) {
        try {
            T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType);
            if (convertedBean == null) {
                throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());
            }
            return convertedBean;
        } catch (TypeMismatchException ex) {
            if (logger.isTraceEnabled()) {
                logger.trace(&quot;Failed to convert bean &#39;&quot; + name + &quot;&#39; to required type &#39;&quot; +
                        ClassUtils.getQualifiedName(requiredType) + &quot;&#39;&quot;, ex);
            }
            throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());
        }
    }
    return (T) bean;
}
</code></pre>
<pre><code class="java">public Object getSingleton(String beanName) {
    return getSingleton(beanName, true);
}

//getSingleton(beanName, true);源码
@Nullable
protected Object getSingleton(String beanName, boolean allowEarlyReference) {
    // singletonObjects 就是Spring内部用来存放单例Bean的对象池, key为beanName，value为Bean
    Object singletonObject = this.singletonObjects.get(beanName);
    // singletonsCurrentlyInCreation 存放了当前正在创建的bean的BeanName
    if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {
        synchronized (this.singletonObjects) {
            // earlySingletonObjects 是早期单例Bean的缓存池, 此时Bean已经被创建(newInstance),但是还没有完成初始化
            // key为beanName，value为Bean
            singletonObject = this.earlySingletonObjects.get(beanName);
            // 是否允许早期依赖
            if (singletonObject == null &amp;&amp; allowEarlyReference) {
                //singletonFactories 单例工厂的缓存,key为beanName,value 为ObjectFactory
                ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);
                if (singletonFactory != null) {
                    //获取早期Bean
                    singletonObject = singletonFactory.getObject();
                    //将早期Bean放到earlySingletonObjects中
                    this.earlySingletonObjects.put(beanName, singletonObject);
                    this.singletonFactories.remove(beanName);
                }
            }
        }
    }
    return singletonObject;
}
</code></pre>
<pre><code class="java">protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException {
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Creating instance of bean &#39;&quot; + beanName + &quot;&#39;&quot;);
        }
        // 确保此时实际解析了bean类
        resolveBeanClass(mbd, beanName);
        // Prepare method overrides.
        try {
            mbd.prepareMethodOverrides();
        }
        catch (BeanDefinitionValidationException ex) {
            throw new BeanDefinitionStoreException(mbd.getResourceDescription(),
                    beanName, &quot;Validation of method overrides failed&quot;, ex);
        }

        try {
            // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.
        //如果bean实现了实例化前处理器接口的，则需要在实例化之前调用这个方法
      //bean的生命周期的中实现了InstantiationAwareBeanPostProcessor会在这里调用实现的postProcessBeforeInstantiation
            Object bean = resolveBeforeInstantiation(beanName, mbd);
            if (bean != null) {
                return bean;
            }
        }
        catch (Throwable ex) {
            throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                    &quot;BeanPostProcessor before instantiation of bean failed&quot;, ex);
        }
        Object beanInstance = doCreateBean(beanName, mbd, args);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Finished creating instance of bean &#39;&quot; + beanName + &quot;&#39;&quot;);
        }
        return beanInstance;
    }
</code></pre>
<pre><code class="java">protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) {
        // Instantiate the bean.
        //BeanWrapper提供设置和获取属性值（单独或批量），获取属性描述符和查询属性以确定它们是可读还是可写的功能
        BeanWrapper instanceWrapper = null;
        //如果RootBeanDefinition是单例的，则移除未完成的FactoryBean实例的缓存
        if (mbd.isSingleton()) {
            instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);
        }
        if (instanceWrapper == null) {
            //创建bean实例
            //详见下文
            //这里会在此方法里直接处理构造器的bean依赖，并实例化这些bean
            instanceWrapper = createBeanInstance(beanName, mbd, args);
        }
      //获取BeanWrapper中封装的Object对象，其实就是bean对象的实例
        final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null);
    //获取BeanWrapper中封装的bean的Class
        Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null);

        // Allow post-processors to modify the merged bean definition.
        synchronized (mbd.postProcessingLock) {
            if (!mbd.postProcessed) {
          //bean 的生命周期之一。如果实现了MergedBeanDefinitionPostProcessor会在这里调用postProcessMergedBeanDefinition方法
                applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);
                mbd.postProcessed = true;
            }
        }

        // Eagerly cache singletons to be able to resolve circular references
        // even when triggered by lifecycle interfaces like BeanFactoryAware.
              //如果RootBeanDefinition是单例的，并且开启了自动尝试解析bean之间的循环引用，并且当前bean正在创建中，则说明这个bean需要被加入到缓存的单例bean集合中
        boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;
                isSingletonCurrentlyInCreation(beanName));
        if (earlySingletonExposure) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;Eagerly caching bean &#39;&quot; + beanName +
                        &quot;&#39; to allow for resolving potential circular references&quot;);
            }
            /**
             * addSingletonFactory会将beanName和ObjectFactory对象作为键值对保存到缓存的单例集合中
             * singletonObjects： 单例对象的缓存 ConcurrentHashMap
             * singletonFactories：单例工厂的缓存 HashMap
             * earlySingletonObjects： 早期单例对象的缓存  HashMap
             * registeredSingletons： 一组已经注册的单例，按注册顺序排序   LinkedHashSet
             */
            addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() {
                public Object getObject() throws BeansException {
                    // 处理循环依赖用，详见下文
                    return getEarlyBeanReference(beanName, mbd, bean);
                }
            });
        }
        // Initialize the bean instance.
        Object exposedObject = bean;

        try {
            //进行属性填充
            // 详见下文
            // 这里会处理property（setter方法）的依赖
            populateBean(beanName, mbd, instanceWrapper);
            if (exposedObject != null) {
                //初始化给定的bean实例，应用工厂回调以及init方法和bean后处理器
                //详见下文
                exposedObject = initializeBean(beanName, exposedObject, mbd);
            }
        }
        catch (Throwable ex) {
            if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) {
                throw (BeanCreationException) ex;
            }
            else {
                throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex);
            }
        }
    //如果单例bean已经缓存了，则直接获取 
        if (earlySingletonExposure) {
            Object earlySingletonReference = getSingleton(beanName, false);
            if (earlySingletonReference != null) {
                if (exposedObject == bean) {
                    exposedObject = earlySingletonReference;
                }
//如果不允许在循环引用的情况下使用注入原始bean实例（即使注入的bean最终被包装），并且依赖的bean列表中存在需要创建bean。这时候就说明存在循环依赖
                else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) {
                    //根据beanName获取所有依赖的bean的beanName
                    String[] dependentBeans = getDependentBeans(beanName);
                    Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length);
                    for (String dependentBean : dependentBeans) {
                        //删除存在循环依赖的bean    
                        if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) {
                            actualDependentBeans.add(dependentBean);
                        }
                    }
                    if (!actualDependentBeans.isEmpty()) {
                        throw new BeanCurrentlyInCreationException(beanName,
                                &quot;Bean with name &#39;&quot; + beanName + &quot;&#39; has been injected into other beans [&quot; +
                                StringUtils.collectionToCommaDelimitedString(actualDependentBeans) +
                                &quot;] in its raw version as part of a circular reference, but has eventually been &quot; +
                                &quot;wrapped. This means that said other beans do not use the final version of the &quot; +
                                &quot;bean. This is often the result of over-eager type matching - consider using &quot; +
                                &quot;&#39;getBeanNamesOfType&#39; with the &#39;allowEagerInit&#39; flag turned off, for example.&quot;);
                    }
                }
            }
        }

        // Register bean as disposable.
        try {
                        //将给定的bean添加到此一次性Bean列表中，这个列表中的bean在Spring关闭的时候会查询里面的bean，并调用实现的销毁方法（包含实现了DisposableBean接口的方法和自定义的destory方法），满足其中一个条件
            // 1.实现了DisposableBean接口
            //2.自定义了destroy方法
            //3.实现了AutoCloseable接口
            registerDisposableBeanIfNecessary(beanName, bean, mbd);
        }
        catch (BeanDefinitionValidationException ex) {
            throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex);
        }

        return exposedObject;
    }
</code></pre>
<pre><code class="java">  protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) {
        // Make sure bean class is actually resolved at this point.
        //获取RootBeanDefinition的Class属性
        Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);
        //如果bean的类修饰符不是public则报错
        if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) {
            throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                    &quot;Bean class isn&#39;t public, and non-public access not allowed: &quot; + beanClass.getName());
        }
        //查看RootBeanDefinition的factor-method属性是不是空的，不为空，说明bean 
        // 的实现要通过先实例化对应的factoryBean然后调用factoryMethod方法实现，或者直接调用静态的factoryMethod方法
        if (mbd.getFactoryMethodName() != null)  {
            return instantiateUsingFactoryMethod(beanName, mbd, args);
        }

        // Shortcut when re-creating the same bean...
         //重新创建同一个bean时相关的判断条件
        boolean resolved = false;
        boolean autowireNecessary = false;
        if (args == null) {
            synchronized (mbd.constructorArgumentLock) {
    //如果缓存的已解析的构造函数或工厂方法对象不为空，则说明这是重新创建同一个bean
                if (mbd.resolvedConstructorOrFactoryMethod != null) {
                    resolved = true;
                    autowireNecessary = mbd.constructorArgumentsResolved;
                }
            }
        }
  //如果是重新创建，就直接创建
        if (resolved) {
        //如果构造函数参数标记是已解析，就直接进行构造，否则重新解析然后创建
            if (autowireNecessary) {
                return autowireConstructor(beanName, mbd, null, null);
            }
            else {
                //使用给出的构造器来创建bean并封装到BeanWrapperImpl中，这个方法在autowireConstructor也有用到
                return instantiateBean(beanName, mbd);
            }
        }

        // Need to determine the constructor...
        //如果不是重新创建的bean，需要确定要用于给定bean的候选构造函数，检查所有已注册的构造函数
        //bean 的生命周期之一，如果实现了SmartInstantiationAwareBeanPostProcessor接口，会在这里调用determineCandidateConstructors方法
        // 这里其实是调用了AutowiredAnnotationBeanPostProcessor的determineConstructorsFromBeanPostProcessors方法
        // 然后进行autowireConstructor
        Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);
        if (ctors != null ||
                mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR ||
                mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args))  {
                    // 真正处理循环依赖的方法，详见下文
            return autowireConstructor(beanName, mbd, ctors, args);
        }

        // No special handling: simply use no-arg constructor.
          //没有特殊处理：只需使用no-arg构造函数
        return instantiateBean(beanName, mbd);
    }
</code></pre>
<pre><code class="java">    public BeanWrapper autowireConstructor(
            final String beanName, final RootBeanDefinition mbd, Constructor&lt;?&gt;[] chosenCtors, final Object[] explicitArgs) {
        //先实例化一个BeanWrapperImpl类对象
        BeanWrapperImpl bw = new BeanWrapperImpl();
        //这里的beanFactory是初始化ConstructorResolver构造器的时候在AbstractAutowireCapableBeanFactory类的autowireConstructor方法中传进来的就是AbstractAutowireCapableBeanFactory
        this.beanFactory.initBeanWrapper(bw);

        Constructor&lt;?&gt; constructorToUse = null;
        ArgumentsHolder argsHolderToUse = null;
        Object[] argsToUse = null;
        //如果构造参数不为空就直接使用
        if (explicitArgs != null) {
            argsToUse = explicitArgs;
        }
        else {
            Object[] argsToResolve = null;
            synchronized (mbd.constructorArgumentLock) {
                //获取已缓存解析的构造函数或工厂方法（resolvedConstructorOrFactoryMethod----用于缓存已解析的构造函数或工厂方法）
                constructorToUse = (Constructor&lt;?&gt;) mbd.resolvedConstructorOrFactoryMethod;
                //如果缓存不为空，并且构造参数已经解析缓存了，(constructorArgumentsResolved为包可见，用于表示构造参数状态是否已经解析)
                if (constructorToUse != null &amp;&amp; mbd.constructorArgumentsResolved) {
                    // Found a cached constructor...
                    //获取缓存的构造函数（resolvedConstructorArguments---用于缓存完全解析的构造函数参数的包可见字段）
                    argsToUse = mbd.resolvedConstructorArguments;
                    if (argsToUse == null) {
                        //如果获取到的缓存的构造参数是空，就获取缓存的部分准备的构造函数参数（preparedConstructorArguments---用于缓存部分准备的构造函数参数的包可见字段）
                        argsToResolve = mbd.preparedConstructorArguments;
                    }
                }
            }
            //如果缓存的参数不是空，就进行解析，解析时会对argsToResolve中的每个的类型进行转化，也是一个复杂的逻辑
            if (argsToResolve != null) {
                argsToUse = resolvePreparedArguments(beanName, mbd, bw, constructorToUse, argsToResolve);
            }
        }
        //如果缓存的构造器不存在，就说明没有bean进行过解析，需要去关联对应的bean的构造器
        if (constructorToUse == null) {
            // Need to resolve the constructor.
            //如果传入的构造器不是空的，那么就获取bean的注入模式，如果是空就按照构造器注入方式注入
            boolean autowiring = (chosenCtors != null ||
                    //getResolvedAutowireMode方法逻辑是，如果是自适应注入方法就看有没有无参构造器，如果存在就按照type类型注入，如果不存在就按照构造器方式注入，如果没有设置注入方式就不注入
                    mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR);
            ConstructorArgumentValues resolvedValues = null;

            int minNrOfArgs;
            //传入的构造参数不为空，这种构造器最小参数个数个传入的个数
            if (explicitArgs != null) {
                minNrOfArgs = explicitArgs.length;
            }
            else {
                //如果传的构造参数是空的，则从RootBeanDefinition中获取构造器参数，并解析对应的构造参数然后添加到ConstructorArgumentValues中
                ConstructorArgumentValues cargs = mbd.getConstructorArgumentValues();
                resolvedValues = new ConstructorArgumentValues();
                minNrOfArgs = resolveConstructorArguments(beanName, mbd, bw, cargs, resolvedValues);
            }

            // Take specified constructors, if any.
            Constructor&lt;?&gt;[] candidates = chosenCtors;
            //如果传入的构造器为空，则获取bean的Class对象，然后根据bean是不是public修饰的来按照不同的方式获取所有的构造器
            if (candidates == null) {
                Class&lt;?&gt; beanClass = mbd.getBeanClass();
                try {
                    //getDeclaredConstructors返回所有的构造器（包括public和private修饰的），getConstructors返回public修饰的
                    candidates = (mbd.isNonPublicAccessAllowed() ?
                            beanClass.getDeclaredConstructors() : beanClass.getConstructors());
                }
                catch (Throwable ex) {
                    throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                            &quot;Resolution of declared constructors on bean Class [&quot; + beanClass.getName() +
                            &quot;] from ClassLoader [&quot; + beanClass.getClassLoader() + &quot;] failed&quot;, ex);
                }
            }
            //按照访问方式和数量对构造器进行排序；public&gt;protect&gt;private，在同为public时构造器多的排在前面
            AutowireUtils.sortConstructors(candidates);
            int minTypeDiffWeight = Integer.MAX_VALUE;
            Set&lt;Constructor&lt;?&gt;&gt; ambiguousConstructors = null;
            List&lt;Exception&gt; causes = null;
            //便利排序后的构造器
            for (int i = 0; i &lt; candidates.length; i++) {
                Constructor&lt;?&gt; candidate = candidates[i];
                Class&lt;?&gt;[] paramTypes = candidate.getParameterTypes();
                //按照参数个数和构造器的参数类型个数进行比较，如果相等就用这个构造器
                if (constructorToUse != null &amp;&amp; argsToUse.length &gt; paramTypes.length) {
                    // Already found greedy constructor that can be satisfied -&gt;
                    // do not look any further, there are only less greedy constructors left.
                    break;
                }
                if (paramTypes.length &lt; minNrOfArgs) {
                    continue;
                }

                ArgumentsHolder argsHolder;
                //没有找到合适的构造器就进行下面的步骤
                //如果ConstructorArgumentValues不为空就说明有构造参数
                if (resolvedValues != null) {
                    try {
                        String[] paramNames = null;
                        //检查给定的“java.beans.ConstructorProperties”类型的参数能否被加载，“java.beans.ConstructorProperties”是ConstructorResolver的一个静态常量，是一个Java标签的路径
                        if (constructorPropertiesAnnotationAvailable) {
                            //获取有ConstructorProperties标签的参数，因为上面有判断是否可以被加载，所这里直接能够拿到贴了标签的构造参数名称
                            //ConstructorProperties标签的作用=======》构造函数上的注释，显示该构造函数的参数如何与构造对象的getter方法相对应
                            paramNames = ConstructorPropertiesChecker.evaluate(candidate, paramTypes.length);
                        }
                        //如果paramNames是空，则说明参数没有被获取到，则在beanFactory中获取用于获取方法参数的ParameterNameDiscoverer对象，然后获取参数名称
                        if (paramNames == null) {
                            ParameterNameDiscoverer pnd = this.beanFactory.getParameterNameDiscoverer();
                            if (pnd != null) {
                                paramNames = pnd.getParameterNames(candidate);
                            }
                        }
                        //根据获取到的参数名和已经查到的构造参数和构造参数类型来创建用户创建构造器用的构造参数数组，这个数组中包含了原始的参数列表和构造后的参数列表，用来对比用
                        //划重点，这里会调用resolveAutowiredArgument方法
                        //进而调用DefaultListableBeanFactory#resolveDependency方法
                        //进而调用doResolveDependency方法
                        //进而调用DependencyDescriptor#resolveCandidate方法
                        //进而调用getBean--&gt;doGetBean来完成一个循环调用的链
                        //以保证最顶层的bean实例化之前，他所有依赖链上的bean都已经实例化完毕
                        //此处极为复杂！！
                        argsHolder = createArgumentArray(
                                beanName, mbd, resolvedValues, bw, paramTypes, paramNames, candidate, autowiring);
                    }
                    catch (UnsatisfiedDependencyException ex) {
                        if (this.beanFactory.logger.isTraceEnabled()) {
                            this.beanFactory.logger.trace(
                                    &quot;Ignoring constructor [&quot; + candidate + &quot;] of bean &#39;&quot; + beanName + &quot;&#39;: &quot; + ex);
                        }
                        if (i == candidates.length - 1 &amp;&amp; constructorToUse == null) {
                            if (causes != null) {
                                for (Exception cause : causes) {
                                    this.beanFactory.onSuppressedException(cause);
                                }
                            }
                            throw ex;
                        }
                        else {
                            // Swallow and try next constructor.
                            if (causes == null) {
                                causes = new LinkedList&lt;Exception&gt;();
                            }
                            causes.add(ex);
                            continue;
                        }
                    }
                }
                else {
                    // Explicit arguments given -&gt; arguments length must match exactly.
                    if (paramTypes.length != explicitArgs.length) {
                        continue;
                    }
                    argsHolder = new ArgumentsHolder(explicitArgs);
                }
                //如果是宽松的构造策略，则对比spring构造的参数数组的类型和获取到的构造器参数的参数类型进行对比，返回不同的个数
                //如果是严格的构造策略，则检查能否将构造的参数数组赋值到构造器参数的参数列表中
                int typeDiffWeight = (mbd.isLenientConstructorResolution() ?
                        argsHolder.getTypeDifferenceWeight(paramTypes) : argsHolder.getAssignabilityWeight(paramTypes));
                // Choose this constructor if it represents the closest match.
                if (typeDiffWeight &lt; minTypeDiffWeight) {
                    constructorToUse = candidate;
                    argsHolderToUse = argsHolder;
                    argsToUse = argsHolder.arguments;
                    minTypeDiffWeight = typeDiffWeight;
                    ambiguousConstructors = null;
                }
                else if (constructorToUse != null &amp;&amp; typeDiffWeight == minTypeDiffWeight) {
                    if (ambiguousConstructors == null) {
                        ambiguousConstructors = new LinkedHashSet&lt;Constructor&lt;?&gt;&gt;();
                        ambiguousConstructors.add(constructorToUse);
                    }
                    ambiguousConstructors.add(candidate);
                }
            }

            if (constructorToUse == null) {
                throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                        &quot;Could not resolve matching constructor &quot; +
                        &quot;(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities)&quot;);
            }
            else if (ambiguousConstructors != null &amp;&amp; !mbd.isLenientConstructorResolution()) {
                throw new BeanCreationException(mbd.getResourceDescription(), beanName,
                        &quot;Ambiguous constructor matches found in bean &#39;&quot; + beanName + &quot;&#39; &quot; +
                        &quot;(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities): &quot; +
                        ambiguousConstructors);
            }

            if (explicitArgs == null) {
                argsHolderToUse.storeCache(mbd, constructorToUse);
            }
        }

        try {
            Object beanInstance;
            //下面步骤都是一样的，用上面得到的构造器（无论是从bean对象中获取的还是spring自己构建的）和参数来反射创建bean实例，并放到BeanWrapperImpl对象中然后返回
            if (System.getSecurityManager() != null) {
                final Constructor&lt;?&gt; ctorToUse = constructorToUse;
                final Object[] argumentsToUse = argsToUse;
                beanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() {
                    public Object run() {
                        return beanFactory.getInstantiationStrategy().instantiate(
                                mbd, beanName, beanFactory, ctorToUse, argumentsToUse);
                    }
                }, beanFactory.getAccessControlContext());
            }
            else {
                beanInstance = this.beanFactory.getInstantiationStrategy().instantiate(
                        mbd, beanName, this.beanFactory, constructorToUse, argsToUse);
            }

            bw.setWrappedInstance(beanInstance);
            return bw;
        }
        catch (Throwable ex) {
            throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Instantiation of bean failed&quot;, ex);
        }
    }
</code></pre>
<pre><code class="java">    protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
        Object exposedObject = bean;
        //bean不为空，并且RootBeanDefinition是程序自己定义的，并且实现了InstantiationAwareBeanPostProcessors（一个bean实例化过程中调用的类）
        if (bean != null &amp;&amp; !mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {
            for (BeanPostProcessor bp : getBeanPostProcessors()) {
                if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {
                    SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;
                    //获取早期访问指定bean的引用，通常用于解析循环引用。
                    exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);
                    if (exposedObject == null) {
                        return null;
                    }
                }
            }
        }
        return exposedObject;
    }
</code></pre>
<pre><code class="java">protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) {
        //获取RootBeanDefinition中bean的属性值
        PropertyValues pvs = mbd.getPropertyValues();
        //如果BeanWrapper为null说明bean没有实例化成功，会报错
        if (bw == null) {
            if (!pvs.isEmpty()) {
                throw new BeanCreationException(
                        mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;);
            }
            else {
                // Skip property population phase for null instance.
                return;
            }
        }
        // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the state of the bean before properties are set. This can be used, for example, to support styles of field injection.
        //为任何实现了InstantiationAwareBeanPostProcessors接口的方法，提供在设置属性之前修改bean状态的机会，就是实例化bean的时候（不是复赋值的时候）
        boolean continueWithPropertyPopulation = true;
        if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {
            for (BeanPostProcessor bp : getBeanPostProcessors()) {
                if (bp instanceof InstantiationAwareBeanPostProcessor) {
                    InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
                    //调用实现的postProcessAfterInstantiation方法
                    if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {
                        continueWithPropertyPopulation = false;
                        break;
                    }
                }
            }
        }
        if (!continueWithPropertyPopulation) {
            return;
        }
        if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME ||
                mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) {
            //深拷贝RootBeanDefinition的所有的属性值。保证PropertyValue引用是独立的，但它不能深度复制当前由各个PropertyValue对象引用的对象。
            MutablePropertyValues newPvs = new MutablePropertyValues(pvs);
            // Add property values based on autowire by name if applicable.
            //按照按名称注入的方式注入
            if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) {

                autowireByName(beanName, mbd, bw, newPvs);
            }
            // Add property values based on autowire by type if applicable.
            //按照按名称类型的方式注入
            if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) {
                autowireByType(beanName, mbd, bw, newPvs);
            }
            pvs = newPvs;
        }
        boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();
        boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);
        //如果bean实现了InstantiationAwareBeanPostProcessor接口或者bean需要进行依赖检查，需要进行处理
        if (hasInstAwareBpps || needsDepCheck) {
            PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);
            //一次调用实现的InstantiationAwareBeanPostProcessor接口的postProcessPropertyValues方法
            //这里会调用AutowiredAnnotationBeanPostProcessor#postProcessPropertyValues方法
            //然后调用InjectionMetadata#inject方法
            //进而调用AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement#inject方法
            //进而调用DefaultListableBeanFactory#resolveDependency方法
            //进而调用doResolveDependency方法
            //进而调用DependencyDescriptor#resolveCandidate方法
            //进而调用getBean--&gt;doGetBean来完成一个循环调用的链
            //以保证最顶层的bean的feild加载之前，他所有依赖链上的feild都已经实例化完毕
            //此处极为复杂！！
            if (hasInstAwareBpps) {
                for (BeanPostProcessor bp : getBeanPostProcessors()) {
                    if (bp instanceof InstantiationAwareBeanPostProcessor) {
                        InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;
                        pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);
                        if (pvs == null) {
                            return;
                        }
                    }
                }
            }
            //进行依赖检查，主要检查设置到bean中的数据类型和对象是否个bean对象自身定义的数据类型和对象是不是一样
            if (needsDepCheck) {
                checkDependencies(beanName, mbd, filteredPds, pvs);
            }
        }

        applyPropertyValues(beanName, mbd, bw, pvs);
    }

//其中的autowireByName方法解析
      protected void autowireByName(
            String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) {
        //获取所有的不是普通属性（普通指的基本类型，字符串，数字类型，日期，URL，URI一个Local类或者一个Class对象）的元素的name（name从BeanWrapper中获取）数组
        String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw);
        //按照获取的名称去找对应的bean，并添加到依赖缓存集合中记录
        for (String propertyName : propertyNames) {
            if (containsBean(propertyName)) {
                Object bean = getBean(propertyName);
                pvs.add(propertyName, bean);
                registerDependentBean(propertyName, beanName);
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Added autowiring by name from bean name &#39;&quot; + beanName +
                            &quot;&#39; via property &#39;&quot; + propertyName + &quot;&#39; to bean named &#39;&quot; + propertyName + &quot;&#39;&quot;);
                }
            }
            else {
                if (logger.isTraceEnabled()) {
                    logger.trace(&quot;Not autowiring property &#39;&quot; + propertyName + &quot;&#39; of bean &#39;&quot; + beanName +
                            &quot;&#39; by name: no matching bean found&quot;);
                }
            }
        }
    }
</code></pre>
<pre><code class="java">    protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) {
        //如果bean是BeanNameAware，BeanClassLoaderAware或者BeanFactoryAware其中某一个的实现类就需要进行处理
        if (System.getSecurityManager() != null) {
            AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() {
                public Object run() {
                    invokeAwareMethods(beanName, bean);
                    return null;
                }
            }, getAccessControlContext());
        }
        else {
            invokeAwareMethods(beanName, bean);
        }

        Object wrappedBean = bean;
        //bean的生命周期之一。如果实现了BeanPostProcessor接口则在这里调用postProcessBeforeInitialization方法
        if (mbd == null || !mbd.isSynthetic()) {
            wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);
        }
        //bean的生命周期之一，如果实现了InitializingBean接口，会在这里调用实现的afterPropertiesSet方法
        try {
            invokeInitMethods(beanName, wrappedBean, mbd);
        }
        catch (Throwable ex) {
            throw new BeanCreationException(
                    (mbd != null ? mbd.getResourceDescription() : null),
                    beanName, &quot;Invocation of init method failed&quot;, ex);
        }
        //bean的生命周期之一。如果实现了BeanPostProcessor接口则在这里调用postProcessAfterInitialization方法
        if (mbd == null || !mbd.isSynthetic()) {
            wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);
        }
        return wrappedBean;
    }
</code></pre>
<p>bean都加载完了，最最后finishRefresh</p>
<pre><code class="java">protected void finishRefresh() {
    // Initialize lifecycle processor for this context.
    // 1.为此上下文初始化生命周期处理器
    initLifecycleProcessor();
    // Propagate refresh to lifecycle processor first.
    // 2.首先将刷新完毕事件传播到生命周期处理器（触发isAutoStartup方法返回true的SmartLifecycle的start方法）
    getLifecycleProcessor().onRefresh();
    // Publish the final event.
    // 3.推送上下文刷新完毕事件到相应的监听器
    publishEvent(new ContextRefreshedEvent(this));
    // Participate in LiveBeansView MBean, if active.
    LiveBeansView.registerApplicationContext(this);
}
</code></pre>
<h2 id="关于循环依赖"><a href="#关于循环依赖" class="headerlink" title="关于循环依赖"></a>关于循环依赖</h2><p>最后说一下spring如何解决property上的循环依赖</p>
<p>Spring容器的’三级缓存’<br>在Spring容器的整个声明周期中，单例Bean有且仅有一个对象。这很容易让人想到可以用缓存来加速访问。<br> 从源码中也可以看出Spring大量运用了Cache的手段，在循环依赖问题的解决过程中甚至不惜使用了“三级缓存”，这也便是它设计的精妙之处~</p>
<p>三级缓存其实它更像是Spring容器工厂的内的术语，采用三级缓存模式来解决循环依赖问题，这三级缓存分别指：</p>
<pre><code class="java">public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry {
    ...
    // 从上至下 分表代表这“三级缓存”
    private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); //一级缓存
    private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); // 二级缓存
    private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); // 三级缓存
    ...

    /** Names of beans that are currently in creation. */
    // 这个缓存也十分重要：它表示bean创建过程中都会在里面呆着~
    // 它在Bean开始创建时放值，创建完成时会将其移出~
    private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16));

    /** Names of beans that have already been created at least once. */
    // 当这个Bean被创建完成后，会标记为这个 注意：这里是set集合 不会重复
    // 至少被创建了一次的  都会放进这里~~~~
    private final Set&lt;String&gt; alreadyCreated = Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(256));
}
</code></pre>
<p>注：AbstractBeanFactory继承自DefaultSingletonBeanRegistry~</p>
<ul>
<li>singletonObjects：用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用</li>
<li>earlySingletonObjects：提前曝光的单例对象的cache，存放原始的 bean 对象（尚未填充属性），用于解决循环依赖</li>
<li>singletonFactories：单例对象工厂的cache，存放 bean 工厂对象，用于解决循环依赖</li>
</ul>
<p>加载过程上文分析过，这里重新总结下：</p>
<ul>
<li>先从一级缓存singletonObjects中去获取。（如果获取到就直接return）</li>
<li>如果获取不到或者对象正在创建中（isSingletonCurrentlyInCreation()），那就再从二级缓存earlySingletonObjects中获取。（如果获取到就直接return）</li>
<li>如果还是获取不到，且允许singletonFactories（allowEarlyReference=true）通过getObject()获取。就从三级缓存singletonFactory.getObject()获取。（如果获取到了就从singletonFactories中移除，并且放进earlySingletonObjects。其实也就是从三级缓存移动（是剪切、不是复制哦~）到了二级缓存）</li>
</ul>
<p>所以才有了这段代码</p>
<pre><code class="java">protected Object doCreateBean( ... ){
    ...

    // 这段告诉我们：如果允许循环依赖的话，此处会添加一个ObjectFactory到三级缓存里面，以备创建对象并且提前暴露引用~
    // 此处Tips：getEarlyBeanReference是后置处理器SmartInstantiationAwareBeanPostProcessor的一个方法，它的功效为：
    // 保证自己被循环依赖的时候，即使被别的Bean @Autowire进去的也是代理对象~~~~  AOP自动代理创建器此方法里会创建的代理对象~~~
    // Eagerly cache singletons to be able to resolve circular references
    // even when triggered by lifecycle interfaces like BeanFactoryAware.
    boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName));
    if (earlySingletonExposure) { // 需要提前暴露（支持循环依赖），就注册一个ObjectFactory到三级缓存
        addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));
    }

    // 此处注意：如果此处自己被循环依赖了  那它会走上面的getEarlyBeanReference，从而创建一个代理对象从三级缓存转移到二级缓存里
    // 注意此时候对象还在二级缓存里，并没有在一级缓存。并且此时可以知道exposedObject仍旧是原始对象~~~
    populateBean(beanName, mbd, instanceWrapper);
    exposedObject = initializeBean(beanName, exposedObject, mbd);

    // 经过这两大步后，exposedObject还是原始对象（注意此处以事务的AOP为例子的，
    // 因为事务的AOP自动代理创建器在getEarlyBeanReference创建代理后，initializeBean就不会再重复创建了，二选一的，下面会有描述~~~）

    ...

    // 循环依赖校验（非常重要）~~~~
    if (earlySingletonExposure) {
        // 前面说了因为自己被循环依赖了，所以此时候代理对象还在二级缓存里~~~（备注：本利讲解的是自己被循环依赖了的情况）
        // so，此处getSingleton，就会把里面的对象拿出来，我们知道此时候它已经是个Proxy代理对象~~~
        // 最后赋值给exposedObject  然后return出去，进而最终被addSingleton()添加进一级缓存里面去  
        // 这样就保证了我们容器里**最终实际上是代理对象**，而非原始对象~~~~~
        Object earlySingletonReference = getSingleton(beanName, false);
        if (earlySingletonReference != null) {
            if (exposedObject == bean) { // 这个判断不可少（因为如果initializeBean改变了exposedObject ，就不能这么玩了，否则就是两个对象了~~~）
                exposedObject = earlySingletonReference;
            }
        }
        ...
    }

}
</code></pre>
<p>其实就是为了解决循环依赖，spring会提前把实例加载到三级缓存中去，然后依赖链上的实例创建后，如果需要这个之前缓存的实例，就会先在二级缓存中找，找不到再去三级缓存里找，找到了再把它移出三级缓存，拿到二级缓存里，并用它来装配对象的属性，最后都搞定后，再把二级缓存中的实例拿到一级缓存里去保存。</p>
<p><img src="https://i.loli.net/2020/11/27/54TMuSmHck78UhY.png" alt="image.png"></p>
<p>最后说一下，为什么构造器循环依赖不行</p>
<p>其实前文源码阅读已经说过了，bean的实例化也是依赖构造器的，在检查到构造器有依赖时，会把这个构造器的依赖链上的所有依赖的bean，都通过构造器实例化一遍，这样A发现自己的构造器依赖B，就去实例化B，B也发现自己的构造器依赖A，也去实例化A，而这时候，A已经开始实例化了（spring里有一个cache标志了正在实例化的实例），这样就会产生冲突而报错。</p>
<p>field（property）注入因为已经通过无参构造器完成了实例化，然后在注入property，所以不存在问题。</p>
<h2 id="关于解决依赖"><a href="#关于解决依赖" class="headerlink" title="关于解决依赖"></a>关于解决依赖</h2><p>上文已经提过，实际上依赖的解决是AutowiredAnnotationBeanPostProcessor做的，他调用的是resolveDependency</p>
<h2 id="关于自动装配"><a href="#关于自动装配" class="headerlink" title="关于自动装配"></a>关于自动装配</h2><p>上文已经提过，实际上是ConfigurationClassPostProcessor做的，他会处理所有@import的类，进而去找SpringFactoriesLoader里的东西进行bean definition的注册</p>
<p>不得不说，spring确实太复杂了，搞了两天才搞完。</p>
]]></content>
      
        <categories>
            
            <category> spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[设计模式]]></title>
      <url>/2020/11/25/design-patterns/</url>
      <content type="html"><![CDATA[<p><a href="http://c.biancheng.net/view/8385.html" target="_blank" rel="noopener">http://c.biancheng.net/view/8385.html</a>  这篇文章对Java设计模式有十分全面的介绍。本文结合网上资料和自己经验总结一些设计模式的案例。</p>
<h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><h3 id="简单的"><a href="#简单的" class="headerlink" title="简单的"></a>简单的</h3><pre><code class="java">private static Singleton instance;

    private Singleton() {
    }

    public static Singleton getInstance() {
        if (instance == null)
            instance = new Singleton();

        return instance;
    }
</code></pre>
<h3 id="双重检查"><a href="#双重检查" class="headerlink" title="双重检查"></a>双重检查</h3><p>为什么要双重检查<br>如果不加内层检查，两个线程可以同时进入if创建实例<br>如果不加外层检查，会重复上锁影响性能</p>
<pre><code class="java">
// 注意一定要用volatile来避免指令重排
private volatile static Singleton instance;

public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null)
                    instance = new Singleton();
            }
        }

        return instance;
    }
</code></pre>
<h3 id="静态内部类"><a href="#静态内部类" class="headerlink" title="静态内部类"></a>静态内部类</h3><pre><code class="java">class Singleton {
    public static Singleton instance;

    private static class SingletonWrapper {
        static Singleton instance = new Singleton();
    }

    private Singleton() {

    }

    public static Singleton getInstance() {
        return SingletonWrapper.instance;
    }
}
</code></pre>
<h3 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h3><pre><code class="java">public class Main {
    public static void main(String[] args) {
        Singleton.INSTANCE.sayHello();
    }
}

enum Singleton {
    INSTANCE;

    public void sayHello() {
        System.out.println(&quot;hello&quot;);
    }
}
</code></pre>
<h2 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h2><h3 id="简单工厂"><a href="#简单工厂" class="headerlink" title="简单工厂"></a>简单工厂</h3><p><img src="https://i.loli.net/2020/11/26/4LXkhJd2n7lCerH.png" alt="image.png"></p>
<pre><code class="java">public class Client {
    public static void main(String[] args) {
    }

    //抽象产品
    public interface Product {
        void show();
    }

    //具体产品：ProductA
    static class ConcreteProduct1 implements Product {
        public void show() {
            System.out.println(&quot;具体产品1显示...&quot;);
        }
    }

    //具体产品：ProductB
    static class ConcreteProduct2 implements Product {
        public void show() {
            System.out.println(&quot;具体产品2显示...&quot;);
        }
    }

    final class Const {
        static final int PRODUCT_A = 0;
        static final int PRODUCT_B = 1;
        static final int PRODUCT_C = 2;
    }

    static class SimpleFactory {
        public static Product makeProduct(int kind) {
            switch (kind) {
                case Const.PRODUCT_A:
                    return new ConcreteProduct1();
                case Const.PRODUCT_B:
                    return new ConcreteProduct2();
            }
            return null;
        }
    }
}
</code></pre>
<p>简单工厂模式没啥好说的，因为它太简单了。代码直接略过。唯一要说的是提供一种spring下的工厂模式实现思路，可以把一个接口的所有实现类都注册成bean，然后通过不同bean的名字来实现一个简单工厂，我在做分布式锁的时候用过这种方式，代码更简洁优雅。<a href="https://github.com/IBM/distributed-lock-spring-boot-starter/blob/master/src/main/java/com/ibm/distributedlock/provider/factory/LockProviderFactory.java" target="_blank" rel="noopener">详见这里</a></p>
<h3 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h3><p><img src="https://i.loli.net/2020/11/26/jyYDLfAWOs1altw.png" alt="image.png"></p>
<pre><code class="java">package FactoryMethod;

public class AbstractFactoryTest {
    public static void main(String[] args) {
        try {
            Product a;
            AbstractFactory af;
            af = (AbstractFactory) ReadXML1.getObject();
            a = af.newProduct();
            a.show();
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }
}

//抽象产品：提供了产品的接口
interface Product {
    public void show();
}

//具体产品1：实现抽象产品中的抽象方法
class ConcreteProduct1 implements Product {
    public void show() {
        System.out.println(&quot;具体产品1显示...&quot;);
    }
}

//具体产品2：实现抽象产品中的抽象方法
class ConcreteProduct2 implements Product {
    public void show() {
        System.out.println(&quot;具体产品2显示...&quot;);
    }
}

//抽象工厂：提供了厂品的生成方法
interface AbstractFactory {
    public Product newProduct();
}

//具体工厂1：实现了厂品的生成方法
class ConcreteFactory1 implements AbstractFactory {
    public Product newProduct() {
        System.out.println(&quot;具体工厂1生成--&gt;具体产品1...&quot;);
        return new ConcreteProduct1();
    }
}

//具体工厂2：实现了厂品的生成方法
class ConcreteFactory2 implements AbstractFactory {
    public Product newProduct() {
        System.out.println(&quot;具体工厂2生成--&gt;具体产品2...&quot;);
        return new ConcreteProduct2();
    }
}
</code></pre>
<h3 id="抽象工厂"><a href="#抽象工厂" class="headerlink" title="抽象工厂"></a>抽象工厂</h3><p><img src="https://i.loli.net/2020/11/26/58I6cRCzoAsJ3bU.png" alt="image.png"></p>
<pre><code class="java">package AbstractFactory;

import java.awt.*;
import javax.swing.*;

public class FarmTest {
    public static void main(String[] args) {
        try {
            Farm f;
            Animal a;
            Plant p;
            f = (Farm) ReadXML.getObject();
            a = f.newAnimal();
            p = f.newPlant();
            a.show();
            p.show();
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }
}

//抽象产品：动物类
interface Animal {
    public void show();
}

//具体产品：马类
class Horse implements Animal {
    JScrollPane sp;
    JFrame jf = new JFrame(&quot;抽象工厂模式测试&quot;);

    public Horse() {
        Container contentPane = jf.getContentPane();
        JPanel p1 = new JPanel();
        p1.setLayout(new GridLayout(1, 1));
        p1.setBorder(BorderFactory.createTitledBorder(&quot;动物：马&quot;));
        sp = new JScrollPane(p1);
        contentPane.add(sp, BorderLayout.CENTER);
        JLabel l1 = new JLabel(new ImageIcon(&quot;src/A_Horse.jpg&quot;));
        p1.add(l1);
        jf.pack();
        jf.setVisible(false);
        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);//用户点击窗口关闭
    }

    public void show() {
        jf.setVisible(true);
    }
}

//具体产品：牛类
class Cattle implements Animal {
    JScrollPane sp;
    JFrame jf = new JFrame(&quot;抽象工厂模式测试&quot;);

    public Cattle() {
        Container contentPane = jf.getContentPane();
        JPanel p1 = new JPanel();
        p1.setLayout(new GridLayout(1, 1));
        p1.setBorder(BorderFactory.createTitledBorder(&quot;动物：牛&quot;));
        sp = new JScrollPane(p1);
        contentPane.add(sp, BorderLayout.CENTER);
        JLabel l1 = new JLabel(new ImageIcon(&quot;src/A_Cattle.jpg&quot;));
        p1.add(l1);
        jf.pack();
        jf.setVisible(false);
        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);//用户点击窗口关闭
    }

    public void show() {
        jf.setVisible(true);
    }
}

//抽象产品：植物类
interface Plant {
    public void show();
}

//具体产品：水果类
class Fruitage implements Plant {
    JScrollPane sp;
    JFrame jf = new JFrame(&quot;抽象工厂模式测试&quot;);

    public Fruitage() {
        Container contentPane = jf.getContentPane();
        JPanel p1 = new JPanel();
        p1.setLayout(new GridLayout(1, 1));
        p1.setBorder(BorderFactory.createTitledBorder(&quot;植物：水果&quot;));
        sp = new JScrollPane(p1);
        contentPane.add(sp, BorderLayout.CENTER);
        JLabel l1 = new JLabel(new ImageIcon(&quot;src/P_Fruitage.jpg&quot;));
        p1.add(l1);
        jf.pack();
        jf.setVisible(false);
        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);//用户点击窗口关闭
    }

    public void show() {
        jf.setVisible(true);
    }
}

//具体产品：蔬菜类
class Vegetables implements Plant {
    JScrollPane sp;
    JFrame jf = new JFrame(&quot;抽象工厂模式测试&quot;);

    public Vegetables() {
        Container contentPane = jf.getContentPane();
        JPanel p1 = new JPanel();
        p1.setLayout(new GridLayout(1, 1));
        p1.setBorder(BorderFactory.createTitledBorder(&quot;植物：蔬菜&quot;));
        sp = new JScrollPane(p1);
        contentPane.add(sp, BorderLayout.CENTER);
        JLabel l1 = new JLabel(new ImageIcon(&quot;src/P_Vegetables.jpg&quot;));
        p1.add(l1);
        jf.pack();
        jf.setVisible(false);
        jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);//用户点击窗口关闭
    }

    public void show() {
        jf.setVisible(true);
    }
}

//抽象工厂：农场类
interface Farm {
    public Animal newAnimal();

    public Plant newPlant();
}

//具体工厂：韶关农场类
class SGfarm implements Farm {
    public Animal newAnimal() {
        System.out.println(&quot;新牛出生！&quot;);
        return new Cattle();
    }

    public Plant newPlant() {
        System.out.println(&quot;蔬菜长成！&quot;);
        return new Vegetables();
    }
}

//具体工厂：上饶农场类
class SRfarm implements Farm {
    public Animal newAnimal() {
        System.out.println(&quot;新马出生！&quot;);
        return new Horse();
    }

    public Plant newPlant() {
        System.out.println(&quot;水果长成！&quot;);
        return new Fruitage();
    }
}
</code></pre>
<h2 id="建造者模式（Bulider模式）"><a href="#建造者模式（Bulider模式）" class="headerlink" title="建造者模式（Bulider模式）"></a>建造者模式（Bulider模式）</h2><p><img src="https://i.loli.net/2020/11/26/tGfYeFNySTjC74s.png" alt="image.png"></p>
<pre><code class="java">class Product
{
    private String partA;
    private String partB;
    private String partC;
    public void setPartA(String partA)
    {
        this.partA=partA;
    }
    public void setPartB(String partB)
    {
        this.partB=partB;
    }
    public void setPartC(String partC)
    {
        this.partC=partC;
    }
    public void show()
    {
        //显示产品的特性
    }
}

abstract class Builder
{
    //创建产品对象
    protected Product product=new Product();
    public abstract void buildPartA();
    public abstract void buildPartB();
    public abstract void buildPartC();
    //返回产品对象
    public Product getResult()
    {
        return product;
    }
}

public class ConcreteBuilder extends Builder
{
    public void buildPartA()
    {
        product.setPartA(&quot;建造 PartA&quot;);
    }
    public void buildPartB()
    {
        product.setPartB(&quot;建造 PartB&quot;);
    }
    public void buildPartC()
    {
        product.setPartC(&quot;建造 PartC&quot;);
    }
}

class Director
{
    private Builder builder;
    public Director(Builder builder)
    {
        this.builder=builder;
    }
    //产品构建与组装方法
    public Product construct()
    {
        builder.buildPartA();
        builder.buildPartB();
        builder.buildPartC();
        return builder.getResult();
    }
}

public class Client
{
    public static void main(String[] args)
    {
        Builder builder=new ConcreteBuilder();
        Director director=new Director(builder);
        Product product=director.construct();
        product.show();
    }
}
</code></pre>
<h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><p><img src="https://i.loli.net/2020/11/26/Rrjncpv1TX3KCPG.png" alt="image.png"></p>
<pre><code class="java">package proxy;
public class ProxyTest {
    public static void main(String[] args) {
        Proxy proxy = new Proxy();
        proxy.Request();
    }
}
//抽象主题
interface Subject {
    void Request();
}
//真实主题
class RealSubject implements Subject {
    public void Request() {
        System.out.println(&quot;访问真实主题方法...&quot;);
    }
}
//代理
class Proxy implements Subject {
    private RealSubject realSubject;
    public void Request() {
        if (realSubject == null) {
            realSubject = new RealSubject();
        }
        preRequest();
        realSubject.Request();
        postRequest();
    }
    public void preRequest() {
        System.out.println(&quot;访问真实主题之前的预处理。&quot;);
    }
    public void postRequest() {
        System.out.println(&quot;访问真实主题之后的后续处理。&quot;);
    }
}
</code></pre>
<h2 id="适配器模式（Adapter模式）"><a href="#适配器模式（Adapter模式）" class="headerlink" title="适配器模式（Adapter模式）"></a>适配器模式（Adapter模式）</h2><p>类适配器模式</p>
<p>接口实现类调用另一个子类的方法<br><img src="https://i.loli.net/2020/11/26/8zxAJljOfcSukTV.png" alt="image.png"></p>
<pre><code class="java">package adapter;
//目标接口
interface Target
{
    public void request();
}
//适配者接口
class Adaptee
{
    public void specificRequest()
    {       
        System.out.println(&quot;适配者中的业务代码被调用！&quot;);
    }
}
//类适配器类
class ClassAdapter extends Adaptee implements Target
{
    public void request()
    {
        specificRequest();
    }
}
//客户端代码
public class ClassAdapterTest
{
    public static void main(String[] args)
    {
        System.out.println(&quot;类适配器模式测试：&quot;);
        Target target = new ClassAdapter();
        target.request();
    }
}
</code></pre>
<p>对象适配器模式</p>
<p>用适配对象去实现接口，调用适配器方法<br><img src="https://i.loli.net/2020/11/26/mUu9nSiBM5qwFRP.png" alt="image.png"></p>
<pre><code class="java">package adapter;
//对象适配器类
class ObjectAdapter implements Target
{
    private Adaptee adaptee;
    public ObjectAdapter(Adaptee adaptee)
    {
        this.adaptee=adaptee;
    }
    public void request()
    {
        adaptee.specificRequest();
    }
}
//客户端代码
public class ObjectAdapterTest
{
    public static void main(String[] args)
    {
        System.out.println(&quot;对象适配器模式测试：&quot;);
        Adaptee adaptee = new Adaptee();
        Target target = new ObjectAdapter(adaptee);
        target.request();
    }
}
</code></pre>
<h2 id="桥接模式（Bridge模式）"><a href="#桥接模式（Bridge模式）" class="headerlink" title="桥接模式（Bridge模式）"></a>桥接模式（Bridge模式）</h2><p>通过一个抽象类对一个接口的引用实现桥接</p>
<p><img src="https://i.loli.net/2020/11/26/nJZfzRM9tI4galG.png" alt="image.png"></p>
<pre><code class="java">package bridge;
public class BridgeTest
{
    public static void main(String[] args)
    {
        Implementor imple=new ConcreteImplementorA();
        Abstraction abs=new RefinedAbstraction(imple);
        abs.Operation();
    }
}
//实现化角色
interface Implementor
{
    public void OperationImpl();
}
//具体实现化角色
class ConcreteImplementorA implements Implementor
{
    public void OperationImpl()
    {
        System.out.println(&quot;具体实现化(Concrete Implementor)角色被访问&quot; );
    }
}
//抽象化角色
abstract class Abstraction
{
   protected Implementor imple;
   protected Abstraction(Implementor imple)
   {
       this.imple=imple;
   }
   public abstract void Operation();   
}
//扩展抽象化角色
class RefinedAbstraction extends Abstraction
{
   protected RefinedAbstraction(Implementor imple)
   {
       super(imple);
   }
   public void Operation()
   {
       System.out.println(&quot;扩展抽象化(Refined Abstraction)角色被访问&quot; );
       imple.OperationImpl();
   }
}
</code></pre>
<h2 id="装饰（Decorator）模式"><a href="#装饰（Decorator）模式" class="headerlink" title="装饰（Decorator）模式"></a>装饰（Decorator）模式</h2><p>装饰者和具体实现，实现同一个接口，装饰者为借口方法提供额外功能</p>
<p><img src="https://i.loli.net/2020/11/26/Ay9Iev1C67BNpxJ.png" alt="image.png"></p>
<pre><code class="java">package decorator;
public class DecoratorPattern
{
    public static void main(String[] args)
    {
        Component p=new ConcreteComponent();
        p.operation();
        System.out.println(&quot;---------------------------------&quot;);
        Component d=new ConcreteDecorator(p);
        d.operation();
    }
}
//抽象构件角色
interface  Component
{
    public void operation();
}
//具体构件角色
class ConcreteComponent implements Component
{
    public ConcreteComponent()
    {
        System.out.println(&quot;创建具体构件角色&quot;);       
    }   
    public void operation()
    {
        System.out.println(&quot;调用具体构件角色的方法operation()&quot;);           
    }
}
//抽象装饰角色
class Decorator implements Component
{
    private Component component;   
    public Decorator(Component component)
    {
        this.component=component;
    }   
    public void operation()
    {
        component.operation();
    }
}
//具体装饰角色
class ConcreteDecorator extends Decorator
{
    public ConcreteDecorator(Component component)
    {
        super(component);
    }   
    public void operation()
    {
        super.operation();
        addedFunction();
    }
    public void addedFunction()
    {
        System.out.println(&quot;为具体构件角色增加额外的功能addedFunction()&quot;);           
    }
}
</code></pre>
<h2 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h2><p><img src="https://i.loli.net/2020/11/26/eIOKTmESi8kA6n7.png" alt="image.png"></p>
<pre><code class="java">package composite;
import java.util.ArrayList;
public class ShoppingTest {
    public static void main(String[] args) {
        float s = 0;
        Bags BigBag, mediumBag, smallRedBag, smallWhiteBag;
        Goods sp;
        BigBag = new Bags(&quot;大袋子&quot;);
        mediumBag = new Bags(&quot;中袋子&quot;);
        smallRedBag = new Bags(&quot;红色小袋子&quot;);
        smallWhiteBag = new Bags(&quot;白色小袋子&quot;);
        sp = new Goods(&quot;婺源特产&quot;, 2, 7.9f);
        smallRedBag.add(sp);
        sp = new Goods(&quot;婺源地图&quot;, 1, 9.9f);
        smallRedBag.add(sp);
        sp = new Goods(&quot;韶关香菇&quot;, 2, 68);
        smallWhiteBag.add(sp);
        sp = new Goods(&quot;韶关红茶&quot;, 3, 180);
        smallWhiteBag.add(sp);
        sp = new Goods(&quot;景德镇瓷器&quot;, 1, 380);
        mediumBag.add(sp);
        mediumBag.add(smallRedBag);
        sp = new Goods(&quot;李宁牌运动鞋&quot;, 1, 198);
        BigBag.add(sp);
        BigBag.add(smallWhiteBag);
        BigBag.add(mediumBag);
        System.out.println(&quot;您选购的商品有：&quot;);
        BigBag.show();
        s = BigBag.calculation();
        System.out.println(&quot;要支付的总价是：&quot; + s + &quot;元&quot;);
    }
}
//抽象构件：物品
interface Articles {
    public float calculation(); //计算
    public void show();
}
//树叶构件：商品
class Goods implements Articles {
    private String name;     //名字
    private int quantity;    //数量
    private float unitPrice; //单价
    public Goods(String name, int quantity, float unitPrice) {
        this.name = name;
        this.quantity = quantity;
        this.unitPrice = unitPrice;
    }
    public float calculation() {
        return quantity * unitPrice;
    }
    public void show() {
        System.out.println(name + &quot;(数量：&quot; + quantity + &quot;，单价：&quot; + unitPrice + &quot;元)&quot;);
    }
}
//树枝构件：袋子
class Bags implements Articles {
    private String name;     //名字  
    private ArrayList&lt;Articles&gt; bags = new ArrayList&lt;Articles&gt;();
    public Bags(String name) {
        this.name = name;
    }
    public void add(Articles c) {
        bags.add(c);
    }
    public void remove(Articles c) {
        bags.remove(c);
    }
    public Articles getChild(int i) {
        return bags.get(i);
    }
    public float calculation() {
        float s = 0;
        for (Object obj : bags) {
            s += ((Articles) obj).calculation();
        }
        return s;
    }
    public void show() {
        for (Object obj : bags) {
            ((Articles) obj).show();
        }
    }
}
</code></pre>
<h2 id="模板方法（Template-Method）模式"><a href="#模板方法（Template-Method）模式" class="headerlink" title="模板方法（Template Method）模式"></a>模板方法（Template Method）模式</h2><p><img src="https://i.loli.net/2020/11/26/fhAeZQog5TBPEWY.png" alt="image.png"></p>
<pre><code class="java">public class TemplateMethodPattern {
    public static void main(String[] args) {
        AbstractClass tm = new ConcreteClass();
        tm.TemplateMethod();
    }
}
//抽象类
abstract class AbstractClass {
    //模板方法
    public void TemplateMethod() {
        SpecificMethod();
        abstractMethod1();
        abstractMethod2();
    }
    //具体方法
    public void SpecificMethod() {
        System.out.println(&quot;抽象类中的具体方法被调用...&quot;);
    }
    //抽象方法1
    public abstract void abstractMethod1();
    //抽象方法2
    public abstract void abstractMethod2();
}
//具体子类
class ConcreteClass extends AbstractClass {
    public void abstractMethod1() {
        System.out.println(&quot;抽象方法1的实现被调用...&quot;);
    }
    public void abstractMethod2() {
        System.out.println(&quot;抽象方法2的实现被调用...&quot;);
    }
}
</code></pre>
<h2 id="责任链（Chain-of-Responsibility）模式"><a href="#责任链（Chain-of-Responsibility）模式" class="headerlink" title="责任链（Chain of Responsibility）模式"></a>责任链（Chain of Responsibility）模式</h2><p><img src="https://i.loli.net/2020/11/26/iHjhBoMSt7DpIq4.png" alt="image.png"></p>
<pre><code class="java">package chainOfResponsibility;
public class ChainOfResponsibilityPattern {
    public static void main(String[] args) {
        //组装责任链
        Handler handler1 = new ConcreteHandler1();
        Handler handler2 = new ConcreteHandler2();
        handler1.setNext(handler2);
        //提交请求
        handler1.handleRequest(&quot;two&quot;);
    }
}
//抽象处理者角色
abstract class Handler {
    private Handler next;
    public void setNext(Handler next) {
        this.next = next;
    }
    public Handler getNext() {
        return next;
    }
    //处理请求的方法
    public abstract void handleRequest(String request);
}
//具体处理者角色1
class ConcreteHandler1 extends Handler {
    public void handleRequest(String request) {
        if (request.equals(&quot;one&quot;)) {
            System.out.println(&quot;具体处理者1负责处理该请求！&quot;);
        } else {
            if (getNext() != null) {
                getNext().handleRequest(request);
            } else {
                System.out.println(&quot;没有人处理该请求！&quot;);
            }
        }
    }
}
//具体处理者角色2
class ConcreteHandler2 extends Handler {
    public void handleRequest(String request) {
        if (request.equals(&quot;two&quot;)) {
            System.out.println(&quot;具体处理者2负责处理该请求！&quot;);
        } else {
            if (getNext() != null) {
                getNext().handleRequest(request);
            } else {
                System.out.println(&quot;没有人处理该请求！&quot;);
            }
        }
    }
}
</code></pre>
<h2 id="观察者模式（Observer模式）"><a href="#观察者模式（Observer模式）" class="headerlink" title="观察者模式（Observer模式）"></a>观察者模式（Observer模式）</h2><p><img src="https://i.loli.net/2020/11/26/IqKrnykPt2hObdQ.png" alt="image.png"></p>
<pre><code class="java">package net.biancheng.c.observer;
import java.util.*;
public class ObserverPattern {
    public static void main(String[] args) {
        Subject subject = new ConcreteSubject();
        Observer obs1 = new ConcreteObserver1();
        Observer obs2 = new ConcreteObserver2();
        subject.add(obs1);
        subject.add(obs2);
        subject.notifyObserver();
    }
}
//抽象目标
abstract class Subject {
    protected List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;();
    //增加观察者方法
    public void add(Observer observer) {
        observers.add(observer);
    }
    //删除观察者方法
    public void remove(Observer observer) {
        observers.remove(observer);
    }
    public abstract void notifyObserver(); //通知观察者方法
}
//具体目标
class ConcreteSubject extends Subject {
    public void notifyObserver() {
        System.out.println(&quot;具体目标发生改变...&quot;);
        System.out.println(&quot;--------------&quot;);
        for (Object obs : observers) {
            ((Observer) obs).response();
        }
    }
}
//抽象观察者
interface Observer {
    void response(); //反应
}
//具体观察者1
class ConcreteObserver1 implements Observer {
    public void response() {
        System.out.println(&quot;具体观察者1作出反应！&quot;);
    }
}
//具体观察者1
class ConcreteObserver2 implements Observer {
    public void response() {
        System.out.println(&quot;具体观察者2作出反应！&quot;);
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> 设计模式 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[用LockSupport实现一个先进先出的不可重入锁]]></title>
      <url>/2020/11/25/juc-action-2/</url>
      <content type="html"><![CDATA[<p>这是网上的解法，感觉不太好，还用了ConcurrentLinkedQueue</p>
<pre><code class="java">public class FIFOMutex {

    private final AtomicBoolean locked = new AtomicBoolean(false);
    private final Queue&lt;Thread&gt; waiters = new ConcurrentLinkedQueue&lt;Thread&gt;();

    public void lock() {
        boolean wasInterrupted = false;
        Thread current = Thread.currentThread();
        waiters.add(current);

        // 只有自己在队首才可以获得锁，否则阻塞自己
        // cas 操作失败的话说明这里有并发，别人已经捷足先登了，那么也要阻塞自己的
        // 有了waiters.peek() != current判断如果自己队首了，为什么不直接获取到锁还要cas 操作呢？
        // 主要是因为接下来那个remove 操作把自己移除掉了额，但是他还没有真正释放锁，锁的释放在unlock方法中释放的
        while (waiters.peek() != current ||
            !locked.compareAndSet(false, true)) {
            // 这里就是使用LockSupport 来阻塞当前线程
            LockSupport.park(this);
            // 这里的意思就是忽略线程中断，只是记录下曾经被中断过
            // 大家注意这里的java 中的中断仅仅是一个状态，要不要退出程序或者抛异常需要程序员来控制的
            if (Thread.interrupted()) {
                wasInterrupted = true;
            }
        }
        // 移出队列，注意这里移出后，后面的线程就处于队首了，但是还是不能获取到锁的，locked 的值还是true,
        // 上面while 循环的中的cas 操作还是会失败进入阻塞的
        waiters.remove();
        // 如果被中断过，那么设置中断状态
        if (wasInterrupted) {
            current.interrupt();
        }

    }

    public void unlock() {
        locked.set(false);
        // 唤醒位于队首的线程
        LockSupport.unpark(waiters.peek());
    }

}
</code></pre>
<p>然后我自己又写了个不用ConcurrentLinkedQueue的版本，只用cas, 没有head，只有tail的尾插clh队列，前驱节点自旋，</p>
<pre><code class="java">public class FIFOMutex {

    private final AtomicBoolean locked = new AtomicBoolean(false);

    private AtomicReference&lt;Node&gt; tail = new AtomicReference&lt;&gt;(new Node());

    public FIFOMutex(){
    }

    static class Node {
        Thread t;
        Node prev;
        Node next;
        public Node(Thread t){
            this.t = t;
        }
        public Node(){
        }
    }

    public void lock(){
        // 初始化节点
        Node node = new Node(Thread.currentThread());
        for (;;){
            // 拿锁
            if (!locked.compareAndSet(false, true)){
                    // 设置尾节点
                    if (node.prev == null){
                        for(;;){
                            Node oldTail = tail.get();
                            if (tail.compareAndSet(oldTail, node)){
                                node.prev = oldTail;
                                oldTail.next = node;
                                break;
                            }
                        }
                    }
                    // 如果前驱节点有线程，park
                    if (node.prev.t != null){
                        LockSupport.park(Thread.currentThread());
                    }

            }else {
                // 释放节点，使前驱节点有效自旋
                node.t = null;
                // 如果后驱节点不为空，unpark
                if (node.next != null){
                    LockSupport.unpark(node.next.t);
                }
                break;
            }
        }
    }

    public void unlock(){
        locked.set(false);
    }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[并发案例之生产者消费者]]></title>
      <url>/2020/11/25/juc-action-1/</url>
      <content type="html"><![CDATA[<p>转自 <a href="https://my.oschina.net/hosee/blog/485121#OSC_h4_4" target="_blank" rel="noopener">https://my.oschina.net/hosee/blog/485121#OSC_h4_4</a> ， 用一个案例说清了大部分juc下工具的使用, 本文有删改。</p>
<h2 id="生产者消费者问题"><a href="#生产者消费者问题" class="headerlink" title="生产者消费者问题"></a>生产者消费者问题</h2><p> 生产者消费者问题是研究多线程程序时绕不开的经典问题之一，它描述是有一块缓冲区作为仓库，生产者可以将产品放入仓库，消费者则可以从仓库中取走产品。解决生产者/消费者问题的方法可分为两类：（1）采用某种机制保护生产者和消费者之间的同步；（2）在生产者和消费者之间建立一个管道。第一种方式有较高的效率，并且易于实现，代码的可控制性较好，属于常用的模式。第二种管道缓冲区不易控制，被传输数据对象不易于封装等，实用性不强。</p>
<p>同步问题核心在于：如何保证同一资源被多个线程并发访问时的完整性。常用的同步方法是采用信号或加锁机制，保证资源在任意时刻至多被一个线程访问。Java语言在多线程编程上实现了完全对象化，提供了对同步机制的良好支持。在Java中一共有五种方法支持同步，其中前四个是同步方法，一个是管道方法。</p>
<ul>
<li>wait() / notify()方法</li>
<li>await() / signal()方法</li>
<li>BlockingQueue阻塞队列方法</li>
<li>Semaphore方法</li>
<li>PipedInputStream / PipedOutputStream</li>
</ul>
<h2 id="wait-notify-方法"><a href="#wait-notify-方法" class="headerlink" title="wait() / notify()方法"></a>wait() / notify()方法</h2><p>wait() / nofity()方法是基类Object的两个方法，也就意味着所有Java类都会拥有这两个方法，这样，我们就可以为任何对象实现同步机制。</p>
<p>wait()方法：当缓冲区已满/空时，生产者/消费者线程停止自己的执行，放弃锁，使自己处于等等状态，让其他线程执行。</p>
<p>notify()方法：当生产者/消费者向缓冲区放入/取出一个产品时，向其他等待的线程发出可执行的通知，同时放弃锁，使自己处于等待状态。</p>
<p>各起了4个生产者，4个消费者 ：</p>
<pre><code class="java">package test;

public class Hosee
{
    private static Integer count = 0;
    private final Integer FULL = 10;
    private static String LOCK = &quot;LOCK&quot;;

    class Producer implements Runnable
    {
        @Override
        public void run()
        {
            for (int i = 0; i &lt; 10; i++)
            {
                try
                {
                    Thread.sleep(3000);
                }
                catch (Exception e)
                {
                    e.printStackTrace();
                }
                synchronized (LOCK)
                {
                    while (count == FULL)
                    {
                        try
                        {
                            LOCK.wait();
                        }
                        catch (Exception e)
                        {
                            e.printStackTrace();
                        }
                    }
                    count++;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;生产者生产，目前总共有&quot; + count);
                    LOCK.notifyAll();
                }
            }
        }

    }

    class Consumer implements Runnable
    {

        @Override
        public void run()
        {
            for (int i = 0; i &lt; 10; i++)
            {
                try
                {
                    Thread.sleep(3000);
                }
                catch (InterruptedException e1)
                {
                    e1.printStackTrace();
                }
                synchronized (LOCK)
                {
                    while (count == 0)
                    {
                        try
                        {
                            LOCK.wait();
                        }
                        catch (Exception e)
                        {
                            // TODO: handle exception
                            e.printStackTrace();
                        }
                    }
                    count--;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;消费者消费，目前总共有&quot; + count);
                    LOCK.notifyAll();
                }
            }

        }

    }

    public static void main(String[] args) throws Exception
    {
        Hosee hosee = new Hosee();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();

        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
    }

}
</code></pre>
<p>(需要注意的是，用什么加锁就用什么notify和wait，实例中使用的是LOCK)</p>
<h2 id="await-signal-方法"><a href="#await-signal-方法" class="headerlink" title="await() / signal()方法"></a>await() / signal()方法</h2><p>首先，我们先来看看await()/signal()与wait()/notify()的区别：</p>
<ul>
<li>wait()和notify()必须在synchronized的代码块中使用 因为只有在获取当前对象的锁时才能进行这两个操作 否则会报异常 而await()和signal()一般与Lock()配合使用。</li>
<li>wait是Object的方法，而await只有部分类有，如Condition。</li>
<li>await()/signal()和新引入的锁定机制Lock直接挂钩，具有更大的灵活性。</li>
</ul>
<p>那么为什么有了synchronized还要提出Lock呢？</p>
<p>synchronized并不完美，它有一些功能性的限制 —— 它无法中断一个正在等候获得锁的线程，也无法通过投票得到锁，如果不想等下去，也就没法得到锁。同步还要求锁的释放只能在与获得锁所在的堆栈帧相同的堆栈帧中进行，多数情况下，这没问题（而且与异常处理交互得很好），但是，确实存在一些非块结构的锁定更合适的情况。</p>
<p>所以在确实需要一些 synchronized 所没有的特性的时候，比如时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者锁投票使用ReentrantLock。</p>
<pre><code class="java">package test;

import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class Hosee {
    private static Integer count = 0;
    private final Integer FULL = 10;
    final Lock lock = new ReentrantLock();
    final Condition NotFull = lock.newCondition();
    final Condition NotEmpty = lock.newCondition();

    class Producer implements Runnable {
        @Override
        public void run() {
            for (int i = 0; i &lt; 10; i++) {
                try {
                    Thread.sleep(3000);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                lock.lock();
                try {
                    while (count == FULL) {
                        try {
                            NotFull.await();
                        } catch (InterruptedException e) {
                            // TODO Auto-generated catch block
                            e.printStackTrace();
                        }
                    }
                    count++;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;生产者生产，目前总共有&quot; + count);
                    NotEmpty.signal();
                } finally {
                    lock.unlock();
                }

            }
        }
    }

    class Consumer implements Runnable {

        @Override
        public void run() {
            for (int i = 0; i &lt; 10; i++) {
                try {
                    Thread.sleep(3000);
                } catch (InterruptedException e1) {
                    e1.printStackTrace();
                }
                lock.lock();
                try {
                    while (count == 0) {
                        try {
                            NotEmpty.await();
                        } catch (Exception e) {
                            // TODO: handle exception
                            e.printStackTrace();
                        }
                    }
                    count--;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;消费者消费，目前总共有&quot; + count);
                    NotFull.signal();
                } finally {
                    lock.unlock();
                }

            }

        }

    }

    public static void main(String[] args) throws Exception {
        Hosee hosee = new Hosee();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();

        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
    }

}
</code></pre>
<p>运行结果与第一个类似。上述代码用了两个Condition，其实用一个也是可以的，只不过要signalall()。</p>
<h2 id="BlockingQueue阻塞队列方法"><a href="#BlockingQueue阻塞队列方法" class="headerlink" title="BlockingQueue阻塞队列方法"></a>BlockingQueue阻塞队列方法</h2><p>BlockingQueue是JDK5.0的新增内容，它是一个已经在内部实现了同步的队列，实现方式采用的是我们第2种await() / signal()方法。它可以在生成对象时指定容量大小。它用于阻塞操作的是put()和take()方法。</p>
<p>put()方法：类似于我们上面的生产者线程，容量达到最大时，自动阻塞。<br>take()方法：类似于我们上面的消费者线程，容量为0时，自动阻塞。</p>
<pre><code class="java">package test;

import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;

public class Hosee {
    private static Integer count = 0;
    final BlockingQueue&lt;Integer&gt; bq = new ArrayBlockingQueue&lt;Integer&gt;(10);
    class Producer implements Runnable {
        @Override
        public void run() {
            for (int i = 0; i &lt; 10; i++) {
                try {
                    Thread.sleep(3000);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                try {
                    bq.put(1);
                    count++;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;生产者生产，目前总共有&quot; + count);
                } catch (InterruptedException e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }
            }
        }
    }

    class Consumer implements Runnable {

        @Override
        public void run() {
            for (int i = 0; i &lt; 10; i++) {
                try {
                    Thread.sleep(3000);
                } catch (InterruptedException e1) {
                    e1.printStackTrace();
                }
                try {
                    bq.take();
                    count--;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;消费者消费，目前总共有&quot; + count);
                } catch (Exception e) {
                    // TODO: handle exception
                    e.printStackTrace();
                }
            }
        }

    }

    public static void main(String[] args) throws Exception {
        Hosee hosee = new Hosee();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();

        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
    }

}
</code></pre>
<h2 id="Semaphore方法"><a href="#Semaphore方法" class="headerlink" title="Semaphore方法"></a>Semaphore方法</h2><p>Semaphore 信号量，就是一个允许实现设置好的令牌。也许有1个，也许有10个或更多。<br>谁拿到令牌(acquire)就可以去执行了，如果没有令牌则需要等待。<br>执行完毕，一定要归还(release)令牌，否则令牌会被很快用光，别的线程就无法获得令牌而执行下去了。</p>
<pre><code class="java">package test;

import java.util.concurrent.Semaphore;

public class Hosee
{
    int count = 0;
    final Semaphore notFull = new Semaphore(10);
    final Semaphore notEmpty = new Semaphore(0);
    final Semaphore mutex = new Semaphore(1);

    class Producer implements Runnable
    {
        @Override
        public void run()
        {
            for (int i = 0; i &lt; 10; i++)
            {
                try
                {
                    Thread.sleep(3000);
                }
                catch (Exception e)
                {
                    e.printStackTrace();
                }
                try
                {
                    notFull.acquire();//顺序不能颠倒，否则会造成死锁。
                    mutex.acquire();
                    count++;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;生产者生产，目前总共有&quot; + count);
                }
                catch (Exception e)
                {
                    e.printStackTrace();
                }
                finally
                {
                    mutex.release();
                    notEmpty.release();
                }

            }
        }
    }

    class Consumer implements Runnable
    {

        @Override
        public void run()
        {
            for (int i = 0; i &lt; 10; i++)
            {
                try
                {
                    Thread.sleep(3000);
                }
                catch (InterruptedException e1)
                {
                    e1.printStackTrace();
                }
                try
                {
                    notEmpty.acquire();//顺序不能颠倒，否则会造成死锁。
                    mutex.acquire();
                    count--;
                    System.out.println(Thread.currentThread().getName()
                            + &quot;消费者消费，目前总共有&quot; + count);
                }
                catch (Exception e)
                {
                    e.printStackTrace();
                }
                finally
                {
                    mutex.release();
                    notFull.release();
                }

            }

        }

    }

    public static void main(String[] args) throws Exception
    {
        Hosee hosee = new Hosee();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();

        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
    }

}
</code></pre>
<h2 id="PipedInputStream-PipedOutputStream"><a href="#PipedInputStream-PipedOutputStream" class="headerlink" title="PipedInputStream / PipedOutputStream"></a>PipedInputStream / PipedOutputStream</h2><p>这个类位于java.io包中，是解决同步问题的最简单的办法，一个线程将数据写入管道，另一个线程从管道读取数据，这样便构成了一种生产者/消费者的缓冲区编程模式。PipedInputStream/PipedOutputStream只能用于多线程模式，用于单线程下可能会引发死锁。</p>
<pre><code class="java">package test;

import java.io.IOException;
import java.io.PipedInputStream;
import java.io.PipedOutputStream;

public class Hosee {
    final PipedInputStream pis = new PipedInputStream();
    final PipedOutputStream pos = new PipedOutputStream();
    {
        try {
            pis.connect(pos);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    class Producer implements Runnable {
        @Override
        public void run() {
            try{
                while(true){
                    int b = (int) (Math.random() * 255);
                    System.out.println(&quot;Producer: a byte, the value is &quot; + b);
                    pos.write(b);
                    pos.flush();
                }
            }catch(Exception e){
                e.printStackTrace();
            }finally{
                try{
                    pos.close();
                    pis.close();
                }catch(IOException e){
                    System.out.println(e);
                }
            }
        }
    }

    class Consumer implements Runnable {

        @Override
        public void run() {
            try{
                while(true){
                    int b = pis.read();
                    System.out.println(&quot;Consumer: a byte, the value is &quot; + String.valueOf(b));
                }
            }catch(Exception e){
                e.printStackTrace();
            }finally{
                try{
                    pos.close();
                    pis.close();
                }catch(IOException e){
                    System.out.println(e);
                }
            }
        }

    }

    public static void main(String[] args) throws Exception {
        Hosee hosee = new Hosee();
        new Thread(hosee.new Producer()).start();
        new Thread(hosee.new Consumer()).start();
    }

}
</code></pre>
<p>与阻塞队列一样，由于read()/write()方法与输出方法不一定同步，输出结果方面会发生不匹配现象，为了使结果更加明显，这里只有1个消费者和1个生产者。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ForkJoinPool]]></title>
      <url>/2020/11/25/juc-18/</url>
      <content type="html"><![CDATA[<p>直接看这篇文章吧，我觉得了解就好了，实际似乎用的场景很少？</p>
<p><a href="http://blog.dyngr.com/blog/2016/09/15/java-forkjoinpool-internals/" target="_blank" rel="noopener">http://blog.dyngr.com/blog/2016/09/15/java-forkjoinpool-internals/</a></p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ThreadPoolExecutor]]></title>
      <url>/2020/11/25/juc-17/</url>
      <content type="html"><![CDATA[<h2 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h2><p><img src="https://i.loli.net/2020/11/25/2F5etwLdmrR9fTn.png" alt="image.png"></p>
<h2 id="线程池的主要处理流程"><a href="#线程池的主要处理流程" class="headerlink" title="线程池的主要处理流程"></a>线程池的主要处理流程</h2><p><img src="https://i.loli.net/2020/11/25/i8es5gX9SJwD7GC.png" alt="image.png"></p>
<p>根据返回的对象类型创建线程池可以分为三类：</p>
<ul>
<li><p>创建返回ThreadPoolExecutor对象</p>
</li>
<li><p>创建返回ScheduleThreadPoolExecutor对象</p>
</li>
<li><p>创建返回ForkJoinPool对象</p>
</li>
</ul>
<h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><p>在介绍Executors创建线程池方法前先介绍一下ThreadPoolExecutor，因为这些创建线程池的静态方法都是返回ThreadPoolExecutor对象，和我们手动创建ThreadPoolExecutor对象的区别就是我们不需要自己传构造函数的参数。</p>
<p>ThreadPoolExecutor的构造函数共有四个，但最终调用的都是同一个：</p>
<pre><code class="java">public ThreadPoolExecutor(int corePoolSize, // 线程池核心线程数量
                          int maximumPoolSize, // 线程池最大数量
                          long keepAliveTime, // 空闲线程存活时间
                          TimeUnit unit, // 时间单位
                          BlockingQueue&lt;Runnable&gt; workQueue, // 线程池所使用的缓冲队列
                          ThreadFactory threadFactory, // 线程池创建线程使用的工厂
                          RejectedExecutionHandler handler // 线程池对拒绝任务的处理策略
                          );
</code></pre>
<h3 id="Executors-newCachedThreadPool方法"><a href="#Executors-newCachedThreadPool方法" class="headerlink" title="Executors#newCachedThreadPool方法"></a>Executors#newCachedThreadPool方法</h3><pre><code class="java">public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue&lt;Runnable&gt;());
}
</code></pre>
<ul>
<li>corePoolSize =&gt; 0，核心线程池的数量为0</li>
<li>maximumPoolSize =&gt; Integer.MAX_VALUE，可以认为最大线程数是无限的</li>
<li>keepAliveTime =&gt; 60L</li>
<li>unit =&gt; 秒</li>
<li>workQueue =&gt; SynchronousQueue</li>
</ul>
<p>当一个任务提交时，corePoolSize为0不创建核心线程，SynchronousQueue是一个不存储元素的队列，可以理解为队里永远是满的，因此最终会创建非核心线程来执行任务。<br>对于非核心线程空闲60s时将被回收。因为Integer.MAX_VALUE非常大，可以认为是可以无限创建线程的，在资源有限的情况下容易引起OOM异常</p>
<h3 id="Executors-newSingleThreadExecutor方法"><a href="#Executors-newSingleThreadExecutor方法" class="headerlink" title="Executors#newSingleThreadExecutor方法"></a>Executors#newSingleThreadExecutor方法</h3><pre><code class="java">public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue&lt;Runnable&gt;()));
}
</code></pre>
<ul>
<li>corePoolSize =&gt; 1，核心线程池的数量为1</li>
<li>maximumPoolSize =&gt; 1，只可以创建一个非核心线程</li>
<li>keepAliveTime =&gt; 0L</li>
<li>unit =&gt; 秒</li>
<li>workQueue =&gt; LinkedBlockingQueue</li>
</ul>
<p>当一个任务提交时，首先会创建一个核心线程来执行任务，如果超过核心线程的数量，将会放入队列中，因为LinkedBlockingQueue是长度为Integer.MAX_VALUE的队列，可以认为是无界队列，因此往队列中可以插入无限多的任务，在资源有限的时候容易引起OOM异常，同时因为无界队列，maximumPoolSize和keepAliveTime参数将无效，压根就不会创建非核心线程</p>
<h2 id="Executors-newFixedThreadPool方法"><a href="#Executors-newFixedThreadPool方法" class="headerlink" title="Executors#newFixedThreadPool方法"></a>Executors#newFixedThreadPool方法</h2><pre><code class="java">public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&lt;Runnable&gt;());
}
</code></pre>
<ul>
<li>corePoolSize =&gt; 1，核心线程池的数量为1</li>
<li>maximumPoolSize =&gt; 1，只可以创建一个非核心线程</li>
<li>keepAliveTime =&gt; 0L</li>
<li>unit =&gt; 秒</li>
<li>workQueue =&gt; LinkedBlockingQueue</li>
</ul>
<p>它和SingleThreadExecutor类似，唯一的区别就是核心线程数不同，并且由于使用的是LinkedBlockingQueue，在资源有限的时候容易引起OOM异常</p>
<p>总结：<br>FixedThreadPool和SingleThreadExecutor =&gt; 允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而引起OOM异常<br>CachedThreadPool =&gt; 允许创建的线程数为Integer.MAX_VALUE，可能会创建大量的线程，从而引起OOM异常<br>这就是为什么禁止使用Executors去创建线程池，而是推荐自己去创建ThreadPoolExecutor的原因</p>
<p>顺便说一下ScheduledThreadPoolExecutor，就不分析源码了：</p>
<p>ScheduledThreadPoolExecutor继承ThreadPoolExecutor来重用线程池的功能，它的实现方式如下：</p>
<ul>
<li>将任务封装成ScheduledFutureTask对象，ScheduledFutureTask基于相对时间，不受系统时间的改变所影响；</li>
<li>ScheduledFutureTask实现了java.lang.Comparable接口和java.util.concurrent.Delayed接口，所以有两个重要的方法：compareTo和getDelay。compareTo方法用于比较任务之间的优先级关系，如果距离下次执行的时间间隔较短，则优先级高；getDelay方法用于返回距离下次任务执行时间的时间间隔；</li>
<li>ScheduledThreadPoolExecutor定义了一个DelayedWorkQueue，它是一个有序队列，会通过每个任务按照距离下次执行时间间隔的大小来排序；</li>
<li>ScheduledFutureTask继承自FutureTask，可以通过返回Future对象来获取执行的结果。</li>
</ul>
<p>如何定义线程池参数:</p>
<ul>
<li>CPU密集型 =&gt; 线程池的大小推荐为CPU数量 + 1，CPU数量可以根据Runtime.availableProcessors方法获取</li>
<li>IO密集型 =&gt; CPU数量 <em> CPU利用率 </em> (1 + 线程等待时间/线程CPU时间)</li>
<li>混合型 =&gt; 将任务分为CPU密集型和IO密集型，然后分别使用不同的线程池去处理，从而使每个线程池可以根据各自的工作负载来调整</li>
<li>阻塞队列 =&gt; 推荐使用有界队列，有界队列有助于避免资源耗尽的情况发生</li>
<li>拒绝策略 =&gt; <ul>
<li>直接丢弃（DiscardPolicy）</li>
<li>丢弃队列中最老的任务(DiscardOldestPolicy)。</li>
<li>抛异常(AbortPolicy)</li>
<li>将任务分给调用线程来执行(CallerRunsPolicy)。<br>默认采用的是AbortPolicy拒绝策略，直接在程序中抛出RejectedExecutionException异常【因为是运行时异常，不强制catch】，这种处理方式不够优雅。处理拒绝策略有以下几种比较推荐：</li>
<li>在程序中捕获RejectedExecutionException异常，在捕获异常中对任务进行处理。针对默认拒绝策略</li>
<li>使用CallerRunsPolicy拒绝策略，该策略会将任务交给调用execute的线程执行【一般为主线程】，此时主线程将在一段时间内不能提交任何任务，从而使工作线程处理正在执行的任务。此时提交的线程将被保存在TCP队列中，TCP队列满将会影响客户端，这是一种平缓的性能降低</li>
<li>自定义拒绝策略，只需要实现RejectedExecutionHandler接口即可</li>
<li>如果任务不是特别重要，使用DiscardPolicy和DiscardOldestPolicy拒绝策略将任务丢弃也是可以的</li>
</ul>
</li>
<li>如果使用Executors的静态方法创建ThreadPoolExecutor对象，可以通过使用Semaphore对任务的执行进行限流也可以避免出现OOM异常</li>
</ul>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><h3 id="核心属性"><a href="#核心属性" class="headerlink" title="核心属性"></a>核心属性</h3><pre><code class="java">// 状态控制属性：高3位表示线程池的运行状态，剩下的29位表示当前有效的线程数量
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));

// 线程池的基本大小，当提交一个任务到线程池时，线程池会创建一个线程来执行任务，
// 即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于
// 线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，
// 线程池会提前创建并启动所有基本线程。
private volatile int corePoolSize;

// 线程池线程最大数量，如果队列满了，并且已创建的线程数小于最大线程数，
// 则线程池会再创建新的线程执行任务。如果使用了无界的任务队列这个参数就没什么效果。
private volatile int maximumPoolSize;

// 用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设 置更有意义的名字。
private volatile ThreadFactory threadFactory;

// 饱和策略，默认情况下是AbortPolicy。
private volatile RejectedExecutionHandler handler;

// 线程池的工作线程空闲后，保持存活的时间。如果任务很多，并且每个任务执行的时间比较短，
// 可以调大时间，提高线程的利用率。
private volatile long keepAliveTime;

// 用于保存等待执行的任务的阻塞队列，具体可以参考[JAVA并发容器-阻塞队列](https://www.jianshu.com/p/5646fb5faee1)
private final BlockingQueue&lt;Runnable&gt; workQueue;

// 存放工作线程的容器，必须获取到锁才能访问
private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();

// ctl的拆包和包装
private static int runStateOf(int c)     { return c &amp; ~CAPACITY; }
private static int workerCountOf(int c)  { return c &amp; CAPACITY; }
private static int ctlOf(int rs, int wc) { return rs | wc; }

// 阻塞队列参考之前的文章
// ctl状态控制属性，高3位表示线程池的运行状态（runState），剩下的29位表示当前有效的线程数量（workerCount）
// 线程池最大线程数是(1 &lt;&lt; COUNT_BITS) - 1 = 536 870 911
</code></pre>
<h3 id="线程池的运行状态runState"><a href="#线程池的运行状态runState" class="headerlink" title="线程池的运行状态runState"></a>线程池的运行状态runState</h3><table>
<thead>
<tr>
<th>状态</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>RUNNING</td>
<td>运行态，可处理新任务并执行队列中的任务</td>
</tr>
<tr>
<td>SHUTDOW</td>
<td>关闭态，不接受新任务，但处理队列中的任务</td>
</tr>
<tr>
<td>STOP</td>
<td>停止态，不接受新任务，不处理队列中任务，且打断运行中任务</td>
</tr>
<tr>
<td>TIDYING</td>
<td>整理态，所有任务已经结束，workerCount = 0 ，将执行terminated()方法</td>
</tr>
<tr>
<td>TERMINATED</td>
<td>结束态，terminated() 方法已完成</td>
</tr>
</tbody>
</table>
<p><img src="https://i.loli.net/2020/11/25/kdPgAxHU8evOSsn.png" alt="image.png"></p>
<h3 id="核心内部类-Worker"><a href="#核心内部类-Worker" class="headerlink" title="核心内部类 Worker"></a>核心内部类 Worker</h3><pre><code class="JAVA">
```private final class Worker  extends AbstractQueuedSynchronizer  implements Runnable {
    // 正在执行任务的线程
    final Thread thread;
    // 线程创建时初始化的任务
    Runnable firstTask;
    // 完成任务计数器
    volatile long completedTasks;

    Worker(Runnable firstTask) {
        // 在runWorker方法运行之前禁止中断，要中断线程必须先获取worker内部的互斥锁
        setState(-1); // inhibit interrupts until runWorker
        this.firstTask = firstTask;
        this.thread = getThreadFactory().newThread(this);
    }

    /** delegates main run loop to outer runworker  */
    // 直接委托给外部runworker方法
    public void run() {
        runWorker(this);
    }
    // Lock methods
    //
    // The value 0 represents the unlocked state.
    // The value 1 represents the locked state.

    protected boolean isHeldExclusively() {
        return getState() != 0;
    }

    // 重写的aqs方法，直接cas
    protected boolean tryAcquire(int unused) {
        if (compareAndSetState(0, 1)) {
            setExclusiveOwnerThread(Thread.currentThread());
            return true;
        }
        return false;
    }

    // 重写方法，直接release
    protected boolean tryRelease(int unused) {
        setExclusiveOwnerThread(null);
        setState(0);
        return true;
    }
}
</code></pre>
<p>Worker 类将执行任务的线程封装到了内部，在初始化Worker 的时候，会调用ThreadFactory初始化新线程；Worker 继承了AbstractQueuedSynchronizer，在内部实现了一个互斥锁，主要目的是控制工作线程的中断状态。</p>
<p>线程的中断一般是由其他线程发起的，比如<code>ThreadPoolExecutor#interruptIdleWorkers(boolean)</code>方法，它在调用过程中会去中断worker内部的工作线程，Work的互斥锁可以保证正在执行的任务不被打断。它是怎么保证的呢？在线程真正执行任务的时候，也就是runWorker方法被调用时，它会先获取到Work的锁，当我们在其他线程需要中断当前线程时也需要获取到work的互斥锁，否则不能中断。</p>
<h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p>前文说过了</p>
<pre><code class="java">    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue&lt;Runnable&gt; workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize &lt; 0 ||
            maximumPoolSize &lt;= 0 ||
            maximumPoolSize &lt; corePoolSize ||
            keepAliveTime &lt; 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }
</code></pre>
<h3 id="execute-提交线程"><a href="#execute-提交线程" class="headerlink" title="execute() 提交线程"></a>execute() 提交线程</h3><pre><code class="java">public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    // 获取控制的值
    int c = ctl.get();
    // 判断工作线程数是否小于corePoolSize
    if (workerCountOf(c) &lt; corePoolSize) {
        // 新创建核心线程
        if (addWorker(command, true))
            return;
        c = ctl.get();
    }
    // 工作线程数大于或等于corePoolSize
    // 判断线程池是否处于运行状态，如果是将任务command入队
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        int recheck = ctl.get();
        // 再次检查线程池的运行状态，如果不在运行中，那么将任务从队列里面删除，并尝试结束线程池
        if (!isRunning(recheck) &amp;&amp; remove(command))
            // 调用驱逐策略
            reject(command);
        // 检查活跃线程总数是否为0
        else if (workerCountOf(recheck) == 0)
            // 新创建非核心线程
            addWorker(null, false);
    }
    // 队列满了，新创建非核心线程
    else if (!addWorker(command, false))
        // 调用驱逐策略
        reject(command);
}
</code></pre>
<p>excute()方法中添加任务的方式是使用addWorker（）方法。</p>
<h3 id="addWorker-新创建线程"><a href="#addWorker-新创建线程" class="headerlink" title="addWorker() 新创建线程"></a>addWorker() 新创建线程</h3><pre><code class="java">private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    // 外层循环，用于判断线程池状态
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        // 仅在必要的时候检查队列是否为NULL
        // 检查队列是否处于非运行状态
        if (rs &gt;= SHUTDOWN &amp;&amp;
            ! (rs == SHUTDOWN &amp;&amp;
               firstTask == null &amp;&amp;
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            // 内层的循环，任务是将worker数量加1
            // 获取活跃线程数
            int wc = workerCountOf(c);
            // 判断线程是否超过最大值，当队列满了则验证线程数是否大于maximumPoolSize，
            // 没有满则验证corePoolSize
            if (wc &gt;= CAPACITY ||
                wc &gt;= (core ? corePoolSize : maximumPoolSize))
                return false;
            // 增加活跃线程总数，否则重试
            if (compareAndIncrementWorkerCount(c))
                // 如果成功跳出外层循环
                break retry;
            c = ctl.get();  // Re-read ctl
            // 再次校验一下线程池运行状态
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }
// worker加1后，接下来将woker添加到HashSet&lt;Worker&gt; workers中，并启动worker
    // 工作线程是否启动
    boolean workerStarted = false;
    // 工作线程是否创建
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 新创建线程
        w = new Worker(firstTask);
        // 获取新创建的线程
        final Thread t = w.thread;
        if (t != null) {
            // 创建线程要获得全局锁
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());
                // 检查线程池的运行状态
                if (rs &lt; SHUTDOWN ||
                    (rs == SHUTDOWN &amp;&amp; firstTask == null)) {
                    // 检查线程的状态
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    // 将新建工作线程存放到容器
                    workers.add(w);
                    int s = workers.size();
                    if (s &gt; largestPoolSize) {
                        // 跟踪线程池最大的工作线程总数
                        largestPoolSize = s;
                    }
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            // 启动工作线程
            if (workerAdded) {
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            // 启动新的工作线程失败，
            // 1. 将工作线程移除workers容器
            // 2. 还原工作线程总数（workerCount）
            // 3. 尝试结束线程
            addWorkerFailed(w);
    }
    return workerStarted;
}
</code></pre>
<p>如果启动新线程失败那么addWorkerFailed()这个方法将做一下三件事：</p>
<ul>
<li>将工作线程移除workers容器</li>
<li>还原工作线程总数（workerCount）</li>
<li>尝试结束线程</li>
</ul>
<h3 id="execute-执行过程"><a href="#execute-执行过程" class="headerlink" title="execute() 执行过程"></a>execute() 执行过程</h3><p><img src="https://i.loli.net/2020/11/25/ATZyz3X4kJv9wR1.png" alt="image.png"></p>
<ul>
<li>如果当前运行的线程少于corePoolSize，即使有空闲线程也会创建新线程来执行任务，（注意，执行这一步骤 需要获取全局锁）。如果调用了线程池的restartAllCoreThreads()方法， 线程池会提前创建并启动所有基本线程。</li>
<li>如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</li>
<li>如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执<br>行这一步骤需要获取全局锁）。</li>
<li>如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用 RejectedExecutionHandler.rejectedExecution()方法。</li>
</ul>
<h3 id="线程任务的执行"><a href="#线程任务的执行" class="headerlink" title="线程任务的执行"></a>线程任务的执行</h3><p>线程的正在执行是<code>ThreadPoolExecutor.Worker#run()</code>方法，但是这个方法直接委托给了外部的runWorker()方法，源码如下：</p>
<pre><code class="java">// 直接委托给外部runworker方法
public void run() {
    runWorker(this);
}
</code></pre>
<h3 id="runWorker-执行任务"><a href="#runWorker-执行任务" class="headerlink" title="runWorker() 执行任务"></a>runWorker() 执行任务</h3><pre><code class="java">final void runWorker(Worker w) {
    // 当前Work中的工作线程
    Thread wt = Thread.currentThread();
    // 获取初始任务
    Runnable task = w.firstTask;
    // 初始任务置NULL(表示不是建线程)
    w.firstTask = null;
    // 修改锁的状态，使需发起中断的线程可以获取到锁（使工作线程可以响应中断）
    // 因为worker初始化的时候setState(-1); 
    // 根据注释, 这样做的原因是为了抑制工作线程的 interrupt 信号, 直到此工作线程正是开始执行 task. 
    // 那么在 addWorker 中的 w.unlock(); 就是允许 Worker 的 interrupt 信号.
    w.unlock(); // allow interrupts
    // 工作线程是否是异常结束
    boolean completedAbruptly = true;
    try {
        // 循环的从队列里面获取任务
        while (task != null || (task = getTask()) != null) {
            // 每次执行任务时需要获取到内置的互斥锁
            w.lock();
            // 1. 当前工作线程不是中断状态，且线程池是STOP,TIDYING,TERMINATED状态，我们需要中断当前工作线程
            // 2. 当前工作线程是中断状态，且线程池是STOP,TIDYING,TERMINATED状态，我们需要中断当前工作线程
            if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP)))
                    &amp;&amp; !wt.isInterrupted())
                // 中断线程，中断标志位设置成true
                wt.interrupt();
            try {
                // 执行任务前置方法,扩展用
                beforeExecute(wt, task);
                Throwable thrown = null;
                try {
                    // 执行任务
                    task.run();
                } catch (RuntimeException x) {
                    thrown = x; throw x;
                } catch (Error x) {
                    thrown = x; throw x;
                } catch (Throwable x) {
                    thrown = x; throw new Error(x);
                } finally {
                    // 执行任务后置方法,扩展用
                    afterExecute(task, thrown);
                }
            } finally {
                // 任务NULL表示已经处理了
                task = null;
                w.completedTasks++;
                w.unlock();
            }
        }
        completedAbruptly = false;
    } finally {
        // 队列里没任务的时候
        // 将工作线程从容器中剔除
        processWorkerExit(w, completedAbruptly);
    }
}
</code></pre>
<p>正在执行线程的方法，执行流程：</p>
<ul>
<li>获取到当前的工作线程</li>
<li>获取初始化的线程任务</li>
<li>修改锁的状态，使工作线程可以响应中断</li>
<li>获取工作线程的锁（保证在任务执行过程中工作线程不被外部线程中断），如果获取到的任务是NULL，则结束当前工作线程</li>
<li>判断先测试状态，看是否需要中断当前工作线程</li>
<li>执行任务前置方法beforeExecute(wt, task);</li>
<li>执行任务(执行提交到线程池的线程)task.run();</li>
<li>执行任务后置方法afterExecute(task, thrown);，处理异常信息</li>
<li>修改完成任务的总数</li>
<li>解除当前工作线程的锁</li>
<li>获取队列里面的任务，循环第4步</li>
<li>将工作线程从容器中剔除</li>
</ul>
<pre><code>- `wt.isInterrupted()`：获取中断状态，无副作用
- `Thread.interrupted()`：获取中断状态，并将中断状态恢重置成false(不中断)
- `beforeExecute(wt, task)`：执行任务前置方法，扩展用。如果这个方法在执行过程中抛出异常，那么会导致当前工作线程直接死亡而被回收，工作线程异常结束标记位completedAbruptly被设置成true，任务线程不能被执行
- `task.run()`： 执行任务
- `afterExecute(task, thrown)`：执行任务后置方法，扩展用。这个方法可以收集到任务运行的异常信息，这个方法如果有异常抛出，也会导致当前工作线程直接死亡而被回收，工作线程异常结束标记位completedAbruptly被设置成true
- 任务运行过程中的异常信息除了RuntimeException以外，其他全部封装成Error，然后被afterExecute方法收集
- `terminated()`这也是一个扩展方法，在线程池结束的时候调用
</code></pre><h3 id="getTask-获取任务"><a href="#getTask-获取任务" class="headerlink" title="getTask() 获取任务"></a>getTask() 获取任务</h3><p>主要从q里拿任务</p>
<pre><code class="java">private Runnable getTask() {
    // 记录最后一次获取任务是不是超时了
    boolean timedOut = false; // Did the last poll() time out?

    for (;;) {
        int c = ctl.get();
        // 获取线程池状态
        int rs = runStateOf(c);

        // 线程池是停止状态或者状态是关闭并且队列为空
        if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) {
            // 扣减工作线程总数
            decrementWorkerCount();
            return null;
        }
        // 获取工作线程总数
        int wc = workerCountOf(c);

        // 工作线程是否需要剔除
        boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;

        if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))
            &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) {
            // 扣减工作线程总数
            if (compareAndDecrementWorkerCount(c))
                // 剔除工作线程，当返回为NULL的时候，runWorker方法的while循环会结束
                return null;
            continue;
        }

        try {
            Runnable r = timed ?
                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                workQueue.take();
            if (r != null)
                return r;
            timedOut = true;
        } catch (InterruptedException retry) {
            timedOut = false;
        }
    }
}
</code></pre>
<p>getTask() 阻塞或定时获取任务。当该方法返回NULL时，当前工作线程会结束，最后被回收，下面是返回NULL的几种情况：</p>
<ul>
<li>当前工作线程总数wc大于maximumPoolSize最大工作线程总数。maximumPoolSize可能被setMaximumPoolSize方法改变。</li>
<li>当线程池处于停止状态时。</li>
<li>当线程池处于关闭状态且阻塞队列为空。</li>
<li>当前工作线程超时等待任务，并且当前工作线程总数wc大于corePoolSize或者allowCoreThreadTimeOut=true允许核心线程超时被回收，默认是false。</li>
<li>线程池在运行过程中可以调用setMaximumPoolSize()方法来修改maximumPoolSize值，新的值必须大于corePoolSize，如果新的maximumPoolSize小于原来的值，那么在该方法会去中断当前的空闲线程(工作线程内置锁的是解锁状态的线程为空闲线程)。</li>
</ul>
<h3 id="processWorkerExit-工作线程结束"><a href="#processWorkerExit-工作线程结束" class="headerlink" title="processWorkerExit() 工作线程结束"></a>processWorkerExit() 工作线程结束</h3><pre><code class="java">private void processWorkerExit(Worker w, boolean completedAbruptly) {
    // 判断是否是异常情况导致工作线程被回收
    if (completedAbruptly) // If abrupt, then workerCount wasn&#39;t adjusted
        // 如果是扣减工作线程总数，如果不是在getTask()方法就已经扣减了
        decrementWorkerCount();

    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        // 将当前工作线程完成任务的总数加到completedTaskCount标志位上
        completedTaskCount += w.completedTasks;
        // 剔除当前工作线程
        workers.remove(w);
    } finally {
        mainLock.unlock();
    }
    // 尝试结束线程池
    tryTerminate();

    // 判刑是否需要新实例化工程线程
    int c = ctl.get();
    if (runStateLessThan(c, STOP)) {
        if (!completedAbruptly) {
            int min = allowCoreThreadTimeOut ? 0 : corePoolSize;
            if (min == 0 &amp;&amp; ! workQueue.isEmpty())
                min = 1;
            if (workerCountOf(c) &gt;= min)
                return; // replacement not needed
        }
        addWorker(null, false);
    }
}
</code></pre>
<p>剔除线程流程：</p>
<ul>
<li>判断是否是异常情况导致工作线程被回收，如果是workerCount–</li>
<li>获取到全局锁</li>
<li>将当前工作线程完成任务的总数加到completedTaskCount标志位上</li>
<li>剔除工作线程</li>
<li>解锁</li>
<li>尝试结束线程池tryTerminate()</li>
<li>判刑是否需要重新实例化工程线程放到workers容器</li>
</ul>
<h3 id="shutdown-关闭线程池"><a href="#shutdown-关闭线程池" class="headerlink" title="shutdown() 关闭线程池"></a>shutdown() 关闭线程池</h3><pre><code class="java">public void shutdown() {
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        // 检查权限
        checkShutdownAccess();
        // 设置线程池状态为关闭
        advanceRunState(SHUTDOWN);
        // 中断线程
        interruptIdleWorkers();
        // 扩展方法
        onShutdown(); // hook for ScheduledThreadPoolExecutor
    } finally {
        mainLock.unlock();
    }
    // 尝试结束线池
    tryTerminate();
}
</code></pre>
<ul>
<li>通过遍历工作线程容器workers，然后逐个中断工作线程，如果无法响应中断的任务可能永远无法终止</li>
<li>shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</li>
<li>正在执行的任务依旧会执行</li>
</ul>
<h3 id="shutdownNow-关闭线程池"><a href="#shutdownNow-关闭线程池" class="headerlink" title="shutdownNow() 关闭线程池"></a>shutdownNow() 关闭线程池</h3><pre><code class="java">public List&lt;Runnable&gt; shutdownNow() {
    List&lt;Runnable&gt; tasks;
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        // 检查权限
        checkShutdownAccess();
        // 设置线程池状态为停止状态
        advanceRunState(STOP);
        // 中断线程
        interruptIdleWorkers();
        // 将所有任务移动到list容器
        tasks = drainQueue();
    } finally {
        mainLock.unlock();
    }
    // 尝试结束线池
    tryTerminate();
    // 返回所有未执行的任务
    return tasks;
}
</code></pre>
<ul>
<li>通过遍历工作线程容器workers，然后逐个中断工作线程，如果无法响应中断的任务可能永远无法终止</li>
<li>shutdownNow首先将线程池的状态设置成 STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表</li>
</ul>
<h3 id="tryTerminate-尝试结束线程池"><a href="#tryTerminate-尝试结束线程池" class="headerlink" title="tryTerminate() 尝试结束线程池"></a>tryTerminate() 尝试结束线程池</h3><pre><code class="java">final void tryTerminate() {
    for (;;) {
        int c = ctl.get();
        //  判断是否在运行中,如果是直接返回
        if (isRunning(c) ||
            // 判断是否进入整理状态，如果进入了直接返回
            runStateAtLeast(c, TIDYING) ||
            // 如果是状态是关闭并且队列非空，也直接返回（关闭状态需要等到队列里面的线程处理完）
            (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty()))
            return;
        // 判断工作线程是否都关闭了
        if (workerCountOf(c) != 0) { // Eligible to terminate
            // 中断空闲线程
            interruptIdleWorkers(ONLY_ONE);
            return;
        }

        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            // 将状态替换成整理状态
            if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {
                try {
                    // 整理发放执行
                    terminated();
                } finally {
                    // 状态替换成结束状态
                    ctl.set(ctlOf(TERMINATED, 0));
                    termination.signalAll();
                }
                return;
            }
        } finally {
            mainLock.unlock();
        }
        // else retry on failed CAS
    }
}
</code></pre>
<p>结束线程池大致流程为：</p>
<ul>
<li>判断是否在运行中，如果是则不结束线程</li>
<li>判断是否进入整理状态，如果是也不用执行后面内容了</li>
<li>判断如果线程池是关闭状态并且队列非空，则不结束线程池（关闭状态需要等到队列里面的线程处理完）</li>
<li>判断工作线程是否都关闭了，如果没有就发起中断工作线程的请求</li>
<li>获取全局锁将线程池状态替换成整理状态</li>
<li>调用terminated();扩展方法（这也是一个扩展方法，在线程池结束的时候调用）</li>
<li>将线程池状态替换成结束状态</li>
<li>解除全局锁</li>
</ul>
<p>注意：</p>
<ul>
<li>我们可以通过的shutdown或shutdownNow方法来结束线程池。他们都是通过遍历工作线程容器，然后逐个中断工作线程，所以无法响应中断的任务 可能永远无法终止。</li>
<li>shutdown和shutdownNow的区别在于：shutdownNow首先将线程池的状态设置成 STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表；而 shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</li>
<li>只要调用了shutdown和shutdownNow那么isShutdown方法就会返回true<br>当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true<br>。</li>
</ul>
<p>总结下，worker里面包着thread，thread执行task，线程池初始化是没有worker（可以通过prestartAllCoreThreads预处理），直到真正提交task的时候才开始初始化worker，task执行结束后，会再从queue里拿task，没有的话就会阻塞，以保持线程不会被销毁（waiting状态），保持了核心线程的活跃。特殊情况，例如task中抛出异常，worker会被回收，但如果回收后的线程数量少于核心线程时，就又会建立一个新的没有task的worker。</p>
<p>线程池需要关闭么？</p>
<p>局部线程池在确定不会使用的情况下需要关闭。</p>
<p>如何优雅的让线程池自动关闭？</p>
<ul>
<li>核心线程数为 0 并指定线程存活时间</li>
<li>通过 allowCoreThreadTimeOut 控制核心线程存活时间</li>
</ul>
<p>最后上张图</p>
<p><img src="https://i.loli.net/2020/11/25/1XPFJerVGqEv7ni.png" alt="image.png"></p>
<p>最最后，线程池是可以执行runnable callable future的，三着区别详见：<a href="https://zhuanlan.zhihu.com/p/88933756" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/88933756</a></p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ConcurrentSkipListMap]]></title>
      <url>/2020/11/25/juc-16/</url>
      <content type="html"><![CDATA[<h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><p>对于一个单链表，即使链表是有序的，如果我们想要在其中查找某个数据，也只能从头到尾遍历链表，这样效率自然就会很低。而跳表是在这个单链表的基础上同时维护了多个链表，并且链表是分层的。</p>
<p><img src="https://s3.ax1x.com/2020/11/25/DaiIzD.png" alt="DaiIzD.png"></p>
<p>最低层的链表维护了跳表内所有的元素，每上面一层链表都是下面一层的子集。</p>
<p>跳表内的所有链表的元素都是排序的。查找时，可以从顶级链表开始找。一旦发现被查找的元素大于当前链表中的取值，就会转入下一层链表继续找。这也就是说在查找过程中，搜索是跳跃式的。如上图所示，在跳表中查找元素 18。</p>
<p><img src="https://i.loli.net/2020/11/25/G3FKLseBHM6Jt7l.png" alt="image.png"></p>
<p>查找 18 的时候原来需要遍历 12 次，现在只需要 7 次即可。针对链表长度比较大的时候，构建索引查找效率的提升就会非常明显。</p>
<p>使用跳表实现 Map 和使用哈希算法实现 Map 的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。</p>
<p>在 JDK 的 ConcurrentSkipListMap 实现中，没有使用到锁，而是通过 CAS 来进行数据的修改，当插入数据时，通过 CAS 修改最下层列表的内容，然后再逐层向上维护各级列表（各层列表的修改都是通过 CAS 完成），这两个过程是独立的，因为上层列表维护的数据少也只会影响查找数据的速度，而不会影响到数据的准确性，因为添加与查找数据都以最下层列表内容为准。</p>
<h2 id="ConcurrentSkipListMap的跳表内部实现"><a href="#ConcurrentSkipListMap的跳表内部实现" class="headerlink" title="ConcurrentSkipListMap的跳表内部实现"></a>ConcurrentSkipListMap的跳表内部实现</h2><p>内部节点类 Node</p>
<pre><code class="java">static final class Node&lt;K, V&gt;{
    final K key;  // key 是 final 的, 说明节点一旦定下来, 除了删除, 不然不会改动 key 了
    volatile Object value; // 对应的 value
    volatile Node&lt;K, V&gt; next; // 下一个节点

    // 构造函数
    public Node(K key, Object value, Node&lt;K, V&gt; next) {
        this.key = key;
        this.value = value;
        this.next = next;
    }

    /**
     * 创建一个标记节点(通过 this.value = this 来标记)
     * 这个标记节点非常重要: 有了它, 就能对链表中间节点进行同时删除了插入
     * ps: ConcurrentLinkedQueue 只能在头上, 尾端进行插入, 中间进行删除 
     */
    public Node(Node&lt;K, V&gt; next) {
        this.key = null;
        this.value = this;
        this.next = next;
    }

    /**
     * CAS 操作设置 Value
     */
    boolean casValue(Object cmp, Object val){
        return unsafe.compareAndSwapObject(this, valueOffset, cmp, val);
    }

    /**
     * CAS 操作设置 next
     */
    boolean casNext(Node&lt;K, V&gt; cmp, Node&lt;K, V&gt; val){
        return unsafe.compareAndSwapObject(this, nextOffset, cmp, val);
    }

    /**
     * 检测是否为标记节点
     */
    boolean isMarker(){
        return value == this;
    }

    /**
     * 检测是否为 链表最左下角的 BASE_HEADER 节点
     */
    boolean isBaseHeader(){
        return value == BASE_HEADER;
    }

    /**
     * 对节点追加一个标记节点, 为最终的删除做准备
     */
    boolean appendMarker(Node&lt;K, V&gt; f){
        return casNext(f, new Node&lt;K, V&gt;(f));
    }

    /**
     * Help out a deletion by appending marker or unlinking from
     * predecessor. This called during traversals when value
     * field seen to be null
     * 
     * helpDelete 方法, 这个方法要么追加一个标记节点, 要么进行删除操作
     */
    void helpDelete(Node&lt;K, V&gt; b, Node&lt;K, V&gt; f){
        /**
         * Rechecking links and then doing only one of the
         * help-out stages per call tends to minimize CAS
         * interference among helping threads
         */
        if(f == next &amp;&amp; this == b.next){
            if(f == null || f.value != f){ // 还没有对删除的节点进行节点 marker
                casNext(f, new Node&lt;K, V&gt;(f));
            }else{
                b.casNext(this, f.next); // 删除 节点 b 与 f.next 之间的节点
            }
        }
    }

    /**
     * 校验数据
     */
    V getValidValue(){
        Object v = value;
        if(v == this || v == BASE_HEADER){
            return null;
        }
        V vv = (V)v;
        return vv;
    }

    /**
     * Creates and returns a new SimpleImmutableEntry holding current
     * mapping if this node holds a valid value, else null.
     *
     * @return new entry or null
     */
    AbstractMap.SimpleImmutableEntry&lt;K, V&gt; createSnapshot(){
        Object v = value;
        if(v == null || v == this || v == BASE_HEADER){
            return null;
        }
        V vv = (V) v;
        return new AbstractMap.SimpleImmutableEntry&lt;K, V&gt;(key, vv);
    }

    // UNSAFE mechanics
    private static final Unsafe unsafe;
    private static final long valueOffset;
    private static final long nextOffset;

    static {
        try {
            unsafe = UnSafeClass.getInstance();
            Class&lt;?&gt; k = Node.class;
            valueOffset = unsafe.objectFieldOffset(k.getDeclaredField(&quot;value&quot;));
            nextOffset = unsafe.objectFieldOffset(k.getDeclaredField(&quot;next&quot;));
        }catch (Exception e){
            throw new Error(e);
        }
    }

}
</code></pre>
<p>索引节点 Index</p>
<pre><code class="java">static class Index&lt;K, V&gt;{

    final Node&lt;K, V&gt; node; // 索引指向的节点, 纵向上所有索引指向链表最下面的节点
    final Index&lt;K, V&gt; down; // 下边level层的 Index
    volatile Index&lt;K, V&gt; right; // 右边的  Index

    /**
     * Creates index node with given values
     * @param node
     * @param down
     * @param right
     */
    public Index(Node&lt;K, V&gt; node, Index&lt;K, V&gt; down, Index&lt;K, V&gt; right) {
        this.node = node;
        this.down = down;
        this.right = right;
    }

    /**
     * compareAndSet right field
     * @param cmp
     * @param val
     * @return
     */
    final boolean casRight(Index&lt;K, V&gt; cmp, Index&lt;K, V&gt; val){
        return unsafe.compareAndSwapObject(this, rightOffset, cmp, val);
    }

    /**
     * Returns true if the node this indexes has been deleted.
     * @return true if indexed node is known to be deleted
     */
    final boolean indexesDeletedNode(){
        return node.value == null;
    }

    /**
     * Tries to CAS newSucc as successor. To minimize races with
     * unlink that may lose this index node, if the node being
     * indexed is known to be deleted, it doesn&#39;t try to link in
     *
     * @param succ the expecteccurrent successor
     * @param newSucc the new successor
     * @return true if successful
     */
    /**
     * 在 index 本身 和 succ 之间插入一个新的节点 newSucc
     * @param succ
     * @param newSucc
     * @return
     */
    final boolean link(Index&lt;K, V&gt; succ, Index&lt;K, V&gt; newSucc){
        Node&lt;K, V&gt; n = node;
        newSucc.right = succ;
        return n.value != null  &amp;&amp; casRight(succ, newSucc);
    }

    /**
     * Tries to CAS field to skip over apparent successor
     * succ. Fails (forcing a retravesal by caller) if this node
     * is known to be deleted
     * @param succ the expected current successor
     * @return true if successful
     */
    /**
     * 将当前的节点 index 设置其的 right 为 succ.right 等于删除 succ 节点
     * @param succ
     * @return
     */
    final boolean unlink(Index&lt;K, V&gt; succ){
        return node.value != null &amp;&amp; casRight(succ, succ.right);
    }

    // Unsafe mechanics
    private static final Unsafe unsafe;
    private static final long rightOffset;

    static {
        try{
            unsafe = UnSafeClass.getInstance();
            Class&lt;?&gt; k = Index.class;
            rightOffset = unsafe.objectFieldOffset(k.getDeclaredField(&quot;right&quot;));
        }catch (Exception e){
            throw new Error(e);
        }
</code></pre>
<p>头索引节点 HeadIndex</p>
<pre><code class="java">/**
 * Nodes heading each level keep track of their level.
 */
//  level 属性用来标示索引层级; 注意所有的 HeadIndex 都指向同一个 Base_header 节点;
static final class HeadIndex&lt;K,V&gt; extends Index&lt;K,V&gt; {
    final int level;
    HeadIndex(Node&lt;K,V&gt; node, Index&lt;K,V&gt; down, Index&lt;K,V&gt; right, int level) {
        super(node, down, right);
        this.level = level;
    }
}
</code></pre>
<p>ConcurrentSkipListMap的put方法过去冗长和复杂，这里只上一个图解便于理解，就不上代码了，参考 <a href="https://www.jianshu.com/p/edc2fd149255" target="_blank" rel="noopener">https://www.jianshu.com/p/edc2fd149255</a><br>doPut步骤:<br>整个doPut方法看起来有点吓人, 但没事,我们将这个方法进行分割:</p>
<p>Part I：找到目标节点的位置并插入</p>
<ul>
<li>这里的目标节点是数据节点，也就是最底层的那条链；</li>
<li>寻找目标节点之前最近的一个索引对应的数据节点（数据节点都是在最底层的链表上）；</li>
<li>从这个数据节点开始往后遍历，直到找到目标节点应该插入的位置；</li>
<li>如果这个位置有元素，就更新其值（onlyIfAbsent=false）；</li>
<li>如果这个位置没有元素，就把目标节点插入；</li>
<li>至此，目标节点已经插入到最底层的数据节点链表中了；</li>
</ul>
<p>Part II：随机决定是否需要建立索引及其层次，如果需要则建立自上而下的索引</p>
<ul>
<li>取个随机数rnd，计算(rnd &amp; 0x80000001)；</li>
<li>如果不等于0，结束插入过程，也就是不需要创建索引，返回；</li>
<li>如果等于0，才进入创建索引的过程（只要正偶数才会等于0）；</li>
<li>计算while (((rnd &gt;&gt;&gt;= 1) &amp; 1) != 0)，决定层级数，level从1开始；</li>
<li>如果算出来的层级不高于现有最高层级，则直接建立一条竖直的索引链表（只有down有值），并结束Part II；</li>
<li>如果算出来的层级高于现有最高层级，则新的层级只能比现有最高层级多1；</li>
<li>同样建立一条竖直的索引链表（只有down有值）；</li>
<li>将头索引也向上增加到相应的高度，结束Part II；</li>
<li>也就是说，如果层级不超过现有高度，只建立一条索引链，否则还要额外增加头索引链的高度（脑补一下，后面举例说明）；</li>
</ul>
<p>Part III：将新建的索引节点（包含头索引节点）与其它索引节点通过右指针连接在一起（补上right指针）</p>
<ul>
<li>从最高层级的头索引节点开始，向右遍历，找到目标索引节点的位置；</li>
<li>如果当前层有目标索引，则把目标索引插入到这个位置，并把目标索引前一个索引向下移一个层级；</li>
<li>如果当前层没有目标索引，则把目标索引位置前一个索引向下移一个层级；</li>
<li>同样地，再向右遍历，寻找新的层级中目标索引的位置，回到第（2）步；</li>
<li>依次循环找到所有层级目标索引的位置并把它们插入到横向的索引链表中；</li>
</ul>
<p>总结起来，一共就是三大步：</p>
<ul>
<li>插入目标节点到数据节点链表中；</li>
<li>建立竖直的down链表；</li>
<li>建立横向的right链表；</li>
</ul>
<p>图解：</p>
<p>初始时, 只存在 HeadIndex 和 Base_Header 节点<br><img src="https://i.loli.net/2020/11/25/5o7LuKrHONkSCRq.png" alt="image.png"></p>
<p>添加 key=1, value = A 节点, 结果如图:<br><img src="https://i.loli.net/2020/11/25/RSJzn8pPLsG4qoZ.png" alt="image.png"></p>
<p>再添加一个节点2<br><img src="https://i.loli.net/2020/11/25/BgQ3ADuToWtVZp7.png" alt="image.png"></p>
<p>再次添加 key=3, value = C 节点<br><img src="https://i.loli.net/2020/11/25/OlwUhmug5QF29EB.png" alt="image.png"></p>
<p>这时再put节点 key=4 value = D (情形和 Node1, Node2 一样), 最终结果:<br><img src="https://i.loli.net/2020/11/25/GPqkx2Z4lXbVMot.png" alt="image.png"></p>
<p>再次添加 key=5, value = E 节点, 结果如图:<br><img src="https://i.loli.net/2020/11/25/JAEesmL5Zvluwcf.png" alt="image.png"></p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ConcurrentHashMap]]></title>
      <url>/2020/11/24/juc-15/</url>
      <content type="html"><![CDATA[<p>搬运自 <a href="https://my.oschina.net/xiaolyuh/blog/3080609" target="_blank" rel="noopener">https://my.oschina.net/xiaolyuh/blog/3080609</a>  略有修改</p>
<h2 id="jdk-1-7"><a href="#jdk-1-7" class="headerlink" title="jdk 1.7"></a>jdk 1.7</h2><p>在jdk1.7中，用的是锁分段技术：</p>
<p>底层存储结构<br>在 JDK1.7中，本质上还是采用链表+数组的形式存储键值对的。但是，为了提高并发，把原来的整个 table 划分为 n 个 Segment 。所以，从整体来看，它是一个由 Segment 组成的数组。然后，每个 Segment 里边是由 HashEntry 组成的数组，每个 HashEntry之间又可以形成链表。我们可以把每个 Segment 看成是一个小的 HashMap，其内部结构和 HashMap 是一模一样的。</p>
<p><img src="https://i.loli.net/2020/11/24/KTmC3ynGUb69ZQO.png" alt="image.png"></p>
<p>当对某个 Segment 加锁时，如图中 Segment2，并不会影响到其他 Segment 的读写。每个 Segment 内部自己操作自己的数据。这样一来，我们要做的就是尽可能的让元素均匀的分布在不同的 Segment中。最理想的状态是，所有执行的线程操作的元素都是不同的 Segment，这样就可以降低锁的竞争。</p>
<p>采用Segment数组结构和HashEntry数组结构组成，Segment数组的大小就是ConcurrentHashMap的并发度。Segment继承自ReentrantLock，所以他本身就是一个锁。Segment数组一旦初始化后就不会再进行扩容，这也是jdk1.8去掉他的原因。Segment里面又包含了一个table数组，这个数组是可以扩容的。</p>
<p>如图我们在定位数据的时候需要对key的hash值进行两次寻址操作，第一次找到在Segment数组的位置，第二次找到在table数组中的位置。</p>
<h3 id="Segment-类"><a href="#Segment-类" class="headerlink" title="Segment 类"></a>Segment 类</h3><pre><code class="java">// 直接继承自ReentrantLock，所以一个Segment本身就是一个锁
static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable { 
    ...
   // table数组  
   transient volatile HashEntry&lt;K,V&gt;[] table;

    // 一个Segment内的元素个数
    transient int count;

    // 扩容阈值
    transient int threshold;

    // 扩容因子
    final float loadFactor;

    Segment(float lf, int threshold, HashEntry&lt;K,V&gt;[] tab) {
        this.loadFactor = lf;
        this.threshold = threshold;
        this.table = tab;
    }
...
</code></pre>
<p>我们发现Segment直接继承自ReentrantLock，所以一个Segment本身就是一个锁。所以Segment数组的长度大小直接影响了ConcurrentHashMap的并发度。还有每个Segment单独维护了扩容阈值，扩容因子，所以每个Segment的扩容操作时完全独立互不干扰的。</p>
<h3 id="HashEntry-类"><a href="#HashEntry-类" class="headerlink" title="HashEntry 类"></a>HashEntry 类</h3><pre><code class="java">static final class HashEntry&lt;K,V&gt; {
    // 不可变
    final int hash;
    final K key;
    // volatile保证可见性，这样我们在get操作时就不用加锁了
    volatile V value;
    volatile HashEntry&lt;K,V&gt; next;

    HashEntry(int hash, K key, V value, HashEntry&lt;K,V&gt; next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }
...
}
</code></pre>
<h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><pre><code class="java">public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    //  参数校验
    if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)
        throw new IllegalArgumentException();
    // 并发度控制，最大是65536
    if (concurrencyLevel &gt; MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    // Find power-of-two sizes best matching arguments
    // 等于ssize从1向左移位的 次数
    int sshift = 0;
    int ssize = 1;
    // 找出最接近concurrencyLevel的2的n次幂的数值
    while (ssize &lt; concurrencyLevel) {
        ++sshift;
        ssize &lt;&lt;= 1;
    }
    // 这里之所 以用32是因为ConcurrentHashMap里的hash()方法输出的最大数是32位的
    this.segmentShift = 32 - sshift;
    // 散列运算的掩码，等于ssize减1
    this.segmentMask = ssize - 1;
    if (initialCapacity &gt; MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    int c = initialCapacity / ssize;
    if (c * ssize &lt; initialCapacity)
        ++c;
    // 里HashEntry数组的长度度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以cap不是1，就是2的N次方。
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    // 保证HashEntry数组大小一定是2的n次幂
    while (cap &lt; c)
        cap &lt;&lt;= 1;
    // create segments and segments[0]
    // 初始化Segment数组，并实际只填充Segment数组的第0个元素。
    Segment&lt;K,V&gt; s0 =
        new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor),
                         (HashEntry&lt;K,V&gt;[])new HashEntry[cap]);
    Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize];
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss;
}`
</code></pre>
<p>通过代码我们可以看出，在构造ConcurrentHashMap的时候我们就会完成以下件事情：</p>
<ul>
<li>确认ConcurrentHashMap的并发度，也就是Segment数组长度，并保证它是2的n次幂</li>
<li>确认HashEntry数组的初始化长度，并保证它是2的n次幂</li>
<li>将Segment数组初始化好并且只填充第0个元素</li>
</ul>
<h3 id="put-方法"><a href="#put-方法" class="headerlink" title="put() 方法"></a>put() 方法</h3><pre><code class="java">public V put(K key, V value) {
    Segment&lt;K,V&gt; s;
    if (value == null)
        throw new NullPointerException();
    // 1. 先获取key的hash值
    int hash = hash(key);
    int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;
    if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject          // nonvolatile; recheck
         (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //  in ensureSegment
        // 2. 定位到Segment
        s = ensureSegment(j);
    // 3.调用Segment的put方法
    return s.put(key, hash, value, false);
}
</code></pre>
<p>主要流程是：</p>
<ul>
<li>先获取key的hash值</li>
<li>定位到Segment</li>
<li>调用Segment的put方法</li>
</ul>
<h3 id="hash-方法"><a href="#hash-方法" class="headerlink" title="hash() 方法"></a>hash() 方法</h3><pre><code class="java">private int hash(Object k) {
        int h = hashSeed;

        if ((0 != h) &amp;&amp; (k instanceof String)) {
            return sun.misc.Hashing.stringHash32((String) k);
        }

        h ^= k.hashCode();

        // Spread bits to regularize both segment and index locations,
        // using variant of single-word Wang/Jenkins hash.
        h += (h &lt;&lt;  15) ^ 0xffffcd7d;
        h ^= (h &gt;&gt;&gt; 10);
        h += (h &lt;&lt;   3);
        h ^= (h &gt;&gt;&gt;  6);
        h += (h &lt;&lt;   2) + (h &lt;&lt; 14);
        return h ^ (h &gt;&gt;&gt; 16);
    }
</code></pre>
<p>这个方法大致思路是：先拿到key的hashCode，然后对这个值进行再散列。</p>
<h3 id="Segment-put-方法"><a href="#Segment-put-方法" class="headerlink" title="Segment.put() 方法"></a>Segment.put() 方法</h3><pre><code class="java">final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 1. 加锁
    HashEntry&lt;K,V&gt; node = tryLock() ? null :
            // scanAndLockForPut在没有获取到锁的情况下，去查询key是否存在，如果不存在就新建一个Node
        scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        HashEntry&lt;K,V&gt;[] tab = table;
        // 确定元素在table数组上的位置
        int index = (tab.length - 1) &amp; hash;
        HashEntry&lt;K,V&gt; first = entryAt(tab, index);
        for (HashEntry&lt;K,V&gt; e = first;;) {
            if (e != null) {
                K k;
                // 如果原来位置上有值并且key相同，那么直接替换原来的value
                if ((k = e.key) == key ||
                    (e.hash == hash &amp;&amp; key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            }
            else {
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry&lt;K,V&gt;(hash, key, value, first);
                // 元素总数加一
                int c = count + 1;
                // 判断是否需要扩容
                if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)
                    rehash(node);
                else
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        unlock();
    }
    return oldValue;
}
</code></pre>
<p>大致过程是：</p>
<ul>
<li>加锁</li>
<li>定位key在table数组上的索引位置index，获取到头结点</li>
<li>判断是否有hash冲突</li>
<li>如果没有冲突直接将新节点node添加到数组index索引位</li>
<li>如果有冲突，先判断是否有相同key</li>
<li>有相同key直接替换对应node的value值</li>
<li>没有添加新元素到链表尾部</li>
<li>解锁<br>这里需要注意的是scanAndLockForPut方法，他在没有获取到锁的时候不仅会通过自旋获取锁，还会做一些其他的查找或新增节点的工，以此来提升put性能。</li>
</ul>
<h3 id="Segment-scanAndLockForPut-方法"><a href="#Segment-scanAndLockForPut-方法" class="headerlink" title="Segment.scanAndLockForPut() 方法"></a>Segment.scanAndLockForPut() 方法</h3><pre><code class="java">private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) {
    //定位HashEntry数组位置，获取第一个节点
    HashEntry&lt;K,V&gt; first = entryForHash(this, hash);
    HashEntry&lt;K,V&gt; e = first;
    HashEntry&lt;K,V&gt; node = null;
    //扫描次数，循环标记位
    int retries = -1; // negative while locating node
    while (!tryLock()) {
        HashEntry&lt;K,V&gt; f; // to recheck first below
        // 表示遍历链表还没有结束
        if (retries &lt; 0) {
            if (e == null) {
                if (node == null) // speculatively create node
                    //  完成新节点初始化
                    node = new HashEntry&lt;K,V&gt;(hash, key, value, null);
                // 完成链表的遍历，还是没有找到相同key的节点
                retries = 0;
            }
            // 有hash冲突，开始查找是否有相同的key
            else if (key.equals(e.key))
                retries = 0;
            else
                e = e.next;
        }
        // 断循环次数是否大于最大扫描次数
        else if (++retries &gt; MAX_SCAN_RETRIES) {
            // 自旋获取锁
            lock();
            break;
        }
        // 每间隔一次循环，检查一次first节点是否改变
        else if ((retries &amp; 1) == 0 &amp;&amp;
                 (f = entryForHash(this, hash)) != first) {
            // 首节点有变动，更新first，重新扫描
            e = first = f; // re-traverse if entry changed
            retries = -1;
        }
    }
    return node;
}
</code></pre>
<p>scanAndLockForPut方法在当前线程获取不到segment锁的情况下，完成查找或新建节点的工作。当获取到锁后直接将该节点加入链表即可，提升了put操作的性能。大致过程：</p>
<ul>
<li>定位key在HashEntry数组的索引位，并获取第一个节点</li>
<li>尝试获取锁，如果成功直接返回，否则进入自旋</li>
<li>判断是否有hash冲突，没有就直接完成新节点的初始化</li>
<li>有hash冲突，开始遍历链表查找是否有相同key</li>
<li>如果没找到相同key，那么就完成新节点的初始化</li>
<li>如果找到相同key，判断循环次数是否大于最大扫描次数</li>
<li>如果循环次数大于最大扫描次数，就直接CAS拿锁（阻塞式）</li>
<li>如果循环次数不大于最大扫描次数，判断头结点是否有变化</li>
<li>进入下次循环</li>
</ul>
<h3 id="Segment-rehash-扩容方法"><a href="#Segment-rehash-扩容方法" class="headerlink" title="Segment.rehash() 扩容方法"></a>Segment.rehash() 扩容方法</h3><pre><code class="java">private void rehash(HashEntry&lt;K,V&gt; node) {
    // 复制老数组
    HashEntry&lt;K,V&gt;[] oldTable = table;
    int oldCapacity = oldTable.length;
    // table数组扩容2倍
    int newCapacity = oldCapacity &lt;&lt; 1;
    // 扩容阈值也增加两倍
    threshold = (int)(newCapacity * loadFactor);
    // 创建新数组
    HashEntry&lt;K,V&gt;[] newTable =
        (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity];
    // 计算新的掩码
    int sizeMask = newCapacity - 1;
    for (int i = 0; i &lt; oldCapacity ; i++) {
        HashEntry&lt;K,V&gt; e = oldTable[i];
        if (e != null) {
            HashEntry&lt;K,V&gt; next = e.next;
            // 计算新的索引位
            int idx = e.hash &amp; sizeMask;
            // 转移数据
            if (next == null)   //  Single node on list
                newTable[idx] = e;
            else { // Reuse consecutive sequence at same slot
                HashEntry&lt;K,V&gt; lastRun = e;
                int lastIdx = idx;
                for (HashEntry&lt;K,V&gt; last = next;
                     last != null;
                     last = last.next) {
                    int k = last.hash &amp; sizeMask;
                    if (k != lastIdx) {
                        lastIdx = k;
                        lastRun = last;
                    }
                }
                newTable[lastIdx] = lastRun;
                // Clone remaining nodes
                for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) {
                    V v = p.value;
                    int h = p.hash;
                    int k = h &amp; sizeMask;
                    HashEntry&lt;K,V&gt; n = newTable[k];
                    newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n);
                }
            }
        }
    }
    // 将新的节点加到对应索引位
    int nodeIndex = node.hash &amp; sizeMask; // add the new node
    node.setNext(newTable[nodeIndex]);
    newTable[nodeIndex] = node;
    table = newTable;
}
</code></pre>
<p>在这里我们可以发现每次扩容是针对一个单独的Segment的，在扩容完成之前中不会对扩容前的数组进行修改，这样就可以保证get()不被扩容影响。大致过程是：</p>
<ul>
<li>新建扩容后的数组，容量是原来的两倍</li>
<li>遍历扩容前的数组</li>
<li>通过e.hash &amp; sizeMask;计算key新的索引位</li>
<li>转移数据</li>
<li>将扩容后的数组指向成员变量table</li>
</ul>
<h3 id="get-方法"><a href="#get-方法" class="headerlink" title="get() 方法"></a>get() 方法</h3><pre><code class="java">public V get(Object key) {
    Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead
    HashEntry&lt;K,V&gt;[] tab;
    int h = hash(key);
    // 计算出Segment的索引位
    long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE;
    // 以原子的方式获取Segment
    if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp;
        (tab = s.table) != null) {
        // 原子方式获取HashEntry
        for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile
                 (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE);
             e != null; e = e.next) {
            K k;
            // key相同
            if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k)))
                // value是volatile所以可以不加锁直接取值返回
                return e.value;
        }
    }
    return null;
}
</code></pre>
<p>我们可以看到get方法是没有加锁的，因为HashEntry的value和next属性是volatile的，volatile直接保证了可见性，所以读的时候可以不加锁.</p>
<h3 id="size-方法"><a href="#size-方法" class="headerlink" title="size() 方法"></a>size() 方法</h3><pre><code class="java">public int size() {
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    final Segment&lt;K,V&gt;[] segments = this.segments;
    int size;
    // true表示size溢出32位（大于Integer.MAX_VALUE）
    boolean overflow; // true if size overflows 32 bits
    long sum;         // sum of modCounts
    long last = 0L;   // previous sum
    int retries = -1; // first iteration isn&#39;t retry
    try {
        for (;;) {
            // retries 如果retries等于2则对所有Segment加锁
            if (retries++ == RETRIES_BEFORE_LOCK) {
                for (int j = 0; j &lt; segments.length; ++j)
                    ensureSegment(j).lock(); // force creation
            }
            sum = 0L;
            size = 0;
            overflow = false;
            // 统计每个Segment元素个数
            for (int j = 0; j &lt; segments.length; ++j) {
                Segment&lt;K,V&gt; seg = segmentAt(segments, j);
                if (seg != null) {
                    sum += seg.modCount;
                    int c = seg.count;
                    if (c &lt; 0 || (size += c) &lt; 0)
                        overflow = true;
                }
            }
            if (sum == last)
                break;
            last = sum;
        }
    } finally {
        // 解锁
        if (retries &gt; RETRIES_BEFORE_LOCK) {
            for (int j = 0; j &lt; segments.length; ++j)
                segmentAt(segments, j).unlock();
        }
    }
    // 如果size大于Integer.MAX_VALUE值则直接返货Integer.MAX_VALUE
    return overflow ? Integer.MAX_VALUE : size;
}
</code></pre>
<p>size的核心思想是先进性两次不加锁统计，如果两次的值一样则直接返回，否则第三个统计的时候会将所有segment全部锁定，再进行size统计，所以size()尽量少用。因为这是在并发情况下，size其他线程也会改变size大小，所以size()的返回值只能表示当前线程、当时的一个状态，可以算其实是一个预估值。</p>
<h3 id="isEmpty-方法"><a href="#isEmpty-方法" class="headerlink" title="isEmpty() 方法"></a>isEmpty() 方法</h3><pre><code class="java">public boolean isEmpty() {
    long sum = 0L;
    final Segment&lt;K,V&gt;[] segments = this.segments;
    for (int j = 0; j &lt; segments.length; ++j) {
        Segment&lt;K,V&gt; seg = segmentAt(segments, j);
        if (seg != null) {
            // 只要有一个Segment的元素个数不为0则表示不为null
            if (seg.count != 0)
                return false;
            // 统计操作总数
            sum += seg.modCount;
        }
    }
    if (sum != 0L) { // recheck unless no modifications
        for (int j = 0; j &lt; segments.length; ++j) {
            Segment&lt;K,V&gt; seg = segmentAt(segments, j);
            if (seg != null) {
                if (seg.count != 0)
                    return false;
                sum -= seg.modCount;
            }
        }
        // 说明在统计过程中ConcurrentHashMap又被操作过，
        // 因为上面判断了ConcurrentHashMap不可能会有元素，所以这里如果有操作一定是新增节点
        if (sum != 0L)
            return false;
    }
    return true;
}
</code></pre>
<ul>
<li>先判断Segment里面是否有元素，如果有直接返回，如果没有则统计操作总数；</li>
<li>为了保证在统计过程中ConcurrentHashMap里面的元素没有发生变化，再对所有的Segment的操作数做了统计；</li>
<li>最后 sum==0 表示ConcurrentHashMap里面确实没有元素返回true，否则一定进行过新增元素返回false。<br>和size方法一样这个方法也是一个若一致方法，最后的结果也是一个预估值。</li>
</ul>
<h2 id="jdk1-8"><a href="#jdk1-8" class="headerlink" title="jdk1.8"></a>jdk1.8</h2><p><img src="https://i.loli.net/2020/11/25/cM5TOhxaEjqLQid.png" alt="image.png"></p>
<p>这个结构和HashMap一样</p>
<h3 id="核心属性"><a href="#核心属性" class="headerlink" title="核心属性"></a>核心属性</h3><pre><code class="java">//最大容量
private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;
//初始容量
private static final int DEFAULT_CAPACITY = 16;
//数组最大容量
static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
//默认并发度，兼容1.7及之前版本
private static final int DEFAULT_CONCURRENCY_LEVEL = 16;
//加载/扩容因子，实际使用n - (n &gt;&gt;&gt; 2)
private static final float LOAD_FACTOR = 0.75f;
//链表转红黑树的节点数阀值
static final int TREEIFY_THRESHOLD = 8;
//红黑树转链表的节点数阀值
static final int UNTREEIFY_THRESHOLD = 6;
//当数组长度还未超过64,优先数组的扩容,否则将链表转为红黑树
static final int MIN_TREEIFY_CAPACITY = 64;
//扩容时任务的最小转移节点数
private static final int MIN_TRANSFER_STRIDE = 16;
//sizeCtl中记录stamp的位数
private static int RESIZE_STAMP_BITS = 16;
//帮助扩容的最大线程数
private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;
//size在sizeCtl中的偏移量
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

// ForwardingNode标记节点的hash值（表示正在扩容）
static final int MOVED     = -1; // hash for forwarding nodes
// TreeBin节点的hash值，它是对应桶的根节点
static final int TREEBIN   = -2; // hash for roots of trees
static final int RESERVED  = -3; // hash for transient reservations
static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash

//存放Node元素的数组,在第一次插入数据时初始化
transient volatile Node&lt;K,V&gt;[] table;
//一个过渡的table表,只有在扩容的时候才会使用
private transient volatile Node&lt;K,V&gt;[] nextTable;
//基础计数器值(size = baseCount + CounterCell[i].value)
private transient volatile long baseCount;
/**
 * 控制table数组的初始化和扩容，不同的值有不同的含义：
 * -1:表示正在初始化
 * -n:表示正在扩容
 * 0:表示还未初始化，默认值
 * 大于0：表示下一次扩容的阈值
 */
private transient volatile int sizeCtl;
//节点转移时下一个需要转移的table索引
private transient volatile int transferIndex;
//元素变化时用于控制自旋
private transient volatile int cellsBusy;
// 保存table中的每个节点的元素个数 长度是2的幂次方，初始化是2，每次扩容为原来的2倍
// size = baseCount + CounterCell[i].value
private transient volatile CounterCell[] counterCells;
</code></pre>
<h3 id="Node-类"><a href="#Node-类" class="headerlink" title="Node 类"></a>Node 类</h3><pre><code class="java">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
    final int hash;
    final K key;
    volatile V val;
    volatile Node&lt;K,V&gt; next;

    Node(int hash, K key, V val, Node&lt;K,V&gt; next) {
        this.hash = hash;
        this.key = key;
        this.val = val;
        this.next = next;
    }
...
</code></pre>
<p>链表节点，保存着key和value的值。</p>
<h3 id="TreeNode类"><a href="#TreeNode类" class="headerlink" title="TreeNode类"></a>TreeNode类</h3><pre><code class="java">static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; {
    TreeNode&lt;K,V&gt; parent;  // red-black tree links
    TreeNode&lt;K,V&gt; left;
    TreeNode&lt;K,V&gt; right;
    TreeNode&lt;K,V&gt; prev;    // needed to unlink next upon deletion
    boolean red;

    TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next,
             TreeNode&lt;K,V&gt; parent) {
        super(hash, key, val, next);
        this.parent = parent;
    }
...
</code></pre>
<p>红黑树节点，包含了树的信息。</p>
<h3 id="TreeBin类"><a href="#TreeBin类" class="headerlink" title="TreeBin类"></a>TreeBin类</h3><p>TreeBins中使用的节点</p>
<pre><code class="java">static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; {
    TreeNode&lt;K,V&gt; root;
    volatile TreeNode&lt;K,V&gt; first;
    // 锁的持有者
    volatile Thread waiter;
    // 锁状态
    volatile int lockState;
    // values for lockState
    // 表示持有写锁
    static final int WRITER = 1; // set while holding write lock
    // 表示等待
    static final int WAITER = 2; // set when waiting for write lock
    // 表示读锁的增量值
    static final int READER = 4; // increment value for setting read lock
...
</code></pre>
<p>与HashMap有点区别的是，他不直接使用TreeNode作为数的根节点，而是使用TreeBins对其做了装饰后成为了根节点；同时它还记录了锁的状态；需要注意的是：</p>
<ul>
<li>TreeBins节点的hash值是 -2</li>
<li>我们对红黑树添加节点后，红黑树的根节点有可能会因为旋转而发生变化，所以我们在添加树节点的时候在putTreeVal()方法里面我们使用cas在加了一次锁。</li>
</ul>
<h3 id="ForwardingNode-类"><a href="#ForwardingNode-类" class="headerlink" title="ForwardingNode 类"></a>ForwardingNode 类</h3><pre><code class="java">/**
 * A node inserted at head of bins during transfer operations.
 */
static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; {
    final Node&lt;K,V&gt;[] nextTable;
    ForwardingNode(Node&lt;K,V&gt;[] tab) {
        super(MOVED, null, null, null);
        this.nextTable = tab;
    }

    Node&lt;K,V&gt; find(int h, Object k) {
        // loop to avoid arbitrarily deep recursion on forwarding nodes
        outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) {
            Node&lt;K,V&gt; e; int n;
            // 1. 判断新的数组是否是null，
            // 2. 如果不为NULL给那就找到对应索引位上的头结点
            // 3. 判断头节点是否为NULL
            if (k == null || tab == null || (n = tab.length) == 0 ||
                (e = tabAt(tab, (n - 1) &amp; h)) == null)
                return null;
            // 自旋找节点
            for (;;) {
                int eh; K ek;
                if ((eh = e.hash) == h &amp;&amp;
                    ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek))))
                    return e;
                if (eh &lt; 0) {
                    // 如果又变成了ForwardingNode标记节点，那说明有发生了扩容，需要跳出循环从新查找
                    if (e instanceof ForwardingNode) {
                        tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable;
                        continue outer;
                    }
                    else
                        return e.find(h, k);
                }
                if ((e = e.next) == null)
                    return null;
            }
        }
    }
}
</code></pre>
<p>ForwardingNode 节点是一个扩容标记节点，只要在数组上发现对应索引位上是ForwardingNode 节点时，表示正在扩容。当get方法调用时，如果遇到ForwardingNode 节点，那么它将会到扩容后的数据上查找数据，否则还是在扩容前的数组上查找数据。这个要注意两点：</p>
<ul>
<li>这个节点的hash值是 -1</li>
<li>这个节点的find方法是在对扩容后的数组进行查找</li>
</ul>
<h3 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h3><pre><code class="java">public ConcurrentHashMap18() {
}
</code></pre>
<p>与HashMap一样，构造函数啥都没干，初始化操作是在第一次put完成的。</p>
<h3 id="put-方法-1"><a href="#put-方法-1" class="headerlink" title="put() 方法"></a>put() 方法</h3><pre><code class="java">public V put(K key, V value) {
        return putVal(key, value, false);
    }
</code></pre>
<h3 id="spread-方法"><a href="#spread-方法" class="headerlink" title="spread() 方法"></a>spread() 方法</h3><pre><code class="java">static final int spread(int h) {
        return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;
    }
</code></pre>
<p>计算key.hashCode（）并将更高位的散列扩展（XOR）降低。采用位运算主要是是加快计算速度。</p>
<h3 id="putVal-方法"><a href="#putVal-方法" class="headerlink" title="putVal() 方法"></a>putVal() 方法</h3><pre><code class="java">/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 计算hash值
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node&lt;K,V&gt;[] tab = table;;) {
        Node&lt;K,V&gt; f; int n, i, fh;
        // 判断是否需要初始化
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        // 找出key对应的索引位上的第一个节点
        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
            // 如果该索引位为null，则直接将数据放到该索引位
            if (casTabAt(tab, i, null,
                         new Node&lt;K,V&gt;(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // 正在扩容
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            // 加内置锁锁定一个数组的索引位，并添加节点
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    // 表示链表节点
                    if (fh &gt;= 0) {
                        binCount = 1;
                        for (Node&lt;K,V&gt; e = f;; ++binCount) {
                            K ek;
                            // key相同直接替换value值
                            if (e.hash == hash &amp;&amp;
                                ((ek = e.key) == key ||
                                 (ek != null &amp;&amp; key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 将新节点添加到链表尾部
                            Node&lt;K,V&gt; pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node&lt;K,V&gt;(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    // 表示树节点
                    else if (f instanceof TreeBin) {
                        Node&lt;K,V&gt; p;
                        binCount = 2;
                        // 添加数节点
                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                // 尝试将链表转换成红黑树
                if (binCount &gt;= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
</code></pre>
<p>主要流程：</p>
<ul>
<li>计算key的hash值</li>
<li>判断是否需要初始化，如果是则调用initTable() 方法完成初始化</li>
<li>判断是否有hash冲突，如没有直接设置新节点到对饮索引位，如果有获取头结点</li>
<li>根据头结点的hash值判断是否正在扩容，如果是则帮助扩容</li>
<li>如果没有扩容则对头结点加锁，添加新节点</li>
<li>fh &gt;= 0根据头结点hash值判断是否是链表节点，如果是新增链表节点，否则新增树节点</li>
<li>新增树节点putTreeVal()需要注意，红黑树的根节点有可能会因为旋转而发生变化，所以我们在添加节点的时候还需要对根节点使用cas在加了一次锁。</li>
<li>判断是否需要尝试由链表转换成树结构</li>
<li>addCount(1L, binCount);新增count数，并判断是否需要扩容或者帮助扩容</li>
</ul>
<p>sizeCtl值含义：<br>-1:表示正在初始化<br>-n:表示正在扩容<br>0:表示还未初始化，默认值<br>大于0：表示下一次扩容的阈值</p>
<h3 id="initTable-初始化方法"><a href="#initTable-初始化方法" class="headerlink" title="initTable() 初始化方法"></a>initTable() 初始化方法</h3><pre><code class="java">private final Node&lt;K,V&gt;[] initTable() {
    Node&lt;K,V&gt;[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        // 正在初始化
        if ((sc = sizeCtl) &lt; 0)
            // 让出CPU执行权，然后自旋
            Thread.yield(); // lost initialization race; just spin
        // CAS替换标志位（相当于获取锁）
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                // 二次判断
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings(&quot;unchecked&quot;)
                    Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                    table = tab = nt;
                    // 相当于sc=n*3/4
                    sc = n - (n &gt;&gt;&gt; 2); 
                }
            } finally {
                // 扩容阈值
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
</code></pre>
<p>主要过程：</p>
<ul>
<li>根据sizeCtl判断是否正在初始化</li>
<li>如果其他线程正在初始化就让出CPU执行权，进入下一次CPU执行权的竞争Thread.yield();</li>
<li>如果没有进行初始化的线程则，CAS替换sizeCtl标志位（相当于获取锁）</li>
<li>获取到锁后再次判断是否初始化</li>
<li>如果没有则初始化Node数组,并设置sizeCtl值为下一次扩容阈值</li>
</ul>
<h3 id="helpTransfer-帮助扩容"><a href="#helpTransfer-帮助扩容" class="headerlink" title="helpTransfer()帮助扩容"></a>helpTransfer()帮助扩容</h3><pre><code class="java">final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) {
    Node&lt;K,V&gt;[] nextTab; int sc;
    // ForwardingNode标记节点，表示正在扩容
    if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;
        (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) {
        int rs = resizeStamp(tab.length);
        while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;
               (sc = sizeCtl) &lt; 0) {
            if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                sc == rs + MAX_RESIZERS || transferIndex &lt;= 0)
                break;
            if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
                transfer(tab, nextTab);
                break;
            }
        }
        return nextTab;
    }
    return table;
}
</code></pre>
<p>判断是否正在扩容，如果是就帮助扩容。</p>
<h3 id="transfer-扩容方法"><a href="#transfer-扩容方法" class="headerlink" title="transfer() 扩容方法"></a>transfer() 扩容方法</h3><pre><code class="java">private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) {\
    // n原来数组长度
    int n = tab.length, stride;
    if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE)
        stride = MIN_TRANSFER_STRIDE; // subdivide range
    // 判断是发起扩容的线程还是帮助扩容的线程，如果是发起扩容的需要初始化新数组
    if (nextTab == null) {            // initiating
        try {
            @SuppressWarnings(&quot;unchecked&quot;)
            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];
            nextTab = nt;
        } catch (Throwable ex) {      // try to cope with OOME
            sizeCtl = Integer.MAX_VALUE;
            return;
        }
        nextTable = nextTab;
        transferIndex = n;
    }
    int nextn = nextTab.length;
    // 扩容期间的数据节点（用于标志位，hash值是-1）
    ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab);
    // 当advance == true时，表明该节点已经处理过了
    boolean advance = true;
    // 在扩容完成之前保证get不被影响
    boolean finishing = false; // to ensure sweep before committing nextTab
    // 1. 从右往左找到第一个有数据的索引位节点（有hash冲突的桶）
    // 2. 如果找到的节点是NULL节点（没有hash冲突的节点），那么将该索引位的NULL替换成ForwardingNode标记节点，这个节点的hash是-1
    // 3. 如果找到不为NULL的节点（有hash冲突的桶），则对这个节点进行加锁
    // 4. 开始进进移动节点数据
    for (int i = 0, bound = 0;;) {
        //f:当前处理i位置的node（头结点或者根节点）;
        Node&lt;K,V&gt; f; int fh;
        // 通过while循环获取本次需要移动的节点索引i
        while (advance) {
            // nextIndex:下一个要处理的节点索引; nextBound:下一个需要处理的节点的索引边界
            int nextIndex, nextBound;
            // i是老数组索引位，通过--i来讲索引位往前一个索引位移动，直到0索引位
            if (--i &gt;= bound || finishing)
                advance = false;
            // 节点已全部转移
            else if ((nextIndex = transferIndex) &lt;= 0) {
                i = -1;
                advance = false;
            }
            // transferIndex（初值为最后一个节点的索引），表示从transferIndex开始后面所有的节点都已分配，
            // 每次线程领取扩容任务后，需要更新transferIndex的值(transferIndex-stride)。
            // CAS修改transferIndex，并更新索引边界
            else if (U.compareAndSwapInt
                     (this, TRANSFERINDEX, nextIndex,
                      nextBound = (nextIndex &gt; stride ?
                                   nextIndex - stride : 0))) {
                bound = nextBound;
                // 老数组最后一个索引位置
                i = nextIndex - 1;
                advance = false;
            }
        }
        if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) {
            int sc;
            // 已经完成所有节点复制了
            if (finishing) {
                nextTable = null;
                table = nextTab;
                // sizeCtl阈值为原来的1.5倍
                sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);
                // 结束自旋
                return;
            }
            // CAS 更新扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作
            if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)
                    return;
                finishing = advance = true;
                i = n; // recheck before commit
            }
        }
        // 将以前老数组上为NULL的节点（还没有元素的桶或者说成没有hash冲突的数据节点），用ForwardingNode标记节点补齐
        // 主要作用是：其他线程在put元素，发现找到的索引位是fwd节点则表示正在扩容，那么该线程会来帮助扩通，而不是在那里等待
        else if ((f = tabAt(tab, i)) == null)
            advance = casTabAt(tab, i, null, fwd);
        // 表示处理过该节点了
        else if ((fh = f.hash) == MOVED)
            advance = true; // already processed
        else {
            // 对应索引位加锁
            synchronized (f) {
                // 再次校验一下老数组对应索引位节点是否是我们找到的节点f
                if (tabAt(tab, i) == f) {
                    // 低索引位头节点(i位)， 高位索引位头节点（i+tab.length）
                    Node&lt;K,V&gt; ln, hn;
                    // fh &gt;=0 表示链表节点，TreeBin节点的hash值-2
                    if (fh &gt;= 0) {
                        // fh &amp; n算法可以算出新的节点该分配到那个索引位（runBit要么为0放低位ln，要么为n放高位hn），
                        // runBit表示链表中最后一个元素的hash值&amp;n的值
                        int runBit = fh &amp; n;
                        // lastRun表示链表中最后一个元素
                        Node&lt;K,V&gt; lastRun = f;
                        // 找到链表中最后一个节点，并赋值给lastRun
                        for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) {
                            int b = p.hash &amp; n;
                            if (b != runBit) {
                                runBit = b;
                                lastRun = p;
                            }
                        }
                        // 判断原来的最后一个节点应该添加到高位还是低位
                        if (runBit == 0) {
                            ln = lastRun;
                            hn = null;
                        }
                        else {
                            hn = lastRun;
                            ln = null;
                        }
                        // f表示头结点，如果p不是尾节点，则转移节点
                        // 如果以前节点顺序是 1 2 3 4 转移后就是 3 2 1 4 
                        for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) {
                            int ph = p.hash; K pk = p.key; V pv = p.val;
                            if ((ph &amp; n) == 0)
                                // 转移节点时都是新建节点,以免破坏原来数组结构影响get方法
                                ln = new Node&lt;K,V&gt;(ph, pk, pv, ln);
                            else
                                hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);
                        }
                        // 设置新数组低索引位头节点(i位)
                        setTabAt(nextTab, i, ln);
                        // 设置新数组高位索引位头节点（i+tab.length）
                        setTabAt(nextTab, i + n, hn);
                        // 设置老数组i位为标记节点，表示已经处理过了
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                    else if (f instanceof TreeBin) {
                        TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f;
                        TreeNode&lt;K,V&gt; lo = null, loTail = null;
                        TreeNode&lt;K,V&gt; hi = null, hiTail = null;
                        int lc = 0, hc = 0;
                        for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) {
                            int h = e.hash;
                            TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;
                                (h, e.key, e.val, null, null);
                            if ((h &amp; n) == 0) {
                                if ((p.prev = loTail) == null)
                                    lo = p;
                                else
                                    loTail.next = p;
                                loTail = p;
                                ++lc;
                            }
                            else {
                                if ((p.prev = hiTail) == null)
                                    hi = p;
                                else
                                    hiTail.next = p;
                                hiTail = p;
                                ++hc;
                            }
                        }
                        ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                            (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t;
                        hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                            (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t;
                        // 设置新数组低索引位头节点(i位)
                        setTabAt(nextTab, i, ln);
                        // 设置新数组高位索引位头节点（i+tab.length）
                        setTabAt(nextTab, i + n, hn);
                        // 设置老数组i位为标记节点，表示已经处理过了
                        setTabAt(tab, i, fwd);
                        advance = true;
                    }
                }
            }
        }
    }
}
</code></pre>
<p>主要过程：</p>
<ul>
<li>tab为扩容前的数组</li>
<li>判断是否是第一个发起扩容的线程，如果是需要初始化扩容后的数组nextTable</li>
<li>fwd = new ForwardingNode<k,v>(nextTab)初始化扩容标记节点</k,v></li>
<li>进入扩容循环</li>
<li>在扩容前的数组tab上从右往左（从高索引位到低索引位）遍历所有头结点，索引位为i</li>
<li>如果找到的头结点是NULL(没有hash冲突)则tab[i]=fwd。</li>
<li>找到的头结点不为NULL则（有hash冲突）则锁定头结点synchronized (f)</li>
<li>再次校验头结点是否发生改变，如果改变直接结束</li>
<li>初始化高索引位和第索引位的头结点</li>
<li>移动节点到相应索引位</li>
<li>设置扩容后的数组低索引位头节点(i位)</li>
<li>设置扩容后的数组高位索引位头节点（i+tab.length）</li>
<li>设置扩容前的数组i位为标记节点（tab[i]=fwd），表示已经处理过了</li>
<li>进入第3步直到完成</li>
</ul>
<p>注意：</p>
<ul>
<li>第5点有tab[i]=fwd有两层含义：1,表示对应索引位已经处理过了；2,当其他线程拿到该头结点的时候能知晓正在扩容，这时在put的时候帮助扩容，在get的时候去扩容后的数组上找相应的key</li>
<li>int runBit = fh &amp; n;算法可以算出新的节点该分配到那个索引位（runBit要么为0放低位ln，要么为n放高位hn）</li>
<li>如果是链表节点，以前节点顺序是 1 2 3 4 扩容后会变成 3 2 1 4</li>
</ul>
<p>扩容的大致过程图解：</p>
<ol>
<li>发起扩容，扩容前数组tab</li>
</ol>
<p><img src="https://i.loli.net/2020/11/25/WL3vCiXeB7tqyfU.png" alt="image.png"></p>
<ol>
<li>在扩容前的数组tab上从右往左（从高索引位到低索引位）遍历所有头结点，索引位为i，如果找到的头结点是NULL则直接赋值成<code>`fwd</code> 标记节点。</li>
</ol>
<p><img src="https://i.loli.net/2020/11/25/luVcF6AwN2TtaUK.png" alt="image.png"></p>
<ol>
<li>扩容前的数组上找到不为NULL的节点，则还是移动节点到扩容后的额数组</li>
</ol>
<p><img src="https://i.loli.net/2020/11/25/cZKgYvChXGIirf9.png" alt="image.png"></p>
<h3 id="addCount-方法"><a href="#addCount-方法" class="headerlink" title="addCount() 方法"></a>addCount() 方法</h3><pre><code class="java">private final void addCount(long x, int check) {
    // CounterCell[] as;使用计数器数组因该是为了提升并发量，减小冲突概率
    CounterCell[] as; long b, s;
    // 计数器表不为NULL（counterCells当修改baseCount有冲突时，需要将size增量放到这个计数器数组里面）
    if ((as = counterCells) != null ||
        // 使用CAS更新baseCount的值（+1）如果失败说明存在竞争
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell a; long v; int m;
        // CounterCell是否存在竞争的标记位
        boolean uncontended = true;
        // CounterCell[] as为NULL表示as没有竞争
        if (as == null || (m = as.length - 1) &lt; 0 ||
            // 随机一个数组位置来验证是否为NULL，如果a是null表示没有竞争，随机也是为了减小冲突概率
            (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null ||
            // CAS替换a的value，如果失败表示存在竞争
            !(uncontended =
              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            // 将size增量值存到as上
            fullAddCount(x, uncontended);
            return;
        }
        if (check &lt;= 1)
            return;
        // 统计size
        s = sumCount();
    }
    // 检查是否需要扩容
    if (check &gt;= 0) {
        Node&lt;K,V&gt;[] tab, nt; int n, sc;
        // size大于阈值sizeCtl，tab数组长度小于最大值1&lt;&lt;30
        while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp;
               (n = tab.length) &lt; MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);
            // 表示正在扩容
            if (sc &lt; 0) {
                if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex &lt;= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    // 帮助扩容
                    transfer(tab, nt);
            }
            // sc = (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2，移位后是负数
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2))
                // 发起扩容，此时nextTable=null
                transfer(tab, null);
            s = sumCount();
        }
    }
}
</code></pre>
<p>在put()方法执行最后会对当前Map的size+1，ConcurrentHashMap中size由baseCount和CounterCell[] as组成，size=baseCount+as[i].value。addCount的大致过程如下：</p>
<ul>
<li>CAS替换baseCount值，如果失败说明对size的增量（size++）存在竞争</li>
<li>如果存在竞争，我们会使用到CounterCell[] as数组</li>
<li>as[ThreadLocalRandom.getProbe() &amp; m]随机取一个索引位，使用CAS完成size++</li>
<li>如果as[i]也存在竞争会调用fullAddCount(x, uncontended);方法完成size++</li>
<li>size++完成后通过size=baseCount+as[i].value公式计算出元素总数</li>
<li>判断是否需要扩容</li>
<li>如果需要扩容，在判断一下是帮助扩容还是发起扩容</li>
</ul>
<p>注意：</p>
<ul>
<li>CounterCell[] as：这个的只要目的是分散对baseCount的单一竞争，提示size++的并发率，这里和table数组一样使用了锁分离技术，as的长度也是2的n次方，初始长度是2</li>
<li>在第三步中使用随机数也是为了提升并发效率，ThreadLocalRandom类是JDK7在JUC包下新增的随机数生成器，它解决了Random类在多线程下，多个线程竞争内部唯一的原子性种子变量，而导致大量线程自旋重试的不足</li>
<li>fullAddCount(x, uncontended);方法里面完成了as的初始化和扩容</li>
<li>元素总数的计算公式是size=baseCount+as[i].value</li>
</ul>
<h3 id="sumCount-方法"><a href="#sumCount-方法" class="headerlink" title="sumCount() 方法"></a>sumCount() 方法</h3><pre><code class="java">final long sumCount() {
    CounterCell[] as = counterCells; CounterCell a;
    long sum = baseCount;
    if (as != null) {
        for (int i = 0; i &lt; as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}
</code></pre>
<p>元素总数的计算公式是size=baseCount+as[i].value</p>
<h3 id="get-方法-1"><a href="#get-方法-1" class="headerlink" title="get() 方法"></a>get() 方法</h3><pre><code class="java">public V get(Object key) {
    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;
    int h = spread(key.hashCode());
    // table 不为NULL并且对饮索引位不为NULL
    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
        (e = tabAt(tab, (n - 1) &amp; h)) != null) {
        if ((eh = e.hash) == h) {
            // 头节点key相同
            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))
                return e.val;
        }
        // 树节点或者ForwardingNode标记节点
        else if (eh &lt; 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        // 链表节点
        while ((e = e.next) != null) {
            // key相同
            if (e.hash == h &amp;&amp;
                ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
</code></pre>
<p>主要流程：</p>
<ul>
<li>判断table和key对应索引位是否为NULL</li>
<li>判断头节点是否是要找的节点</li>
<li>eh &lt; 0表示是树节点或ForwardingNode标记节点，直接通过find方法找对应的key</li>
<li>否则是链表节点，挨个链表节点找相应的key</li>
<li>返回结果</li>
</ul>
<p>注意：</p>
<ul>
<li>get 方法没有加锁，原因是节点的value是volatile的，已经保证了可见性，只要value有更新，那么我们一定能读到最新数据。</li>
<li>e.find(h, key)这里：如果对应索引位头结点是ForwardingNode节点，那么会直接去扩通后的数组找对应的key，可以参见上面ForwardingNode.find()方法</li>
</ul>
<h3 id="size-方法-1"><a href="#size-方法-1" class="headerlink" title="size()方法"></a>size()方法</h3><pre><code class="java">public int size() {
    long n = sumCount();
    return ((n &lt; 0L) ? 0 :
            (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}
</code></pre>
<h3 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h3><p>get方法和containsKey方法都是遍历对应索引位上所有节点，来判断是否存在key相同的节点以及获得该节点的value。但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。</p>
<h3 id="JDK1-8与JDK1-7的不同点"><a href="#JDK1-8与JDK1-7的不同点" class="headerlink" title="JDK1.8与JDK1.7的不同点"></a>JDK1.8与JDK1.7的不同点</h3><ul>
<li>去掉了Segment 数组：这样做锁的粒度更小，减少了并发冲突的概率；查找数据时不用计算两次hash；</li>
<li>存储数据是采用了链表+红黑树的形式：当一个桶内数据量很大的时候，红黑树的查询效率远高于链表。</li>
<li>1.8直接使用了内置锁synchronized：简化了加锁操作</li>
<li>1.8的初始化是在第一次put时完成的，1.7的时候再构造的时候完成的</li>
<li>在put过程中当发现正在扩容，1.8的线程会帮助扩容，1.7的只是会检查key是否存在或者完成新节点的初始化工作</li>
<li>1.8的hash值计算更简单了</li>
<li>1.8扩容过程中会修改扩容前的数组，1.7扩容过程中不会修改原来数组</li>
<li>1.8在get()时如果判断到当前索引位正在扩容，那么直接在扩容后的数组中去找对应的key</li>
<li>1.7的size计算使用的三次计算的方式，1.8使用了锁分离技术</li>
</ul>
<p>1、整体结构<br>1.7：Segment + HashEntry + Unsafe</p>
<p>1.8: 移除Segment，使锁的粒度更小，Synchronized + CAS + Node + Unsafe</p>
<p>2、put（）<br>1.7：先定位Segment，再定位桶，put全程加锁，没有获取锁的线程提前找桶的位置，并最多自旋64次获取锁，超过则挂起。</p>
<p>1.8：由于移除了Segment，类似HashMap，可以直接定位到桶，拿到first节点后进行判断，1、为空则CAS插入；2、为-1则说明在扩容，则跟着一起扩容；3、else则加锁put（类似1.7）</p>
<p>3、get（）<br>基本类似，由于value声明为volatile，保证了修改的可见性，因此不需要加锁。</p>
<p>4、resize（）<br>1.7：跟HashMap步骤一样，只不过是搬到单线程中执行，避免了HashMap在1.7中扩容时死循环的问题，保证线程安全。</p>
<p>1.8：支持并发扩容，HashMap扩容在1.8中由头插改为尾插（为了避免死循环问题），ConcurrentHashmap也是，迁移也是从尾部开始，扩容前在桶的头部放置一个hash值为-1的节点，这样别的线程访问时就能判断是否该桶已经被其他线程处理过了。</p>
<p>5、size（）<br>1.7：很经典的思路：计算两次，如果不变则返回计算结果，若不一致，则锁住所有的Segment求和。</p>
<p>1.8：用baseCount来存储当前的节点个数，这就设计到baseCount并发环境下修改的问题</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之CoryOnWriteArrayList、CopyOnWriteArraySet]]></title>
      <url>/2020/11/24/juc-14/</url>
      <content type="html"><![CDATA[<p>CopyOnWrite（简称：COW）：即复制再写入，就是在添加元素的时候，先把原 List 列表复制一份，再添加新的元素</p>
<p>CopyOnWriteArrayList 用于读场景远多于写场景的情况，它能够让读与读之间不互斥，读与写也不互斥，只有写与写之间才会互斥。它的思路也很简单，内部通过一个数组来维护数据，正常读数据时直接通过索引从数组中提取数据。</p>
<pre><code class="java">/** The array, accessed only via getArray/setArray. */
private transient volatile Object[] array;

@SuppressWarnings(&quot;unchecked&quot;)
private E get(Object[] a, int index) {
    return (E) a[index];
}

/**
 * {@inheritDoc}
 *
 * @throws IndexOutOfBoundsException {@inheritDoc}
 */
public E get(int index) {
    return get(getArray(), index);
}

/**
 * Gets the array.  Non-private so as to also be accessible
 * from CopyOnWriteArraySet class.
 */
final Object[] getArray() {
    return array;
}
</code></pre>
<p>而写数据时，需要将整个数组都复制一遍，然后在新数组的末尾添加最新的数据。最后替换掉原来的数组，这样原来的数组就会被回收。很显然，这种实现方式在减小竞争的同时，承担了数据空间 * 2 的压力。</p>
<pre><code class="java">/** The lock protecting all mutators */
final transient ReentrantLock lock = new ReentrantLock();

/**
 * Appends the specified element to the end of this list.
 *
 * @param e element to be appended to this list
 * @return {@code true} (as specified by {@link Collection#add})
 */
public boolean add(E e) {
    // 加锁
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        // 获取原始集合
        Object[] elements = getArray();
        int len = elements.length;

        // 复制一个新集合
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        newElements[len] = e;

        // 替换原始集合为新集合
        setArray(newElements);
        return true;
    } finally {
        // 释放锁
        lock.unlock();
    }
}

/**
 * Sets the array.
 */
final void setArray(Object[] a) {
    array = a;
}
</code></pre>
<p>CopyOnWriteArraySet<br>CopyOnWriteArraySet逻辑就更简单了，就是使用 CopyOnWriteArrayList 的 addIfAbsent 方法来去重的，添加元素的时候判断对象是否已经存在，不存在才添加进集合。</p>
<pre><code class="java">/**
 * Appends the element, if not present.
 *
 * @param e element to be added to this list, if absent
 * @return {@code true} if the element was added
 */
public boolean addIfAbsent(E e) {
    Object[] snapshot = getArray();
    return indexOf(e, snapshot, 0, snapshot.length) &gt;= 0 ? false :
        addIfAbsent(e, snapshot);
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ConcurrentLinkedQueue]]></title>
      <url>/2020/11/24/juc-13/</url>
      <content type="html"><![CDATA[<p>内容转载自 <a href="https://www.beikejiedeliulangmao.top/java/concurrent/concurrent-linked-queue/" target="_blank" rel="noopener">https://www.beikejiedeliulangmao.top/java/concurrent/concurrent-linked-queue/</a> 稍有改动</p>
<p>Java 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。</p>
<p>ConcurrentLinkedQueue 使用了链表作为其数据结构．内部使用 CAS 来进行链表的维护。ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。</p>
<p>接下来我们简单地看一下 ConcurrentLinkedQueue 的实现，在 ConcurrentLinkedQueue 中所有数据通过单向链表存储，同时我们还会保存该链表的头指针和尾指针。</p>
<pre><code class="java">// 链表中的节点
private static class Node&lt;E&gt; {
    volatile E item;
    volatile Node&lt;E&gt; next;
    //...
}
/**
 * A node from which the first live (non-deleted) node (if any)
 * can be reached in O(1) time.
 * Invariants:
 * - all live nodes are reachable from head via succ()
 * - head != null
 * - (tmp = head).next != tmp || tmp != head
 * Non-invariants:
 * - head.item may or may not be null.
 * - it is permitted for tail to lag behind head, that is, for tail
 *   to not be reachable from head!
 */
private transient volatile Node&lt;E&gt; head;

/**
 * A node from which the last node on list (that is, the unique
 * node with node.next == null) can be reached in O(1) time.
 * Invariants:
 * - the last node is always reachable from tail via succ()
 * - tail != null
 * Non-invariants:
 * - tail.item may or may not be null.
 * - it is permitted for tail to lag behind head, that is, for tail
 *   to not be reachable from head!
 * - tail.next may or may not be self-pointing to tail.
 */
private transient volatile Node&lt;E&gt; tail;
</code></pre>
<p>在对象实例化时，会创建一个虚节点。看到后面你会发现，如果想通过 CAS 维护一个链表，一般都会使用到虚节点。</p>
<pre><code class="java">public ConcurrentLinkedQueue() {
    head = tail = new Node&lt;E&gt;(null);
}
</code></pre>
<p>介绍完内部数据结构，我们看一下增删节点的实现方式。先来看一下增加数据的逻辑：</p>
<ul>
<li>入队操作是在一个循环中尝试 CAS 操作，首先判断，尾结点 p.next 是不是 null，是的话就通过 CAS 将 null-&gt; newNode，如果 CAS 成功，说明该节点就已经算是加入到队列中了<ul>
<li>但是这里并没有直接修改尾结点，因为 ConcurrentLinkedQueue 中 tail 并不一定是实际上的尾结点，在并发很大时，如果所有线程都要去竞争修改尾结点的话，对性能会有影响，所以，当实际的尾结点（代码中的变量 p）不等于 tail 时，才会进行更新。</li>
<li>在 ConcurrentLinkedQueue 中会出现 Node1 (head)-&gt;Node2 (tail)-&gt;null 以及 Node1 (head)-&gt;Node2 (tail)-&gt;Node3-&gt;null 这样的情况甚至 Node1 (head)-&gt;Node2 (tail)-&gt;Node3-&gt;Node4 这样的情况，虽然 tail 指针没有直接指向尾结点会导致将新节点加入链表时，需要从 tail 向后查找实际的尾结点，但是这个过程相较于对 tail 节点的竞争来说，影响较小，最终效率也更高</li>
</ul>
</li>
<li>如果发现当前 p 节点不是实际上的尾结点，会先检查它的 next 指针是否指向自己，在出队函数 poll 中，将一个元素出队后会把它的 next 指针指向自己，所以这一步实际上是判断当前的 p 节点是否已经出队<ul>
<li>如果满足上述情况，我们需要重新获取 tail 指针，如果发现在上述过程中 tail 指针发生了变化，这说明期间已经好有个并发插入过程完成了，我们直接从最新的 tail 对象开始上述流程即可，所以这里就将 p 赋为最新的 tail 指向的对象，</li>
<li>如果整个过程中 tail 指针都没变，说明当前的情况类似于 Node1 (head，tail)-&gt; Node2-&gt;null, 但是在判断 p == q 之前，发生了出队操作，状态变成了 Node1 (tail, 已经出队的对象) Node2 (head)-&gt;null，这个时候我们要将 p 设置为 head 然后从 head 开始向后遍历</li>
</ul>
</li>
<li>最后就是单纯的没有遍历到尾结点的情况了， Node1 (head)-&gt;Node2 (tail，当前 p 变量)-&gt;Node3（当前 q 变量）-&gt;null<ul>
<li>如果发现已经进行过一次向后遍历的过程，即 p != t ，并且 tail 指针发生了变化，我们就直接使用 tail 指针，不再向后遍历了 p = t (最新的 tail 指针)</li>
<li>如果不满足上述情况，比如还从来没遍历过，或者虽然遍历过但是 tail 指针没变，我们就继续遍历 p = q (p.next)</li>
</ul>
</li>
</ul>
<pre><code class="java">public boolean offer(E e) {
    checkNotNull(e);
    final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e);

    for (Node&lt;E&gt; t = tail, p = t;;) {
        Node&lt;E&gt; q = p.next;
        if (q == null) {
            // p is last node
            // 找到了最后一个节点，通过 CAS 将其 next 指向新节点
            if (p.casNext(null, newNode)) {
                // Successful CAS is the linearization point
                // for e to become an element of this queue,
                // and for newNode to become &quot;live&quot;.
                // 如果 tail.next 为null就不修改tail，tail.next != null 时才会修改
                // 这里会出现多个线程同时发现 tail.next != null 的情况，所以 tail 指针和实际的尾结点的距离不一定是1
                if (p != t) // hop two nodes at a time
                    casTail(t, newNode);  // Failure is OK. 因为没有要求 tail 指针和实际的尾结点的距离是1
                return true;
            }
            // Lost CAS race to another thread; re-read next
        }
        else if (p == q)
            // 如果发现当前p节点不是实际上的尾结点，会先检查它的next 指针是否指向自己，在出队函数poll中，将一个元素出队后会把它的next指针指向自己，所以这一步实际上是判断当前的 p 节点是否已经出队
            // 如果 tail 指针发生了变化，就从最新的 tail 开始遍历
            // 否则，从 head 开始遍历，因为这时候 tail 可能指向了一个死掉(next 指向自己，已经从队列中移除)的节点
            // We have fallen off list.  If tail is unchanged, it
            // will also be off-list, in which case we need to
            // jump to head, from which all live nodes are always
            // reachable.  Else the new tail is a better bet.
            p = (t != (t = tail)) ? t : head;
        else
            // 最后就是单纯的没有遍历到尾结点的情况了
            // 如果发现已经进行过一次向后遍历的过程，并且 tail 指针发生了变化，我们就直接使用 tail 指针
            // 如果还从来没遍历过，或者虽然遍历过但是 tail 指针没变，我们就继续遍历
            // Check for tail updates after two hops.
            p = (p != t &amp;&amp; t != (t = tail)) ? t : q;
    }
}
</code></pre>
<p>最后，我们介绍一下出队的操作，整个出队过程也是在一个 CAS 循环中进行：</p>
<ul>
<li>首先我们检查头指针的 p (head).item 是不是 null，不是的话才说明该节点是一个有效节点，因为初始化是创建的虚节点 item 才等于 null，这里通过 item 是不是 null 来判断是不是虚节点也就是说 ConcurrentLinkedQueue 中不能添加值为 null 的节点<ul>
<li>找到有效节点后，通过 cas 将 item 改为 null，后续的操作和添加元素时类似，因为 head 指针也是一个竞争点，所以这里并没有直接修改 head 指针，而是发现从 head 至少向后遍历过一次时，才会修改 head 指针，这和 offer 中的方式类似</li>
<li>如果当前线程要负责修改 head 指针，会判断 刚删掉的节点 p 的 next 是不是 null，是的话就让 p 作为 head（此时 p 充当新的虚节点），如果不是的话，就让 p.next 作为 next（此时 head 就是实际上的头结点）</li>
</ul>
</li>
<li>如果 p 的 item == null 或者 cas 失败（别的线程已经把 p.item 置为 null），我们要检查一下 p.next 是不是 null，如果是的话说明 p 已经是最后一个节点了，我们需要返回 null，但是在此之前，我们不妨把 p 设为新的 head 来减少其他线程的遍历开销</li>
<li>检查当前 p 节点的 next 指针是不是指向自己，是的话说明当前检查的这个节点已经被别的线程从队列中移除了，那我们就重新开始执行 poll</li>
<li>否则，让 p = q (p.next)，也就是说这是从 head 开始向后遍历的过程</li>
</ul>
<pre><code class="java">public E poll() {
    restartFromHead:
    for (;;) {
        for (Node&lt;E&gt; h = head, p = h, q;;) {
            E item = p.item;
            // item != null 说明该节点是一个有效节点, 通过 CAS 将其item改为 null
            if (item != null &amp;&amp; p.casItem(item, null)) {
                // CAS 成功说明已经移除一个节点了，后续的操作和添加元素时类似，因为 head 指针也是一个竞争点
                // 所以这里并没有直接修改 head 指针，而是发现从 head 至少向后遍历过一次时，才会修改 head 指针，这和 offer 中的方式类似
                // Successful CAS is the linearization point
                // for item to be removed from this queue.
                if (p != h) // hop two nodes at a time
                    // 判断刚删掉的节点 p 的 next 是不是null，是的话就让 p 作为 head（此时p充当新的虚节点），
                    // 如果不是的话，就让 p.next 作为 next（此时head就是实际上的头结点）
                    updateHead(h, ((q = p.next) != null) ? q : p);
                return item;
            }
            else if ((q = p.next) == null) {
                // 说明 p已经是最后一个节点了，我们需要返回 null
                // 但是在此之前，我们不妨把p设为新的head来减少其他线程的遍历开销
                updateHead(h, p);
                return null;
            }
            else if (p == q)
                // 说明当前检查的这个节点已经被别的线程从队列中移除了，那我们就重新开始执行 poll
                continue restartFromHead;
            else
                // p = q(p.next)，也就是说这是从 head 开始向后遍历的过程
                p = q;
        }
    }
}
</code></pre>
<p>updateHead 的过程中先会检查是不是真的有必要重置 head 指针，有必要的话在通过 CAS 修改 head 指针，如果 CAS 失败了也无妨，毕竟我们不要求 head 一定指向实际的头结点，poll 中的遍历过程能 cover 这种情况。如果 CAS 成功，会将删掉的 head 指针指向自己。</p>
<pre><code class="java">/**
 * Tries to CAS head to p. If successful, repoint old head to itself
 * as sentinel for succ(), below.
 */
final void updateHead(Node&lt;E&gt; h, Node&lt;E&gt; p) {
    if (h != p &amp;&amp; casHead(h, p))
        h.lazySetNext(h);
}

void lazySetNext(Node&lt;E&gt; val) {
    UNSAFE.putOrderedObject(this, nextOffset, val);
}
</code></pre>
<p>这里大家可能会有疑问，为什么要 lazySet next 指针呢？要想理解这个问题，我们需要先理解 putOrderedObject 和 putObjectVolatile 的区别。因为 Node 中的 next 属性是用 volatile 修饰的，而 volatile 有什么特点呢？一个是防止指令重拍，一个是将其他 CPU cache 中的相关数据无效化，迫使这些 CPU 重新从主存中拉取最新数据。这是通过 Fence (内存屏障) 实现的，在 linux x86 架构中一般是 lock; addl $0,0(%%esp). , 通过加锁来保证互斥。</p>
<p>而 putObjectVolatile 函数等效于声明一个 volatile 变量，然后直接对该变量进行修改。也就是说，无论是 putObjectVolatile 还是对 volatile 变量的直接修改，都依赖与 StoreLoad barriers ，这里 StoreLoad barriers 就是说如果指令的顺序是 Store1; StoreLoad; Load2 ，就需要确保 Store1 保存的数据在 Load2 访问数据之前，一定要能够对所有线程可见。关于内存屏障的解释，可以参考这篇手册, 其中介绍了各个内存屏障的要求，以及在不同架构上的实现方式。</p>
<p>而 putOrderedObject 函数呢，只需要保证当前 cpu 内指令是有序的，不会出现非法的内存访问即可，这也就是说，putOrderedObject 没有多处理期间的可见性保证，也就不会有多余的开销。在我们 ConcurrentLinkedQueue 的场景中，最终将 next 指针指向自己并不需要这么高的可见性需求，而且 next 是修饰为 volatile 的，所以，我们需要显式地调用 putOrderedObject 才能达到 “去 volatile 特性” 的效果，从而提升效率。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之PriorityBlockingQueue]]></title>
      <url>/2020/11/24/juc-12/</url>
      <content type="html"><![CDATA[<p>内容转载自  <a href="https://www.jianshu.com/p/bf6ef56646e5" target="_blank" rel="noopener"> https://www.jianshu.com/p/28c9d9e34b29</a>   稍有改动</p>
<h2 id="PriorityBlockingQueue定义"><a href="#PriorityBlockingQueue定义" class="headerlink" title="PriorityBlockingQueue定义"></a>PriorityBlockingQueue定义</h2><p>PriorityBlockingQueue 是基于 二叉堆, ReentrantLock, Condition 实现的并发安全的优先级队列.<br>主要有以下特点:</p>
<ul>
<li>数据容量没有界限(最大值 Integer.MAX_VALUE - 8)</li>
<li>居于ReentrantLock 实现并发安全, 基于 Condition 实现线程等待唤醒</li>
<li>数据底层存放在居于数组实现的二叉堆上, 注意这里没有实现堆排序, 只是每次有数据变更时将最小/大放在了堆的最上面的节点上</li>
</ul>
<h2 id="初始化方法-堆化-heapify"><a href="#初始化方法-堆化-heapify" class="headerlink" title="初始化方法 堆化(heapify)"></a>初始化方法 堆化(heapify)</h2><p>实现思路: 从堆的最后一个 parent 开始, 将最小/大值放在 parent位置, 直到最顶层的parent为止；<br>直接看代码</p>
<pre><code class="java">/**
 * Establishes the heap invariant (described above) in the entire tree
 * assuming nothing about the order of the elements prior to the call
 */
private void heapify(){
    /**
     * 将这个数组进行 堆化 (heapify)
     *
     */
    Object[] array = queue;
    int n = size;
    int half = (n &gt;&gt;&gt; 1) -1;                // 1. 这里有个注意点 n 是数组的 length,
    Comparator&lt;? super E&gt; cmp = comparator; // 2. 获取 比较器, 若这里的 comparator是空, 则用元素自己实现的比较接口进行比较
    if(cmp == null){
        for(int i = half; i &gt;= 0; i--){     // 3. 从整个数组的最后一颗树开始, 将二叉树的最小值放置在parent位置, 一直到最上面的那颗二叉树
            siftDownComparable(i, (E)array[i], array, n);
        }
    }else{
        for(int i = half; i &gt;= 0; i--){
            siftDownUsingComparator(i, (E)array[i], array, n, cmp);
        }
    }
                                            // 4. 经过这个 heapify 方法后, 整个二叉堆中的最小值已经放在的 index=0 的位置上(注意: 这时不保证 左子树一定小于右子树)
                                            // 5. 若要进行二叉堆的排序, 则需要将 index=0的位置排查在外 从 index= 1的位置开始, 到最后一个位置, 再进行上面的操作
                                            // 其实思路就是 每次将最小值放在数组的最上面, 然后排除这个节点在外, 将下面的数组作为一个整体, 然后重复上面的步骤, 直到最后一个元素
}
</code></pre>
<p>这个方法其实从最后一个 parent 开始进行与子节点比较, 将最小/大值放在 parent 位置, 直到 顶层的 parent 为止<br>我们发现代码中有个 siftDownComparable 方法, 这是实现 堆化的重要步骤</p>
<pre><code class="java">/**
 * Inserts item x at position k, maintaining heap invariant by
 * demoting x down the tree repeatedly until it is less than or
 * equal to its children or is a leaf
 *
 * @param k     the position to fill
 * @param x     the item to insert
 * @param array the heap array
 * @param n     the heap array
 * @param &lt;T&gt;
 */
private static &lt;T&gt; void siftDownComparable(int k, T x, Object[] array, int n){
    /**
     * 从整个数组的 k 位置开始向下进行 比较更换操作
     * 1. 获取这个数组的中间值(大于等于它其实就是说已经没有子节点)
     *      举例: 数组 array 含有元素 : 1,2,3,4,5,6,7,8,9,10 共10个元素
     *          其中的之间 half = n &gt;&gt;&gt; 1 = 10 &gt;&gt;&gt; 1 = 5; (就是下面代码中的 half, 堆中所有parent的 index 均小于 5)
     *          而最大 parent 的index 是 : (9 - 1) &gt;&gt;&gt; 1 = 4;
     *          再parent调整好后, 再下面的代码中获取的 k 就变成 9/10, 但是 9/10 &gt; 5 (就是下面代码的 while(k &lt; half))
     * 2. 从k位子开始不断向下比较, 将最小值放到 parent位置, 直到 k &gt;= half
     * 3. 经过这个方法比较后, 从k往下 都是最小值上parent上的一个棵二叉树
     */
    if(n &gt; 0){
        Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;)x;
        int half = n &gt;&gt;&gt; 1;                 // 1. 获取整个数组的中间坐标
        while(k &lt; half){                    // 2. k这里其实表示 parent 在数组中的 index, k &gt;= half 其实就说明 k 在数组中已经没有子节点
            int child = (k &lt;&lt; 1) + 1;       // 3. 获取 k 的左子节点的 index
            Object c = array[child];        // 4. 获取左子节点的值
            int right = child + 1;          // 5. 获取右子节点的 index
            if(right &lt; n &amp;&amp;                 // 6. 这个 if 判断其实是 判断左右子节点的大小, 并且找到其中的最小值, 赋值给 c;
                    ((Comparable&lt;? super T&gt;)c).compareTo((T)array[right]) &gt; 0
                    ){
                c = array[child = right];
            }
            if(key.compareTo((T)c) &lt;= 0){   // 7. key &lt;= c 则说明, 进行下面 sift 已经完成 (父节点k已经小于等于子节点), 直接 break 出
                break;
            }
            array[k] = c;                   // 8. 代码运行到这里说明 k &gt; c， 则将子数据c赋值到k的位置
            k = child;                      // 9. 将上次的子节点 child作为父节点, 再次下面进行比较, 直到 k &gt;= half
        }
        array[k] = key;                     // 10. 将key值赋值给最后一次进行 siftdown 比较的  父节点上
    }
}
</code></pre>
<p>操作思路:</p>
<pre><code class="java"> 从整个数组的 k 位置开始向下进行 比较更换操作
  1. 获取这个数组的中间值(大于等于它其实就是说已经没有子节点)
       举例: 数组 array 含有元素 : 1,2,3,4,5,6,7,8,9,10 共10个元素
           其中的之间 half = n &gt;&gt;&gt; 1 = 10 &gt;&gt;&gt; 1 = 5; (就是下面代码中的 half, 堆中所有parent的 index 均小于 5)
           而最大 parent 的index 是 : (9 - 1) &gt;&gt;&gt; 1 = 4;
           再parent调整好后, 再下面的代码中获取的 k 就变成 9/10, 但是 9/10 &gt; 5 (就是下面代码的 while(k &lt; half))
  2. 从k位子开始不断向下比较, 将最小值放到 parent位置, 直到 k &gt;= half
  3. 经过这个方法比较后, 从k往下 都是最小值上parent上的一个棵二叉树
</code></pre>
<h2 id="添加元素-offer-方法"><a href="#添加元素-offer-方法" class="headerlink" title="添加元素 offer 方法"></a>添加元素 offer 方法</h2><p>主要思路: 将添加的元素放置到数组的最尾端, 然后调用 siftUp 进行向上调整</p>
<pre><code class="java">  /**
 * Inserts the specified element into this priority queue
 * As the queue is unbounded, his method will never return {@code false}
 *
 * @param e the lement to add
 * @return {@code true} (as specified element cannot be compared
 *          with elements currently in the priority queue according to the
 *          priority queue&#39;s ordering)
 * @throws NullPointerException if the specified element is null
 */
@Override
public boolean offer(E e) {
    if(e != null){
        throw new NullPointerException();
    }
    final ReentrantLock lock = this.lock;       // 1. 获取全局共享的锁
    lock.lock();
    int n, cap;
    Object[] array;                             // 2. 判断容器是否需要扩容
    while((n = size) &gt;= (cap = (array = queue).length)){
        tryGrow(array, cap);                    // 3. 进行扩容操作
    }

    try{
        Comparator&lt;? super E&gt; cmp = comparator;
        if(cmp == null){                        // 4. 进行 保持 heap 性质的 siftUp 操作
            siftUpComparable(n, e, array);
        }else{
            siftUpUsingComparator(n, e, array, cmp);
        }
        size = n + 1;                           // 5. 数据插入后, 整个容量值 + 1;
        notEmpty.signal();                      // 6. Condition 释放信号, 告知其他等待的线程: 容器中已经有元素
    }finally {
        lock.unlock();                          // 7. 释放锁
    }
    return true;
}
</code></pre>
<p>在代码中我们看到了 tryGrow, 这个调整堆存储空间的方法<br>在里面运用了 先进行锁的释放 lock.unlock, 然后 根据 allocationSpinLock 这个指标判断是否其他线程在进行扩容, 基本上每次扩容都是 * 1.5</p>
<pre><code class="java">/**
 * Tries to grow array to accommodate at least one more element
 * (but normally expend by about 50%), giving up (allowing retry)
 * on contention (which we expect to be race). Call only this while
 * holding lock
 *
 * @param array the heap array
 * @param oldCap    the length of the array
 */
private void tryGrow(Object[] array, int oldCap){
    /**
     * tryGrow 数组容量扩容操作
     * 整个方法的执行是在已经 ReentrantLock 获取锁的情况下进行的
     */

    lock.unlock(); // must release and then re-acquire main lock // 1. 释放全局的锁(为什么呢? 原因也非常简单, 这个 lock 是全局方法共享的, 为的是更好的并发性能, 而扩容操作的并发是通过简单的乐观锁 allocationSpinLock 来进行控制de)
    Object[] newArray = null;
    if(allocationSpinLock == 0 &amp;&amp;                                // 2. 居于CAS操作, 在 allocationSpinLock 实现乐观锁, 这个也是为了在扩容时不影响容器的其他并发操作
            unsafe.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)){
        try{
            int newCap = oldCap + ((oldCap &lt; 64)?                // 3. 容量若小于 64则直接 double + 2; 大于的话, 直接 ＊ 1.5
                    (oldCap + 2): // grow faster if small
                    (oldCap &gt;&gt; 1)
                                    );
            if(newCap - MAX_ARRAY_SIZE &gt; 0){ // possible overflow
                int minCap = oldCap + 1;                         // 4. 扩容后超过最大容量处理
                if(minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE){
                    throw new OutOfMemoryError();
                }
                newCap = MAX_ARRAY_SIZE;
            }
            if(newCap &gt; oldCap &amp;&amp; queue == array){              // 5. queue == array 若数组没变化, 直接进行新建数组
                newArray = new Object[newCap];
            }
        }finally {
            allocationSpinLock = 0;
        }
    }
                                                                // 6. newArray == null 说明上面的操作过程中, 有其他的线程进行了扩容的操作
    if(newArray == null){ // back off if another thread is allocating
        Thread.yield();                                         // 7. 让出 CPU 调度(因为其他线程扩容后必定有其他的操作)
    }
    lock.lock();                                                // 8. 重新获取锁
    if(newArray != null &amp;&amp; queue == array){                     // 9. 判断数组 queue 有没有在其他线程中变化过
        queue = newArray;                                       // 10. 未变化, 直接进行赋值操作
        System.arraycopy(array, 0, newArray, 0, oldCap);
    }
}
</code></pre>
<p>在进行offer元素时主要还调用了 siftUpComparable 方法<br>思路: 将元素与上面的 parent 进行比较, 直到 parent &gt;= 这个元素</p>
<pre><code class="java">    /**
     * Insert item x at position k, maintaining heap invariant by
     * promoting x up the tree until it is greater than or equal to
     * its parent, or is the root
     *
     * To simplify and speed up coercions and comparisons. the
     * Comparable and Comparator versions are separated into different
     * method that are otherwise identical. (Similarly for siftDown)
     * These methods are statics, with heap state as arguments, to
     * simplify use in light og possible comparator exceptions
     *
     * @param k the position to fill
     * @param x the item to insert
     * @param array the heap array
     * @param &lt;T&gt;
     */
    private static &lt;T&gt; void siftUpComparable(int k, T x, Object[] array){
        /**
         * 简单的 siftUp 操作: 大体操作就是将元素x放置到k位置, 然后对k的parent进行比较, 直到 k&gt;=parent为止
         */
        Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;)x;
        while(k &gt; 0){                           // 1. k是否到达二叉树的顶端
            int parent = (k - 1) &gt;&gt;&gt; 1;         // 2. 寻找 k 的parent位置
            Object e = array[parent];           // 3. 获取parent的值
            if(key.compareTo((T)e) &gt;= 0){       // 4. key &gt;= e说明 parent &gt;=子节点, 则不需要 siftUp 操作
                break;
            }
            array[k] = e;                       // 5. 将上次比较中 parent节点的值放在子节点上
            k = parent;                         // 6. 将这次比较中的 parent 当作下次比价的k(k是下次比较的子节点)
        }
        array[k] = key;                         // 7. 将值key放置合适的位置上
    }
</code></pre>
<h2 id="删除元素-poll-方法"><a href="#删除元素-poll-方法" class="headerlink" title="删除元素 poll 方法"></a>删除元素 poll 方法</h2><p>思路: 将元素的首节点拿出, 作为返回, 末尾节点放置到 index=0位置, 开始 siftDown直到 满足 parent &gt;= child</p>
<pre><code class="java">@Override
public E poll() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        return dequeue();
    } finally {
        lock.unlock();
    }
}

private E dequeue(){
    int n = size - 1;
    if(n &lt; 0){                              // 1. 判断元素是否未空
        return null;                        // 2. 容器中没有元素, 直接返回 null
    }
    else{
        Object[] array = queue;
        E result = (E)array[0];             // 3. 取出数组中的第一个元素, 作为返回值
        E x = (E)array[n];                  // 4. 将数组的最后一个元素取出
        array[n] = null;
        Comparator&lt;? super E&gt; cmp = comparator;
        if(cmp == null){                    // 5. 将刚才取出的数组中最后一个元素放到第一个index位置, 进行siftDown操作(就是向下堆化操作)
            siftDownComparable(0, x, array, n);
        }else{
            siftDownUsingComparator(0, x, array, n, cmp);
        }
        size = n;                           // 6. 重新赋值 size值
        return result;                      // 7. 返回取出的值
    }
}
</code></pre>
<p>PriorityBlockingQueue的注意要点</p>
<p>PriorityBlockingQueue底层由数组维护，是基于PriorityQueue实现的阻塞队列。构造PriorityBlockingQueue最好传参数capacity(容量)，防止过度扩张，默认为11。</p>
<p>但因为PriorityBlockingQueue可以扩容，可以被无限扩容到Integer.MAX_VALUE - 8，所以可以看做是一个”无界”阻塞队列。注意资源耗竭问题(会产生OOM)。</p>
<p>PriorityBlockingQueue底层对于元素的入队列和出队列使用的是同一个lock对象。</p>
<p>因为PriorityBlockingQueue是”无界”阻塞队列，所以put()不需要阻塞，直接调用offer()方法。因为，put方法在队列满时阻塞，take方法在队列空时阻塞，由于PriorityBlockingQueue是”无界”阻塞队列，所以不需要阻塞。</p>
<p>PriorityBlockingQueue和ArrayBlockingQueue都是由数组维护。二者区别是，PriorityBlockingQueue支持扩容，ArrayBlockingQueue并不支持。由于LinkedBlockingQueue由链表维护，没有扩容的概念，只是会有容量限制。PriorityBlockingQueue的扩容使用CAS自旋锁。</p>
<p>PriorityBlockingQueue的offer()方法(add()、put()方法相当于调用offer()方法)，poll()方法调用lock.lock()获取锁，不响应中断，因为这两个方法不是阻塞的；take()方法都调用lock.lockInterruptibly();方法获取锁，注意：该方法支持线程中断响应。</p>
<p>PriorityBlockingQueue的插入移除参考二叉堆中的最小堆，因为数字越小优先级越高，数字越大优先级越低。所以数字最小的是在队头。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之LinkedBlockingQueue、SynchronousQueue]]></title>
      <url>/2020/11/24/juc-11/</url>
      <content type="html"><![CDATA[<p>内容转载自   <a href="https://www.jianshu.com/p/28c9d9e34b29" target="_blank" rel="noopener">https://www.jianshu.com/p/28c9d9e34b29</a>   稍有改动</p>
<h2 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h2><p>LinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，满足 FIFO 的特性，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。因为Integer.MAX_VALUE数值很大，所以可以称为”无界”队列(这里的无界并不是真正意义上的无界)。</p>
<p>LinkedBlockingQueue比ArrayBlockingQueue具有更高的吞吐量，但在大多数并发应用程序中的预测性能较差。</p>
<p>队列中存在最久的元素存在于 head.next 节点上(PS: head 节点永远存在, 且是一个 dummy 节点), 存储时间最短的节点存储在tail上; 通常情况下 LinkedBlockingQueue 的吞吐量要好于 ArrayBlockingQueue.<br>主要特点:</p>
<p>基于两个lock的 queue, putLock, takeLock; 并且两个锁都有相关联的 condition 用于相应的 await; 每次进行 put/offer 或 take/poll 之后会根据queue的容量进行判断是否需要进行对应的唤醒<br>队列中总是存在一个 dummy 节点, 每次 poll 节点时获取的是 head.next 节点中的值</p>
<p>为了实现阻塞效果并保证线程安全，它的内部用到了两个锁和两个 Condition。（ArrayBlockingQueue只有一个锁，这导致了LinkedBlockingQueue可以一边取一边放，而ArrayBlockingQueue不行。为啥？因为固定长度的count是个int，不能保证原子性和可见性，至于为什么这么设计，我也不清楚）</p>
<p>queue中的数据存储在 Node 对象中, 且 Node 具有以下的特点:</p>
<ul>
<li>head.item 永远是 null, head是一个 dummy 节点, 所以进行 poll 时获取的是 head.next 的值</li>
<li>tail.next = null</li>
</ul>
<pre><code class="java">/** Linked list node class */
/**
 * Linked 的数据节点, 这里有个特点, LinkedBlockingQueue 开始构建时会创建一个dummy节点(类似于 ConcurrentLinkedQueue)
 * 而整个队列里面的头节点都是 dummy 节点
 * @param &lt;E&gt;
 */
static class Node&lt;E&gt;{
    E item;

    /**
     * One of:
     * - the real successor Node
     * - this Node, meaning the successor is head.next
     * - null, meaning there is no successor (this is the last node)
     */
    /**
     * 在进行 poll 时 会将 node.next = node 来进行 help gc
     * next == null 指的是要么是队列的 tail 节点
     */
    Node&lt;E&gt; next;
    Node(E x){
        item = x;
    }
}

/** The capacity bound, or Integer.MAX_VALUE if none */
private final int capacity;

/** Current number of elements */
private final AtomicInteger count = new AtomicInteger();

/**
 * Head of linked list
 * Invariant: head.item == null
 * Head 节点的不变性 head.item == null &lt;- 这是一个 dummy 节点(dummy 节点什么作用呢, 主要是方便代码, 不然的话需要处理一些 if 的判断, 加大代码的复杂度, 尤其是非阻塞的实现)
 */
transient Node&lt;E&gt; head;

/**
 * Tail of linked list
 * Invariant: last.next == null
 * Tail 节点的不变性 last.next == null &lt;- 尾节点的 next 是 null
 */
private transient Node&lt;E&gt; last;

/** ReentrantLock Condition 的常见使用方式 */
/** Lock held by take, poll, etc */
private final ReentrantLock takeLock = new ReentrantLock();

/** Wait queue for waiting takes */
private final Condition notEmpty = takeLock.newCondition();

/** Lock held by put, offer, etc */
private final ReentrantLock putLock = new ReentrantLock();

/** Wait queue for waiting puts */
private final Condition notFull = putLock.newCondition();
</code></pre>
<p>LinkedBlockingQueue 构造函数<br>LinkedBlockingQueue的构造函数比较简单, 主要是初始化一下容量(默认 Integer.MAX_VALUE), 及 head, tail</p>
<pre><code class="java">/**
 * Creates a {@code KLinkedBlockingQueue} with the given (fixed) capacity
 *
 * @param capacity the capacity of this queue
 * @throws IllegalArgumentException if {@code capacity} is not greater
 *                                  than zero
 */
public KLinkedBlockingQueue(int capacity){
    if(capacity &lt;= 0) throw new IllegalArgumentException();
    this.capacity = capacity; // 指定 queue 的容量
    last = head = new Node&lt;E&gt;(null); // 默认的在 queue 里面 创建 一个 dummy 节点
}
</code></pre>
<p>添加元素 put方法<br>put 方法是将元素添加到队列尾部, queue满时进行await, 添加成功后容量还未满, 则进行 signal</p>
<pre><code class="java">/**
 * Inserts the specified element at the tail of this queue, waiting if
 * necessary for space to become available
 *
 *  将元素加入到 queue 的尾部
 * @param e
 * @throws InterruptedException
 */
public void put(E e) throws InterruptedException{
    if(e == null) throw new NullPointerException();
    // Note: convention in all put/take/etc is to preset local var
    // holding count negativeto indicate failure unless set.
    // 有趣的 变量 c 下面会有对它的讲解
    int c = -1;
    Node&lt;E&gt; node = new Node&lt;E&gt;(e);
    final ReentrantLock putLocK = this.putLock;
    final AtomicInteger count = this.count;  // 获取 queue 的数量 count 
    putLocK.lockInterruptibly(); // 获取 put 的lock
    try {
        /**
         * Note that count is used in wait guard even though it is
         * not protected by lock. This works because count can
         * only decrease at this point (all other puts are shut
         * out by lock), and we (or some other waiting put) are
         * signalled if it ever changes from capacity. Similarly
         * for all other uses of count in other wait guards
         */
        /**
         * 若 queue 的容量满了 则进行 await,直到有人进行通知
         * 那何时进行通知呢?
         * 有两种情况进行通知,
         *      (1) 有线程进行 put/offer 成功后且 (c + 1) &lt; capacity 时
         *      (2) 在线程进行 take/poll 成功 且 (c == capacity) (PS: 这里的 c 指的是 在进行 take/poll 之前的容量)
         */

        while(count.get() == capacity){     // 容量满了, 进行等待
            notFull.await();
        }
        enqueue(node);                        // 进行节点的入队操作
        c = count.getAndIncrement();          // 进行节点个数的增加1, 返回原来的值
        if(c + 1 &lt; capacity){               // 说明 现在的 put 操作后 queue 还没满
            notFull.signal();               // 唤醒其他在睡的线程
        }

    }finally {
        putLock.unlock();                   // 释放锁
    }
    if(c == 0){                             // c == 0 说明 原来queue是空的, 所以这里 signalNotEmpty 一下, 唤醒正在 poll/take 等待中的线程
        signalNotEmpty();
    }
}

/**
 * Links node at end of queue
 * 节点 入队列 (PS: 这里因为有个 dummy 节点, 不需要判空 &lt;- 现在有点感觉 dummy 节点的作用了吧)
 * @param node the node
 */
private void enqueue(Node&lt;E&gt; node){
    // assert putLock.isHeldByCurrentThread()
    // assert last.next == null
    last = last.next = node;
}

/**
 * Signals a waiting take. Called only from put/offer (which do not
 * otherwise ordinarily lock takeLock.)
 */
private void signalNotEmpty(){
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lock();
    try {
        notEmpty.signal();
    }finally {
        takeLock.unlock();
    }
}
</code></pre>
<p>代码的注释中基本把操作思想都说了, 有几个注意的地方</p>
<ul>
<li>当queue满时, 会调用 notFull.await() 进行等待, 而相应的唤醒的地方有两处, 一个是 “有线程进行 put/offer 成功后且 (c + 1) &lt; capacity 时”, 另一处是 “在线程进行 take/poll 成功 且 (c == capacity) (PS: 这里的 c 指的是 在进行 take/poll 之前的容量)”</li>
<li>代码中的 “signalNotEmpty” 这时在原来queue的数量 c (getAndIncrement的返回值是原来的值) ==0 时对此时在调用 take/poll 方法的线程进行唤醒</li>
</ul>
<p>添加元素offer 方法</p>
<p>offer与put都是添加元素到queue的尾部, 只不过 put 方法在队列满时会进行阻塞, 直到成功; 而 offer 操作在容量满时直接返回 false.</p>
<pre><code class="java">/**
 * Inserts the specified element at the tail of this queue, waiting if
 * necessary up to the specified wait time for space to become available
 *
 *  支持中断和超时的 offer 节点
 *
 * @param e
 * @param timeout
 * @param unit
 * @return {@code true} if successful, or {@code false} if
 *          the specified waiting time elapses before space is available
 * @throws InterruptedException
 */
public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException{
    if(e == null) throw new NullPointerException();
    long nanos = unit.toNanos(timeout);
    int c = -1;
    final ReentrantLock putLock = this.putLock;     // 获取 put lock
    final AtomicInteger count = this.count;         // 获取 queue 的容量
    putLock.lockInterruptibly();
    try {
        while(count.get() == capacity){             // queue的容量满了进行 带 timeout 的 await
            if(nanos &lt;= 0){                           //  用光了 timeout 直接 return false
                return false;
            }
            nanos = notFull.awaitNanos(nanos);      // 直接 await (PS: 返回值 nanos &lt;= 0 说明 等待是超时了, 正常 await 并且 被 signal nanos &gt; 0; 具体详情会在 Condition 那一篇中详细说明)
        }
        enqueue(new Node&lt;E&gt;(e));                    // 节点若队列
        c = count.getAndIncrement();                // 获取入队列之前的容量
        if(c + 1 &lt; capacity){                     // c + 1 &lt; capacity 说明 现在的 offer 成功后 queue 还没满
            notFull.signal();                     // 唤醒其他正在 await 的线程
        }
    }finally {
        putLock.unlock();                           // 释放锁
    }
    if(c == 0){
        signalNotEmpty();                            // c == 0 说明 原来queue是空的, 所以这里 signalNotEmpty 一下, 唤醒正在 poll/take 等待中的线程
    }
    return true;
}
</code></pre>
<p>offer 整个操作和 put 差不多, 唯一变化的是多了一个 notFull.awaitNanos(nanos), 这个函数的返回值若是负数, 则说明等待超时, 则直接 return false (关于 Condition.awaitNanos 方法会在后续再说)</p>
<p>获取queue头元素 take 方法<br>此方法是获取 queue 中呆着时间最长的节点的值(head.next)</p>
<pre><code class="java">/**
 * 取走 queue 中呆着时间最长的节点的 item (其实就是 head.next.item 的值)
 * @return
 * @throws InterruptedException
 */
public E take() throws InterruptedException{
    E x;
    int c = -1;
    final AtomicInteger count = this.count;          // 获取 queue 的容量
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();                      // 获取 lock
    try {
        while(count.get() == 0){                      // queue 为空, 进行 await
            notEmpty.await();
        }
        x = dequeue();                                 // 将 head.next.item 的值取出, head = head.next
        c = count.getAndDecrement();                   // queue 的容量计数减一
        if(c &gt; 1){
            notEmpty.signal();                        // c &gt; 1 说明 进行 take 后 queue 还有值
        }
    }finally {
        takeLock.unlock();                              // 释放 lock
    }
    if(c == capacity){                                // c == capacity 说明一开始 queue 是满的, 调用 signalNotFull 进行唤醒一下 put/offer 的线程
        signalNotFull();
    }
    return x;
}

/**
 * Removes a node from head of queue
 * 节点出队列 这里有个注意点 head 永远是 dummy 节点, dequeue 的值是 head.next.item 的值
 * 在 dequeue 后 将 原  head 的后继节点设置为 head(成为了 dummy 节点)
 * @return the node
 */
private E dequeue(){
    // assert takeLock.isHeldByCurrentThread();
    // assert head.item == null;
    Node&lt;E&gt; h = head;       // 这里的 head 是一个 dummy 节点
    Node&lt;E&gt; first = h.next; // 获取真正的节点
    h.next = h;             // help GC
    head = first;           // 重行赋值 head
    E x = first.item;       // 获取 dequeue 的值
    first.item = null;      // 将 item 置 空
    return x;
}

/** Signal a waiting put. Called only from take/poll */
private void signalNotFull(){
    final ReentrantLock putLock = this.putLock;
    putLock.lock();
    try {
        notFull.signal();
    }finally {
        putLock.unlock();
    }
}
</code></pre>
<p>操作过程: 将 head.next 的值取出, 将 head.next 设置为新的head; 操作的步骤比较少, 只有两处 condition 的唤醒需要注意一下：</p>
<p>当 take 结束时, 判断 queue 是否还有元素 (c &gt; 1) 来进行 notEmpty.signal()<br>当 take 结束时, 判断原先的容量是否已经满 (c == capacity) 来决定是否需要调用 signalNotFull 进行唤醒此刻还在等待 put/offer 的线程</p>
<p>获取queue头元素 poll 方法<br>poll 与 take 都是获取头节点的元素, 唯一的区别是 take在queue为空时进行await, poll 则直接返回</p>
<pre><code class="java">/**
 * 带 timeout 的poll 操作, 获取 head.next.item 的值
 * @param timeout
 * @param unit
 * @return
 * @throws InterruptedException
 */
public E poll(long timeout, TimeUnit unit) throws InterruptedException{
    E x = null;
    int c = -1;
    long nanos = unit.toNanos(timeout);             //  计算超时时间
    final AtomicInteger count = this.count;       // 获取 queue 的容量
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();                   // 获取 lock
    try{
        while(count.get() == 0){                   // queue 为空, 进行 await
            if(nanos &lt;= 0){                        // timeout 用光了, 直接 return null
                return null;
            }
            nanos = notEmpty.awaitNanos(nanos);   // 调用 condition 进行 await, 在 timeout之内进行 signal -&gt; nanos&gt; 0
        }
        x = dequeue();                             // 节点出queue
        c = count.getAndDecrement();               // 计算器减一
        if(c &gt; 1){                                 // c &gt; 1 说明 poll 后 容器内还有元素, 进行 换新 await 的线程
            notEmpty.signal();
        }
    }finally {
        takeLock.unlock();                         // 释放锁
    }
    if(c == capacity){                           // c == capacity 说明一开始 queue 是满的, 调用 signalNotFull 进行唤醒一下 put/offer 的线程
        signalNotFull();
    }
    return x;
}
</code></pre>
<p>LinkedBlockingQueue 是一个基于链表实现的阻塞queue, 它的性能好于 ArrayBlockingQueue, 但是差于 ConcurrentLinkeQueue; 并且它非常适于生产者消费者的环境中, 比如 Executors.newFixedThreadPool() 就是基于这个队列的。</p>
<p>LinkedBlockingQueue的静态工厂方法<br>使用LinkedBlockingQueue的好处：</p>
<p>因为线程大小固定的线程池，其线程的数量是不具备伸缩性的，当任务非常繁忙的时候，就势必会导致所有的线程都处于工作状态，导致队列满的情况发生，从而导致任务无法提交而抛出RejectedExecutionException；<br>而使用”无界”队列由于其良好的存储容量的伸缩性，可以很好的去缓冲任务繁忙情况下场景，即使任务非常多，也可以进行动态扩容，当任务被处理完成之后，队列中的节点也会被随之被GC回收，非常灵活。</p>
<p>FixedThreadPool的execute()说明</p>
<p><img src="https://s3.ax1x.com/2020/11/24/DNQXj0.png" alt="DNQXj0.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/24/DNQxBT.png" alt="DNQxBT.png"></p>
<p>FixedThreadPool的execute()执行流程</p>
<ul>
<li><p>如果当前运行的线程数少于corePoolSize，则会创建新线程来执行任务；</p>
</li>
<li><p>在线程池完成预热之后(当前运行的线程数等于corePoolSize)，将任务加入LinkedBlockingQueue；</p>
</li>
<li><p>线程执行完步骤A中的任务后，会在循环中反复从LinkedBlockingQueue获取任务来执行。</p>
</li>
</ul>
<p>使用Executors.newFixedThreadPool相关的方法，LinkedBlockingQueue的capacity为Integer.MAX_VALUE，所以会对线程池有以下影响：</p>
<ul>
<li><p>当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize；</p>
</li>
<li><p>由于A影响，使用”无界”队列时maximumPoolSize将是一个无效参数；</p>
</li>
<li><p>由于A、B影响，使用”无界”队列时keepAliveTime将是一个无效参数；</p>
</li>
<li><p>由于使用”无界队列”，运行中的FixedThreadPool(未执行shutdown()或shutdownNow())不会拒绝任务(不会调用RejectedExecutionException.rejectedExecution方法)。</p>
</li>
</ul>
<p>SingleThreadExecutor的execute()说明</p>
<p><img src="https://s3.ax1x.com/2020/11/24/DNlDvq.png" alt="DNlDvq.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/24/DNl6bT.png" alt="DNl6bT.png"></p>
<p>SingleThreadExecutor的execute()执行流程</p>
<ul>
<li><p>如果当前运行的线程数少于corePoolSize(即线程池中无运行的线程)，则会创建一个新线程来执行任务；</p>
</li>
<li><p>在线程池完成预热之后(当前线程池中有一个运行的线程)，将任务加入LinkedBlockingQueue；</p>
</li>
<li><p>线程执行完步骤A中的任务后，会在一个无线循环中反复从LinkedBlockingQueue获取任务来执行。</p>
</li>
</ul>
<p>SingleThreadExecutor使用”无界”的工作队列对线程池带来的影响与使用Executors.newFixedThreadPool相同。</p>
<p>ArrayBlockingQueue和LinkedBlockingQueue的比较</p>
<ul>
<li>ArrayBlockingQueue由于其底层基于数组，并且在创建时指定存储的大小，在完成后就会立即在内存分配固定大小容量的数组元素，因此其存储通常有限；</li>
<li>而LinkedBlockingQueue可以由用户指定最大存储容量，也可以无需指定，如果不指定则最大存储容量将是Integer.MAX_VALUE，由于其节点的创建都是动态创建，并且在节点出队列后可以被GC所回收，因此其具有灵活的伸缩性。</li>
<li>但是由于ArrayBlockingQueue的有界性，因此其能够更好的对于性能进行预测，</li>
<li><p>而LinkedBlockingQueue由于没有限制大小，当任务非常多的时候，不停地向队列中存储，就有可能导致内存溢出的情况发生。</p>
</li>
<li><p>ArrayBlockingQueue中在入队列和出队列操作过程中，使用的是同一个lock，所以即使在多核CPU的情况下，其读取和操作的都无法做到并行，而LinkedBlockingQueue的读取和插入操作所使用的锁是两个不同的lock，它们之间的操作互相不受干扰，因此两种操作可以并行完成，故LinkedBlockingQueue的吞吐量要高于ArrayBlockingQueue。</p>
</li>
</ul>
<h2 id="SynchronousQueue"><a href="#SynchronousQueue" class="headerlink" title="SynchronousQueue"></a>SynchronousQueue</h2><p>每个插入操作必须等待另一个线程的对应移除操作 ，反之亦然。同步队列没有任何内部容量，甚至连一个队列的容量都没有。<br>SynchronousQueue的支持公平策略和非公平策略，所以底层可能两种数据结构：队列（实现公平策略）和栈（实现非公平策略），队列与栈都是通过链表来实现的。</p>
<p>SynchronousQueue的静态工厂方法</p>
<p>SynchronousQueue的execute()说明</p>
<p><img src="https://s3.ax1x.com/2020/11/24/DNG0oT.png" alt="DNG0oT.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/24/DNGrYF.png" alt="DNGrYF.png"></p>
<p>可以看到CacheThreadPool的corePoolSize被设置为0，即corePool为空，maximumPoolSize被设置为Integer.MAX_VALUE，即maximumPool是”无界”的，这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度，CacheThreadPool会不断创建新的线程，极端情况下，CacheThreadPool会因为创建过多线程而耗尽CPU和内存资源；keepAliveTime设置为60L，意味着CacheThreadPool中的空闲线程等待新任务的最长时间为60s，空闲线程超过60s将被终止。</p>
<p>SynchronousQueue的execute()执行流程</p>
<ul>
<li><p>首先执行SynchronousQueue.offer(E o)。如果当前maximumPool中有空闲线程正在执行SynchronousQueue.poll(long timeout, TimeUnit unit)，那么主线程执行offer操作与空闲线程执行的poll操作配对成功，主线程把任务交给空闲线程执行，execute()方法执行完成；否则执行下面的步骤2；</p>
</li>
<li><p>当初始maximumPool为空，或者maximumPool中当前没有空闲线程，将没有线程执行SynchronousQueue.poll(long timeout, TimeUnit unit)。这种情况下步骤1将失败。此时CacheThreadPool会创建一个新线程执行任务，execute()方法执行完成；</p>
</li>
<li><p>在步骤2中创建的线程将任务执行完成后，会执行SynchronousQueue.poll(long timeout, TimeUnit unit)。这个poll操作会让线程最多在SynchronousQueue中等待60s。如果60s内主线程就提交了一个新任务(主线程执行步骤1)，那么这个空闲线程将执行主线程提交的新任务；否则，这个空闲线程将终止。由于60s的空闲线程会被终止，因此长时间保持空闲的CacheThreadPool不会使用任何资源。</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ArrayBlockingQueue]]></title>
      <url>/2020/11/24/juc-10/</url>
      <content type="html"><![CDATA[<p>内容转载自 <a href="https://juejin.cn/post/6844903989788540941" target="_blank" rel="noopener">https://juejin.cn/post/6844903989788540941</a> 稍有改动</p>
<h2 id="BlockingQueue-介绍"><a href="#BlockingQueue-介绍" class="headerlink" title="BlockingQueue 介绍"></a>BlockingQueue 介绍</h2><p>BlockingQueue 继承自 Queue 接口,下面看看阻塞队列提供的接口；</p>
<pre><code class="java">public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; {
    /**
     * 插入数据到队列尾部（如果立即可行且不会超过该队列的容量）
     * 在成功时返回 true，如果此队列已满，则抛IllegalStateException。(与offer方法的区别)
     */
    boolean add(E e);

    /**
     * 插入数据到队列尾部，如果没有空间，直接返回false;
     * 有空间直接插入，返回true。
     */
    boolean offer(E e);

    /**
     * 插入数据到队列尾部，如果队列没有空间，一直阻塞；
     * 有空间直接插入。
     */
    void put(E e) throws InterruptedException;

    /**
     * 插入数据到队列尾部，如果没有额外的空间，等待一定的时间，有空间即插入，返回true，
     * 到时间了，还是没有额外空间，返回false。
     */
    boolean offer(E e, long timeout, TimeUnit unit)
        throws InterruptedException;

    /**
     * 取出和删除队列中的头元素，如果没有数据，会一直阻塞到有数据
     */
    E take() throws InterruptedException;

    /**
     * 取出和删除队列中的头元素，如果没有数据，需要会阻塞一定的时间，过期了还没有数据，返回null
     */
    E poll(long timeout, TimeUnit unit)
        throws InterruptedException;

    //除了上述方法还有继承自Queue接口的方法 
    /**
     * 取出和删除队列头元素，如果是空队列直接返回null。
     */
    E poll();

    /**
     * 取出但不删除头元素，该方法与peek方法的区别是当队列为空时会抛出NoSuchElementException异常
     */
    E element();

    /**
     * 取出但不删除头元素，空队列直接返回null
     */
    E peek();

    /**
     * 返回队列总额外的空间
     */
    int remainingCapacity();

    /**
     * 删除队列中存在的元素
     */
    boolean remove(Object o);

   /**
    * 判断队列中是否存在当前元素
    */
    boolean contains(Object o);

}
</code></pre>
<h2 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h2><p>ArrayBlockingQueue() 是一个用数组实现的有界阻塞队列，内部按先进先出的原则对元素进行排序；固定长度，不用扩容。<br>其中 put 方法和 take 方法为添加和删除元素的阻塞方法。<br>ArrayBlockingQueue 实现的生产者消费者的 Demo，代码只是一个简单的 ArrayBlockingQueue 的使用，Consumer 消费者和 Producer 生产者通过 ArrayBlockingQueue 来获取（take）和添加（put）数据。</p>
<pre><code class="java">/**
 * 使用 ArrayBlockingQueue 实现的生产者消费者简单模型
 */
public class ArrayBlockingQueueDemo {

    private final static ExecutorService THREAD_POOL = Executors.newFixedThreadPool(4);
    private final static ArrayBlockingQueue&lt;Data&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(1);

    public static void main(String[] args) {
        THREAD_POOL.execute(new Producer(QUEUE));
        THREAD_POOL.execute(new Consumer(QUEUE));
        THREAD_POOL.execute(new Producer(QUEUE));
        THREAD_POOL.execute(new Consumer(QUEUE));
        THREAD_POOL.shutdown();
    }
}

class Data {

}

class Producer implements Runnable {

    private final ArrayBlockingQueue&lt;Data&gt; mAbq;

    public Producer(ArrayBlockingQueue&lt;Data&gt; mAbq) {
        this.mAbq = mAbq;
    }

    @Override
    public void run() {
        for (int i = 0; i &lt; 10; i++) {
            produce();
        }

    }

    private void produce() {
        try {
            Data data = new Data();
            this.mAbq.put(data);
            System.out.println(&quot;生产了数据@&quot; + data);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

class Consumer implements Runnable {

    private final ArrayBlockingQueue&lt;Data&gt; mAbq;

    public Consumer(ArrayBlockingQueue&lt;Data&gt; mAbq) {
        this.mAbq = mAbq;
    }

    @Override
    public void run() {
        for (int i = 0; i &lt; 10; i++) {
            consumer();
        }
    }

    private void consumer() {
        try {
            Data data = this.mAbq.take();
            System.out.println(&quot;消费数据-&quot; + data);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

}
</code></pre>
<p>ArrayBlockingQueue 内部的阻塞队列是通过 ReentrantLock 和 Condition 条件队列实现的，<br>所以 ArrayBlockingQueue 中的元素存在公平和非公平访问的区别，这是因为 ReentrantLock 里面存在公平锁和非公平锁的原因，</p>
<p>下面对 ArrayBlockingQueue 构造方法进行分析：</p>
<pre><code class="java">/**
 * 创建一个具体容量的队列，默认是非公平队列
 */
public ArrayBlockingQueue(int capacity) {
    this(capacity, false);
}

/**
 * 创建一个具体容量、是否公平的队列 
 */
public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity &lt;= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];
    lock = new ReentrantLock(fair);
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}
</code></pre>
<p>ArrayBlockingQueue 除了实现上述 BlockingQueue 接口的方法，其他方法介绍如下：</p>
<pre><code class="java">//返回队列剩余容量
public int remainingCapacity()

// 判断队列中是否存在当前元素o
public boolean contains(Object o) 

// 返回一个按正确顺序，包含队列中所有元素的数组
public Object[] toArray()

// 返回一个按正确顺序，包含队列中所有元素的数组；数组的运行时类型是指定数组的运行时类型
@SuppressWarnings(&quot;unchecked&quot;)
public &lt;T&gt; T[] toArray(T[] a)


// 自动清空队列中的所有元素
public void clear()

// 移除队列中所有可用元素，并将他们加入到给定的 Collection 中    
public int drainTo(Collection&lt;? super E&gt; c)

// 从队列中最多移除指定数量的可用元素，并将他们加入到给定的 Collection 中    
public int drainTo(Collection&lt;? super E&gt; c, int maxElements)

// 返回此队列中按正确顺序进行迭代的，包含所有元素的迭代器
public Iterator&lt;E&gt; iterator()
</code></pre>
<p>ArrayBlockingQueue 源码和实现原理分析</p>
<pre><code class="java">public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;
        implements BlockingQueue&lt;E&gt;, java.io.Serializable {

    /** 存储数据的数组 */
    final Object[] items;

    /** 获取数据的索引，用于下次 take, poll, peek or remove 等方法 */
    int takeIndex;

    /** 添加元素的索引， 用于下次 put, offer, or add 方法 */
    int putIndex;

    /** 队列元素的个数 */
    int count;

    /*
     * 并发控制使用任何教科书中的经典双条件算法
     */

    /** 控制并发访问的锁 */
    final ReentrantLock lock;

    /** 非空条件对象，用于通知 take 方法中在等待获取数据的线程，队列中已有数据，可以执行获取操作 */
    private final Condition notEmpty;

    /** 未满条件对象，用于通知 put 方法中在等待添加数据的线程，队列未满，可以执行添加操作 */
    private final Condition notFull;

    /** 迭代器 */
    transient Itrs itrs = null;
}
</code></pre>
<p>添加(阻塞添加)的实现分析</p>
<pre><code class="java">/**
 * 在当前 put 位置插入数据，put 位置前进一位，
 * 同时唤醒 notEmpty 条件对象等待队列(链表)中第一个可用线程去 take 数据。
 * 当然这一系列动作只有该线程获取锁的时候才能进行，即只有获取锁的线程
 * 才能执行 enqueue 操作。
 */
// 元素统一入队操作
private void enqueue(E x) {
    // assert lock.getHoldCount() == 1;
    // assert items[putIndex] == null;
    final Object[] items = this.items;
    items[putIndex] = x; // putIndex 位置添加数据
    //putIndex 进行自增，当达到数组长度的时候，putIndex 重头再来，即设置为0
    //因为线程会阻塞，所以进到这个方法的线程肯定是OK的，有空间的，直接冲头再来就好了
    if (++putIndex == items.length) 
        putIndex = 0;
    count++; //元素个数自增
    notEmpty.signal(); //添加完数据后，说明数组中有数据了，所以可以唤醒 notEmpty 条件对象等待队列(链表)中第一个可用线程去 take 数据
}

// 添加数据，数组中元素已满时，直接返回 false。
public boolean offer(E e) {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    // 获取锁，保证线程安全
    lock.lock();
    try {
        // 当数组元素个数已满时，直接返回false
        if (count == items.length)
            return false;
        else {
            // 执行入队操作，enqueue 方法在上面分析了
            enqueue(e);
            return true;
        }
    } finally {
        // 释放锁，保证其他等待锁的线程可以获取到锁
        // 为什么放到 finally (避免死锁)
        lock.unlock();
    }
}

// add 方法其实就是调用了 offer 方法来实现，
// 与 offer 方法的区别就是 offer 方法数组满，抛出 IllegalStateException 异常。
public boolean add(E e) {
    if (offer(e))
        return true;
    else
        throw new IllegalStateException(&quot;Queue full&quot;);
}

/**
 * 插入数据到队列尾部，如果队列已满，阻塞等待空间
 */
public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    // 获取锁，期间线程可以打断，打断则不会添加
    lock.lockInterruptibly();
    try {
        // 通过上述分析，我们通过 count 来判断数组中元素个数
        while (count == items.length)
            notFull.await(); // 元素已满，线程挂起，线程加入 notFull 条件对象等待队列(链表)中，等待被唤醒
        enqueue(e); // 队列未满，直接执行入队操作
    } finally {
        lock.unlock();
    }
}
</code></pre>
<p>提取(阻塞提取)的实现分析</p>
<pre><code class="java">/**
 * 提取 takeIndex 位置上的元素， 然后 takeIndex 前进一位，
 * 同时唤醒 notFull 等待队列(链表)中的第一个可用线程去 put 数据。
 * 这些操作都是在当前线程获取到锁的前提下进行的，
 * 同时也说明了 dequeue 方法线程安全的。
 */
private E dequeue() {
    // assert lock.getHoldCount() == 1;
    // assert items[takeIndex] != null;
    final Object[] items = this.items; 
    @SuppressWarnings(&quot;unchecked&quot;)
    E x = (E) items[takeIndex]; // 提取 takeIndex位置上的数据
    items[takeIndex] = null; // 同时清空数组在 takeIndex 位置上的数据
    // takeIndex 向前前进一位，如果前进后位置超过了数组的长度，则将其设置为0；
    // 为什么设置为0，理由在 putIndex 设置为0的时候介绍过了，原因是一样的。
    if (++takeIndex == items.length) 
        takeIndex = 0;
    count--; // 同时数组的元素个数进行减1
    if (itrs != null)
        itrs.elementDequeued(); // 同时更新迭代器中的元素，迭代器的具体分析会在下面单独整理
    notFull.signal(); // 提取完数据后，说明数组中有空位，所以可以唤醒 notFull 条件对象的等待队列(链表)中的第一个可用线程去 put 数据
    return x;
}

// 提取数据，数组中数据为空时，直接返回 null
public E poll() {
    final ReentrantLock lock = this.lock;
    lock.lock(); // 加锁，前面也分析过，要执行 dequeue操作时，当前线程必须获取锁，保证线程安全
    try {
        return (count == 0) ? null : dequeue(); // 元素个数为0时，直接返回 null，不为0时，元素出队
    } finally {
        // 释放锁，在 finally 中释放可以避免死锁
        lock.unlock();
    }
}


// 返回数组上第 i 个元素
final E itemAt(int i) {
    return (E) items[i];
}

/**
 * 通过代码可以看到，peek 是获取元素，而不是提取， 不会删除 takeIndex 位置上的数据。
 * 内部通过 itemAt 方法实现，而不是 dequeue 方法。
 */
public E peek() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
     return itemAt(takeIndex); //当队列为空时，返回 null
    } finally {
     lock.unlock();
    }
}

// 从队列头部提取数据，队列中没有元素则阻塞，阻塞期间线程可中断
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly(); //获取锁，期间线程可以打断，打断则不会提取
    try {
        // 元素为0时，当有线程提取元素，则将该线程加入到 notEmpty 条件对象的等待队列中，
        // 直到当队列中有数据之后，会唤醒该线程去提取数据。
        while (count == 0)
            notEmpty.await();
        return dequeue(); // 若有数据，直接调用 dequeue 提取数据
    } finally {
        lock.unlock();
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之Exchanger]]></title>
      <url>/2020/11/23/juc-9/</url>
      <content type="html"><![CDATA[<p>内容转载自 <a href="https://blog.csdn.net/u014634338/article/details/78385521" target="_blank" rel="noopener">https://blog.csdn.net/u014634338/article/details/78385521</a>  稍有改动</p>
<p>前面分别介绍了CyclicBarrier、CountDownLatch、Semaphore，现在介绍并发工具类中的最后一个Exchange。<br>Exchanger 是一个用于线程间协作的工具类，Exchanger用于进行线程间的数据交换，它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange 方法交换数据，如果第一个线程先执行exchange 方法，它会一直等待第二个线程也执行exchange 方法，当两个线程都到达同步点时，这两个线程就可以交换数据。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>Exchanger 使用是非常简单的，但是实现原理和前面几种工具比较确实最难的，前面几种工具都是通过同步器或者锁来实现，而Exchanger 是一种无锁算法，和前面SynchronousQueue一样，都是通过循环 cas 来实现线程安全，因此这种方式就会显得比较抽象和麻烦。</p>
<pre><code class="java">public class ExchangerDemo {

    static Exchanger&lt;String&gt;exchanger=new Exchanger&lt;String&gt;();
    static class Task implements Runnable{
        @Override
        public void run() {
            try {
                String result=exchanger.exchange(Thread.currentThread().getName());
                System.out.println(&quot;this is &quot;+Thread.currentThread().getName()+&quot; receive data:&quot;+result);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
    public static void main(String[] args)throws  Exception{

        Thread t1=new Thread(new Task(),&quot;thread1&quot;);
        Thread t2=new Thread(new Task(),&quot;thread2&quot;);
        t1.start();
        t2.start();
        t1.join();
        t2.join();
    }
}
</code></pre>
<h2 id="单槽-Exchanger"><a href="#单槽-Exchanger" class="headerlink" title="单槽 Exchanger"></a>单槽 Exchanger</h2><p>Exchanger 有单槽位和多槽位之分，单个槽位在同一时刻只能用于两个线程交换数据，这样在竞争比较激烈的时候，会影响到性能，多个槽位就是多个线程可以同时进行两个的数据交换，彼此之间不受影响，这样可以很好的提高吞吐量。<br>单槽 Exchanger相对要简单许多，我们就先从这里开始分析吧。</p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>槽位定义：</p>
<pre><code class="java">@sun.misc.Contended static final class Node {
    int index;              // arena的下标，多个槽位的时候利用
    int bound;              // 上一次记录的Exchanger.bound；
    int collides;           // 在当前bound下CAS失败的次数；
    int hash;               // 用于自旋；
    Object item;            // 这个线程的当前项，也就是需要交换的数据；
    volatile Object match;  // 交换的数据
    volatile Thread parked; // 线程
}
/**
 * Value representing null arguments/returns from public
 * methods. Needed because the API originally didn&#39;t disallow null
 * arguments, which it should have.
 * 如果交换的数据为 null,则用NULL_ITEM  代替
 */
private static final Object NULL_ITEM = new Object();

/**
 * Elimination array; null until enabled (within slotExchange).
 * Element accesses use emulation of volatile gets and CAS.
 * 多槽位节点
 */
private volatile Node[] arena;

/**
 * Slot used until contention detected.
 * 单槽位节点
 */
private volatile Node slot;

/**
 * The index of the largest valid arena position, OR&#39;ed with SEQ
 * number in high bits, incremented on each update.  The initial
 * update from 0 to SEQ is used to ensure that the arena array is
 * constructed only once.
 * 最大槽位
 */
private volatile int bound;
</code></pre>
<p>Node 定义中，index，bound，collides 这些都是用于多槽位的，这些可以暂时不用管，item 是本线程需要交换的数据，match 是和其它线程交换后的数据，开始是为null,交换数据成功后，就是我们需要的数据了，parked记录线程，用于阻塞和唤醒线程。</p>
<pre><code class="java">/** The number of CPUs, for sizing and spin control */
private static final int NCPU = Runtime.getRuntime().availableProcessors();
/**
 * The bound for spins while waiting for a match. The actual
 * number of iterations will on average be about twice this value
 * due to randomization. Note: Spinning is disabled when NCPU==1.
 */
private static final int SPINS = 1 &lt;&lt; 10; // 自旋次数
/**
 * Slot used until contention detected.
 */
private volatile Node slot; // 用于交换数据的槽位
</code></pre>
<p>Node是每个线程自身用于数据交换的节点，相当于每个Node就代表了每个线程，为了保证线程安全，把线程的Node 节点 放在哪里呢，当然是ThreadLocal咯。</p>
<pre><code class="java">/**
 * Per-thread state  每个线程的数据，ThreadLocal 子类
 */
private final Participant participant;

/** The corresponding thread local class */
 static final class Participant extends ThreadLocal&lt;Node&gt; {
     // 初始值返回Node
     public Node initialValue() { return new Node(); }
 }
</code></pre>
<p>单个槽位需要准备的知识就这么多，具体部分字段的理解，在代码中再来细看。</p>
<h2 id="exchange-方法"><a href="#exchange-方法" class="headerlink" title="exchange 方法"></a>exchange 方法</h2><p>1、没有设定超时时间的exchange 方法</p>
<pre><code class="java">public V exchange(V x) throws InterruptedException {
    Object v;
    Object item = (x == null) ? NULL_ITEM : x; // translate null args
    if ((arena != null ||
         (v = slotExchange(item, false, 0L)) == null) &amp;&amp;
        ((Thread.interrupted() || // disambiguates null return
          (v = arenaExchange(item, false, 0L)) == null)))
        throw new InterruptedException();
    return (v == NULL_ITEM) ? null : (V)v;
}
</code></pre>
<p>2、具有超时功能的exchange 方法</p>
<pre><code class="java">public V exchange(V x, long timeout, TimeUnit unit)
    throws InterruptedException, TimeoutException {
    Object v;
    Object item = (x == null) ? NULL_ITEM : x;
    long ns = unit.toNanos(timeout);
    if ((arena != null ||
         (v = slotExchange(item, true, ns)) == null) &amp;&amp;
        ((Thread.interrupted() ||
          (v = arenaExchange(item, true, ns)) == null)))
        throw new InterruptedException();
    if (v == TIMED_OUT)
        throw new TimeoutException();
    return (v == NULL_ITEM) ? null : (V)v;
}
</code></pre>
<p>exchange 把 执行 单槽位交换还是多槽位交换，同时如果发生中断，则返回前会重设中断标志位 这几个操作通过一个语句来实现，因此看的时候可能需要仔细一点。<br>两个方法，主要的不同还是在于是否有超时时间设置，如果有超时时间设置，那么如果在指定的时间内没有交换到数据，那么就会返回（抛出超时异常），不会一直等待。<br>接下来我们就来看单槽位交换的核心方法slotExchange。</p>
<p>slotExchange 方法</p>
<pre><code class="java">private final Object slotExchange(Object item, boolean timed, long ns) {
    // 得到一个初试的Node
    Node p = participant.get();
    // 当前线程
    Thread t = Thread.currentThread();
    // 如果发生中断，返回null,会重设中断标志位，并没有直接抛异常
    if (t.isInterrupted()) // preserve interrupt status so caller can recheck
        return null;

    for (Node q;;) {
        // 槽位 solt不为null,则说明已经有线程在这里等待交换数据了
        if ((q = slot) != null) {
            // 重置槽位
            if (U.compareAndSwapObject(this, SLOT, q, null)) {
                //获取交换的数据
                Object v = q.item;
                //等待线程需要的数据
                q.match = item;
                //等待线程
                Thread w = q.parked;
                //唤醒等待的线程
                if (w != null)
                    U.unpark(w);
                return v; // 返回拿到的数据，交换完成
            }
            // create arena on contention, but continue until slot null
            //存在竞争，其它线程抢先了一步该线程，因此需要采用多槽位模式，这个后面再分析
            if (NCPU &gt; 1 &amp;&amp; bound == 0 &amp;&amp;
                U.compareAndSwapInt(this, BOUND, 0, SEQ))
                arena = new Node[(FULL + 2) &lt;&lt; ASHIFT];
        }
        else if (arena != null) //多槽位不为空，需要执行多槽位交换
            return null; // caller must reroute to arenaExchange
        else { //还没有其他线程来占据槽位
            p.item = item;
            // 设置槽位为p(也就是槽位被当前线程占据)
            if (U.compareAndSwapObject(this, SLOT, null, p))
                break; // 退出无限循环
            p.item = null; // 如果设置槽位失败，则有可能其他线程抢先了，重置item,重新循环
        }
    }

    //当前线程占据槽位，等待其它线程来交换数据
    int h = p.hash;
    long end = timed ? System.nanoTime() + ns : 0L;
    int spins = (NCPU &gt; 1) ? SPINS : 1;
    Object v;
    // 直到成功交换到数据
    while ((v = p.match) == null) {
        if (spins &gt; 0) { // 自旋
            h ^= h &lt;&lt; 1; h ^= h &gt;&gt;&gt; 3; h ^= h &lt;&lt; 10;
            if (h == 0)
                h = SPINS | (int)t.getId();
            else if (h &lt; 0 &amp;&amp; (--spins &amp; ((SPINS &gt;&gt;&gt; 1) - 1)) == 0)
                // 主动让出cpu,这样可以提供cpu利用率（反正当前线程也自旋等待，还不如让其它任务占用cpu）
                Thread.yield();
        }
        else if (slot != p) //其它线程来交换数据了，修改了solt,但是还没有设置match,再稍等一会
            spins = SPINS;
        //需要阻塞等待其它线程来交换数据
        //没发生中断，并且是单槽交换，没有设置超时或者超时时间未到 则继续执行
        else if (!t.isInterrupted() &amp;&amp; arena == null &amp;&amp;
                 (!timed || (ns = end - System.nanoTime()) &gt; 0L)) {
            // cas 设置BLOCKER，可以参考Thread 中的parkBlocker
            U.putObject(t, BLOCKER, this);
            // 需要挂起当前线程
            p.parked = t;
            if (slot == p)
                U.park(false, ns); // 阻塞当前线程
            // 被唤醒后    
            p.parked = null;
            // 清空 BLOCKER
            U.putObject(t, BLOCKER, null);
        }
        // 不满足前面 else if 条件，交换失败，需要重置solt
        else if (U.compareAndSwapObject(this, SLOT, p, null)) {
            v = timed &amp;&amp; ns &lt;= 0L &amp;&amp; !t.isInterrupted() ? TIMED_OUT : null;
            break;
        }
    }
    //清空match
    U.putOrderedObject(p, MATCH, null);
    p.item = null;
    p.hash = h;
    // 返回交换得到的数据（失败则为null）
    return v;
}
</code></pre>
<p>理解slotExchange 应该不难吧，相比前面的SynchronousQueue 之类的应该要简单多了，还是再来简述一遍：<br>当一个线程来交换数据时，如果发现槽位（solt）有数据时，说明其它线程已经占据了槽位，等待交换数据，那么当前线程就和该槽位进行数据交换，设置相应字段，如果交换失败，则说明其它线程抢先了该线程一步和槽位交换了数据，那么这个时候就存在竞争了，这个时候就会生成多槽位（area）,后面就会进行多槽位交换了。<br>如果来交换的线程发现槽位没有被占据，啊哈，这个时候自己就把槽位占据了，如果占据失败，则有可能其他线程抢先了占据了槽位，重头开始循环。<br>当来交换的线程占据了槽位后，就需要等待其它线程来进行交换数据了，首先自己需要进行一定时间的自旋，因为自旋期间有可能其它线程就来了，那么这个时候就可以进行数据交换工作，而不用阻塞等待了，如果不幸，进行了一定自旋后，没有其他线程到来，那么还是避免不了需要阻塞（如果设置了超时等待，发生了超时或中断异常，则退出，不阻塞等待），当准备阻塞线程的时候，发现槽位值变了，那么说明其它线程来交换数据了，但是还没有完全准备好数据，这个时候就不阻塞了，再稍微等那么一会，如果始终没有等到其它线程来交换，那么就挂起当前线程。<br>当其它线程到来并成功交换数据后，会唤醒被阻塞的线程，阻塞的线程被唤醒后，拿到数据（如果是超时，或中断，则数据为null）返回，结束。</p>
<p>单槽位的交换就结束了，整个过程应该不难，如果竞争激烈，那么一个槽位显然就成了性能瓶颈了，因此就衍生出了多槽位交换，各自交换各自的，互不影响。</p>
<h2 id="多槽-Exchanger"><a href="#多槽-Exchanger" class="headerlink" title="多槽 Exchanger"></a>多槽 Exchanger</h2><p>多槽位呢，实际就是一个Node 数组，代表了很多的槽位，对于多槽位，我个人对代码的部分理解得不是完全透彻，有些地方有点不知其所以然，在前面分析SynchronousQueue 的时候也曾遇到，但是SynchronousQueue 调试方便，跟几遍就可以很好的理解了，但是这个多槽位有点不好调试，而且一两个线程观察不出来，因此有些地方可能会说不清楚，或者有误，因此如果朋友发现有问题的，欢迎指出来，共同学习。</p>
<pre><code class="java">@sun.misc.Contended static final class Node {
    int index;              //arena的下标，多个槽位的时候利用
    int bound;              // 上一次记录的Exchanger.bound；
    int collides;           // 在当前bound下CAS失败的次数；
    int hash;               // 用于自旋；
    Object item;            // 这个线程的当前项，也就是需要交换的数据；
    volatile Object match;  // 交换的数据
    volatile Thread parked; // 线程
}

/**
 * The byte distance (as a shift value) between any two used slots
 * in the arena.  1 &lt;&lt; ASHIFT should be at least cacheline size.
 * CacheLine填充
 */
private static final int ASHIFT = 7;

/**
 * The maximum supported arena index. The maximum allocatable
 * arena size is MMASK + 1. Must be a power of two minus one, less
 * than (1&lt;&lt;(31-ASHIFT)). The cap of 255 (0xff) more than suffices
 * for the expected scaling limits of the main algorithms.
 */
private static final int MMASK = 0xff;

/**
 * Unit for sequence/version bits of bound field. Each successful
 * change to the bound also adds SEQ.
 * bound的&quot;版本号&quot;
 */
private static final int SEQ = MMASK + 1;

/**
 * The maximum slot index of the arena: The number of slots that
 * can in principle hold all threads without contention, or at
 * most the maximum indexable value.
 */
static final int FULL = (NCPU &gt;= (MMASK &lt;&lt; 1)) ? MMASK : NCPU &gt;&gt;&gt; 1;

/**
 * Elimination array; null until enabled (within slotExchange).
 * Element accesses use emulation of volatile gets and CAS.
 */
private volatile Node[] arena;

/**
 * The index of the largest valid arena position, OR&#39;ed with SEQ
 * number in high bits, incremented on each update.  The initial
 * update from 0 to SEQ is used to ensure that the arena array is
 * constructed only once.
 */
private volatile int bound;
</code></pre>
<p>为了不误导大家，重要的属性保留了源码的注释，这样有助于理解。<br>在Node 前面有个@sun.misc.Contended 的注解，这个是什么呢，这个是用来避免伪共享的（当然不仅仅是加个注解就ok了），下面的伪共享说明</p>
<p>伪共享说明：假设一个类的两个相互独立的属性a和b在内存地址上是连续的(比如FIFO队列的头尾指针)，那么它们通常会被加载到相同的cpu cache line里面。并发情况下，如果一个线程修改了a，会导致整个cache line失效(包括b)，这时另一个线程来读b，就需要从内存里再次加载了，这种多线程频繁修改ab的情况下，虽然a和b看似独立，但它们会互相干扰，非常影响性能。</p>
<p>ASHIFT 这个字段就是用于避免伪共享的，1 &lt;&lt; ASHIFT 可以避免两个Node在同一个共享区，这个可以从后面代码再来具体分析。</p>
<p>在slotExchange 当存在竞争时，会构建area,现在我们再来回顾这个代码：</p>
<pre><code class="java">if (NCPU &gt; 1 &amp;&amp; bound == 0 &amp;&amp;U.compareAndSwapInt(this, BOUND, 0, SEQ))
      arena = new Node[(FULL + 2) &lt;&lt; ASHIFT];
</code></pre>
<p>初始化arena 时会设置bound为SEQ(SEQ=MMASK + 1)。MMASK 值为255，二进制：8个1<br>arena的大小为(FULL + 2) &lt;&lt; ASHIFT，因为1 &lt;&lt; ASHIFT 是用于避免伪共享的，因此实际有效的Node 只有FULL + 2 个，这个我们从后面的代码也可以得出。</p>
<p>arenaExchange 方法</p>
<p>多槽的交换大致思想就是：当一个线程来交换的时候，如果”第一个”槽位是空的，那么自己就在那里等待，如果发现”第一个”槽位有等待线程，那么就直接交换，如果交换失败，说明其它线程在进行交换，那么就往后挪一个槽位，如果有数据就交换，没数据就等一会，但是不会阻塞在这里，在这里等了一会，发现还没有其它线程来交换数据，那么就往“第一个”槽位的方向挪，如果反复这样过后，挪到了第一个槽位，没有线程来交换数据了，那么自己就在”第一个”槽位阻塞等待。<br>简单来说，如果有竞争冲突，那么就寻找后面的槽位，在后面的槽位等待一定时间，没有线程来交换，那么就又往前挪。</p>
<pre><code class="java">private final Object arenaExchange(Object item, boolean timed, long ns) {
    // 槽位数组
    Node[] a = arena;
    // 代表当前线程的Node
    Node p = participant.get(); // p.index 初始值为 0
    for (int i = p.index;;) {                      // access slot at i
        int b, m, c; long j;                       // j is raw array offset
        //在槽位数组中根据&quot;索引&quot; i 取出数据 j相当于是 &quot;第一个&quot;槽位
        Node q = (Node)U.getObjectVolatile(a, j = (i &lt;&lt; ASHIFT) + ABASE);
        // 该位置上有数据(即有线程在这里等待交换数据)
        if (q != null &amp;&amp; U.compareAndSwapObject(a, j, q, null)) {
            // 进行数据交换，这里和单槽位的交换是一样的
            Object v = q.item;                     // release
            q.match = item;
            Thread w = q.parked;
            if (w != null)
                U.unpark(w);
            return v;
        }
        // bound 是最大的有效的 位置，和MMASK相与，得到真正的存储数据的索引最大值
        else if (i &lt;= (m = (b = bound) &amp; MMASK) &amp;&amp; q == null) {
            // i 在这个范围内，该槽位也为空

            // 将需要交换的数据 设置给p
            p.item = item;                         // offer
            // 设置该槽位数据(在该槽位等待其它线程来交换数据)
            if (U.compareAndSwapObject(a, j, null, p)) {
                long end = (timed &amp;&amp; m == 0) ? System.nanoTime() + ns : 0L;
                Thread t = Thread.currentThread(); // wait
                // 进行一定时间的自旋
                for (int h = p.hash, spins = SPINS;;) {
                    Object v = p.match;
                    //在自旋的过程中，有线程来和该线程交换数据
                    if (v != null) {
                        //交换数据后，清空部分设置，返回交换得到的数据，over
                        U.putOrderedObject(p, MATCH, null);
                        p.item = null;             // clear for next use
                        p.hash = h;
                        return v;
                    }
                    else if (spins &gt; 0) {
                        h ^= h &lt;&lt; 1; h ^= h &gt;&gt;&gt; 3; h ^= h &lt;&lt; 10; // xorshift
                        if (h == 0)                // initialize hash
                            h = SPINS | (int)t.getId();
                        else if (h &lt; 0 &amp;&amp;          // approx 50% true
                                 (--spins &amp; ((SPINS &gt;&gt;&gt; 1) - 1)) == 0)
                            Thread.yield();        // two yields per wait
                    }
                    // 交换数据的线程到来，但是还没有设置好match，再稍等一会
                    else if (U.getObjectVolatile(a, j) != p)
                        spins = SPINS; 
                    // 符合条件，特别注意m==0 这个说明已经到达area 中最小的存储数据槽位了
                    // 没有其他线程在槽位等待了，所有当前线程需要阻塞在这里     
                    else if (!t.isInterrupted() &amp;&amp; m == 0 &amp;&amp;
                             (!timed ||
                              (ns = end - System.nanoTime()) &gt; 0L)) {
                        U.putObject(t, BLOCKER, this); // emulate LockSupport
                        p.parked = t;              // minimize window
                        // 再次检查槽位，看看在阻塞前，有没有线程来交换数据
                        if (U.getObjectVolatile(a, j) == p) 
                            U.park(false, ns); // 挂起
                        p.parked = null;
                        U.putObject(t, BLOCKER, null);
                    }
                    // 当前这个槽位一直没有线程来交换数据，准备换个槽位试试
                    else if (U.getObjectVolatile(a, j) == p &amp;&amp;
                             U.compareAndSwapObject(a, j, p, null)) {
                        //更新bound
                        if (m != 0)                // try to shrink
                            U.compareAndSwapInt(this, BOUND, b, b + SEQ - 1);
                        p.item = null;
                        p.hash = h;
                        // 减小索引值 往&quot;第一个&quot;槽位的方向挪动
                        i = p.index &gt;&gt;&gt;= 1;        // descend
                        // 发送中断，返回null
                        if (Thread.interrupted())
                            return null;
                        // 超时
                        if (timed &amp;&amp; m == 0 &amp;&amp; ns &lt;= 0L)
                            return TIMED_OUT;
                        break;                     // expired; restart 继续主循环
                    }
                }
            }
            else
                //占据槽位失败，先清空item,防止成功交换数据后，p.item还引用着item
                p.item = null;                     // clear offer
        }
        else { // i 不在有效范围，或者被其它线程抢先了
            //更新p.bound
            if (p.bound != b) {                    // stale; reset
                p.bound = b;
                //新bound ，重置collides
                p.collides = 0;
                //i如果达到了最大，那么就递减
                i = (i != m || m == 0) ? m : m - 1;
            }
            else if ((c = p.collides) &lt; m || m == FULL ||
                     !U.compareAndSwapInt(this, BOUND, b, b + SEQ + 1)) {
                p.collides = c + 1; // 更新冲突
                // i=0 那么就从m开始，否则递减i
                i = (i == 0) ? m : i - 1;          // cyclically traverse
            }
            else
                //递增，往后挪动
                i = m + 1;                         // grow
            // 更新index
            p.index = i;
        }
    }
}
</code></pre>
<p>理解起来应该有点抽象，当然我分析的也不一定就正确，不要全相信我的描述，结合自己理解。</p>
<pre><code class="java">Node q = (Node)U.getObjectVolatile(a, j = (i &lt;&lt; ASHIFT) + ABASE);
</code></pre>
<p>对于上面这个代码，开始理解可能有点难，i &lt;&lt; ASHIFT 是用于避免伪共享的，虽然arena数组很大，但是里面并不是每个位置都利用的，还有一些是没有利用的，其间隔就是1 &lt;&lt; ASHIFT。</p>
<pre><code class="java">Class&lt;?&gt; ak = Node[].class;
ABASE = U.arrayBaseOffset(ak) + (1 &lt;&lt; ASHIFT);
</code></pre>
<p>ABASE 就是arena的起始位置上加了(1 &lt;&lt; ASHIFT) 这个偏移，相当于ABASE作为了 arena数组的其实位置，其前(1 &lt;&lt; ASHIFT)的位置没有利用。</p>
<p>当发现槽位q 有数据的时候就交换数据，如果cas 失败，说明存在竞争，那么就会执行后面的else,更新bound 还是递增或者递减索引i。<br>如果槽位q 没有数据，并且索引 i在有效范围内，如果是”第一个”槽位，那么会占据槽位，进行一定时间的自旋，然后阻塞等待，如果不是”第一个”槽位，那么就会换个槽位等待，清空当前槽位，然后索引值减半。（如果设置了超时，需要进行超时判断，如果发生超时就返回）。</p>
<p>对于 i &lt;= (m = (b = bound) &amp; MMASK) , m 的值肯定在[0,MMASK]之间。</p>
<pre><code class="java">U.compareAndSwapInt(this, BOUND, b, b + SEQ + 1
</code></pre>
<p>上面这行代码则是在递增BOUND,SEQ+1的二进制位位：100000001，当它和MMASK 相与的结果相比原来就增加了1，因此这个是递增BOUND。</p>
<pre><code class="java">if (m != 0)                // try to shrink
    U.compareAndSwapInt(this, BOUND, b, b + SEQ - 1);
</code></pre>
<p>对于上面这行代码，SEQ - 1 就是MMASK,这个新bound和MMASK 相与的结果应该变大了，（注意m！=0 ,则说明bound低8位存在1），那么索引i 就越有可能在这个范围内，如果还是没有其他线程来交换，则会再次减小i，也就是说增大了m,反而减小了i, jdk 源码上的注释（try to shrink）则是尝试缩小,不知是不是指的这个含义。</p>
<p>估计我描述的晕咚咚的，这个部分，我也不是特别明白，因此就不好多阐述了，后面抽空还会进行研究研究，如果朋友有新的理解，可以指教一二。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Exchanger 还是很有意思的，用于线程之间两两交换数据，在多线程下，互相交换数据的两个线程是不确定的。<br>在竞争比较小的时候，采用单槽位进行交换数据，当线程来交换数据时，发现槽位为空，则自己在这里等待，否则就和槽位进行交换数据，同时会唤醒等待的线程。</p>
<p>在竞争比较激烈的情况下，就会转到多槽位的交换，这个多槽位的交换，其实思想还是很好理解，但是局部有些细节确实还没有理解透，同时调试也困难，只有自己脑海里不挺的模拟，但是这个可能模拟出错（哈哈）。但是对多槽位的大致思想应该还是明白了，当一个线程来交换的时候，如果”第一个”槽位是空的，那么自己就在那里等待，如果发现”第一个”槽位有等待线程，那么就直接交换，如果交换失败，说明其它线程在进行交换，那么就往后挪一个槽位，如果有数据就交换，没数据就等一会，但是不会阻塞在这里，在这里等了一会，发现还没有其它线程来交换数据，那么就往“第一个”槽位的方向挪，如果反复这样过后，挪到了第一个槽位，没有线程来交换数据了，那么自己就在”第一个”槽位阻塞等待。</p>
<p>第一个槽位并不是指的数组中的第一个，而是逻辑第一个，因为存在伪共享，多槽位中，部分空间没有被利用。</p>
<p>最后用一个在网上看到的段子结束此篇博客（<a href="http://brokendreams.iteye.com/blog/2253956），博主对其做了一点点修改，以便更加符合在1.8环境下的Exchanger：" target="_blank" rel="noopener">http://brokendreams.iteye.com/blog/2253956），博主对其做了一点点修改，以便更加符合在1.8环境下的Exchanger：</a></p>
<p>其实就是”我”和”你”(可能有多个”我”，多个”你”)在一个叫Slot的地方做交易(一手交钱，一手交货)，过程分以下步骤：</p>
<ol>
<li>我先到一个叫做Slot的交易场所交易，发现你已经到了，那我就尝试喊你交易，如果你回应了我，决定和我交易那么进入第2步；如果别人抢先一步把你喊走了，那我就进入第5步。</li>
<li>我拿出钱交给你，你可能会接收我的钱，然后把货给我，交易结束；也可能嫌我掏钱太慢(超时)或者接个电话(中断)，TM的不卖了，走了，那我只能再找别人买货了(从头开始)。</li>
<li>我到交易地点的时候，你不在，那我先尝试把这个交易点给占了(一屁股做凳子上…)，如果我成功抢占了单间(交易点)，那就坐这儿等着你拿货来交易，进入第4步；如果被别人抢座了，那我只能在找别的地方儿了，进入第5步。</li>
<li>你拿着货来了，喊我交易，然后完成交易；也可能我等了好长时间你都没来，我不等了，继续找别人交易去，走的时候我看了一眼，一共没多少人，弄了这么多单间(交易地点Slot)，太TM浪费了，我喊来交易地点管理员：一共也没几个人，搞这么多单间儿干毛，给哥撤一个！。然后再找别人买货(从头开始)；或者我老大给我打了个电话，不让我买货了(中断)。</li>
<li>我跑去喊管理员，尼玛，就一个坑交易个毛啊，然后管理在一个更加开阔的地方开辟了好多个单间，然后我就挨个来看每个单间是否有人。如果有人我就问他是否可以交易，如果回应了我，那我就进入第2步。如果我没有人，那我就占着这个单间等其他人来交易，进入第4步。</li>
<li>如果我尝试了几次都没有成功，我就会认为，是不是我TM选的这个单间风水不好？不行，得换个地儿继续(从头开始)；如果我尝试了多次发现还没有成功，怒了，把管理员喊来：给哥再开一个单间(Slot)，加一个凳子，这么多人就这么几个破凳子够谁用！</li>
</ol>
<p>看起来在并发竞争多的时候，exchanger这种先到先得的模式，无法保证与某一个特定的线程交换值。这玩意真的有使用场景么？</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之CyclicBarrier]]></title>
      <url>/2020/11/22/juc-8/</url>
      <content type="html"><![CDATA[<p>内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<h2 id="CyclicBarrier是什么？"><a href="#CyclicBarrier是什么？" class="headerlink" title="CyclicBarrier是什么？"></a>CyclicBarrier是什么？</h2><p>字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。<br>叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。<br>叫做栅栏，大概是描述所有线程被栅栏挡住了，当都达到时，一起跳过栅栏执行，也算形象。我们可以把这个状态就叫做barrier。</p>
<p>举个报旅行团旅行的例子。<br>出发时，导游会在机场收了护照和签证，办理集体出境手续，所以，要等大家都到齐才能出发，出发前再把护照和签证发到大家手里。<br>对应CyclicBarrier使用。<br>每个人到达后进入barrier状态。<br>都到达后，唤起大家一起出发去旅行。<br>旅行出发前，导游还会有个发护照和签证的动作。</p>
<pre><code class="java">/**
 * 旅行线程
 * Created by jiapeng on 2018/1/7.
 */
public class TravelTask implements Runnable{

    private CyclicBarrier cyclicBarrier;
    private String name;
    private int arriveTime;//赶到的时间

    public TravelTask(CyclicBarrier cyclicBarrier,String name,int arriveTime){
        this.cyclicBarrier = cyclicBarrier;
        this.name = name;
        this.arriveTime = arriveTime;
    }

    @Override
    public void run() {
        try {
            //模拟达到需要花的时间
            Thread.sleep(arriveTime * 1000);
            System.out.println(name +&quot;到达集合点&quot;);
            cyclicBarrier.await();
            System.out.println(name +&quot;开始旅行啦～～&quot;);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (BrokenBarrierException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 导游线程，都到达目的地时，发放护照和签证
 * Created by jiapeng on 2018/1/7.
 */
public class TourGuideTask implements Runnable{

    @Override
    public void run() {
        System.out.println(&quot;****导游分发护照签证****&quot;);
        try {
            //模拟发护照签证需要2秒
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

/**
 * Created by jiapeng on 2018/1/7.
 */
public class Client {

    public static void main(String[] args) throws Exception{

        CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new TourGuideTask());
        Executor executor = Executors.newFixedThreadPool(3);
        //登哥最大牌，到的最晚
        executor.execute(new TravelTask(cyclicBarrier,&quot;哈登&quot;,5));
        executor.execute(new TravelTask(cyclicBarrier,&quot;保罗&quot;,3));
        executor.execute(new TravelTask(cyclicBarrier,&quot;戈登&quot;,1));
    }
}
</code></pre>
<p>通过CyclicBarrier我们可以实现n个线程相互等待。我们可以通过参数指定达到公共屏障点之后的行为。</p>
<p>我们先来看一下CyclicBarrier的成员变量：</p>
<pre><code class="java">private final ReentrantLock lock = new ReentrantLock();
private final Condition trip = lock.newCondition();
private final int parties;
private final Runnable barrierCommand;
private Generation generation = new Generation();
private int count;
</code></pre>
<p>CyclicBarrier是通过独占锁lock和Condition对象trip来实现的，成员parties表示必须有parties个线程到达barrier，成员barrierCommand表示当parties个线程到达之后要执行的代码，成员count表示离触发barrierCommand还差count个线程（还有count个线程未到达barrier），成员generation表示当前的“代数”，“cyclic”表示可循环使用，generation是对一次循环的标识。注意：Generation是CyclicBarrier的一个私有内部类，他只有一个成员变量来标识当前的barrier是否已“损坏”：</p>
<pre><code class="java">private static class Generation {
     boolean broken = false;
}
</code></pre>
<p>构造函数</p>
<pre><code class="java">public CyclicBarrier(int parties, Runnable barrierAction) {
    if (parties &lt;= 0) throw new IllegalArgumentException();
    this.parties = parties;
    this.count = parties;
    this.barrierCommand = barrierAction;
}

public CyclicBarrier(int parties) {
    this(parties, null);
}
</code></pre>
<p>CyclicBarrier提供了两种构造函数，没有指定barrierCommand的构造函数是调用第二个构造函数实现的。第二个构造函数有两个参数：parties和barrierAction，分别用来初始化成员parties和barrierCommand。注意，parties必须大于0，否则会抛出IllegalArgumentException。</p>
<p>await（）方法</p>
<pre><code class="java">public int await() throws InterruptedException, BrokenBarrierException {
    try {
        return dowait(false, 0L);
    } catch (TimeoutException toe) {
     throw new Error(toe); // cannot happen;
    }
}
</code></pre>
<p>await方法是由调用dowait方法实现的，两个参数分别代表是否定时等待和等待的时长。</p>
<p>doawait（）方法</p>
<pre><code class="java">private int dowait(boolean timed, long nanos)
            throws InterruptedException, BrokenBarrierException, TimeoutException {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            final Generation g = generation;

            //小概率事件：该线程在等待锁的过程中，barrier被破坏
            if (g.broken)
                throw new BrokenBarrierException();

            //小概率事件：该线程在等待锁的过程中被中断
            if (Thread.interrupted()) {
                breakBarrier();
                throw new InterruptedException();
            }

           int index = --count;
           //当有parties个线程到达barrier
           if (index == 0) {  // tripped
                boolean ranAction = false;
                try {
                   final Runnable command = barrierCommand;
                   //如果设置了barrierCommand，令最后到达的barrier的线程执行它
                   if (command != null)
                        command.run();
                    ranAction = true;
                    nextGeneration();
                    return 0;
               } finally {
                    //注意：当执行barrierCommand出现异常时，ranAction派上用场
                    if (!ranAction)
                        breakBarrier();
               }
           }

            // loop until tripped, broken, interrupted, or timed out
            for (;;) {
                try {
                    if (!timed)
                        trip.await();
                    else if (nanos &gt; 0L)
                        //注意：nanos值标识了是否超时，后续用这个nanos值判断是否breakBarrier
                        nanos = trip.awaitNanos(nanos);
                } catch (InterruptedException ie) {
                    if (g == generation &amp;&amp; ! g.broken) {
                        breakBarrier();
                        throw ie;
                    } else {
                        //小概率事件：该线程被中断，进入锁等待队列
                        //在等待过程中，另一个线程更新或破坏了generation
                        //当该线程获取锁之后，应重置interrupt标志而不是抛出异常
                        //原因在于：它中断的太晚了，generation已更新或破坏，它抛出InterruptedException的时机已经过去，
                        //两种情况：
                        //①g被破坏：已有一个线程抛出InterruptedException（只能由第一个抛），与它同时等待的都抛BrokenBarrierException（后续检查broken标志会抛）。
                        //②g被更新：此时抛异常没意义（后续检查g更新后会return index），这里重置interrupt标志，让线程继续执行，让这个标志由上层处理
                        Thread.currentThread().interrupt();
                    }
                }

                //barrier被破坏，抛出异常
                if (g.broken)
                    throw new BrokenBarrierException();

                //barrier正常进入下一循环，上一代await的线程继续执行
                if (g != generation)
                    return index;

                //只要有一个超时，就breakBarrier，后续线程抛的就是barrier损坏异常
                if (timed &amp;&amp; nanos &lt;= 0L) {
                    breakBarrier();
                    throw new TimeoutException();
                }
            }
        } finally {
            lock.unlock();
        }
    }
</code></pre>
<p>dowait方法是CyclicBarrier的精华。应该重点来理解。</p>
<p>方法开头首先申请锁，然后做了两个判断：g.broken和Thread.interrupted()，这两个判断是分别处理两种小概率的事件：</p>
<ul>
<li>该线程在等待锁的过程中，barrier被破坏</li>
<li>该线程在等待锁的过程中被中断。这两个事件应抛出相应的异常。</li>
</ul>
<p>接下来dowait方法修改了令count减1，如果此时count减为0，说明已经有parties个线程到达barrier，这时由最后到达barrier的线程去执行barrierCommand。注意，这里设置了一个布尔值ranAction，作用是来标识barrierCommand是否被正确执行完毕，如果执行失败，finally中会执行breakBarrier操作。</p>
<p>如果count尚未减为0，则在Condition对象trip上执行await操作，注意：这里有一个InterruptedException的catch子句。当前线程在await中被中断时，会抛出InterruptedException，这时候如果g==generation&amp;&amp;!g.broken的话，我们执行breakBarrier操作，同时抛出这个异常；如果g!=generation或者g.broken==true的话，我们的操作是重置interrupt标志而不是抛出这个异常。这么做的原因我们分两种情况讨论：</p>
<ul>
<li><p>g被破坏，这也是一个小概率事件，当前线程被中断后进入锁等待队列，此时另一个线程由于某种原因（超时或者被中断）在他之前获取了锁并执行了breakBarrier方法，那么当前线程持有锁之后就不应再抛InterruptedException，逻辑上应该处理barrier被破坏事件，事实上在后续g.broken的检查中，他会抛出一个BrokenBarrierException。而当前的InterruptedException被我们捕获却没有做出处理，所以执行interrupt方法重置中断标志，交由上层程序处理。</p>
</li>
<li><p>g被更新：说明当前线程在即将完成等待之际被中断，此时抛异常没意义（后续检查g更新后会return index），这里重置interrupt标志，让线程继续执行，让这个标志由上层处理。</p>
</li>
</ul>
<p>后续对g.broken和g!=generation的判断，分表代表了被唤醒线程（非最后一个到达barrier的线程，也不是被中断或第一个超时的线程）的两种退出方法的方式：</p>
<ul>
<li>第一种是以barrier被破坏告终（然后抛异常）</li>
<li>第二个是barrier等到parties个线程，寿终正寝（返回该线程的到达次序index）。</li>
</ul>
<p>最后一个if是第一个超时线程执行breakBarrier操作并跑出异常。最后finally子句要释放锁。</p>
<p>至此，整个doawait方法流程就分析完毕了，我们可以发现，<strong>在barrier上等待的线程，如果以抛异常结束的话，只有第一个线程会抛InterruptedException或TimeoutException并执行breakBarrier操作，其他等待线程只能抛BrokenBarrierException，逻辑上这也是合理的：一个barrier只能因超时或中断被破坏一次。</strong></p>
<pre><code class="java">private void nextGeneration() {
    trip.signalAll();
    count = parties;
    generation = new Generation();
}

private void breakBarrier() {
    generation.broken = true;
    count = parties;
    trip.signalAll();
}
</code></pre>
<p>doawait方法中用到的nextGeneration方法将所有等待线程唤醒，更新generation对象，复位count，进入下一轮任务。</p>
<p>breakBarrier方法将generation状态值为broken，复位count（这个复位看上去没有用，但实际上，在broken之后reset之前，如果调用getNumberWaiting方法查看等待线程数的话，复位count是合理的），并唤醒所有等待线程。在调用reset更新generation之前，barrier将处于不可用状态。</p>
<p>reset（）方法</p>
<pre><code class="java">public void reset() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        breakBarrier();   // break the current generation
        nextGeneration(); // start a new generation
    } finally {
        lock.unlock();
    }
}
</code></pre>
<p>reset方法先break当执行breakBarrier操作（如果有线程在barrier上等待，调用reset会导致BrokenBarrierException），再更新generation对象。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之CountDownLatch]]></title>
      <url>/2020/11/22/juc-7/</url>
      <content type="html"><![CDATA[<p>内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<h2 id="CountDownLatch是什么"><a href="#CountDownLatch是什么" class="headerlink" title="CountDownLatch是什么"></a>CountDownLatch是什么</h2><p>闭锁，CountDownLatch能够使一个线程等待其他线程完成各自的工作后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。</p>
<p>可见CountDownLatch跟之前我们所有的juc对象都有着本质性区别，之前的都是线程能拿到资源，也可以归还资源，CountDownLatch则是只能拿，不能还，而且在资源花完之前，父线程会一直阻塞。</p>
<p>例子：每天起早贪黑的上班，父母每天也要上班，话说今天定了个饭店，一家人一起吃个饭，通知大家下班去饭店集合。假设：3个人在不同的地方上班，必须等到3个人到场才能吃饭，用程序如何实现呢？</p>
<pre><code class="java">public static void main(String[] args) throws InterruptedException{

        new Thread()
        {
            public void run()
            {
                fatherToRes();
                latch.countDown();
            };
        }.start();
        new Thread()
        {
            public void run()
            {
                motherToRes();
                latch.countDown();
            };
        }.start();
        new Thread()
        {
            public void run()
            {
                meToRes();
                latch.countDown();
            };
        }.start();

        latch.await();
        togetherToEat();
    }
</code></pre>
<p>CountDownLatch就是一个使用共享模式的自定义同步器实现的共享锁。</p>
<h2 id="await方法"><a href="#await方法" class="headerlink" title="await方法"></a>await方法</h2><pre><code class="java">public void await() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

public boolean await(long timeout, TimeUnit unit)
    throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}
</code></pre>
<p>CountDownLatch提供了两种await方法：有等待时长限制和一直等待。两种均能响应中断（归根到底是UNSAFE.park可响应中断。但是如果是定时的park，则不能判断被唤醒的原因是超时还是被中断，因此需要isInterrupted判断下，而此方法会清除中断标志，因此如果是延迟处理要“补上”）。</p>
<p>await（）方法调用了同步器的acquireSharedInterruptibly方法，这个方法由上层AQS提供，它调用了我们重写的tryAcquireShared方法而封装了排队等待、唤醒、响应中断的细节，我们只关注自定义同步器中的tryAcquireShared方法即可：</p>
<pre><code class="java">protected int tryAcquireShared(int acquires) {
            return (getState() == 0) ? 1 : -1;
        }
</code></pre>
<p>注意，tryAcquireShared方法的返回值的意义在AQS是这样规定的：负值代表获取资源失败，非负值代表成功获取资源后剩余资源的数量。而这里当getState返回值为0的时候，我们却总是返回1，表示仍有剩余资源。这看上去并不合理，但这确实是正确的：因为可能有多个线程调用了await，同时在队列中等待资源，CountDownLatch的语义要求我们在倒计时结束有唤醒所有等待线程。因此我们在成功获取资源后，总是要告诉AQS“还有剩余”，这样AQS便会继续唤醒队列中的其他等待线程（由AQS中的setHeadAndPropagate方法调用doReleaseShared来唤醒）。一句话：成功获取总返回1是为了保证唤醒的“延续性”。</p>
<p>有等待时长限制的await(long, TimeUnit)方法调用了同步器的tryAcquireSharedNanos方法：</p>
<pre><code class="java">public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (Thread.interrupted())
            throw new InterruptedException();
        return tryAcquireShared(arg) &gt;= 0 ||
            doAcquireSharedNanos(arg, nanosTimeout);
    }
</code></pre>
<p>这个方法首先检测中断，然后试图获取，失败后进入“自旋-等待”阶段，直到成功获取或被中断。这是AQS的内容，不再赘述。</p>
<h2 id="countDown方法"><a href="#countDown方法" class="headerlink" title="countDown方法"></a>countDown方法</h2><pre><code class="java"> public void countDown() {
        sync.releaseShared(1);
    }
</code></pre>
<p>countDown方法调用releaseShared释放资源：</p>
<pre><code class="java">public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
</code></pre>
<p>releaseShared会调用tryReleaseShared方法：</p>
<pre><code class="java">protected boolean tryReleaseShared(int releases) {
            // Decrement count; signal when transition to zero
            for (;;) {
                int c = getState();
                if (c == 0)
                    return false;
                int nextc = c-1;
                if (compareAndSetState(c, nextc))
                    return nextc == 0;
            }
        }
</code></pre>
<p>方法一直自旋，直到成功释放或倒计时完毕。因为可能有超过count的线程调用countDown，因此releaseShared是可能失败的。当然在释放过程中也可能发生竞争，CAS自旋保证竞争发生时的正确执行。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CountDownLatch是一个共享锁，但有些特别：他在初始化的时候锁住了所有共享资源，任何线程都可以调用countDown方法释放一个资源，当所有资源都被释放后，所有等待线程被唤醒。从而实现了倒计时的效果。</p>
<p>CountDownLatch是一次性的，计数值不可恢复。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之Semaphore]]></title>
      <url>/2020/11/22/juc-6/</url>
      <content type="html"><![CDATA[<p>内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<h2 id="Semaphore-是什么"><a href="#Semaphore-是什么" class="headerlink" title="Semaphore 是什么"></a>Semaphore 是什么</h2><p>Semaphore是JUC包提供的一个共享锁，一般称之为信号量。可以用来控制同时访问特定资源的线程数量，通过协调各个线程，以保证合理的使用资源。</p>
<p>Semaphore通过自定义的同步器维护了一个或多个共享资源，线程通过调用acquire获取共享资源，通过调用release释放。</p>
<p>注意Semaphore并非lock的子类，所以加锁和解锁，用的是acquire，release，tryacquire，tryrelease</p>
<p>可以把它简单的理解成我们停车场入口立着的那个显示屏，每有一辆车进入停车场显示屏就会显示剩余车位减1，每有一辆车从停车场出去，显示屏上显示的剩余车辆就会加1，当显示屏上的剩余车位为0时，停车场入口的栏杆就不会再打开，车辆就无法进入停车场了，直到有一辆车从停车场出去为止。</p>
<h2 id="用semaphore-实现停车场提示牌功能"><a href="#用semaphore-实现停车场提示牌功能" class="headerlink" title="用semaphore 实现停车场提示牌功能"></a>用semaphore 实现停车场提示牌功能</h2><p>业务场景 ：</p>
<ul>
<li>停车场容纳总停车量10。</li>
<li>当一辆车进入停车场后，显示牌的剩余车位数响应的减1.</li>
<li>每有一辆车驶出停车场后，显示牌的剩余车位数响应的加1。</li>
<li>停车场剩余车位不足时，车辆只能在外面等待。</li>
</ul>
<pre><code class="java">public class TestCar {
​
    //停车场同时容纳的车辆10
    private  static  Semaphore semaphore=new Semaphore(10);
​
    public static void main(String[] args) {
​
        //模拟100辆车进入停车场
        for(int i=0;i&lt;100;i++){
​
            Thread thread=new Thread(new Runnable() {
                public void run() {
                    try {
                        System.out.println(&quot;====&quot;+Thread.currentThread().getName()+&quot;来到停车场&quot;);
                        if(semaphore.availablePermits()==0){
                            System.out.println(&quot;车位不足，请耐心等待&quot;);
                        }
                        semaphore.acquire();//获取令牌尝试进入停车场
                        System.out.println(Thread.currentThread().getName()+&quot;成功进入停车场&quot;);
                        Thread.sleep(new Random().nextInt(10000));//模拟车辆在停车场停留的时间
                        System.out.println(Thread.currentThread().getName()+&quot;驶出停车场&quot;);
                        semaphore.release();//释放令牌，腾出停车场车位
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            },i+&quot;号车&quot;);
​
            thread.start();
​
        }
​
    }
}
</code></pre>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><pre><code class="java">    public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }

    public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }
</code></pre>
<p>初始化Semaphore时需要指定共享资源的个数。Semaphore提供了两种模式：公平模式&amp;非公平模式。如果不指定工作模式的话，默认工作在非公平模式下。后面我们将看到，两种模式的区别在于获取共享资源时的排序策略。Semaphore有三个内部类：Sync&amp;NonfairSync&amp;FairSync。后两个继承自Sync，Sync继承自AQS。除了序列化版本号之外，Semaphore只有一个成员变量sync，公平模式下sync初始化为FairSync，非公平模式下sync初始化为NonfairSync。</p>
<h2 id="acquire-响应中断获取资源"><a href="#acquire-响应中断获取资源" class="headerlink" title="acquire 响应中断获取资源"></a>acquire 响应中断获取资源</h2><p>Semaphore提供了两种获取资源的方式：响应中断&amp;不响应中断。我们先来看一下响应中断的获取。</p>
<pre><code class="java">public void acquire() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }
</code></pre>
<p>acquire方法由同步器sync调用上层AQS提供的acquireSharedInterruptibly方法获取：</p>
<pre><code class="java">public final void acquireSharedInterruptibly(int arg)
            throws InterruptedException {
        if (Thread.interrupted())
            throw new InterruptedException();
        if (tryAcquireShared(arg) &lt; 0)
            doAcquireSharedInterruptibly(arg);
    }
</code></pre>
<p>acquireSharedInterruptibly方法先检测中断。然后调用tryAcquireShared方法试图获取共享资源。这时公平模式和非公平模式的代码执行路径发生分叉，FairSync和NonfairSync各自重写了tryAcquireShared方法。</p>
<p>我们先来看下非公平模式下的tryAcquireShared方法：</p>
<pre><code class="java">     protected int tryAcquireShared(int acquires) {
            return nonfairTryAcquireShared(acquires);
        }
</code></pre>
<p>它直接代用了父类Sync提供的nonfairTryAcquireShared方法：</p>
<pre><code class="java">final int nonfairTryAcquireShared(int acquires) {
            for (;;) {
                int available = getState();
                int remaining = available - acquires;
                if (remaining &lt; 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }
</code></pre>
<p>注意，这里是一个CAS自旋。因为Semaphore是一个共享锁，可能有多个线程同时申请共享资源，因此CAS操作可能失败。直到成功获取返回剩余资源数目，或者发现没有剩余资源返回负值代表申请失败。有一个问题，为什么我们不在CAS操作失败后就直接返回失败呢？因为这样做虽然不会导致错误，但会降低效率：在还有剩余资源的情况下，一个线程因为竞争导致CAS失败后被放入等待序列尾，一定在队列头部有一个线程被唤醒去试图获取资源，这比直接自旋继续获取多了操作等待队列的开销。(有剩余资源的时候就不断的自旋获取，没有剩的了再入队)</p>
<p>这里“非公平”的语义体现在：如果一个线程通过nonfairTryAcquireShared成功获取了共享资源，对于此时正在等待队列中的线程来说，可能是不公平的：队列中线程先到，却没能先获取资源。</p>
<p>如果tryAcquireShared没能成功获取，acquireSharedInterruptibly方法调用doAcquireSharedInterruptibly方法将当前线程放入等待队列并开始自旋检测获取资源：</p>
<pre><code class="java">private void doAcquireSharedInterruptibly(int arg)
        throws InterruptedException {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        failed = false;
                        return;
                    }
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>我们注意到，doAcquireSharedInterruptibly中，当一个线程从parkAndCheckInterrupt方法中被中断唤醒之后，直接抛出了中断异常。还记得我们分析AQS时的doAcquireShared方法吗，它在这里的处理方式是用一个局部变量interrupted记录下这个异常但不立即处理，而是等到成功获取资源之后返回这个中断标志，并在上层调用selfInterrupt方法补上中断。<br>这正是两个方法的关键区别：是否及时响应中断。</p>
<p>我们再来看公平模式下的tryAcquireShared方法：</p>
<pre><code class="java">protected int tryAcquireShared(int acquires) {
            for (;;) {
                if (hasQueuedPredecessors())
                    return -1;
                int available = getState();
                int remaining = available - acquires;
                if (remaining &lt; 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }
</code></pre>
<p>相比较非公平模式的nonfairTryAcquireShared方法，公平模式下的tryAcquireShared方法在试图获取之前做了一个判断，如果发现等对队列中有线程在等待获取资源，就直接返回-1表示获取失败。当前线程会被上层的acquireSharedInterruptibly方法调用doAcquireShared方法放入等待队列中。这正是“公平”模式的语义：如果有线程先于我进入等待队列且正在等待，就直接进入等待队列，效果便是各个线程按照申请的顺序获得共享资源，具有公平性。</p>
<h2 id="acquireUnInterruptibly-不响应中断获取资源"><a href="#acquireUnInterruptibly-不响应中断获取资源" class="headerlink" title="acquireUnInterruptibly 不响应中断获取资源"></a>acquireUnInterruptibly 不响应中断获取资源</h2><pre><code class="java">    public void acquireUninterruptibly() {
        sync.acquireShared(1);
    }
</code></pre>
<p>acquireUnInterruptibly方法调用AQS提供的acquireShared方法：</p>
<pre><code class="java"> public final void acquireShared(int arg) {
        if (tryAcquireShared(arg) &lt; 0)
            doAcquireShared(arg);
    }
</code></pre>
<p>acquireShared方法首先试图获取资源，这与acquireSharedInterruptibly方法相比，没有先检测中断的这一步。紧接着调用doAcquireShared方法，由于这个方法在AQS中已经详细分析过，这里我们只关注它与doAcquireSharedInterruptibly方法的区别：</p>
<pre><code class="java"> private void doAcquireShared(int arg) {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        if (interrupted)
                            selfInterrupt();
                        failed = false;
                        return;
                    }
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>正如刚刚说过的，区别只在线程从parkAndCheckInterrupt方法中因中断而返回时的处理：在这里它没有抛出异常，而是用一个局部变量interrupted记录下这个异常但不立即处理，而是等到成功获取资源之后返回这个中断标志，并在上层调用selfInterrupt方法补上中断。</p>
<h2 id="acquire-int-amp-acquireUninterruptibly-int-指定申请的资源数目的获取"><a href="#acquire-int-amp-acquireUninterruptibly-int-指定申请的资源数目的获取" class="headerlink" title="acquire(int) &amp; acquireUninterruptibly(int) 指定申请的资源数目的获取"></a>acquire(int) &amp; acquireUninterruptibly(int) 指定申请的资源数目的获取</h2><pre><code class="java">public void acquire(int permits) throws InterruptedException {
        if (permits &lt; 0) throw new IllegalArgumentException();
        sync.acquireSharedInterruptibly(permits);
    }

    public void acquireUninterruptibly(int permits) {
        if (permits &lt; 0) throw new IllegalArgumentException();
        sync.acquireShared(permits);
    }
</code></pre>
<p>可以看到，与不指定数目时的获取的区别仅在参数值，不再赘述。</p>
<h2 id="release-释放资源"><a href="#release-释放资源" class="headerlink" title="release 释放资源"></a>release 释放资源</h2><p>公平模式和非公平模式的释放资源操作是一样的：</p>
<pre><code class="java">public void release() {
        sync.releaseShared(1);
    }

    public void release(int permits) {
        if (permits &lt; 0) throw new IllegalArgumentException();
        sync.releaseShared(permits);
    }
</code></pre>
<p>调用AQS提供的releaseShared方法：</p>
<pre><code class="java">public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
</code></pre>
<p>releaseShared方法首先调用我们重写的tryReleaseShared方法试图释放资源。然后调用doReleaseShared方法唤醒队列之后的等待线程。我们主要关注tryReleaseShared方法：</p>
<pre><code class="java">protected final boolean tryReleaseShared(int releases) {
            for (;;) {
                int current = getState();
                int next = current + releases;
                if (next &lt; current) // overflow
                    throw new Error(&quot;Maximum permit count exceeded&quot;);
                if (compareAndSetState(current, next))
                    return true;
            }
        }
</code></pre>
<p>这个方法也是一个CAS自旋，原因是应为Semaphore是一个共享锁，可能有多个线程同时释放资源，因此CAS操作可能失败。最后方法总会成功释放并返回true（如果不出错的话）。</p>
<h2 id="tryAcquire-amp-tryAcquire-timeout-方法"><a href="#tryAcquire-amp-tryAcquire-timeout-方法" class="headerlink" title="tryAcquire &amp; tryAcquire(timeout) 方法"></a>tryAcquire &amp; tryAcquire(timeout) 方法</h2><pre><code class="java">public boolean tryAcquire() {
        return sync.nonfairTryAcquireShared(1) &gt;= 0;
    }

    public boolean tryAcquire(long timeout, TimeUnit unit)
        throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    public boolean tryAcquire(int permits) {
        if (permits &lt; 0) throw new IllegalArgumentException();
        return sync.nonfairTryAcquireShared(permits) &gt;= 0;
    }

    public boolean tryAcquire(int permits, long timeout, TimeUnit unit)
        throws InterruptedException {
        if (permits &lt; 0) throw new IllegalArgumentException();
        return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));
    }
</code></pre>
<p>没有指定等待时间的tryAcquire调用的是nonfairTryAcquireShared方法，我们已经分析过，不再赘述。我们重点关注指定等待时长的方法。限时等待是通过调用AQS提供的tryAcquireSharedNanos方法实现的：</p>
<pre><code class="java">public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (Thread.interrupted())
            throw new InterruptedException();
        return tryAcquireShared(arg) &gt;= 0 ||
            doAcquireSharedNanos(arg, nanosTimeout);
    }
</code></pre>
<p>注意：限时等待默认都是及时响应中断的。方法开始先检测中断，然后调用tryAcquireShared方法试图获取资源，如果成功的话直接返回true，不成功则调用doAcquireSharedNanos方法：</p>
<pre><code class="java">private boolean doAcquireSharedNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (nanosTimeout &lt;= 0L)
            return false;
        final long deadline = System.nanoTime() + nanosTimeout;
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        failed = false;
                        return true;
                    }
                }
                nanosTimeout = deadline - System.nanoTime();
                if (nanosTimeout &lt;= 0L)
                    return false;
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    nanosTimeout &gt; spinForTimeoutThreshold)
                    LockSupport.parkNanos(this, nanosTimeout);
                if (Thread.interrupted())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>方法在自旋之前先计算了一个结束等待的时间节点deadline，然后便开始自旋，每次自旋都要计算一下剩余等待时间nanosTimeout，如果nanosTimeout小于等于0，说明已经到达deadline，直接返回false表示超时。</p>
<p>有一点值得注意，spinForTimeoutThreshold这个值规定了一个阈值，当剩余等待时间小于这个值的时候，线程将不再被park，而是一直在自旋试图获取资源。关于这个值的作用Doug Lea是这样注释的：</p>
<pre><code class="java">/**
     * The number of nanoseconds for which it is faster to spin
     * rather than to use timed park. A rough estimate suffices
     * to improve responsiveness with very short timeouts.
     */
</code></pre>
<p>park和unpark操作需要一定的开销，当nanosTimeout很小的时候，这个开销就相对很大了。这个阈值的设置可以让短时等待的线程一直保持自旋，可以提高短时等待的反应效率，而由于nanosTimeout很小，自旋又不会有过多的开销。</p>
<p>除此之外，doAcquireSharedNanos方法与不限时等待的doAcquireShared方法还有两点重要区别：</p>
<ul>
<li>由于有等待时限，所以线程从park方法返回时我们不能确定返回的原因是中断还是超时，因此需要调用interrupted方法检测一下中断标志；</li>
<li>doAcquireSharedNanos方法是及时响应中断的，而doAcquireShared方法延迟处理中断。</li>
</ul>
<h2 id="drainPermits-amp-reducePermits-修改剩余共享资源数量"><a href="#drainPermits-amp-reducePermits-修改剩余共享资源数量" class="headerlink" title="drainPermits &amp; reducePermits 修改剩余共享资源数量"></a>drainPermits &amp; reducePermits 修改剩余共享资源数量</h2><p>Semaphore提供了“耗尽”所有剩余共享资源的操作：</p>
<pre><code class="java">public int drainPermits() {
        return sync.drainPermits();
    }
</code></pre>
<p>drainPermits调用了自定义同步器Sync的同名方法：</p>
<pre><code class="java">        final int drainPermits() {
            for (;;) {
                int current = getState();
                if (current == 0 || compareAndSetState(current, 0))
                    return current;
            }
        }
</code></pre>
<p>用CAS自旋将剩余资源清空。</p>
<p>我们再来看看“缩减”剩余共享资源的操作：</p>
<pre><code class="java">protected void reducePermits(int reduction) {
        if (reduction &lt; 0) throw new IllegalArgumentException();
        sync.reducePermits(reduction);
    }
</code></pre>
<p>首先，缩减必须是单向的，即只能减少不能增加，然后调用Sync的同名方法：</p>
<pre><code class="java">final void reducePermits(int reductions) {
            for (;;) {
                int current = getState();
                int next = current - reductions;
                if (next &gt; current) // underflow
                    throw new Error(&quot;Permit count underflow&quot;);
                if (compareAndSetState(current, next))
                    return;
            }
        }
</code></pre>
<p>用CAS自旋在剩余共享资源上做缩减。</p>
<p>上述两个对共享资源数量的修改操作有两点需要注意：</p>
<ul>
<li>是不可逆的</li>
<li>是对剩余资源的操作而不是全部资源，当剩余资源数目不足或已经为0时，方法就返回，正咋被占用的资源不参与。</li>
</ul>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>Semaphore是JUC包提供的一个典型的共享锁，它通过自定义两种不同的同步器（FairSync&amp;NonfairSync）提供了公平&amp;非公平两种工作模式，两种模式下分别提供了限时/不限时、响应中断/不响应中断的获取资源的方法（限时获取总是及时响应中断的），而所有的释放资源的release操作是统一的。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ReentrantReadWriteLock]]></title>
      <url>/2020/11/22/juc-5/</url>
      <content type="html"><![CDATA[<p>内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<p>ReentrantLock提供了标准的互斥操作，但在应用中，我们对一个资源的访问有两种方式：读和写，读操作一般不会影响数据的一致性问题。但如果我们使用ReentrantLock，则在需要在读操作的时候也独占锁，这会导致并发效率大大降低。JUC包提供了读写锁ReentrantReadWriteLock，使得读写锁分离，在上述情境下，应用读写锁相对于使用独占锁，并发性能得到较大提高。</p>
<p>我们先来大致了解一下ReentrantReadWriteLock的性质：</p>
<ul>
<li><p>基本性质：读锁是一个共享锁，写锁是一个独占锁。读锁能同时被多个线程获取，写锁只能被一个线程获取。读锁和写锁不能同时存在。</p>
</li>
<li><p>重入性：一个线程可以多次重复获取读锁和写锁。</p>
</li>
<li><p>锁降级：一个线程在已经获取写锁的情况下，可以再次获取读锁，如果线程又释放了写锁，就完成了一次锁降级。</p>
</li>
<li><p>锁升级：ReentrantReadWriteLock不支持锁升级。一个线程在获取读锁的情况下，如果试图去获取写锁，将会导致死锁（后面会详细说明）。</p>
</li>
<li><p>获取锁中断：提供了可中断的lock方法。</p>
</li>
<li><p>重入数：读锁和写锁的重入上限为65535（所有线程获取的锁的总数，为什么是这个值后面会详细说明）。</p>
</li>
<li><p>公平性：ReentrantReadWriteLock提供了公平&amp;非公平两种工作模式。</p>
</li>
</ul>
<p>ReentrantReadWriteLock实现了ReadWriteLock接口：</p>
<pre><code class="java">public interface ReadWriteLock {  
    Lock readLock();  
    Lock writeLock();  
}
</code></pre>
<p>这个接口之有两个方法，分别返回读锁和写锁。ReentrantReadWriteLock定义了两个内部类：readLock&amp;writeLock。</p>
<p>ReentrantReadWriteLock提供了两种自定义的同步器：FairSync&amp;NonfairSync：</p>
<pre><code class="java">　　static final class NonfairSync extends Sync {
        private static final long serialVersionUID = -8159625535654395037L;
        final boolean writerShouldBlock() {
            return false; // writers can always barge
        }
        final boolean readerShouldBlock() {
            return apparentlyFirstQueuedIsExclusive();
        }
    }

    static final class FairSync extends Sync {
        private static final long serialVersionUID = -2274990926593161451L;
        final boolean writerShouldBlock() {
            return hasQueuedPredecessors();
        }
        final boolean readerShouldBlock() {
            return hasQueuedPredecessors();
        }
    }
</code></pre>
<p>他们都继承自父类同步器Sync，而他们只定义了writerShouldBlock&amp;readerShouldBlock方法。这两个方法用在获取锁的操作中，表示要获取锁的线程需要到等待队列中，还是可以直接尝试获取。后面我们会详细分析。</p>
<p>在自定义的同步器Sync中，定义了锁数量的记录方式:</p>
<pre><code class="java">        static final int SHARED_SHIFT   = 16;
        static final int SHARED_UNIT    = (1 &lt;&lt; SHARED_SHIFT);
        static final int MAX_COUNT      = (1 &lt;&lt; SHARED_SHIFT) - 1;
        static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;

        /** Returns the number of shared holds represented in count  */
        static int sharedCount(int c)    { return c &gt;&gt;&gt; SHARED_SHIFT; }
        /** Returns the number of exclusive holds represented in count  */
        static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; }
</code></pre>
<p>可见，ReentrantReadWriteLock用一个32位无符号数记录锁的数量，高16位记录共享锁（读锁）的数量，第16位记录独占锁（写锁）的数量，因此锁的数量上限都是65535。</p>
<h2 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h2><h3 id="lock-获取写锁"><a href="#lock-获取写锁" class="headerlink" title="lock 获取写锁"></a>lock 获取写锁</h3><pre><code class="java">public void lock() {
            sync.acquire(1);
        }
</code></pre>
<p>acquire方法不再赘述。这里重点关注自定义同步器Sync重写的tryAcquire方法： </p>
<pre><code class="java">protected final boolean tryAcquire(int acquires) {
            /*
             * Walkthrough:
             * 1. If read count nonzero or write count nonzero
             *    and owner is a different thread, fail.
             * 2. If count would saturate, fail. (This can only
             *    happen if count is already nonzero.)
             * 3. Otherwise, this thread is eligible for lock if
             *    it is either a reentrant acquire or
             *    queue policy allows it. If so, update state
             *    and set owner.
             */
            Thread current = Thread.currentThread();
            int c = getState();
            int w = exclusiveCount(c);
            if (c != 0) {
                // (Note: if c != 0 and w == 0 then shared count != 0)
                if (w == 0 || current != getExclusiveOwnerThread())
                    return false;
                if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                // Reentrant acquire
                setState(c + acquires);
                return true;
            }
            if (writerShouldBlock() ||
                !compareAndSetState(c, c + acquires))
                return false;
            setExclusiveOwnerThread(current);
            return true;
        }
</code></pre>
<p>首先调用获取了一下state值，然后调用exclusiveCount方法获取当前写锁的数量。</p>
<p>然后做了一个判断，当c！=0时：如果w==0（即读锁的数量！=0），直接返回false。因为我们前面已经说过，读锁和写锁不能同时存在。当c！=0且W！=0的时候，有写锁存在，如果写锁不是由当前线程持有（注意，写锁是独占锁，只能由一个线程持有），直接返回false。如果是当前线程持有写锁，说明当前线程正在试图“重入”写锁。调用setState更新status值。注意，由于写锁是独占锁，因此执行到setState这一步时不可能出现竞争，因此不用调用CAS操作，直接setState即可。</p>
<p>注意：如果一个线程在持有读锁的情况下去申请写锁（试图锁升级），会导致死锁。tryAcquire在这种情况下返回false，AQS的acquire方法会将当前线程放入等待队列去等待写锁，在获取写锁之前不会释放锁持有的读锁，而读锁和写锁不能同时存在，发生死锁，他将永远不能获取这个写锁，其他线程也不能获取写锁，但读锁可被正常获取，只是永远不能获取写锁了。</p>
<p>如果c==0时，说明不存在任何锁。调用writerShouldBlock方法判断一下此时线程是否应该进入等待队列。注意：公平模式&amp;非公平模式下的writerShouldBlock是不同的，非公平模式下，writerShouldBlock方法直接返回false，这也符合非公平的语义：</p>
<pre><code class="java"> final boolean writerShouldBlock() {
            return false; // writers can always barge
        }
</code></pre>
<p>而公平模式下，则调用方法，判断下等待队列中，当前线程之前是否有其他线程正在等待：</p>
<pre><code class="java">final boolean writerShouldBlock() {
            return hasQueuedPredecessors();
        }
</code></pre>
<p>注意，如果有，那么我们当时获取status的值的时候，这些线程还没来得及更改status值（因为我们当时获取的status为0），原因可能是应为刚到，或者刚被唤醒，在自旋中，还没有成功获取锁。 </p>
<pre><code class="java">    public final boolean hasQueuedPredecessors() {
        // The correctness of this depends on head being initialized
        // before tail and on head.next being accurate if the current
        // thread is first in queue.
        Node t = tail; // Read fields in reverse initialization order
        Node h = head;
        Node s;
        return h != t &amp;&amp;
            ((s = h.next) == null || s.thread != Thread.currentThread());
    }
</code></pre>
<p>返回true必须满足两个条件：</p>
<ul>
<li>队列非空</li>
<li>第一个等待线程（head.next）为空 或 不为空但不是当前线程。head.next为空的情形是：在我们获取head之后，head就被队列中下一个等待线程线程踢出队列了，next被置为空，那么踢他出去的这个线程一定不是当前线程，说明有其他线程等待在队列中。</li>
</ul>
<p>我们回到tryAcquire方法中，当发现writerShouldBlock为true，或者writerShouldBlock为false但在CAS操作中失败时（由于这里的获取写锁不是重入，因此可能有多个线程同时竞争写锁），返回false。如果CAS成功，则调用setExclusiveOwnerThread将当前持有写锁的线程设置为当前线程。</p>
<h3 id="release-释放写锁"><a href="#release-释放写锁" class="headerlink" title="release 释放写锁"></a>release 释放写锁</h3><pre><code class="java">public void unlock() {
            sync.release(1);
        }
</code></pre>
<p>与ReentrantLock一样，unlock方法调用AQS提供的release方法,这里重点关注自定义同步器Sync重写的tryRelease方法：</p>
<pre><code class="java">protected final boolean tryRelease(int releases) {
            if (!isHeldExclusively())
                throw new IllegalMonitorStateException();
            int nextc = getState() - releases;
            boolean free = exclusiveCount(nextc) == 0;
            if (free)
                setExclusiveOwnerThread(null);
            setState(nextc);
            return free;
        }
</code></pre>
<p>首先，我们需要清楚一点：tryRelease方法的返回值表示当前释放操作完成后，剩余写锁数量是否等于0（即完成此释放后，写锁是否可用）。这与同样是可重入的ReentrantLock的tryRelease方法一样，ReentrantLock的tryRelease方法返回值的意义也是剩余写锁数量是否等于0（即完成此释放后，写锁是否可用）。</p>
<h3 id="tryLock-获取写锁"><a href="#tryLock-获取写锁" class="headerlink" title="tryLock 获取写锁"></a>tryLock 获取写锁</h3><pre><code class="java">public boolean tryLock( ) {
            return sync.tryWriteLock();
        }
</code></pre>
<p>WriteLock的tryLock方法调用自定义同步器Sync的tryWriteLock方法实现：</p>
<pre><code class="java">final boolean tryWriteLock() {
            Thread current = Thread.currentThread();
            int c = getState();
            if (c != 0) {
                int w = exclusiveCount(c);
                if (w == 0 || current != getExclusiveOwnerThread())
                    return false;
                if (w == MAX_COUNT)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
            }
            if (!compareAndSetState(c, c + 1))
                return false;
            setExclusiveOwnerThread(current);
            return true;
        }
</code></pre>
<p>tryWriteLock方法看上去跟tryAcquire方法真的很像。唯一的区别在于，tryWriteLock忽略的writerShouldBlock方法，即，默认调用tryLock方法的时机，就是需要我们去“抢”写锁的时机。</p>
<h2 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h2><h3 id="lock-获取读锁"><a href="#lock-获取读锁" class="headerlink" title="lock 获取读锁"></a>lock 获取读锁</h3><pre><code class="java">public void lock() {
            sync.acquireShared(1);
        }
</code></pre>
<p>ReadLock的lock方法调用AQS提供的acquireShared方法来实现, 我们重点关注自定义同步器Sync重写的tryAcquireShared方法： </p>
<pre><code class="java">protected final int tryAcquireShared(int unused) {
            /*
             * Walkthrough:
             * 1. If write lock held by another thread, fail.
             * 2. Otherwise, this thread is eligible for
             *    lock wrt state, so ask if it should block
             *    because of queue policy. If not, try
             *    to grant by CASing state and updating count.
             *    Note that step does not check for reentrant
             *    acquires, which is postponed to full version
             *    to avoid having to check hold count in
             *    the more typical non-reentrant case.
             * 3. If step 2 fails either because thread
             *    apparently not eligible or CAS fails or count
             *    saturated, chain to version with full retry loop.
             */
            Thread current = Thread.currentThread();
            int c = getState();
            if (exclusiveCount(c) != 0 &amp;&amp;
                getExclusiveOwnerThread() != current)
                return -1;
            int r = sharedCount(c);
            if (!readerShouldBlock() &amp;&amp;
                r &lt; MAX_COUNT &amp;&amp;
                compareAndSetState(c, c + SHARED_UNIT)) {
                if (r == 0) {
                    firstReader = current;
                    firstReaderHoldCount = 1;
                } else if (firstReader == current) {
                    firstReaderHoldCount++;
                } else {
                    HoldCounter rh = cachedHoldCounter;
                    if (rh == null || rh.tid != getThreadId(current))
                        cachedHoldCounter = rh = readHolds.get();
                    else if (rh.count == 0)
                        readHolds.set(rh);
                    rh.count++;
                }
                return 1;
            }
            return fullTryAcquireShared(current);
        }
</code></pre>
<p>方法首先检测了一下当前是否有其他线程持有写锁，如果是的话，直接返回-1，表示获取失败。后续AQS的acquireShared方法会将当前线程放入等待队列中。</p>
<p>然后方法做了这样一个判断，如果当前线程可以直接参与竞争读锁的话，就调用CAS操作将status值加一个SHARED_UNIT，注意，这里不是加1, 是因为status的高16位代表读锁的数量。</p>
<p>OK，我们必须在这里暂停一下，我们需要详细解释一下几个成员变量：</p>
<pre><code class="java">static final class HoldCounter {
    int count = 0;
    // Use id, not reference, to avoid garbage retention
    final long tid = getThreadId(Thread.currentThread());
}

static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; {
    public HoldCounter initialValue() {
        return new HoldCounter();
    }
}

private transient ThreadLocalHoldCounter readHolds;
private transient HoldCounter cachedHoldCounter;

private transient Thread firstReader = null;
private transient int firstReaderHoldCount;
</code></pre>
<p>HoldCounter是一个final的内部类，有两个成员：tid&amp;count，分别代表一个线程ID和线程对应的一个计数值。</p>
<p>ThreadLocalHoldCounter是一个final的内部类，它继承自<code>ThreadLocal&lt;HoldCounter&gt;</code>，它重写了initialValue方法，ThreadLocalHoldCounter对象对某一个线程第一次调用get方法是，会调用initialValue方法初始化这个线程响应的本地变量，并加入到map中。</p>
<p>readHolds存在的作用是：记录所有持有读锁的线程所持有读锁的数量。对于写锁来说，它是独占锁，我们可以通过status的低16位+独占写锁的线程来记录关于写锁的所有信息，即它被谁持有&amp;被重入的数量。而读锁是一个共享锁，任何线程都可能持有它，因此，我们必须对每个线程都记录一下它所持有的共享锁（读锁）的数量。本地变量ThreadLocal来实现这个记录是非常合适的。</p>
<p>cachedHoldCounter是一个缓存。很多情况下，一个线程获取读锁之后要更新一下它对应的记录值（线程对应的HoldCounter对象），然后有很大可能在很短的时间内就释放掉读锁，这时候需要再次更新HoldCounter，甚至需要从readHolds中删除（如果重入的读锁都被释放掉的话），需要调用readHolds的get方法，这是有一定开销的。因此，设置cachedHoldCounter作为一个缓存，在某个线程需要这个记录值的时候，先检查cachedHoldCounter对应的线程是否是这个线程自己，如果不是的话，再熊readHolds中get出来，这提高了效率。</p>
<p>firsReader&amp;firstReaderHoldCount，这两个值记录了第一个获取读锁的线程和它持有的读锁的数量（可重入的嘛），这两个值在读锁全部释放之后要清空，以便记录下一次首先获取读锁的线程和其锁数目。这两个值存在的意义是：很多时候，读锁只被一个线程获取，这时候我们规定，第一个获取读锁的线程的计数不放入readHolds中，而是单独用这两个计数值来记录，这就避免了当只有一个线程操作读锁的时候，频繁地在readHolds上读取，提高了效率。</p>
<p>注意区别：</p>
<ul>
<li>cachedHoldCounter提高的是一个线程获取-释放之间没有其他线程来获取或释放锁时的效率；</li>
<li>firsReader&amp;firstReaderHoldCount提高的是只有一个线程操作锁时的效率。</li>
</ul>
<p>这时候我们再回到tryAcquireShared方法，当CAS操作成功后，需要去更新刚刚说过的计数值。具体细节代码已经很清楚，不再赘述。</p>
<p>如果CAS失败或readerShouldBlock方法返回true，我们调用fullTryAcquireShared方法继续试图获取读锁。fullTryAcquireShared方法是tryAcquireShared方法的完整版，或者叫升级版，它处理了CAS失败的情况和readerShouldBlock返回true的情况。</p>
<p>在分析fullTryAcquireShared方法之前，我们先来看一下readerShouldBlock方法：</p>
<p>在公平模式下，根据等待队列中在当前线程之前有没有等待线程来判断：</p>
<pre><code class="java"> final boolean readerShouldBlock() {
            return hasQueuedPredecessors();
        }
</code></pre>
<p>而在非公平模式下：</p>
<pre><code class="java">  final boolean readerShouldBlock() {
            return apparentlyFirstQueuedIsExclusive();
        }
</code></pre>
<p>调用了apparentlyFirstQueuedIsExclusive方法：</p>
<pre><code class="java">final boolean apparentlyFirstQueuedIsExclusive() {
        Node h, s;
        return (h = head) != null &amp;&amp;
            (s = h.next)  != null &amp;&amp;
            !s.isShared()         &amp;&amp;
            s.thread != null;
    }
</code></pre>
<p>这个方法返回是否队列的head.next正在等待独占锁（写锁）。当然这个方法执行的过程中队列的形态可能发生变化。这个方法的意思是：读锁不应该让写锁始终等待。</p>
<p>好了，我们现在来看fullTryAcquireShared方法：</p>
<pre><code class="java">/**
         * Full version of acquire for reads, that handles CAS misses
         * and reentrant reads not dealt with in tryAcquireShared.
         */
        final int fullTryAcquireShared(Thread current) {
            /*
             * This code is in part redundant with that in
             * tryAcquireShared but is simpler overall by not
             * complicating tryAcquireShared with interactions between
             * retries and lazily reading hold counts.
             */
            HoldCounter rh = null;
            for (;;) {
                int c = getState();
                if (exclusiveCount(c) != 0) {
                    if (getExclusiveOwnerThread() != current)
                        return -1;
                    // else we hold the exclusive lock; blocking here
                    // would cause deadlock.
                } else if (readerShouldBlock()) {
                    // Make sure we&#39;re not acquiring read lock reentrantly
                    if (firstReader == current) {
                        // assert firstReaderHoldCount &gt; 0;
                    } else {
                        if (rh == null) {
                            rh = cachedHoldCounter;
                            if (rh == null || rh.tid != getThreadId(current)) {
                                rh = readHolds.get();
                                if (rh.count == 0)
                                    readHolds.remove();
                            }
                        }
                        if (rh.count == 0)
                            return -1;
                    }
                }
                if (sharedCount(c) == MAX_COUNT)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                if (compareAndSetState(c, c + SHARED_UNIT)) {
                    if (sharedCount(c) == 0) {
                        firstReader = current;
                        firstReaderHoldCount = 1;
                    } else if (firstReader == current) {
                        firstReaderHoldCount++;
                    } else {
                        if (rh == null)
                            rh = cachedHoldCounter;
                        if (rh == null || rh.tid != getThreadId(current))
                            rh = readHolds.get();
                        else if (rh.count == 0)
                            readHolds.set(rh);
                        rh.count++;
                        cachedHoldCounter = rh; // cache for release
                    }
                    return 1;
                }
            }
        }
</code></pre>
<p>我们可以看到：fullTryAcquireShared方法是tryAcquireShared方法的完整版，或者叫升级版，它处理了CAS失败的情况和readerShouldBlock返回true的情况。</p>
<p>跟tryAcquireShared方法一样，首先检查是否有其他线程正在持有写锁，如果是，直接返回false。如果没有线程正在持有写锁，则调用readerShouldBlock检测当前线程是否应该进入等待队列。就算readerShouldBlock方法返回true，原因可能因为当前是公平模式或者队列的第一个等待线程（head.next）正在等待写锁，我们也不能直接返回false，因为返回false意味着当前线程将要进入等待队列（见AQS的acquireShared方法），原因是：</p>
<ul>
<li>如果当前线程正在持有读锁，且这次读锁的重入被放入等待队列，万一之前队列中有线程正在等待写锁，将会导致死锁；</li>
<li>另一种情况是当前线程正在持有写锁，且这次读锁的“降级申请”被放入等待队列，如果队列中之前有线程正在等待锁，不论等待的是写锁还是读锁，都将导致死锁。</li>
</ul>
<p>因此，我们需要做一个判断，如果这次申请读锁是对读锁的一次重入（因为我们已经检测过没有写锁，因此只考虑上述第①种情况），我们将不能返回false（返回false意味着进队列），而是调用CAS操作去获取读锁，如果CAS失败，则一直自旋，直到成功获取，或者可以返回false去队列的时机的到来。</p>
<p>我们可以这样提fullTryAcquireShared方法说句话：不是我不想进队列休息，实在是因为进队列有可能死锁，所以我才一直自旋！</p>
<p>注意：判断重入的时候firstReader==当前线程即说明是一次重入，因为firstReader线程释放最后一个读锁的时候会将firstReader置为null，这里还不是null，说明依然持有读锁。</p>
<p>另外还记得我们提过apparentlyFirstQueuedIsExclusive方法是不可靠的吗，它在检测的过程中队列结构可能被更改，head可能被踢出，方法可能因为head.next为null而返回false。而且它也只是检测第一个等待线程（head.next），如果有等待写锁的线程在后面，它也不能检测出来。不过没关系，这些都导致它返回false，返回false意味着fullTryAcquireShared可以去抢“锁”并不会影响正确性。</p>
<h3 id="unlock-释放读锁"><a href="#unlock-释放读锁" class="headerlink" title="unlock 释放读锁"></a>unlock 释放读锁</h3><pre><code class="java">public void unlock() {
            sync.releaseShared(1);
        }
</code></pre>
<p>readLock的unlock方法调用AQS提供的releaseShared方法实现, 这里我们关注自定义同步器Sync重写的tryReleaseShared方法：</p>
<pre><code class="java">protected final boolean tryReleaseShared(int unused) {
            Thread current = Thread.currentThread();
            if (firstReader == current) {
                // assert firstReaderHoldCount &gt; 0;
                if (firstReaderHoldCount == 1)
                    firstReader = null;
                else
                    firstReaderHoldCount--;
            } else {
                HoldCounter rh = cachedHoldCounter;
                if (rh == null || rh.tid != getThreadId(current))
                    rh = readHolds.get();
                int count = rh.count;
                if (count &lt;= 1) {
                    readHolds.remove();
                    if (count &lt;= 0)
                        throw unmatchedUnlockException();
                }
                --rh.count;
            }
            for (;;) {
                int c = getState();
                int nextc = c - SHARED_UNIT;
                if (compareAndSetState(c, nextc))
                    // Releasing the read lock has no effect on readers,
                    // but it may allow waiting writers to proceed if
                    // both read and write locks are now free.
                    return nextc == 0;
            }
        }
</code></pre>
<p>分为三部分：</p>
<ul>
<li>如果是firstReader，对firstReader修改；②</li>
<li>如果不是firstReader，修改readHolds；</li>
<li>CAS自旋更新status值。</li>
</ul>
<p>注意：tryReleaseShared方法的返回值如果为true，表示status为0，即已经不存在任何锁，both读锁&amp;写锁。</p>
<h3 id="tryLock-获取读锁"><a href="#tryLock-获取读锁" class="headerlink" title="tryLock 获取读锁"></a>tryLock 获取读锁</h3><pre><code class="java">public boolean tryLock() {
            return sync.tryReadLock();
        }
</code></pre>
<p>ReadLock的tryLock调用自定义同步器Sync的tryReadLock方法实现：</p>
<pre><code class="java">final boolean tryReadLock() {
            Thread current = Thread.currentThread();
            for (;;) {
                int c = getState();
                if (exclusiveCount(c) != 0 &amp;&amp;
                    getExclusiveOwnerThread() != current)
                    return false;
                int r = sharedCount(c);
                if (r == MAX_COUNT)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                if (compareAndSetState(c, c + SHARED_UNIT)) {
                    if (r == 0) {
                        firstReader = current;
                        firstReaderHoldCount = 1;
                    } else if (firstReader == current) {
                        firstReaderHoldCount++;
                    } else {
                        HoldCounter rh = cachedHoldCounter;
                        if (rh == null || rh.tid != getThreadId(current))
                            cachedHoldCounter = rh = readHolds.get();
                        else if (rh.count == 0)
                            readHolds.set(rh);
                        rh.count++;
                    }
                    return true;
                }
            }
        }
</code></pre>
<p>与写锁的tryWriteLock方法类似，tryReadLock同样忽略了readerShouldBlock方法，因为调用这个方法就意味着：现在是适合抢占的时机。</p>
<p>tryReadLock方法与tryAcquireShared方法十分类似，不同在于：当CAS失败时，tryAcquireShared方法调用fullAcquireShared处理CAS失败，而tryReadLock方法遇到CAS失败时，直接返回false，毕竟只是try嘛。</p>
<p>总结：</p>
<p>ReentrantReadWriteLock相比于其他锁，还是比较复杂的，因为他结合了共享锁和独占锁，并混合使用了他们。虽然ReentrantReadWriteLock通过精巧的设计尽量避免死锁的发生，但如果我们使用不当仍然可能发生死锁，比如我们在持有读锁的情况下去申请写，企图做锁升级。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之Condition]]></title>
      <url>/2020/11/22/juc-4/</url>
      <content type="html"><![CDATA[<p>内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<p>Condition在JUC框架下提供了传统Java监视器风格的wait、notify和notifyAll相似的功能。</p>
<p><img src="https://s3.ax1x.com/2020/11/22/DGpqBD.png" alt="DGpqBD.png"></p>
<p>Condition队列与Sync队列（锁等待队列）有几点不同：</p>
<ul>
<li>Condition队列是一个单向链表，而Sync队列是一个双向链表；</li>
<li>Sync队列在初始化的时候，会在队列头部添加一个空的dummy节点，它不持有任何线程，而Condition队列初始化时，头结点就开始持有等待线程了。</li>
<li>Condition永远都是一个公平锁（顺序）的实现</li>
</ul>
<p>Condition必须被绑定到一个独占锁上使用。ReentrantLock中获取Condition的方法为：</p>
<pre><code class="java">public Condition newCondition() {
    return sync.newCondition();
}

final ConditionObject newCondition() {
    return new ConditionObject();
}
</code></pre>
<p>直接初始化并返回了一个AQS提供的ConditionObject对象。因此，Condition实际上是AQS框架的内容。ConditionObject通过维护两个成员变量：</p>
<pre><code class="java">   /** First node of condition queue. */
        private transient Node firstWaiter;
        /** Last node of condition queue. */
        private transient Node lastWaiter;
</code></pre>
<p>下面我们就来分析下Condition的工作流程。</p>
<h2 id="await-在条件变量上等待"><a href="#await-在条件变量上等待" class="headerlink" title="await 在条件变量上等待"></a>await 在条件变量上等待</h2><p>分别是Condition队列的头结点和尾节点。Condition在调用await方法之前，必须先获取锁，注意，这个锁必须是一个独占锁。我们先来看一下await中用到的几个方法：</p>
<p>addConditionWaiter:</p>
<pre><code class="java">private Node addConditionWaiter() {
            Node t = lastWaiter;
            // If lastWaiter is cancelled, clean out.
            if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) {
                unlinkCancelledWaiters();
                t = lastWaiter;
            }
            Node node = new Node(Thread.currentThread(), Node.CONDITION);
            if (t == null)
                firstWaiter = node;
            else
                t.nextWaiter = node;
            lastWaiter = node;
            return node;
        }
</code></pre>
<p>顾名思义，此方法在Condition队列中添加一个等待线程。首先，方法先检查一下队列尾节点是否还在等待Condition（如果被signal或者中断，waitStatus会被修改为0或者CANCELLED）。如果尾节点被取消或者中断，调用unlinkCancelledWaiters方法删除Condition队列中被cancel的节点。然后将当前线程封装在一个Node中，添加到Condition队列的尾部。这里由于我们在操纵Condition队列的时候已经获取了一个独占锁，因此不会发生竞争。</p>
<p>我们有必要在这里提一下Node对象中的nextWaiter成员、SHARED成员和EXCLUSIVE成员：</p>
<pre><code class="java">/** Marker to indicate a node is waiting in shared mode */
        static final Node SHARED = new Node();
        /** Marker to indicate a node is waiting in exclusive mode */
        static final Node EXCLUSIVE = null;

        Node nextWaiter;
</code></pre>
<p>nextWaiter在共享模式下，被设置为SHARED，SHARED为一个final的空节点，用来表示当前模式是共享模式；默认情况下nextWaiter是null，EXCLUSIVE成员是一个final的null，因此默认模式是独占模式。在Condition队列中nextWaiter被用来指向队列里的下一个等待线程。在一个线程从Condition队列中被移除之后，nextWaiter被设置为空（EXCLUSIVE）。这再次表明：Condition必须被绑定在一个独占锁上使用。</p>
<p>我们来看一下unlinkCancelledWaiters方法：</p>
<pre><code class="java">private void unlinkCancelledWaiters() {
            Node t = firstWaiter;
            Node trail = null;
            while (t != null) {
                Node next = t.nextWaiter;
                if (t.waitStatus != Node.CONDITION) {
                    t.nextWaiter = null;
                    if (trail == null)
                        firstWaiter = next;
                    else
                        trail.nextWaiter = next;
                    if (next == null)
                        lastWaiter = trail;
                }
                else
                    trail = t;
                t = next;
            }
        }
</code></pre>
<p>unlinkCancelledWaiters方法很简单，从头到尾遍历Condition队列，移除被cancel或被中断的节点。由于这里我们在操纵Condition队列的时候已经获取了所绑定的独占锁，因此不用担心竞争的发生。</p>
<p>我们再来看一下fullyRelease方法，这个方法用来释放锁：</p>
<pre><code class="java">final int fullyRelease(Node node) {
        boolean failed = true;
        try {
            int savedState = getState();
            if (release(savedState)) {
                failed = false;
                return savedState;
            } else {
                throw new IllegalMonitorStateException();
            }
        } finally {
            if (failed)
                node.waitStatus = Node.CANCELLED;
        }
    }
</code></pre>
<p>方法首先获取了state的值，这个值表示可锁被“重入”深度，并调用release释放全部的重入获取，如果成功，返回这个深度，如果失败，要将当前线程的waitStatus设置为CANCELLED。</p>
<p>我们再来看一下isOnSyncQueue方法，这个方法返节点是否在Sync队列中等待锁：</p>
<pre><code class="java">final boolean isOnSyncQueue(Node node) {
        if (node.waitStatus == Node.CONDITION || node.prev == null)
            return false;
        if (node.next != null) // If has successor, it must be on queue
            return true;
        /*
         * node.prev can be non-null, but not yet on queue because
         * the CAS to place it on queue can fail. So we have to
         * traverse from tail to make sure it actually made it.  It
         * will always be near the tail in calls to this method, and
         * unless the CAS failed (which is unlikely), it will be
         * there, so we hardly ever traverse much.
         */
        return findNodeFromTail(node);
    }
</code></pre>
<p>node从Condition队列移除的第一步，就是设置waitStatus为其他值，因此是否等于Node.CONDITON可以作为判断标志，如果等于，说明还在Condition队列中，即不再Sync队列里。在node被放入Sync队列时，第一步就是设置node的prev为当前获取到的尾节点，所以如果发现node的prev为null的话，可以确定node尚未被加入Sync队列。</p>
<p>相似的，node被放入Sync队列的最后一步是设置node的next，如果发现node的next不为null，说明已经完成了放入Sync队列的过程，因此可以返回true。</p>
<p>当我们执行完两个if而仍未返回时，node的prev一定不为null，next一定为null，这个时候可以认为node正处于放入Sync队列的执行CAS操作执行过程中。而这个CAS操作有可能失败，因此我们再给node一次机会，调用findNodeFromTail来检测：</p>
<pre><code class="java">    private boolean findNodeFromTail(Node node) {
        Node t = tail;
        for (;;) {
            if (t == node)
                return true;
            if (t == null)
                return false;
            t = t.prev;
        }
    }
</code></pre>
<p>findNodeFromTail方法从尾部遍历Sync队列，如果检查node是否在队列中，如果还不在，此时node也许在CAS自旋中，在不久的将来可能会进到Sync队列里。但我们已经等不了了，直接放回false。</p>
<p>我们再来看一下checkInterruptWhileWaiting方法：</p>
<pre><code class="java">/** Mode meaning to reinterrupt on exit from wait */
        private static final int REINTERRUPT =  1;
        /** Mode meaning to throw InterruptedException on exit from wait */
        private static final int THROW_IE    = -1;

        /**
         * Checks for interrupt, returning THROW_IE if interrupted
         * before signalled, REINTERRUPT if after signalled, or
         * 0 if not interrupted.
         */
        private int checkInterruptWhileWaiting(Node node) {
            return Thread.interrupted() ?
                (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :
                0;
        }
</code></pre>
<p>此方法在线程从park中醒来后调用，它的返回值有三种：0代表在park过程中没有发生中断；THORW_IE代表发生了中断，且在后续我们需要抛出中断异常；REINTERRUPT表示发生了中断，但在后续我们不抛出中断异常，而是“补上”这次中断。当没有发生中断时，我们返回0即可，当中断发生时，返回THROW_IE or REINTERRUPT由transferAfterCancelledWait方法判断：</p>
<pre><code class="java">final boolean transferAfterCancelledWait(Node node) {
        if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {
            enq(node);
            return true;
        }
        /*
         * If we lost out to a signal(), then we can&#39;t proceed
         * until it finishes its enq().  Cancelling during an
         * incomplete transfer is both rare and transient, so just
         * spin.
         */
        while (!isOnSyncQueue(node))
            Thread.yield();
        return false;
    }
</code></pre>
<p>transferAfterCancelledWait方法并不在ConditionObject中定义，而是由AQS提供。这个方法根据是否中断发生时，是否有signal操作来“掺和”来返回结果。方法调用CAS操作将node的waitStatus从CONDITION设置为0，如果成功，说明当中断发生时，说明没有signal发生（signal的第一步是将node的waitStatus设置为0），在调用enq将线程放入Sync队列后直接返回true，表示中断先于signal发生，即中断在await等待过程中发生，根据await的语义，在遇到中断时需要抛出中断异常，返回true告诉上层方法返回THROW_IT，后续会根据这个返回值做抛出中断异常的处理。</p>
<p>如果CAS操作失败，是否说明中断后于signal发生呢？只能说这时候我们不能确定中断和signal到底谁先发生，只是在我们做CAS操作的时候，他们俩已经都发生了（中断-&gt;interrupted检测-&gt;signal-&gt;CAS，或者signal-&gt;中断-&gt;interrupted检测-&gt;CAS都有可能），这时候我们无法判断到底顺序是怎样，这里的处理是不管怎样都返回false告诉上层方法返回REINTERRUPT，当做是signal先发生（线程被signal唤醒）来处理，后续根据这个返回值做“补上”中断的处理。在返回false之前，我们要先做一下等待，直到当前线程被成功放入Sync锁等待队列。</p>
<p>因此，我们可以这样总结：transferAfterCancelledWait的返回值表示了线程是否因为中断从park中唤醒。</p>
<p>至此，我们终于可以正式来看await方法了：</p>
<pre><code class="java">        public final void await() throws InterruptedException {
            if (Thread.interrupted())
                throw new InterruptedException();
            Node node = addConditionWaiter();
            int savedState = fullyRelease(node);
            int interruptMode = 0;
            while (!isOnSyncQueue(node)) {
                // 有趣的是这里this是conditionobject，而非thread
                // 我试图debug代码，发现线程并不会stuck在这里
                // LockSupport.park(this)会神奇的做一个移出condition队列，入队sync队列的操作，然后正常跳出循环获取锁
                // 之后再dubug下去，发现代码并不能继续，而是又回到了await()方法里做与刚才同样的操作
                // 这里百思不得其解，求大神解答
                LockSupport.park(this);
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
            }
            if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null) // clean up if cancelled
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
        }
</code></pre>
<p>await方法是及时响应中断的。它首先检查了一下中断标志。然后调用addConditionWaiter将当前线程放入Condition队列的尾，并顺手清理了一下队列里的无用节点。紧接着调用fullyRelease方法释放当前线程持有的锁。然后是一个while循环，这个循环会循环检测线程的状态，直到线程被signal或者中断唤醒且被放入Sync锁等待队列。如果中断发生的话，还需要调用checkInterruptWhileWaiting方法，根据中断发生的时机确定后去处理这次中断的方式，如果发生中断，退出while循环。</p>
<p>退出while循环后，我们调用acquireQueued方法来获取锁，注意，acquireQueued方法的返回值表示在等待获取锁的过程中是否发生中断，如果发生中断 且 原来没有需要做抛出处理的中断发生时，我们将后续处理方式设置为REINTERRUPT（如果原来在await状态有中断发生，即interrruptMode==THROW_IE，依然保持THROW_IE）。</p>
<p>如果是应为中断从park中唤醒（interruptMode==THROT_IE），当前线程仍在Condition队列中，但waitStatus已经变成0了，这里在调用unlinkCancelledWaiters做一次清理。</p>
<p>最后，根据interruptMode的值，调用reportInterruptAfterWait做出相应处理：</p>
<pre><code class="java">
        private void reportInterruptAfterWait(int interruptMode)
            throws InterruptedException {
            if (interruptMode == THROW_IE)
                throw new InterruptedException();
            else if (interruptMode == REINTERRUPT)
                selfInterrupt();
        }
</code></pre>
<p>如果interruptMod==0，donothing，如果是THROW_IE，说明在await状态下发生中断，抛出中断异常，如果是REINTERRUPT，说明是signal“掺和”了中断，我们无法分辨具体的先后顺序，于是统一按照先signal再中断来处理，即成功获取锁之后要调用selfInterrupt“补上”这次中断。</p>
<h2 id="awaitNanos-限时的在条件变量上等待"><a href="#awaitNanos-限时的在条件变量上等待" class="headerlink" title="awaitNanos 限时的在条件变量上等待"></a>awaitNanos 限时的在条件变量上等待</h2><pre><code class="java">public final long awaitNanos(long nanosTimeout)
                throws InterruptedException {
            if (Thread.interrupted())
                throw new InterruptedException();
            Node node = addConditionWaiter();
            int savedState = fullyRelease(node);
            final long deadline = System.nanoTime() + nanosTimeout;
            int interruptMode = 0;
            while (!isOnSyncQueue(node)) {
                if (nanosTimeout &lt;= 0L) {
                    transferAfterCancelledWait(node);
                    break;
                }
                if (nanosTimeout &gt;= spinForTimeoutThreshold)
                    LockSupport.parkNanos(this, nanosTimeout);
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
                nanosTimeout = deadline - System.nanoTime();
            }
            if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null)
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
            return deadline - System.nanoTime();
        }
</code></pre>
<p>awaitNanos方法与await方法大致相同，区别在于每次park是定时的，当被唤醒时，比较一下剩余等待时间Timeout与spinForTimeoutThreshold阈值的大小，如果小于，将不再park。</p>
<p>注意：当已经到达等待的deadline时，调用transferAfterCancelledWait方法，注意，此时可能发生中断（上次调用checkInterruptWhileWaiting之后被中断），再次的，我们无法判断这次中断与到时这两个的先后顺序，我们在这里的处理方式是直接忽略这次中断，统一认为是先到时后中断（体现在没有记录transferAfterCancelledWait方法的返回值），但在transferAfterCancelledWait方法中的处理是考虑了被中断的情况的，只不过这个中断标志位没有检测，留给后续来处理了。这个中断标志将会在调用acquireQueued方法并成功获取锁之后被检测并返回，最终影响interruptMode的值，并在reportInterruptAfterWait方法中被处理。可见，这次中断最终没有被遗漏，只是我们先处理的signal，回过头来再去处理它。</p>
<p>最后方法的返回值是拍唤醒后的剩余等待时间，这个时间可能小于0。</p>
<p>await(long time, TimeUnit unit)方法与awaitNanos方法十分类似，不再赘述。</p>
<h2 id="awaitUtil-指定结束时刻的在条件变量上等待"><a href="#awaitUtil-指定结束时刻的在条件变量上等待" class="headerlink" title="awaitUtil 指定结束时刻的在条件变量上等待"></a>awaitUtil 指定结束时刻的在条件变量上等待</h2><pre><code class="java">public final boolean awaitUntil(Date deadline)
                throws InterruptedException {
            long abstime = deadline.getTime();
            if (Thread.interrupted())
                throw new InterruptedException();
            Node node = addConditionWaiter();
            int savedState = fullyRelease(node);
            boolean timedout = false;
            int interruptMode = 0;
            while (!isOnSyncQueue(node)) {
                if (System.currentTimeMillis() &gt; abstime) {
                    timedout = transferAfterCancelledWait(node);
                    break;
                }
                LockSupport.parkUntil(this, abstime);
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
            }
            if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null)
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
            return !timedout;
        }
</code></pre>
<p>awaitUtil方法在原理上与awaitNanos方法是也十分相似，只不过park操作调用的是LockSupportparkUtil方法，且没有spinForTimeoutThreshold阈值的应用。在返回值上也有些许差别：返回值timedout记录了transferAfterCancelledWait方法的返回值——线程是否因为中断从park中唤醒，如果是的话，表示还没有到等待的deadline。</p>
<h3 id="signal-唤醒Condition队列的头节点持有的线程"><a href="#signal-唤醒Condition队列的头节点持有的线程" class="headerlink" title="signal 唤醒Condition队列的头节点持有的线程"></a>signal 唤醒Condition队列的头节点持有的线程</h3><pre><code class="java">public final void signal() {
            if (!isHeldExclusively())
                throw new IllegalMonitorStateException();
            Node first = firstWaiter;
            if (first != null)
                doSignal(first);
        }
</code></pre>
<p>调用signal之前也需要获取锁，因此signal方法首先检测了一下当前线程是否获取了独占锁。然后调用doSignal唤醒队列中第一个等待线程。注意，这里的“唤醒”意思是将线程从Condition队列移到Sync队列，表示已经完成Condition的等待，具有了去竞争锁的资格。至此，我们可以发现，由于await会直接把线程放入Condition等待队列的尾部，因此Condition是公平的，即按照入列的顺序来signal。</p>
<pre><code class="java">private void doSignal(Node first) {
            do {
                if ( (firstWaiter = first.nextWaiter) == null)
                    lastWaiter = null;
                first.nextWaiter = null;
            } while (!transferForSignal(first) &amp;&amp;
                     (first = firstWaiter) != null);
        }
</code></pre>
<p>doSignal方法先将first节点从队列中摘下，然后调用transferForSignal去改变first节点的waitStatus（所谓唤醒线程），这个方法有可能失败，因为等待线程可能已经到时或者被中断，因此while循环这个操作直到成功唤醒或队列为空。我们来看下transferForSignal方法：</p>
<pre><code class="java">final boolean transferForSignal(Node node) {
        /*
         * If cannot change waitStatus, the node has been cancelled.
         */
        if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
            return false;

        /*
         * Splice onto queue and try to set waitStatus of predecessor to
         * indicate that thread is (probably) waiting. If cancelled or
         * attempt to set waitStatus fails, wake up to resync (in which
         * case the waitStatus can be transiently and harmlessly wrong).
         */
        Node p = enq(node);
        int ws = p.waitStatus;
        if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
            LockSupport.unpark(node.thread);
        return true;
    }
</code></pre>
<p>这个方法并不在ConditionObject中定义，而是由AQS提供。方法首先调用CAS操作修改node的waitStatus，如果失败，表示线程已经放弃等待（到时或被中断），直接返回false。如果成功，调用enq方法将它放入Sync锁等待队列，返回值p是node在Sync队列中的前驱节点。紧接着检测一下前驱p的waitStatus，如果发现不为SIGNAL，需要将node持有的线程（注意不是当前线程）unpark，这里必须搞清楚，node线程是在哪里park的，显然，他还在await方法的那个while循环里。unpark之后，node线程将会从while循环中退出，然后去调用acquireQueued方法，这个方法是一个自旋，弄得线程会在自旋过程中清除已经为CANCELLED状态的前驱，然后注册前驱节点的waitStatus为SIGNAL。</p>
<p>至此，signal方法已经完成了所有该做的，“唤醒”的线程已经成功加入Sync队列并已经参与锁的竞争了，返回true。</p>
<h2 id="signalAll-唤醒Condition队列的所有等待线程"><a href="#signalAll-唤醒Condition队列的所有等待线程" class="headerlink" title="signalAll 唤醒Condition队列的所有等待线程"></a>signalAll 唤醒Condition队列的所有等待线程</h2><pre><code class="java">public final void signalAll() {
            if (!isHeldExclusively())
                throw new IllegalMonitorStateException();
            Node first = firstWaiter;
            if (first != null)
                doSignalAll(first);
        }
</code></pre>
<p>signalAll方法同样先检测是否持有独占锁，然后对奥用doSignalAll方法：</p>
<pre><code class="java">private void doSignalAll(Node first) {
            lastWaiter = firstWaiter = null;
            do {
                Node next = first.nextWaiter;
                first.nextWaiter = null;
                transferForSignal(first);
                first = next;
            } while (first != null);
        }
</code></pre>
<p>doSignalAll方法循环调用transferForSignal方法“唤醒”队列的头结点，直到队列为空。</p>
<p>总结：ConditionObject由AQS提供，它实现了类似wiat、notify和notifyAll类似的功能。Condition必须与一个独占锁绑定使用，在await或signal之前必须现持有独占锁。Condition队列是一个单向链表，他是公平的，按照先进先出的顺序从队列中被“唤醒”，所谓唤醒指的是完成Condition对象上的等待，被移到Sync锁等待队列中，有参与竞争锁的资格（Sync队列有公平&amp;非公平两种模式，注意区别）。</p>
<hr>
<p>加餐：</p>
<p>摘自  <a href="https://juejin.cn/post/6844903984197533704" target="_blank" rel="noopener">https://juejin.cn/post/6844903984197533704</a></p>
<h2 id="Thread-sleep-和Object-wait-的区别"><a href="#Thread-sleep-和Object-wait-的区别" class="headerlink" title="Thread.sleep()和Object.wait()的区别"></a>Thread.sleep()和Object.wait()的区别</h2><ul>
<li>Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁；</li>
<li>Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去；</li>
<li>Thread.sleep()到时间了会自动唤醒，然后继续执行；</li>
<li>Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒；</li>
<li>Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁；</li>
</ul>
<h2 id="Thread-sleep-和Condition-await-的区别"><a href="#Thread-sleep-和Condition-await-的区别" class="headerlink" title="Thread.sleep()和Condition.await()的区别"></a>Thread.sleep()和Condition.await()的区别</h2><p>这个题目的回答思路跟Object.wait()是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。</p>
<p>实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程。</p>
<h2 id="Thread-sleep-和LockSupport-park-的区别"><a href="#Thread-sleep-和LockSupport-park-的区别" class="headerlink" title="Thread.sleep()和LockSupport.park()的区别"></a>Thread.sleep()和LockSupport.park()的区别</h2><ul>
<li>从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源；</li>
<li>Thread.sleep()没法从外部唤醒，只能自己醒过来；</li>
<li>LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒；</li>
<li>Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出；</li>
<li>LockSupport.park()方法不需要捕获中断异常；</li>
<li>Thread.sleep()本身就是一个native方法；</li>
<li>LockSupport.park()底层是调用的Unsafe的native方法；</li>
</ul>
<h2 id="Object-wait-和LockSupport-park-的区别"><a href="#Object-wait-和LockSupport-park-的区别" class="headerlink" title="Object.wait()和LockSupport.park()的区别"></a>Object.wait()和LockSupport.park()的区别</h2><ul>
<li>Object.wait()方法需要在synchronized块中执行；</li>
<li>LockSupport.park()可以在任意地方执行；</li>
<li>Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出；</li>
<li>LockSupport.park()不需要捕获中断异常；</li>
<li>Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容；</li>
<li>LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容；</li>
<li>如果在wait()之前执行了notify()会怎样？抛出IllegalMonitorStateException异常；</li>
<li>如果在park()之前执行了unpark()会怎样？线程不会被阻塞，直接跳过park()，继续执行后续内容；</li>
</ul>
<p>ps：LockSupport.park()不能重入，会死锁</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之ReentrantLock]]></title>
      <url>/2020/11/22/juc-3/</url>
      <content type="html"><![CDATA[<p>内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<p>ReentrantLock是JUC包提供的一种可重入独占锁，它实现了Lock接口。与Semaphore类似，ReentrantLock也提供了两种工作模式：公平模式&amp;非公平模式，也是通过自定义两种同步器FairSync&amp;NonfairSync来实现的。</p>
<h2 id="lock-不响应中断获取锁"><a href="#lock-不响应中断获取锁" class="headerlink" title="lock 不响应中断获取锁"></a>lock 不响应中断获取锁</h2><pre><code class="java">public void lock() {
        sync.lock();
    }
</code></pre>
<p>lock方法通过调用自定义同步器的同名方法来获取锁。注意：ReentrantLock自定义了两种同步器：FairSync&amp;NonfairSync，分别对应公平模式&amp;非公平模式。</p>
<p>我们先来看一下非公平模式下的lock方法：</p>
<pre><code class="java">final void lock() {
            if (compareAndSetState(0, 1))
                setExclusiveOwnerThread(Thread.currentThread());
            else
                acquire(1);
        }
</code></pre>
<p>lock方法并没有直接调用AQS提供的acquire方法，而是先试探地获取了一下锁，CAS操作失败再去调用acquire方法。我的理解是为了提升性能。因为可能很多时候我们能在第一次试探获取时成功，而不需要经过acquire-&gt;tryAcquire-&gt;nonfairAcquire的调用过程：</p>
<pre><code class="java">public final void acquire(int arg) {
        if (!tryAcquire(arg) &amp;&amp;
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</code></pre>
<p>AQS提供的acquire方法首先调用了我们自定义同步器重写的tryAcquire方法试图获取锁，如果失败的话先调用addWaiter方法将当前线程加入等待队列，然后对掉用acquireQueued方法进行自旋、检测获取锁的操作，直到成功获取锁。在自旋、检测的过程中如果被中断（注意：acquireQueued延迟处理中断），要在成功获取锁之后调用selfInterrupt方法“补上”这次中断。这里我们主要关注ReentrantLock重写的tryAcquire方法：</p>
<pre><code class="java"> protected final boolean tryAcquire(int acquires) {
            return nonfairTryAcquire(acquires);
        }
</code></pre>
<p>nonfairSync的tryAcquire方法通过调用其父类Sync的nonfairTryAcquire方法实现：</p>
<pre><code class="java">final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc &lt; 0) // overflow
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                setState(nextc);
                return true;
            }
            return false;
        }
</code></pre>
<p>nonfairTryAcquire方法首先判断锁是否被占用，如果锁可用，通过调用CAS操作试图获取锁，如果失败直接返回false；但如果锁被占用（state==0），并不代表没有机会，因为有可能占用锁的正是当前线程。如果正是当前线程占用了锁，让state做+1操作，然后返回true：这正是可重入的概念，一个已经获取锁的线程可以重复获取锁。</p>
<p>我们再来看一下公平模式下的lock方法：</p>
<pre><code class="java">final void lock() {
            acquire(1);
        }
</code></pre>
<p>fairSync的lock方法直接调用acquire，而没有想NonfairSync一样先试图获取，因为这样可能导致违反“公平”的语义：在已等待在队列中的线程之前获取了锁。</p>
<p>由上面的分析可知，AQS的acquire方法调用了fairSync重写的tryAcquire方法：</p>
<pre><code class="java">protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &amp;&amp;
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc &lt; 0)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                setState(nextc);
                return true;
            }
            return false;
        }
</code></pre>
<p>这与nonfairTryAcquire方法大同小异，主要区别在于，当发现锁未被占用的时候，还要判断一下等待队列中是否有先到的线程正在等待锁，如果有，直接返回false。这保证了公平性：线程按照申请锁的顺序获取锁。</p>
<h2 id="lockInterruptibly-可响应中断获取锁"><a href="#lockInterruptibly-可响应中断获取锁" class="headerlink" title="lockInterruptibly 可响应中断获取锁"></a>lockInterruptibly 可响应中断获取锁</h2><pre><code class="java">public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
</code></pre>
<p>lockInterruptibly方法通过调用AQS提供的acquireInterruptibly方法实现：</p>
<pre><code class="java">public final void acquireInterruptibly(int arg)
            throws InterruptedException {
        if (Thread.interrupted())
            throw new InterruptedException();
        if (!tryAcquire(arg))
            doAcquireInterruptibly(arg);
    }
</code></pre>
<p>acquireInterruptibly方法首先检测一下中断，然后调用重写的tryAcquire方法试图获取锁，如果失败，调用doAcquireInterruptibly方法进行自旋、检测获取锁操作：</p>
<pre><code class="java">private void doAcquireInterruptibly(int arg)
        throws InterruptedException {
        final Node node = addWaiter(Node.EXCLUSIVE);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return;
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>doAcquireInterruptibly方法与acquireQueued方法的区别在于：</p>
<ul>
<li>doAcquireInterruptibly方法将addWaiter的调用写在了方法里，而acquireQueued方法没有；</li>
<li>doAcquireInterruptibly在当前线程从park中被中断唤醒时，直接抛出中断异常，而acquireQueued方法则是用一个局部变量记录下这次中断，但不立即处理，等到成功获取锁/共享资源之后，反馈给上层，由上层调用selfInterrupt方法“补上”这次中断。</li>
</ul>
<p>这些区别与doAcquireSharedInterruptibly&amp;doAcquireShared方法之间的区别一致。</p>
<h2 id="tryLock-amp-tryLock-Timeout-尝试获取锁"><a href="#tryLock-amp-tryLock-Timeout-尝试获取锁" class="headerlink" title="tryLock &amp; tryLock(Timeout) 尝试获取锁"></a>tryLock &amp; tryLock(Timeout) 尝试获取锁</h2><pre><code class="java">public boolean tryLock() {
        return sync.nonfairTryAcquire(1);
    }

    public boolean tryLock(long timeout, TimeUnit unit)
            throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(timeout));
    }
</code></pre>
<p>ReentrantLock提供了两种tryLock方法：限时&amp;不限时。我们注意到，不限时（立即返回）的tryLock方法，不管在公平还是非公平模式下，调用的都是Sync中的nonfairTryAcquire方法。因此，如果在公平模式下调用tryLock，即使队列中有等待线程，也可能获取成功。</p>
<p>而限时（不立即返回）的tryLock(Timeout)方法则公国tryAcquireNanos提供了公平&amp;非公平两种模式的tryLock(Timeout)操作：</p>
<pre><code class="java">public final boolean tryAcquireNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (Thread.interrupted())
            throw new InterruptedException();
        return tryAcquire(arg) ||
            doAcquireNanos(arg, nanosTimeout);
    }
</code></pre>
<p>可以看到，tryAcquireNanos方法通过调用不同的重写的tryAcquire方法提供了两种模式下的不同操作。tryAcquire方法已经分析过，不再赘述。这里重点关注doAcquireNanos方法：</p>
<pre><code class="java">private boolean doAcquireNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (nanosTimeout &lt;= 0L)
            return false;
        final long deadline = System.nanoTime() + nanosTimeout;
        final Node node = addWaiter(Node.EXCLUSIVE);
        boolean failed = true;
        try {
            for (;;) {
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return true;
                }
                nanosTimeout = deadline - System.nanoTime();
                if (nanosTimeout &lt;= 0L)
                    return false;
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    nanosTimeout &gt; spinForTimeoutThreshold)
                    LockSupport.parkNanos(this, nanosTimeout);
                if (Thread.interrupted())
                    throw new InterruptedException();
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>可以看到，doAcquireNanos方法是立即响应中断的（事实上doAcquireSharedNanos方法也是立即响应中断的），即限时（不立即返回）的尝试获取的方法都是及时响应中断的，没有延迟处理中断的版本。</p>
<p>还有一点需要注意，当线程从park中被唤醒时，我们无法确定唤醒原因是被中断还是超时，因此需要检测一下中断标志。</p>
<h2 id="unlock-释放锁"><a href="#unlock-释放锁" class="headerlink" title="unlock 释放锁"></a>unlock 释放锁</h2><p>公平&amp;非公平模式的unlock操作是一致的：</p>
<pre><code class="java">public void unlock() {
        sync.release(1);
    }
</code></pre>
<pre><code class="java">
        protected final boolean tryRelease(int releases) {
            int c = getState() - releases;
            if (Thread.currentThread() != getExclusiveOwnerThread())
                throw new IllegalMonitorStateException();
            boolean free = false;
            if (c == 0) {
                free = true;
                setExclusiveOwnerThread(null);
            }
            setState(c);
            return free;
        }
</code></pre>
<p>tryRelease是在FairSync和NonfairSync的父类Sync中定义的，因此公平&amp;非公平模式下的release操作是统一的。tryRelease方法首先检测当前线程是否持有锁，然后计算一下释放之后锁是否可用（计数值state是否等于0），如果可用，释放&amp;设置持有锁线程为null&amp;返回true，如果不可用，释放&amp;返回返回false。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之aqs]]></title>
      <url>/2020/11/21/juc-2/</url>
      <content type="html"><![CDATA[<p>今天说aqs，juc中的绝对核心。内容转载自：<a href="https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/" target="_blank" rel="noopener">https://www.cnblogs.com/go2sea/tag/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E2%80%94%E2%80%94JUC%E5%8C%85/</a>  稍有改动</p>
<p>AbstractQueuedSynchronizer（AQS）是一个同步器框架，抽象类。在实现锁的时候，一般会实现一个继承自AQS的内部类sync，作为我们的自定义同步器。AQS内部维护了一个state成员和一个队列。其中state标识了共享资源的状态，队列则记录了等待资源的线程。</p>
<p>以下这五个方法，在AQS中实现为直接抛出异常，这是我们自定义同步器需要重写的方法：</p>
<ul>
<li><p>isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。</p>
</li>
<li><p>tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败返回false。</p>
</li>
<li><p>tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败返回false。</p>
</li>
<li><p>tryAcquireShared(int)：共享方式。尝试获取资源。成功返回true，失败返回false。</p>
</li>
<li><p>tryReleaseShared(int)：共享方式。尝试释放资源，成功则返回true，失败返回false。</p>
</li>
</ul>
<p>例如ReentrantLock就是一种独占锁，CountDownLatch和Semaphore是共享锁。与CountDownLatch有一定相似性的CyclicBarrier并没有自己的共享同步器，而是使用Lock和Condition来实现的。</p>
<p>本质上aqs就是一个clh锁，AQS在CLH的基础上进行了变种：CLH是单向队列，其主要特点是自旋检查前驱节点的locked状态。而AQS同步队列是双向队列，每个节点也有状态waitStatus，而其并不是一直对前驱节点的状态自旋，在尝试自旋一次后会将线程阻塞让出CPU时间片，等到占有锁的线程主动唤醒后续节点的继续自旋。</p>
<pre><code> * &lt;pre&gt;
 *      +------+  prev +-----+       +-----+
 * head |      | &lt;---- |     | &lt;---- |     |  tail
 *      +------+       +-----+       +-----+
 * &lt;/pre&gt;
</code></pre><p><img src="https://s3.ax1x.com/2020/11/22/D8ZfXR.png" alt="D8ZfXR.png"></p>
<p>每个线程都会包装成一个node，从队列尾部入队，头节点占有锁的线程（一个虚节点），当前线程会通知检查其前驱节点，看其是否是头节点，如果是就自旋去获取锁（线程可能休息，但自旋会一直进行），其他节点都可以安全阻塞等待被唤醒。</p>
<h2 id="独占模式"><a href="#独占模式" class="headerlink" title="独占模式"></a>独占模式</h2><p>下面是一个简单的独占锁的实现，它是不可重入的。它重写了AQS的tryAcquire方法和tryRelease方法：</p>
<pre><code class="java">class Mutex implements Lock, Serializable {
    //自定义同步器，继承自AQS
   private static class Sync extends AbstractQueuedSynchronizer {
     //试图获取锁，当state为0时能成功获取，
     public boolean tryAcquire(int acquires) {
       assert acquires == 1; //这是一个对于state进行操作的量，含义自定义
       if (compareAndSetState(0, 1)) {    //注意：这是一个原子操作
         setExclusiveOwnerThread(Thread.currentThread());
         return true;
       }
       return false;
     }
     //释放锁，此时state应为1，Mutex处于被独占状态
     protected boolean tryRelease(int releases) {
       assert releases == 1; // Otherwise unused
       if (getState() == 0) throw new IllegalMonitorStateException();
       setExclusiveOwnerThread(null);
       setState(0);
       return true;
     }
     //返回一个Condition
     Condition newCondition() { return new ConditionObject(); }
   }

   private final Sync sync = new Sync();

   public void lock()                { sync.acquire(1); }
   public boolean tryLock()          { return sync.tryAcquire(1); }
   public void unlock()              { sync.release(1); }
   public Condition newCondition()   { return sync.newCondition(); }
   public void lockInterruptibly() throws InterruptedException {
     sync.acquireInterruptibly(1);
   }
   public boolean tryLock(long timeout, TimeUnit unit)
       throws InterruptedException {
     return sync.tryAcquireNanos(1, unit.toNanos(timeout));
   }
 }
</code></pre>
<h3 id="acquire-获取锁"><a href="#acquire-获取锁" class="headerlink" title="acquire 获取锁"></a>acquire 获取锁</h3><p>我们先来看一下Mutex重写的tryAcquire方法：</p>
<pre><code class="java">//试图获取锁，当state为0时能成功获取，
     public boolean tryAcquire(int acquires) {
       assert acquires == 1; //这是一个对于state进行操作的量，含义自定义
       if (compareAndSetState(0, 1)) {    //注意：这是一个原子操作
         setExclusiveOwnerThread(Thread.currentThread());
         return true;
       }
       return false;
     }
</code></pre>
<p>注意：当我们初始化一个Sync的时候，如果没有指定state的初值（无参数），那么state的默认初值是0。可以看到，方法开头首先有一个断言acquires==1，参数acquires代表要在state上做的改变的量（减去或增加），在Mutex中，我们定义state只有两个状态：0或1，0代表共享资源可以被获取，1表示共享资源正在被占用，因此Mutex是不可重入的。实际上，自定义同步器通过重写tryAcquire和tryRelease来定义state代表的意义和资源的共享方式，这是同步器的主要任务。Mutex的tryAcquire使用一个原子操作compareAndSetState来试图获取资源，这个原子操作由上层的AQS提供，如果成功，将当前线程设置为独占线程并返回true。</p>
<p>Mutex的lock方法调用了aqs的acquire方法，acquire方法实现为：</p>
<pre><code class="java">    public final void acquire(int arg) {
        if (!tryAcquire(arg) &amp;&amp;
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
</code></pre>
<p>它首先调用tryAquire去获取共享资源，如果失败，调用addWaiter将当前线程放入等待队列，返回持有当前线程的Node对象，然后调用acquireQueued方法来监视等待队列并获取资源。acquireQueued方法会阻塞线程，直到成功获取。注意，acquire方法不能及时响应中断，只能在成功获取锁之后，再来处理。中断当前线程的操作跑出的异常在acquireQueued方法中被捕获，外部调用者没能看到这个异常，因此调用selfInterrupt来重置中断标识。</p>
<p>我们需要详细了解addWaiter方法和acquireQueued方法，之后再来回顾acquire的过程，才能对整个获取锁的流程有比较详细的了解。</p>
<p>（ps：enqueue：入队，简称enq；dequeue：出队，简称dnq）</p>
<pre><code class="java">private Node addWaiter(Node mode) {
        Node node = new Node(Thread.currentThread(), mode);
        // Try the fast path of enq; backup to full enq on failure
        Node pred = tail;
        if (pred != null) {
            node.prev = pred;
            if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
            }
        }
        enq(node);
        return node;
    }
</code></pre>
<p>addWaiter首先将当前线程包装在一个Node对象node中，然后获取了一下队列的尾节点，如果队列不为空（tail不为null）的话，调用一个CAS函数试图将node放入等待队列的尾部，注意，此时可能发生竞争，如果有另外一个线程在两个if之间抢先更新的队列的尾节点，CAS操作将会失败，这时会调用enq方法，继续试图将node放入队列：</p>
<pre><code class="java">private Node enq(final Node node) {
        for (;;) {
            Node t = tail;
            if (t == null) { // Must initialize
                if (compareAndSetHead(new Node()))
                    tail = head;
            } else {
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
    }
</code></pre>
<p>enq方法会循环检测队列，如果队列为空，则调用CAS函数初始化队列（此时node==head==tail），否则调用CAS函数将node放入队列尾。</p>
<p>请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。头节点虚节点。</p>
<p>如果CAS失败，enq会继续循环检测，直到成功将node入列。这里便是入队操作中的CAS自旋，因为这里还没有涉及锁的竞争，所以不需要响应中断。这里有一个隐含的知识点，即tail是一个volatile成员，确保某个线程更新队列后对其他线程的可见性。</p>
<p>注意：队列为空的时候，第一个线程进入队列的情况有点tricky：第一个发现队列为空并初始化队列（head节点）的线程不一定优先拿到资源。head节点被初始化后，当前线程需要下一次旋转才有机会进入队列，在这期间，完全有可能半路杀出程咬金，将当前线程与它初始化出的head节点无情分开。我们来总结一下，当队列只有一个节点时（head=tail），有两种情况：第一种是这个队列刚刚被初始化，head并没有持有任何线程对象。这个状态不会持续太久，初始化队列的线程有很大机会在下次自旋时把自己接到队尾。第二种情况是，所有等待线程都已经获得资源并继续执行下去了，队列仅有的节点是最后一个获取共享资源的线程，等到下一个线程到达等待队列并将它踢出队列之后，它才有机会被回收。</p>
<p>enq执行完毕，我们已经成功把当前线程放入等待队列，接下来的任务就是监视队列，等待获取资源。这个过程由acquireQueued方法实现：</p>
<pre><code class="java">final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {
                    setHead(node);
                    p.next = null; // help GC
                    failed = false;
                    return interrupted;
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>acquireQueued方法是一个很重要的方法，在分析这个方法之前，我们先来说一下AQS中的那个等待队列。这个队列实际上是一个CLH队列，它保证了竞争资源的线程按到达顺序来获取资源，避免了饥饿的发生。CLH队列的工作过程，就是acquireQueued方法的工作过程。很明显，这又是一个自旋。首先，我们调用predecessor方法获取当前线程的前驱节点，如果这个前驱是head节点，就紧接着调用tryAcquire去获取共享资源，当然这是有可能失败的，因为head节点可能刚刚“上位”，持有锁的线程还没有释放资源。如果很幸运，我们拿到了资源，就调用setHead将node设置为队列的头结点，setHead方法同时会将node的prev置为null，并把thread置为null（前驱节点出队，当前虚节点head占有锁），紧接着将原先head的next也置为null，显然这是为了让其后续被回收。注意：acquireQueued方法在自旋过程中是不可被中断的，当然它会检测到中断（在parkAndCheckInterrupt方法中检测中断标志），但并不会因此结束自旋，只能在获得资源退出方法后，反馈给上层的方法：我刚刚被中断了。还记得acquire方法中的selfInterrupt的调用吗，就是为了“补上”这里没有响应的中断。</p>
<p>好，我们继续往下。获取资源失败后，调用shouldParkAfterFailedAcquire方法检测是否该去“休息”下，毕竟一直自旋很累嘛。如果可以休息就调用parkAndCheckInterrupt放心去休息。我们先来看一下shuldParkAfterFailedAcquire：</p>
<pre><code class="java">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
        int ws = pred.waitStatus;
        if (ws == Node.SIGNAL)
            /*
             * This node has already set status asking a release
             * to signal it, so it can safely park.
             */
            return true;
        if (ws &gt; 0) {
            /*
             * Predecessor was cancelled. Skip over predecessors and
             * indicate retry.
             */
            do {
                node.prev = pred = pred.prev;
            } while (pred.waitStatus &gt; 0);
            pred.next = node;
        } else {
            /*
             * waitStatus must be 0 or PROPAGATE.  Indicate that we
             * need a signal, but don&#39;t park yet.  Caller will need to
             * retry to make sure it cannot acquire before parking.
             */
            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
        }
        return false;
    }
</code></pre>
<p>我们首先了解一下waitStatus。Node对象维护了一个int成员waitStatus，他的可能取值如下：</p>
<pre><code class="java">// 因为超时或者中断，结点会被设置为取消状态，被取消状态的结点不应该去竞争锁，只能保持取消状态不变，不能转换为其他状态。
// 处于这种状态的结点会被踢出队列，被GC回收；
static final int CANCELLED =  1;
// 表示这个结点的继任结点被阻塞了，到时需要通知它；
static final int SIGNAL    = -1;
// 表示这个结点在条件队列中，因为等待某个条件而被阻塞；
static final int CONDITION = -2;
// 使用在共享模式头结点有可能处于这种状态，表示锁的下一次获取可以无条件传播；
static final int PROPAGATE = -3;
// 0：None of the above，新结点会处于这种状态。
</code></pre>
<p>在我们的Mutex的例子中，节点的waitStatus只可能有CANCELLED、SIGNAL和0三中状态（事实上，独占模式下所有不使用Condition的同步器都是这样）。</p>
<p>我们继续来分析shouldParkAfterFailedAcquire方法：</p>
<p>首先检测下node的前驱节点pred，如果pred状态已经被置为SIGNAL，直接返回true。否则，从node的前驱继续往前找，直到找到一个waitStatus小于等于0的节点，设置该点为node的前驱（注意：此时node与这个节点之间的节点从等待队列中被“摘下”，等待被回收了）并返回false。</p>
<p>返回之后，上层的acquireQueued方法继续自旋，再次进入shouldParkAfterFailedAcquire方法之后，如果发现node前驱不是取消状态且waitStatus不等于SIGNAL，调用CAS函数进行注册（从ws-&gt;SIGNAL，标注为可以休息，等待被唤醒）。注意：这个操作可能失败，因此不能直接返回true，而是返回false由上层的自旋再次调用shouldParkAfterFailedAcquire直到确认注册成功。</p>
<p>历尽曲折，我们终于可以安心休息了：</p>
<pre><code class="java">private final boolean parkAndCheckInterrupt() {
        LockSupport.park(this);
        return Thread.interrupted();
    }
</code></pre>
<p>parkAndCheckInterrupt方法十分简单，他调用LockSupport的静态方法park阻塞当前线程，直到被中断，这次中断会被acquireQueued记录，但不会立即响应，直到自旋完成。注意：返回操作中的interrupted方法会将中断标志复位，因此我们在上层需要将这个中断“补上”，再一次：还记得大明湖边的selfInterrupt吗？</p>
<p>注意aqs的线程中断：</p>
<ul>
<li><p>当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。</p>
</li>
<li><p>线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。</p>
</li>
</ul>
<h3 id="release-释放锁"><a href="#release-释放锁" class="headerlink" title="release 释放锁"></a>release 释放锁</h3><p>我们先来看一下Mutex中重写的tryRelease方法：</p>
<pre><code class="java">//释放锁，此时state应为1，Mutex处于被独占状态
     protected boolean tryRelease(int releases) {
       assert releases == 1; // Otherwise unused
       if (getState() == 0) throw new IllegalMonitorStateException();
       setExclusiveOwnerThread(null);
       setState(0);
       return true;
     }
</code></pre>
<p>逻辑比较简单，首先将独占线程置为null，紧接着将state设置为0，这里不会发生资源竞争，因此不需要用CAS去设置state值，直接置0即可。</p>
<pre><code class="java">public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null &amp;&amp; h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
</code></pre>
<p>好，我们开始分析release方法。首先调用tryRelease试图释放共享资源，紧接着检测head的waitStatus是否为SIGNAL，如果是的话，调用unparkSuccessor唤醒队列中的head。独占模式下，waitStatus！=0与waitStatus==-1等价（这里waitStatus不会为CANCELLED，因为已经获取资源了）。如果不为SIGNAL，说明如果有下个等待线程，它正在自旋。所以直接返回true即可。我们来看下unparkSuccessor方法：</p>
<pre><code class="java">private void unparkSuccessor(Node node) {
        /*
         * If status is negative (i.e., possibly needing signal) try
         * to clear in anticipation of signalling.  It is OK if this
         * fails or if status is changed by waiting thread.
         */
        int ws = node.waitStatus;
        if (ws &lt; 0)
            compareAndSetWaitStatus(node, ws, 0);

        /*
         * Thread to unpark is held in successor, which is normally
         * just the next node.  But if cancelled or apparently null,
         * traverse backwards from tail to find the actual
         * non-cancelled successor.
         */
        Node s = node.next;
        if (s == null || s.waitStatus &gt; 0) {
            s = null;
            for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
                if (t.waitStatus &lt;= 0)
                    s = t;
        }
        if (s != null)
            LockSupport.unpark(s.thread);
    }
</code></pre>
<p>unparkSuccessor方法也会在共享模式的工作流程中被调用，因此方法开始做的判断是有必要的。对于独占模式而言，ws应该都是0。然后找到下一个需要被唤醒的线程并调用LockSupport的静态方法unpark唤醒等待线程。</p>
<p>至此，我们比较详细地了解了acquire&amp;release的工作流程。</p>
<h2 id="共享模式"><a href="#共享模式" class="headerlink" title="共享模式"></a>共享模式</h2><h3 id="acquireShared-获取锁"><a href="#acquireShared-获取锁" class="headerlink" title="acquireShared 获取锁"></a>acquireShared 获取锁</h3><p>下面，我们来学习下共享模式下的获取&amp;释放锁的工作流程。</p>
<pre><code class="java">    public final void acquireShared(int arg) {
        if (tryAcquireShared(arg) &lt; 0)
            doAcquireShared(arg);
    }
</code></pre>
<p>acquireShared方法首先调用tryAcquireShared试图获取共享资源。tryAcquireShared的返回值表示剩余资源个数，负值表示获取失败，0表示获取成功但已无剩余资源。如果获取失败，调用doAcquireShared方法完成独占模式下类似的操作，后面我们会详细分析。注意，doAcquireShared方法在等待资源的过程中也是不响应中断的，它能觉察到中断，但在成功获取资源之前不会处理。</p>
<pre><code class="java">private void doAcquireShared(int arg) {
        final Node node = addWaiter(Node.SHARED);
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head) {
                    int r = tryAcquireShared(arg);
                    if (r &gt;= 0) {
                        setHeadAndPropagate(node, r);
                        p.next = null; // help GC
                        if (interrupted)
                            selfInterrupt();
                        failed = false;
                        return;
                    }
                }
                if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                    parkAndCheckInterrupt())
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
</code></pre>
<p>doAcquireShared方法与acquireQueued方法相似，不同的地方在于，共享模式下成功获取资源并将head指向自己之后，要检查并试图唤醒之后的等待线程。因为共享资源可能剩余，可以被后面的等待线程获取。</p>
<pre><code class="java">private void setHeadAndPropagate(Node node, int propagate) {
        Node h = head; // Record old head for check below
        setHead(node);
        if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||
            (h = head) == null || h.waitStatus &lt; 0) {
            Node s = node.next;
            if (s == null || s.isShared())
                doReleaseShared();
        }
    }
</code></pre>
<p>setHeadAndPropagate中有一个长长的if，来判断是否应该去试图唤醒后面的线程。propagate大于0，表示尚有资源可被获取，显然应该继续判断；h == null, 说明没有节点；而当h.waitStatus小于0时，它有两种取值可能，SIGNAL和PROPAGATE，我们将在后面看到，这几种情况都是应该继续判断。后续是对node的后继进行的判断，注意，node此时可能已经不是head节点了，因为这是共享模式，所以可能有一个node的后继成功获取资源后，把自己设为head，将node踢出了队列。这种情况下node的后继s是可能为null的，但貌似这种情况doReleaseShared的调用没有意义。s.isShared的判断主要是考虑到读写锁的情况，在读写锁的使用过程中，申请写锁（独占模式）和申请读锁（共享模式）的线程可能同时存在，这个判断发现后即线程是共享模式的时候，调用doReleaseShared方法唤醒他。</p>
<pre><code class="java">private void doReleaseShared() {
        for (;;) {
            Node h = head;
            if (h != null &amp;&amp; h != tail) {
                int ws = h.waitStatus;
                if (ws == Node.SIGNAL) {
                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                        continue;            // loop to recheck cases
                    unparkSuccessor(h);
                }
                else if (ws == 0 &amp;&amp;
                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                    continue;                // loop on failed CAS
            }
            if (h == head)                   // loop if head changed
                break;
        }
    }
</code></pre>
<p>又是一个自旋。我们首先获取head节点h，然后检查它的waitStatus是否为SIGNAL，如果是的话，调用CAS将h的waitStatus设置为0，并调用unparkSuccessor唤醒下一个等待线程。注意，这里调用CAS方法而不是直接赋值，是因为在共享模式下，这里可能发生竞争。doReleaseShared方法可能由head节点在使用完共享资源后主动调用（后续在releaseShared方法中可以看到），也可能由刚刚“上位”的等待线程调用，在上位之后，原来的head线程已被踢出队列。</p>
<p>因此，doReleaseShared方法的执行情况变得比较复杂，需要细致分析。</p>
<p>第一种情况，只有刚刚释放资源的head线程调用，这时候没有竞争，waitStatus是SIGNAL，就去唤醒下个线程，是0，就重置为PROPAGATE。</p>
<p>第二种情况，刚刚释放完资源的旧head，和刚刚上位的新head同时调用doReleaseShared方法，这时候最新的head获取的都是自己，若干被踢出的旧head获取的可能是旧head，也可能是新head，这些被踢出的旧head线程也在根据自己获取的head（不管新旧）的状态进行CAS操作和unparkSuccessor操作，幸运的是，这些操作不会造成错误，只是多了一些唤醒而已（这些唤醒可能导致一个线程获得资源，也可能是一个“虚晃”）。</p>
<p>我们可以发现，不管head引用怎样更迭，最终新head的waitStatus都会被顺利处理。注意，可能有多个旧head同时参与这个过程，都不影响正确性。</p>
<p>我们注意到，一个新head，在他刚上位的时候有机会调用一次setHeadAndPropagate进而调用doReleaseShared，在他释放资源之后，又一次调用doReleaseShared（这次是必然的）。第一次调用时，不管新head的waitStatus是0还是SIGNAL，最终状态都被PROPAGATE（当然，被踢出队列的head可能还没来得及设置成PROPAGATE，但新上位的head最终会被设置），这也符合PROPAGATE的语义：使用在共享模式头结点有可能处于这种状态，表示锁的下一次获取可以无条件传播。</p>
<p>还有一个问题，它是由SIGNAL–&gt;0–&gt;PROPAGATE变化而来的，为什么不是SIGNAL–&gt;PROPAGA这样直接变化呢？原因是unparkSuccessor方法会试图将当前node的waitStatus复位成0，如果我们直接SIGNAL–&gt;PROPAGA后，那么又被复位成0，还需要一次CAS操作置为PROPAGATE。</p>
<h3 id="releaseShared-释放锁"><a href="#releaseShared-释放锁" class="headerlink" title="releaseShared 释放锁"></a>releaseShared 释放锁</h3><pre><code class="java">public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
</code></pre>
<p>我们可以看到，调用tryReleaseShared成功释放共享资源之后，最终要再次调用doReleaseShared试图唤醒后面的等待线程。</p>
<hr>
<p>之前自己实现过一个分布式锁：<a href="https://github.com/IBM/distributed-lock-spring-boot-starter" target="_blank" rel="noopener">https://github.com/IBM/distributed-lock-spring-boot-starter</a></p>
<p>redis实现的，具体怎么实现以后会单独开文章说。</p>
<p>这里主要说下aqs：</p>
<p>单实例的aqs，头节点永远是占有锁的节点，并永远在自旋。其他节点都可以放心休息。<br>而多实例aqs，肯定会有实例的等待队列的头节点得不到锁，而也错误的进入了休息，这样这个队列就永远不会被唤醒。<br>因此，要解决问题，只需要保持每个实例的队列的头节点都永远在自旋即可。<br>简单改一下aqs中的一行就能实现：</p>
<pre><code class="java">final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
                final Node p = node.predecessor();
                if (p == head &amp;&amp; tryAcquire(arg)) {
                    setHead(node);
                    p.next = null;
                    failed = false;
                    return interrupted;
                }
                // 就是这一行
                if (p != head &amp;&amp; shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) {
                    interrupted = true;
                }
            }
        } finally {
            if (failed) {
                cancelAcquire(node);
            }
        }
    }
</code></pre>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[juc之原子类]]></title>
      <url>/2020/11/21/juc-1/</url>
      <content type="html"><![CDATA[<p>原子类是对Java中不能保证原子类型的指令的扩展。</p>
<p>原子类是典型的cas无锁的应用，并在一些累加方法中加入了自旋锁。原子类相比于锁，有一定优势：<br>粒度更细：原子类把竞争范围缩小到了变量级别<br>效率较高：通常情况下更高，但是高度竞争的情况下效率更低</p>
<p>看了一下源码都差不太多，放在一起说吧</p>
<p>以AtomicInteger为例：</p>
<p>compareAndSet（）：</p>
<pre><code class="java">public final boolean compareAndSet(int expect, int update) {
        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
    }
</code></pre>
<p>直接调用unsafe中的cas方法，没有自旋，一次返回。</p>
<p>getAndSet():</p>
<pre><code class="java">public final int getAndSet(int newValue) {
        return unsafe.getAndSetInt(this, valueOffset, newValue);
    }
</code></pre>
<p>需要注意一下貌似原子类的代码在新版本的jdk中是有改动过的，网上有些解析都是在原子类中自旋，现在都是把自旋的操作隐藏在unsafe里了。因此这个getAndSet方法实际上是有自旋操作的，点进unsafe看：</p>
<pre><code class="java">public final int getAndSetInt(Object var1, long var2, int var4) {
        int var5;
        do {
            var5 = this.getIntVolatile(var1, var2);
        } while(!this.compareAndSwapInt(var1, var2, var5, var4));

        return var5;
    }
</code></pre>
<p>每次都会先取出原子类旧的value，然后做cas操作，直到操作成功。</p>
<p>getAndUpdate（）：</p>
<pre><code class="java">public final int getAndUpdate(IntUnaryOperator updateFunction) {
        int prev, next;
        do {
            prev = get();
            next = updateFunction.applyAsInt(prev);
        } while (!compareAndSet(prev, next));
        return prev;
    }
</code></pre>
<p>跟getAndSet差不多，只不过这里参数是一个函数式的接口，并且把自旋操作拿到了原子类里。</p>
<p>addAndGet（）、decrementAndGet（）、incrementAndGet（），getAndAdd（）、getAndDecrement（）、getAndIncrement（）：<br>都是一样的，全都调用unsafe的getAndAddInt（）,一个自旋锁，也没啥好说的：</p>
<pre><code class="java">public final int getAndAddInt(Object var1, long var2, int var4) {
        int var5;
        do {
            var5 = this.getIntVolatile(var1, var2);
        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

        return var5;
    }
</code></pre>
<p>原子类基本上就是这些，基本类型和对象类型的方法源码基本上都是大同小异，不多说了，AtomicReferenceFieldUpdater就是原子更新对象中的某一个字段，带array的原子类就是在更新时加一个数组下标。</p>
]]></content>
      
        <categories>
            
            <category> juc </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> juc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[thread，threadlocal，InheritableThreadLocal源码详解]]></title>
      <url>/2020/11/20/thread-source-code/</url>
      <content type="html"><![CDATA[<h2 id="Thread-源码解析"><a href="#Thread-源码解析" class="headerlink" title="Thread 源码解析"></a>Thread 源码解析</h2><p>构造方法：</p>
<p>所有构造方法都调用了init（），直接看此方法：</p>
<pre><code class="java">private void init(ThreadGroup g, Runnable target, String name,
                    long stackSize, AccessControlContext acc) {
      if (name == null) {
          throw new NullPointerException(&quot;name cannot be null&quot;);
      }
      this.name = name.toCharArray();
      // 父线程
      Thread parent = currentThread();
      SecurityManager security = System.getSecurityManager();
      if (g == null) {
          // 实际是Thread.currentThread().getThreadGroup();
          // 拿到threadgroup以后会对其进行操作
          // threadgroup里面有nUnstartedThreads代表未启动线程数
          // nthreads启动线程数
          // threads[]线程的数组
          /* Determine if it&#39;s an applet or not */
          /* If there is a security manager, ask the security manager
             what to do. */
          if (security != null) {
              g = security.getThreadGroup();
          }
          /* If the security doesn&#39;t have a strong opinion of the matter
             use the parent thread group. */
          if (g == null) {
              g = parent.getThreadGroup();
          }
      }
      /* checkAccess regardless of whether or not threadgroup is
         explicitly passed in. */
      g.checkAccess();
      /*
       * Do we have the required permissions?
       */
      if (security != null) {
          if (isCCLOverridden(getClass())) {
              security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION);
          }
      }
      // 在ThreadGroup中标记增加了一个未启动的线程，里面操作很简单，nUnstartedThreads++;
      g.addUnstarted();
      this.group = g;
      // 继承父线程的属性
      this.daemon = parent.isDaemon();
      this.priority = parent.getPriority();
      if (security == null || isCCLOverridden(parent.getClass()))
          this.contextClassLoader = parent.getContextClassLoader();
      else
          this.contextClassLoader = parent.contextClassLoader;
      this.inheritedAccessControlContext =
              acc != null ? acc : AccessController.getContext();
      this.target = target;
      // 再设置线程优先级
      setPriority(priority);
      // 设置inheritableThreadLocals用于父子线程变量共享
      if (parent.inheritableThreadLocals != null)
          this.inheritableThreadLocals =
              ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
      /* Stash the specified stack size in case the VM cares */
      // 给这个线程设置的栈的大小,默认为0 
      this.stackSize = stackSize;
      // 设置线程id
      tid = nextThreadID();
  }
</code></pre>
<p>start（）：</p>
<pre><code class="java"> public synchronized void start() {
        /**
         * This method is not invoked for the main method thread or &quot;system&quot;
         * group threads created/set up by the VM. Any new functionality added
         * to this method in the future may have to also be added to the VM.
         *
         * A zero status value corresponds to state &quot;NEW&quot;.
         */
        // 一个新建的未启动的线程的threadStatus必须为0
        // 0 就代表“new”
        if (threadStatus != 0)
            throw new IllegalThreadStateException();

        /* Notify the group that this thread is about to be started
         * so that it can be added to the group&#39;s list of threads
         * and the group&#39;s unstarted count can be decremented. */
        // 将当前线程加入group
        // group中的启动线程数++ 未启动线程数--
        group.add(this);

        boolean started = false;
        try {
            // 调用native方法
            start0();
            started = true;
        } finally {
            try {
                if (!started) {
                    group.threadStartFailed(this);
                }
            } catch (Throwable ignore) {
                /* do nothing. If start0 threw a Throwable then
                  it will be passed up the call stack */
            }
        }
    }
</code></pre>
<p>exit（）：</p>
<pre><code class="java">/**
 * This method is called by the system to give a Thread
 * a chance to clean up before it actually exits.
 */
private void exit() {
    if (group != null) {
        group.threadTerminated(this);
        group = null;
    }
    /* Aggressively null out all reference fields: see bug 4006245 */
    target = null;
    /* Speed the release of some of these resources */
    threadLocals = null;
    inheritableThreadLocals = null;
    inheritedAccessControlContext = null;
    blocker = null;
    uncaughtExceptionHandler = null;
}
</code></pre>
<p>exit（）方法没啥可说的，更重要的是其中调用的group.threadTerminated(this);</p>
<pre><code class="java"> /**
     * Notifies the group that the thread {@code t} has terminated.
     *
     * &lt;p&gt; Destroy the group if all of the following conditions are
     * true: this is a daemon thread group; there are no more alive
     * or unstarted threads in the group; there are no subgroups in
     * this thread group.
     *
     * @param  t
     *         the Thread that has terminated
     */
void threadTerminated(Thread t) {
        synchronized (this) {
            // 从group中删除当前线程
            remove(t);

            if (nthreads == 0) {
                // 唤醒其他线程
                // 这就是为什么被join挂起的线程会被唤醒
                notifyAll();
            }
            if (daemon &amp;&amp; (nthreads == 0) &amp;&amp;
                (nUnstartedThreads == 0) &amp;&amp; (ngroups == 0))
            {
                destroy();
            }
        }
    }
</code></pre>
<p>sleep（）：</p>
<pre><code class="java">public static void sleep(long millis, int nanos)
    throws InterruptedException {
        if (millis &lt; 0) {
            throw new IllegalArgumentException(&quot;timeout value is negative&quot;);
        }
        if (nanos &lt; 0 || nanos &gt; 999999) {
            throw new IllegalArgumentException(
                                &quot;nanosecond timeout value out of range&quot;);
        }
        if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) {
            millis++;
        }
        // 直接调用native方法
        sleep(millis);
    }
</code></pre>
<p>stop（）：<br>stop( )方法是停止线程的执行，这个方法是一个不推荐使用的方法，已经被废弃了，因为使用该方法会出现异常情况。<br>因为它是天生不安全的。停止一个线程会导致它解锁它所锁定的所有monitor（当一个ThreadDeath Exception沿着栈向上传播时会解锁monitor），如果这些被释放的锁所保护的objects有任何一个进入一个不一致的状态，其他将要访问该objects的线程也会以一种不一致的状态来访问这些objects。这种objects称为“被损坏了”。当线程对被损坏的objects上做操作时，可能会产生意想不到的结果，这些行为可能是很严重的，并且难以探测到，</p>
<pre><code class="java">@Deprecated
  public final void stop() {
      SecurityManager security = System.getSecurityManager();
      if (security != null) {
        //检查是否有权限
          checkAccess();
          if (this != Thread.currentThread()) {
              security.checkPermission(SecurityConstants.STOP_THREAD_PERMISSION);
          }
      }
      // A zero status value corresponds to &quot;NEW&quot;, it can&#39;t change to
      // not-NEW because we hold the lock.
      if (threadStatus != 0) {
          resume(); // Wake up thread if it was suspended; no-op otherwise
      }
      // The VM can handle all thread states
      stop0(new ThreadDeath());
  }
</code></pre>
<p>join（）：</p>
<p>join方法是等待该线程执行，直到超时或者终止，可以作为线程通信的一种方式，A线程调用B线程的join（阻塞），等待B完成后再往下执行。 join（）方法中重载了多个方法，但是主要的方法是下面的方法。</p>
<pre><code class="java">public final synchronized void join(long millis)
   throws InterruptedException {
       //得到当前的系统给时间
       long base = System.currentTimeMillis();
       long now = 0;
       if (millis &lt; 0) {
           throw new IllegalArgumentException(&quot;timeout value is negative&quot;);
       }
       if (millis == 0) {
           //如果是活跃的的
           while (isAlive()) {
           //无限期的等待
               wait(0);
           }
       } else {
           while (isAlive()) {
               long delay = millis - now;
               if (delay &lt;= 0) {
                   break;
               }
               //有限期的进行等待
               wait(delay);
               now = System.currentTimeMillis() - base;
           }
       }
   }
</code></pre>
<p>interrupt():</p>
<pre><code class="java">public void interrupt() {
    if (this != Thread.currentThread())
        checkAccess();
    synchronized (blockerLock) {
        Interruptible b = blocker;
        if (b != null) {
            interrupt0();           // Just to set the interrupt flag
            b.interrupt(this);
            return;
        }
    }
    interrupt0();
}
</code></pre>
<p>interrupt()方法是中断当前的线程， 其实Thread类中有三个方法，比较容易混淆，在这里解释一下。</p>
<ul>
<li>interrupt: 置为中断状态</li>
<li>isInterrupt: 线程是否中断</li>
<li>interrupted: 返回线程的上次的中断状态，并清除中断状态。</li>
</ul>
<p>一般来说，阻塞函数：如Thread.sleep、Thread.join、Object.wait等在检查到线程的中断状态的时候，会抛出InteruptedExeption, 同时会清除线程的中断状态。</p>
<p>对于InterruptedException的处理，可以有两种情况：</p>
<p>外层代码可以处理这个异常，直接抛出这个异常即可<br>如果不能抛出这个异常，比如在run()方法内，因为在得到这个异常的同时，线程的中断状态已经被清除了，需要保留线程的中断状态，则需要调用<code>Thread.currentThread().interrupt()</code></p>
<h2 id="threadlocal"><a href="#threadlocal" class="headerlink" title="threadlocal"></a>threadlocal</h2><p>以下内容参考： <a href="https://juejin.cn/post/6844903552477822989" target="_blank" rel="noopener">https://juejin.cn/post/6844903552477822989</a>  <a href="https://www.jianshu.com/p/9d289d33f696" target="_blank" rel="noopener">https://www.jianshu.com/p/9d289d33f696</a></p>
<p>threadLocal是每线程独有的</p>
<p><img src="https://s3.ax1x.com/2020/11/20/DlmQnP.png" alt="DlmQnP.png"></p>
<p>每个Thread维护一个ThreadLocalMap，存储在ThreadLocalMap内的就是一个以Entry为元素的数组，Entry就是一个key-value结构，key为ThreadLocal，value为存储的值。类比HashMap的实现，其实就是每个线程借助于一个哈希表，存储线程独立的值。</p>
<p>这里ThreadLocal和key之间的线是虚线，因为Entry是继承了WeakReference实现的，当ThreadLocalRef销毁时，指向堆中ThreadLocal实例的唯一一条强引用消失了，只有Entry有一条指向ThreadLocal实例的弱引用，那么这里ThreadLocal实例是可以被GC掉的。这时Entry里的key为null了，但是enrty本身还是有一个强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value，如果线程迟迟没有死亡，那么永远无法回收，造成内存泄漏。下面会讲。</p>
<p>ThreadLocalMap用来存储用户的value，这个map的引用在Thread类里，是全线程唯一的。</p>
<pre><code class="java">static class ThreadLocalMap {
    // 注意虚引用
    static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal&lt;?&gt; k, Object v) {
            super(k);
            value = v;
        }
    }
    /**
     * The table, resized as necessary.
     * table.length MUST always be a power of two.
     */
    // 主要数据结构就是一个Entry的数组table；
    private Entry[] table;

    ...
</code></pre>
<p>几个方法一起说了：</p>
<pre><code class="java">
public void set(T value) {
    // 获取当前的Thread对象，通过getMap获取Thread内的ThreadLocalMap
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }


public T get() {
    // 获取当前的Thread对象，通过getMap获取Thread内的ThreadLocalMap
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null) {
            // 如果map已经存在，以当前的ThreadLocal为键，获取Entry对象，并从从Entry中取出值
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings(&quot;unchecked&quot;)
                T result = (T)e.value;
                return result;
            }
        }
        // 否则，调用setInitialValue进行初始化。
        return setInitialValue();
    }

ThreadLocalMap getMap(Thread t) {
        // ThreadLocalMap在当前线程被所有ThreadLocal共享
        return t.threadLocals;
}

void createMap(Thread t, T firstValue) {
    // 初始化map,构建table与Enrty
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}

private T setInitialValue() {
    // 首先是调用initialValue生成一个初始的value值，深入initialValue函数，我们可知它就是返回一个null；
    T value = initialValue();
    Thread t = Thread.currentThread();
    // 然后还是在get以下Map
    ThreadLocalMap map = getMap(t);
    if (map != null)
    // 如果map存在，则直接map.set
        map.set(this, value);
    else
    // 如果不存在则会调用createMap创建ThreadLocalMap
        createMap(t, value);
    return value;
}
</code></pre>
<p>每一个ThreadLocal对象是如何区分的：</p>
<pre><code class="java">    //java提供的,可以用原子方式更新的 int值的类。
    private static AtomicInteger nextHashCode = new AtomicInteger();
    private static final int HASH_INCREMENT = 0x61c88647;
    private final int threadLocalHashCode = nextHashCode();

    private static int nextHashCode() {
        //原子性加一
        return nextHashCode.getAndAdd(HASH_INCREMENT);
    }
</code></pre>
<p>对于每一个ThreadLocal对象，都有一个final的int值threadLocalHashCode；AtomicInteger 是static修饰的，全局唯一，每一次加一之后的值仍然可用，并且保证原子性。所以，每一个线程的ThreadLocal对象都有唯一的threadLocalHashCode值。</p>
<p>为什么不使用当前线程作为key？</p>
<p>上面知道，每一个线程周期，都有一个全线程唯一的map用于存储value，如果线程内多个ThreadLocal对象set了value，那么以当前线程作为键是不能保证key的唯一性的；而每一个ThreadLocal对象都可以由threadLocalHashCode进行唯一区分，所以key使用为ThreadLocal方便存取。</p>
<p>解决内存泄漏</p>
<pre><code class="java">private Entry getEntry(ThreadLocal&lt;?&gt; key) {
    // 首先是计算索引位置i
    int i = key.threadLocalHashCode &amp; (table.length - 1);
    Entry e = table[i];
    if (e != null &amp;&amp; e.get() == key)
    // 根据获取Entry，如果Entry存在且Entry的key恰巧等于ThreadLocal，那么直接返回Entry对象；
        return e;
    else
    // 否则，也就是在此位置上找不到对应的Entry，那么就调用getEntryAfterMiss。
        return getEntryAfterMiss(key, i, e);
}


private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) {
    Entry[] tab = table;
    int len = tab.length;

    while (e != null) {
        ThreadLocal&lt;?&gt; k = e.get();
        if (k == key)
        // 如果k==key,那么代表找到了这个所需要的Entry，直接返回；
            return e;
        if (k == null)
        // 如果k==null，那么证明这个Entry中key已经为null,那么这个Entry就是一个过期对象，这里调用expungeStaleEntry清理该Entry。
        // 这里解决了内存泄漏问题
        // ThreadLocal实例由于只有Entry中的一条弱引用指着，那么就会被GC掉，Entry的key没了，value可能会内存泄露的
        // 其实在每一个get，set操作时都会不断清理掉这种key为null的Entry的。
            expungeStaleEntry(i);
        else
            i = nextIndex(i, len);
        e = tab[i];
    }
    return null;
}

private int expungeStaleEntry(int staleSlot) {
    Entry[] tab = table;
    int len = tab.length;

    // expunge entry at staleSlot
    // 这段主要是将i位置上的Entry的value设为null，Entry的引用也设为null，那么系统GC的时候自然会清理掉这块内存；
    tab[staleSlot].value = null;
    tab[staleSlot] = null;
    size--;

    // Rehash until we encounter null
    // 这段就是扫描位置staleSlot之后，null之前的Entry数组，清除每一个key为null的Entry，同时若是key不为空，做rehash，调整其位置。
    Entry e;
    int i;
    for (i = nextIndex(staleSlot, len);
         (e = tab[i]) != null;
         i = nextIndex(i, len)) {
        ThreadLocal&lt;?&gt; k = e.get();
        if (k == null) {
            e.value = null;
            tab[i] = null;
            size--;
        } else {
            int h = k.threadLocalHashCode &amp; (len - 1);
            if (h != i) {
                tab[i] = null;

                // Unlike Knuth 6.4 Algorithm R, we must scan until
                // null because multiple entries could have been stale.
                while (tab[h] != null)
                    h = nextIndex(h, len);
                tab[h] = e;
            }
        }
    }
    return i;
}
</code></pre>
<p>我们发现无论是set,get还是remove方法，过程中key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，GC时就会被回收。那么怎么会存在内存泄露呢？但是以上的思路是假设你调用get或者set方法了，很多时候我们都没有调用过，所以最佳实践就是*<br>1 .使用者需要手动调用remove函数，删除不再使用的ThreadLocal.<br>2 .还有尽量将ThreadLocal设置成private static的，这样ThreadLocal会尽量和线程本身一起消亡。</p>
<h2 id="InheritableThreadLocal父子线程共享变量"><a href="#InheritableThreadLocal父子线程共享变量" class="headerlink" title="InheritableThreadLocal父子线程共享变量"></a>InheritableThreadLocal父子线程共享变量</h2><p>InheritableThreadLocal的源码非常简单，继承自ThreadLocal，重写其中三个方法。</p>
<pre><code class="java">public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; {
    public InheritableThreadLocal() {
    }

    protected T childValue(T var1) {
        return var1;
    }

    ThreadLocalMap getMap(Thread var1) {
        return var1.inheritableThreadLocals;
    }

    void createMap(Thread var1, T var2) {
        var1.inheritableThreadLocals = new ThreadLocalMap(this, var2);
    }
}
</code></pre>
<p>InheritableThreadLocal获取的也是ThreadLocalMap, 解决父子线程共享变量的地方实际在thread类里，上文说过：</p>
<pre><code class="java">/* ThreadLocal values pertaining to this thread. This map is maintained
     * by the ThreadLocal class. */
    ThreadLocal.ThreadLocalMap threadLocals = null;

    /*
     * InheritableThreadLocal values pertaining to this thread. This map is
     * maintained by the InheritableThreadLocal class.
     */
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;

private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize, AccessControlContext acc,
                      boolean inheritThreadLocals) {
        //..........
        Thread parent = currentThread();
        //..........
        // 如果父线程的inheritableThreadLocals != null
        if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)
        // 新线程：`this.inheritableThreadLocals=ThreadLocal.createInheritedMap(parent.inheritableThreadLocals)`
        // 传入父线程的inheritableThreadLocals 
            this.inheritableThreadLocals =
                ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
        /* Stash the specified stack size in case the VM cares */
        this.stackSize = stackSize;

        /* Set thread ID */
        tid = nextThreadID();
    }
</code></pre>
<pre><code class="java">    static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {
        return new ThreadLocalMap(parentMap);
    }

    // 实际上就是构造了一个新的包含所有parentMap元素的新map
    private ThreadLocalMap(ThreadLocalMap parentMap) {
        // 得到parent的数组
        Entry[] parentTable = parentMap.table;
        int len = parentTable.length;
        setThreshold(len);
        table = new Entry[len];

        for (int j = 0; j &lt; len; j++) {
            Entry e = parentTable[j];
            if (e != null) {
                @SuppressWarnings(&quot;unchecked&quot;)
                ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get();
                if (key != null) {
                    // InheritableThreadLocal重写了这个方法返回原值
                    Object value = key.childValue(e.value);
                    Entry c = new Entry(key, value);
                    //计算hash位置，与ThreadLocal的set方法一样
                    int h = key.threadLocalHashCode &amp; (len - 1);
                    while (table[h] != null)
                        h = nextIndex(h, len);
                    table[h] = c;
                    size++;
                }
            }   
        }
    }
</code></pre>
]]></content>
      
        <categories>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 并发 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[自旋锁]]></title>
      <url>/2020/11/19/cas-spin/</url>
      <content type="html"><![CDATA[<h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><p>自旋锁是采用让当前线程不停地的在循环体内执行实现的，当循环的条件被其他线程改变时 才能进入临界区。如下</p>
<pre><code class="java">public class SpinLock {

  private AtomicReference&lt;Thread&gt; sign =new AtomicReference&lt;&gt;();

  public void lock(){
    Thread current = Thread.currentThread();
    while(!sign .compareAndSet(null, current)){
    }
  }

  public void unlock (){
    Thread current = Thread.currentThread();
    sign .compareAndSet(current, null);
  }
}
</code></pre>
<h2 id="Ticket锁"><a href="#Ticket锁" class="headerlink" title="Ticket锁"></a>Ticket锁</h2><p>Ticket锁主要解决的是访问顺序的问题, 每次都要查询一个serviceNum服务号，影响性能（必须要到主内存读取，并阻止其他cpu修改）。</p>
<pre><code class="java">package com.alipay.titan.dcc.dal.entity;

import java.util.concurrent.atomic.AtomicInteger;

public class TicketLock {
    private AtomicInteger                     serviceNum = new AtomicInteger();
    private AtomicInteger                     ticketNum  = new AtomicInteger();
    private static final ThreadLocal&lt;Integer&gt; LOCAL      = new ThreadLocal&lt;Integer&gt;();

    public void lock() {
        int myticket = ticketNum.getAndIncrement();
        LOCAL.set(myticket);
        while (myticket != serviceNum.get()) {
        }

    }

    public void unlock() {
        int myticket = LOCAL.get();
        serviceNum.compareAndSet(myticket, myticket + 1);
    }
}
</code></pre>
<h2 id="CLHLock"><a href="#CLHLock" class="headerlink" title="CLHLock"></a>CLHLock</h2><p>CLHlock是连表结构，不停的查询前驱变量，导致不适合在NUMA 架构下使用（在这种结构下，每个线程分布在不同的物理内存区域）</p>
<pre><code class="java">public class CLHLock {

    public static class QNode {
        volatile boolean locked;
    }

    // 尾巴，是所有线程共有的一个。所有线程进来后，把自己设置为tail
    private final AtomicReference&lt;QNode&gt; tail;
    // 前驱节点，每个线程独有一个。
    private final ThreadLocal&lt;QNode&gt; myPred;
    // 当前节点，表示自己，每个线程独有一个。
    private final ThreadLocal&lt;QNode&gt; myNode;

    public CLHLock() {
        // 初始状态 tail指向一个node(head)节点
        this.tail = new AtomicReference&lt;&gt;(new QNode());
        this.myNode = ThreadLocal.withInitial(QNode::new);
        this.myPred = new ThreadLocal&lt;&gt;();
    }

    public void lock() {
        // 获取当前线程的代表节点
        QNode node = myNode.get();
        // 将自己的状态设置为true表示获取锁。
        node.locked = true;
        // 将自己放在队列的尾巴，并且返回以前的值。第一次进将获取构造函数中的那个new QNode
        QNode pred = tail.getAndSet(node);
        // 把旧的节点放入前驱节点。
        myPred.set(pred);
        // 判断前驱节点的状态，然后走掉。
        while (pred.locked) {
        }
    }

    public void unlock() {
        // unlock. 获取自己的node。把自己的locked设置为false。
        QNode node = myNode.get();
        node.locked = false;
    }
}
</code></pre>
<p>CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail），CLH的一种变体被应用在了JAVA并发框架中。唯一的缺点是在NUMA系统结构下性能很差，在这种系统结构下，每个线程有自己的内存，如果前趋结点的内存位置比较远，自旋判断前趋结点的locked域，性能将大打折扣，但是在SMP系统结构下该法还是非常有效的。一种解决NUMA系统结构的思路是MCS队列锁。</p>
<h2 id="MCSLock"><a href="#MCSLock" class="headerlink" title="MCSLock"></a>MCSLock</h2><p>MCS 的实现是基于链表的，每个申请锁的线程都是链表上的一个节点，这些线程会一直轮询自己的本地变量，来知道它自己是否获得了锁。已经获得了锁的线程在释放锁的时候，负责通知其它线程，这样 CPU 之间缓存的同步操作就减少了很多，仅在线程通知另外一个线程的时候发生，降低了系统总线和内存的开销。实现如下所示：</p>
<pre><code class="java">public class MCSLock {

    public static class Node{
        // 后继节点
        volatile   Node next;
        // 默认false
        volatile   boolean locked;
    }

    // 指向最后加入的线程
    final AtomicReference&lt;Node&gt; tail = new AtomicReference&lt;&gt;(null);

    ThreadLocal&lt;Node&gt; current;

    public MCSLock(){
        //初始化当前节点的node
        current= ThreadLocal.withInitial(Node::new);
    }
    public void lock() throws InterruptedException {

        // 获取当前线程的Node
        Node own = current.get();

        // 把自己设为尾节点， 并取回旧节点
        Node preNode = tail.getAndSet(own);

        // 如果旧节点不为null，说明有线程已经占用
        if(preNode != null){
            // 设置当前节点为需要占用状态；
            own.locked = true;
            // 把前面节点的next指向自己
            preNode.next = own;

            // 在自己的节点上自旋等待前驱通知
            while(own.locked){

            }


        }

    }

    public void unlock(){
        // 获取自己的节点
        Node own=current.get();
        //
        if(own.next==null){
            // 判断是不是自身是不是最后一个线程
            if(tail.compareAndSet(own,null)){
                // 是的话就结束
                return;
            }

        }
        // 在判断过程中，又有线程进来
        while (own.next==null){

        }
        // 本身解锁，通知它的后继节点可以工作了，不用再自旋了
        own.next.locked = false;
        own.next=null;// for gc
    }
}
</code></pre>
<p>MCS 的能够保证较高的效率，降低不必要的性能消耗，并且它是公平的自旋锁。</p>
<p>CLH 锁与 MCS 锁的原理大致相同，都是各个线程轮询各自关注的变量，来避免多个线程对同一个变量的轮询，从而从 CPU 缓存一致性的角度上减少了系统的消耗。<br>CLH 锁与 MCS 锁最大的不同是，MCS 轮询的是当前队列节点的变量，而 CLH 轮询的是当前节点的前驱节点的变量，来判断前一个线程是否释放了锁。</p>
]]></content>
      
        <categories>
            
            <category> cas </category>
            
            <category> 并发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> cas </tag>
            
            <tag> 并发 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[jvm与并发]]></title>
      <url>/2020/11/18/jvm-multithread/</url>
      <content type="html"><![CDATA[<h2 id="Java中的内存并发模型"><a href="#Java中的内存并发模型" class="headerlink" title="Java中的内存并发模型"></a>Java中的内存并发模型</h2><p>“内存模型”，它可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。</p>
<p>Java内存模型规定了所有的变量都存储在主内存(Main Memory)中。每条线程还有自己的工作内存(Working Memory ，可与前面讲的处理器高速缓存类比)，线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的数据。</p>
<p>此处的变量(Variables)与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。</p>
<p><img src="https://s3.ax1x.com/2020/11/20/DQQT2Q.png" alt="DQQT2Q.png"></p>
<p>Java内存模型中定义了以下8种操作来完成。Java虚拟机实 现时必须保证下面提及的每一种操作都是原子的、不可再分的：</p>
<ul>
<li>lock(锁定):作用于主内存的变量，它把一个变量标识为一条线程独占的状态。</li>
<li>unlock(解锁):作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li>
<li>read(读取):作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。</li>
<li>load(载入):作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。</li>
<li>use(使用):作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。</li>
<li>assign(赋值):作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量， 每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。</li>
<li>store(存储):作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随 后的write操作使用。</li>
<li>write(写入):作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li>
</ul>
<h2 id="并发的三个特性"><a href="#并发的三个特性" class="headerlink" title="并发的三个特性"></a>并发的三个特性</h2><ul>
<li>原子性（注意 “long和double的非原子性协定”）</li>
<li>可见性</li>
<li>有序性</li>
</ul>
<h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><p>当一个变量被定义成volatile之后，它将具备两项特性:</p>
<h4 id="保证可见性"><a href="#保证可见性" class="headerlink" title="保证可见性"></a>保证可见性</h4><p>第一项是保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量并不能做到这一点，普通变量的值在线程间传递时均需要通过主内存来完成。比如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线程A回写完成了之后再对主内存进行读取操作，新变量值才会对线程B可见。（volatile变量在各个线程的工作内存中是不存在一致性问题的，但是Java里面的运算操作符并非原子操作， 这导致volatile变量的运算在并发下一样是不安全的）</p>
<p>由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁 (使用synchronized、java.util.concurrent中的锁或原子类)来保证原子性:</p>
<ul>
<li>运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。</li>
<li>变量不需要与其他的状态变量共同参与不变约束。</li>
</ul>
<h4 id="通过内存屏障避免指令重排"><a href="#通过内存屏障避免指令重排" class="headerlink" title="通过内存屏障避免指令重排"></a>通过内存屏障避免指令重排</h4><p>什么是指令重排</p>
<p>在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待3。通过乱序执行的技术，处理器可以大大提高执行效率。</p>
<p>普通的变量仅会保证，在该方法的执行过程中，所有依赖赋值结果的地方都能获取到正确的结果，而不能保证，变量赋值操作的顺序与程序代码中的执行顺序一致。这就是Java内存模型中描述的所谓“线程内表现为串行的语义”(As-If-Serial)，即所有的动作都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。</p>
<p>Java内存模型关于重排序的规定，总结后如下表所示：</p>
<p><img src="https://s3.ax1x.com/2020/11/20/DQYX6S.png" alt="DQYX6S.png"></p>
<p>什么是内存屏障</p>
<p>内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。</p>
<p>内存屏障可以被分为以下几种类型：</p>
<ul>
<li>LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li>
<li>StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li>
<li>LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li>
<li>StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。</li>
</ul>
<p>对于Java编译器而言，Intel 64/IA-32架构下处理器不需要LoadLoad、LoadStore、StoreStore屏障，因为不会发生需要这三种屏障的重排序。</p>
<p>Java编译器会这样使用内存屏障：</p>
<p><img src="https://s3.ax1x.com/2020/11/20/DQYzwj.png" alt="DQYzwj.png"></p>
<h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2><p>在Java里面，最基本的互斥同步手段就是synchronized关键字，这是一种块结构(Block Structured)的同步语法。synchronized关键字经过Javac编译之后，会在同步块的前后分别形成<br>monitorenter和monitorexit这两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference;如果没有明确指定，那将根据synchronized修饰的方法类型，来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁。</p>
<p>在执行monitorenter指令时，首先要去尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行monitorexit指令时会将锁计数器的值减一。一旦计数器的值为零，锁随即就被释放了。如果获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止。</p>
<ul>
<li>被synchronized修饰的同步块对同一条线程来说是可重入的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。</li>
<li>被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。</li>
</ul>
<p>对象锁和类锁</p>
<ul>
<li>对象锁锁住的是非静态变量，this 对象或非静态方法，使用对象锁的情况，只有使用同一实例的线程才会受锁的影响，多个实例调用同一方法也不会受影响。</li>
<li>类锁锁住的是类中的静态变量，静态方法或xxx.class，类锁是所有线程共享的锁，所以同一时刻，只能有一个线程使用加了锁的方法或方法体，不管是不是同一个实例。</li>
</ul>
<p>使用synchronized是，请将锁住的变量设为final，why：</p>
<pre><code class="java">private String color = &quot;red&quot;;

private void doSomething(){
  synchronized(color) {  // lock is actually on object instance &quot;red&quot; referred to by the color variable
    //...
    color = &quot;green&quot;; // other threads now allowed into this block
    // ...
  }
}
</code></pre>
<h2 id="happens-before"><a href="#happens-before" class="headerlink" title="happens-before"></a>happens-before</h2><ul>
<li>程序次序规则: 在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。</li>
<li>管程锁定规则: 一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。</li>
<li>volatile变量规则: 对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。</li>
<li>线程启动规则: Thread对象的start()方法先行发生于此线程的每一个动作。</li>
<li>线程终止规则: 线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过<code>Thread::join()</code>方法是否结束、<code>Thread::isAlive()</code>的返回值等手段检测线程是否已经终止执行。</li>
<li>线程中断规则: 对线程<code>interrupt()</code>方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过<code>Thread::interrupted()</code>方法检测到是否有中断发生。</li>
<li>对象终结规则:一个对象的初始化完成(构造函数执行结束)先行发生于它的<code>finalize()</code>方法的开始。</li>
<li>传递性: 如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。</li>
</ul>
<h2 id="java线程"><a href="#java线程" class="headerlink" title="java线程"></a>java线程</h2><p>java是使用内核态线程的抢占式模型。</p>
<p>Java线程实现：继承thread类和实现runnable接口，有啥区别吗？没啥区别，Thread也是实现了Runnable接口，提供了更多线程状态控制转换的方法罢了。</p>
<h4 id="状态转换"><a href="#状态转换" class="headerlink" title="状态转换"></a>状态转换</h4><ul>
<li>新建(New): 创建后尚未启动的线程处于这种状态。</li>
<li>运行(Runnable): 包括操作系统线程状态中的Running和Ready也就是处于此状态的线程有可能正在执行，也有可能正在等待着操作系统为它分配执行时间。</li>
<li>无限期等待(Waiting): 处于这种状态的线程不会被分配处理器执行时间，它们要等待被其他线程显式唤醒。以下方法会让线程陷入无限期的等待状态:<ul>
<li>没有设置Timeout参数的<code>Object::wait()</code>方法;</li>
<li>没有设置Timeout参数的<code>Thread::join()</code>方法;</li>
<li><code>LockSupport::park()</code>方法。</li>
</ul>
</li>
<li>限期等待(Timed Waiting): 处于这种状态的线程也不会被分配处理器执行时间，不过无须等待被其他线程显式唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态:<ul>
<li><code>Thread::sleep()</code>方法;</li>
<li>设置了Timeout参数的<code>Object::wait()</code>方法;</li>
<li>设置了Timeout参数的<code>Thread::join()</code>方法;</li>
<li><code>LockSupport::parkNanos()</code>方法;</li>
<li><code>LockSupport::parkUntil()</code>方法。</li>
</ul>
</li>
<li>阻塞(Blocked):线程被阻塞了，“阻塞状态”与“等待状态”的区别是“阻塞状态”在等待着获取到一个锁，这个事件将在另外一个线程放弃这个锁的时候发生;而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。</li>
<li>结束(Terminated):已终止线程的线程状态，线程已经结束执行。</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/20/DQg8wq.png" alt="DQg8wq.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/23/DJTGa6.png" alt="DJTGa6.png"></p>
<h4 id="线程中断"><a href="#线程中断" class="headerlink" title="线程中断"></a>线程中断</h4><p>感觉必须要加一段线程中断和响应中断的详解，不然后续对aqs理解会有问题：</p>
<p>Java没有提供任何机制来安全地终止线程，但提供了中断机制，即thread.interrupt()方法。线程中断是一种协作式的机制，并不是说调用了中断方法之后目标线程一定会立即中断，而是发送了一个中断请求给目标线程，目标线程会自行在某个取消点中断自己。这种设定很有必要，因为如果不论线程执行到何种情况都立即响应中断的话，很容易造成某些对象状态不一致的情况出现。</p>
<p>每个线程对象里都有一个 boolean 类型的标识（不一定就要是 Thread 类的字段，实际上也的确不是，这几个方法最终都是通过 native 方法来完成的），代表着是否有中断请求（该请求可以来自所有线程，包括被中断的线程本身）。例如，当线程 t1 想中断线程 t2，只需要在线程 t1 中将线程 t2 对象的中断标识置为 true，然后线程 2 可以选择在合适的时候处理该中断请求，甚至可以不理会该请求，就像这个线程没有被中断一样。</p>
<p>涉及到中断的线程基础方法有三个：interrupt()、isInterrupted()、interrupted()，它们都位于Thread类下。</p>
<ul>
<li><p>interrupt()方法：对目标线程发送中断请求，看其源码会发现最终是调用了一个本地方法实现的线程中断；</p>
</li>
<li><p>interrupted()方法：返回目标线程是否中断的布尔值（通过本地方法实现），且返回后会重置中断状态为未中断；换句话说，如果连续两次调用该方法，则第二次调用将返回 false（在第一次调用已清除了其中断状态之后，且第二次调用检验完中断状态前，当前线程再次中断的情况除外）。</p>
</li>
<li><p>isInterrupted()方法：该方法返回的是线程中断与否的布尔值（通过本地方法实现），不会重置中断状态；</p>
</li>
</ul>
<p>其中，interrupt 方法是唯一能将中断状态设置为 true 的方法。静态方法 interrupted 会将当前线程的中断状态清除，但这个方法的命名极不直观，很容易造成误解，需要特别注意。</p>
<p>Thread.interrupt()方法仅仅是在当前线程中打了一个停止的标识将中断标志修改为true，并没有真正的停止线程。如果在此基础上进入堵塞状态（sleep(),wait(),join()）,马上就会抛出一个InterruptedException，且中断标志被清除，重新设置为false。记住一点，当调用Thread.interrupt()，还没有进行中断时，此时的中断标志位是true，当发生中断之后（执行到sleep(),wait(),join()），这个时候的中断标志位就是false了。</p>
<p>中断是通过调用Thread.interrupt()方法来做的. 这个方法通过修改了被调用线程的中断状态来告知那个线程, 说它被中断了. 对于非阻塞中的线程, 只是改变了中断状态, 即Thread.isInterrupted()将返回true; 对于可取消的阻塞状态中的线程, 比如等待在这些函数上的线程, Thread.sleep(), Object.wait(), Thread.join(), 这个线程收到中断信号后, 会抛出InterruptedException, 同时会把中断状态置回为false.但调用Thread.interrupted()会对中断状态进行复位。</p>
<h4 id="响应中断的方法和不响应中断的方法"><a href="#响应中断的方法和不响应中断的方法" class="headerlink" title="响应中断的方法和不响应中断的方法"></a>响应中断的方法和不响应中断的方法</h4><p>响应中断的方法： 线程进入等待或是超时等待的状态后，调用interrupt方法都是会响应中断的，所以响应中断的方法：Object.wait()、Thread.join、Thread.sleep、LockSupport.park的有参和无参方法。</p>
<p>不响应中断的方法：线程进入阻塞状态后，是不响应中断的，等待进入synchronized的方法或是代码块，都是会被阻塞的，此时不会响应中断，另外还有一个不响应中断的，那就是阻塞在ReentrantLock.lock方法里面的线程，也是不响应中断的，如果想要响应中断，可以使用ReentrantLock.lockInterruptibly方法。</p>
<p>其ReentrantLock底层是使用LockSupport.park方法进行等待的，前面说了LockSupport.park是响应中断的。</p>
<p>当调用interrupt方法时，会把中断状态设置为true，然后park方法会去判断中断状态，如果为true，就直接返回，然后往下继续执行，并不会抛出异常。注意，这里并不会清除中断标志。（Object.wait()、Thread.join、Thread.sleep方法则会清除中断状态）</p>
<p>当线程进入ReentrantLock.lock方法里面进行阻塞后，此时调用Thread.interrupt()方法之后，该线程是会被中断被唤醒的，但是唤醒之后，会调用LockSupport.park再次进入等待状态，所以仅从宏观（表面）上面看ReentrantLock.lock是不支持响应中断的，从微观（原理）上面讲ReentrantLock.lock内部确实中断了响应，但是还是会被迫进行等待状态。（当然，如果这期间抢到锁了，会在aqs里调用selfInterrupt补一下中断状态）</p>
<p><img src="https://i.loli.net/2020/11/25/osDpLKSBgYuPt4C.png" alt="image.png"></p>
<h2 id="java锁分类"><a href="#java锁分类" class="headerlink" title="java锁分类"></a>java锁分类</h2><p><img src="https://s3.ax1x.com/2020/11/20/DQg6k6.png" alt="DQg6k6.png"></p>
<p>synchronized是一个重量级的，阻塞的，非公平的，可重入的，排他的，悲观锁。</p>
<p>无锁即使cas。Java中的CAS操作，由sun.misc.Unsafe类里面的<code>compareAndSwapInt()</code>和<code>compareAndSwapLong()</code>等几个方法包装提供。HotSpot虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是无条件内联进去了。</p>
<p>当cas与自旋锁结合，便成为了原子类和aqs的核心，cas自旋做形成了不阻塞的锁。</p>
<p>自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。</p>
<p>synchronized已经详细说过，cas自旋锁我会在接下来的文章里详细说，这里主要再仔细说一下偏向锁 和轻量级锁。</p>
<h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><p>Java对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。</p>
<p>Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。</p>
<p>Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p>
<p><img src="https://s3.ax1x.com/2020/11/20/DQfW5t.png" alt="DQfW5t.png"></p>
<p>在代码即将进入同步块的时候，如果此同步对象没有被锁定(锁标志位为“01”状态)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的Mark Word的拷贝。然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。</p>
<p>如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位(Mark Word的最后两个比特)将转变为“00”，表示此对象处于轻量级锁定状态。</p>
<p>如果这个更新操作失败了，那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。如果 出现两条以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要膨胀为重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的就是指向重量级锁(互斥量)的指针，后面等待锁的线程也必须进入阻塞状态。</p>
<p>轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销;但如果确实存在锁竞争，除了互斥量的本身开销外，还额外发生了CAS操作的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。</p>
<h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><p>偏向锁中的“偏”，就是偏心的“偏”、偏袒的“偏”。它的意思是这个锁会偏向于第一个获得它的线 程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。</p>
<p>假设当前虚拟机启用了偏向锁，那么当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设置为“01”、把偏向模式设置为“1”，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作(例如加锁、解锁及对Mark Word的更新操作等)。</p>
<p>一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向(偏向模式设置为“ 0”)，撤销后标志位恢复到未锁定(标志位 为“01”)或轻量级锁定(标志位为“00”)的状态，后续的同步操作就按照上面介绍的轻量级锁那样去执行。</p>
<p><img src="https://s3.ax1x.com/2020/11/20/DQoPl6.png" alt="DQoPl6.png"></p>
]]></content>
      
        <categories>
            
            <category> 并发 </category>
            
            <category> jvm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jvm </tag>
            
            <tag> 并发 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[字节码增强技术]]></title>
      <url>/2020/11/17/class-file-improve/</url>
      <content type="html"><![CDATA[<p>不总结了，详见这篇文章：<a href="https://tech.meituan.com/2019/09/05/java-bytecode-enhancement.html" target="_blank" rel="noopener">https://tech.meituan.com/2019/09/05/java-bytecode-enhancement.html</a></p>
]]></content>
      
        <categories>
            
            <category> jvm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[gc调优-2]]></title>
      <url>/2020/11/16/improve-gc-2/</url>
      <content type="html"><![CDATA[<p>文章节选自<br><a href="https://tech.meituan.com/2020/11/12/java-9-cms-gc.html" target="_blank" rel="noopener">https://tech.meituan.com/2020/11/12/java-9-cms-gc.html</a><br><a href="https://tech.meituan.com/2017/12/29/jvm-optimize.html" target="_blank" rel="noopener">https://tech.meituan.com/2017/12/29/jvm-optimize.html</a></p>
<p>先放内存结构图，这个图更清晰些：</p>
<p><img src="https://s3.ax1x.com/2020/11/18/Deca8I.png" alt="Deca8I.png"></p>
<p>GC 主要工作在 Heap 区和 MetaSpace 区（上图蓝色部分），在 Direct Memory 中，如果使用的是 DirectByteBuffer，那么在分配内存不够时则是 GC 通过 Cleaner#clean 间接管理。</p>
<p>任何自动内存管理系统都会面临的步骤：为新对象分配空间，然后收集垃圾对象空间。</p>
<h2 id="GC-问题判断"><a href="#GC-问题判断" class="headerlink" title="GC 问题判断"></a>GC 问题判断</h2><h3 id="确定你算关注的要素"><a href="#确定你算关注的要素" class="headerlink" title="确定你算关注的要素"></a>确定你算关注的要素</h3><ul>
<li>延迟（Latency）： 也可以理解为最大停顿时间，即垃圾收集过程中一次 STW 的最长时间，越短越好，一定程度上可以接受频次的增大，GC 技术的主要发展方向。</li>
<li>吞吐量（Throughput）： 应用系统的生命周期内，由于 GC 线程会占用 Mutator 当前可用的 CPU 时钟周期，吞吐量即为 Mutator 有效花费的时间占系统总运行时间的百分比，例如系统运行了 100 min，GC 耗时 1 min，则系统吞吐量为 99%，吞吐量优先的收集器可以接受较长的停顿。</li>
<li>可用性 ：X个9，这个X是代表数字3~5。<ul>
<li>3个9：<code>(1-99.9%)*365*24=8.76小时</code>，表示该系统在连续运行1年时间里最多可能的业务中断时间是8.76小时。</li>
<li>4个9：<code>(1-99.99%)*365*24=0.876小时=52.6分钟</code>，表示该系统在连续运行1年时间里最多可能的业务中断时间是52.6分钟。</li>
<li>5个9：<code>(1-99.999%)*365*24*60=5.26分钟</code>，表示该系统在连续运行1年时间里最多可能的业务中断时间是5.26分钟。</li>
</ul>
</li>
</ul>
<p>目前各大互联网公司的系统基本都更追求低延时，避免一次 GC 停顿的时间过长对用户体验造成损失，衡量指标需要结合一下应用服务的 SLA，主要如下两点来判断：</p>
<p><img src="https://s3.ax1x.com/2020/11/18/Dm1bKx.png" alt="Dm1bKx.png"></p>
<p>简而言之，即为一次停顿的时间不超过应用服务的 TP9999，GC 的吞吐量不小于 99.99%。举个例子，假设某个服务 A 的 TP9999 为 80 ms，平均 GC 停顿为 30 ms，那么该服务的最大停顿时间最好不要超过 80 ms，GC 频次控制在 5 min 以上一次。如果满足不了，那就需要调优或者通过更多资源来进行并联冗余。（大家可以先停下来，看看监控平台上面的 gc.meantime 分钟级别指标，如果超过了 6 ms 那单机 GC 吞吐量就达不到 4 个 9 了。）</p>
<p>备注：除了这两个指标之外还有 Footprint（资源量大小测量）、反应速度等指标，互联网这种实时系统追求低延迟，而很多嵌入式系统则追求 Footprint。</p>
<h3 id="GC可能带来的影响"><a href="#GC可能带来的影响" class="headerlink" title="GC可能带来的影响"></a>GC可能带来的影响</h3><p>举例：假设单位时间T内发生一次持续25ms的GC，接口平均响应时间为50ms，且请求均匀到达，根据下图所示：</p>
<p><img src="https://s3.ax1x.com/2020/11/18/De5m1H.png" alt="De5m1H.png"></p>
<p>那么有<code>(50ms+25ms)/T</code>比例的请求会受GC影响，其中GC前的50ms内到达的请求都会增加25ms，GC期间的25ms内到达的请求，会增加0-25ms不等，<code>如果时间T内发生N次GC，受GC影响请求占比=(接口响应时间+GC时间)×N/T</code> 。可见无论降低单次GC时间还是降低GC次数N都可以有效减少GC对响应时间的影响。</p>
<h3 id="判断是不是-GC-引发的问题"><a href="#判断是不是-GC-引发的问题" class="headerlink" title="判断是不是 GC 引发的问题"></a>判断是不是 GC 引发的问题</h3><p>在一次 GC 问题处理的过程中，如何判断是 GC 导致的故障，还是系统本身引发 GC 问题。“GC 耗时增大、线程 Block 增多、慢查询增多、CPU 负载高等四个表象，如何判断哪个是根因？”：</p>
<ul>
<li>时序分析： 先发生的事件是根因的概率更大，通过监控手段分析各个指标的异常时间点，还原事件时间线，如先观察到 CPU 负载高（要有足够的时间 Gap），那么整个问题影响链就可能是：CPU 负载高 -&gt; 慢查询增多 -&gt; GC 耗时增大 -&gt; 线程Block增多 -&gt; RT 上涨。</li>
<li>概率分析： 使用统计概率学，结合历史问题的经验进行推断，由近到远按类型分析，如过往慢查的问题比较多，那么整个问题影响链就可能是：慢查询增多 -&gt; GC 耗时增大 -&gt; CPU 负载高 -&gt; 线程 Block 增多 -&gt; RT上涨。</li>
<li>实验分析： 通过故障演练等方式对问题现场进行模拟，触发其中部分条件（一个或多个），观察是否会发生问题，如只触发线程 Block 就会发生问题，那么整个问题影响链就可能是：线程Block增多 -&gt; CPU 负载高 -&gt; 慢查询增多 -&gt; GC 耗时增大 -&gt; RT 上涨。</li>
<li>反证分析： 对其中某一表象进行反证分析，即判断表象的发不发生跟结果是否有相关性，例如我们从整个集群的角度观察到某些节点慢查和 CPU 都正常，但也出了问题，那么整个问题影响链就可能是：GC 耗时增大 -&gt; 线程 Block 增多 -&gt; RT 上涨。</li>
</ul>
<p>不同的根因，后续的分析方法是完全不同的。如果是 CPU 负载高那可能需要用火焰图看下热点、如果是慢查询增多那可能需要看下 DB 情况、如果是线程 Block 引起那可能需要看下锁竞争的情况，最后如果各个表象证明都没有问题，那可能 GC 确实存在问题，可以继续分析 GC 问题了。</p>
<h3 id="GC-问题分类"><a href="#GC-问题分类" class="headerlink" title="GC 问题分类"></a>GC 问题分类</h3><ul>
<li>Unexpected GC： 意外发生的 GC，实际上不需要发生，我们可以通过一些手段去避免。<ul>
<li>Space Shock： 空间震荡问题，参见“场景一：动态扩容引起的空间震荡”。</li>
<li>Explicit GC： 显示执行 GC 问题，参见“场景二：显式 GC 的去与留”。</li>
</ul>
</li>
<li>Partial GC： 部分收集操作的 GC，只对某些分代/分区进行回收。<ul>
<li>Young GC： 分代收集里面的 Young 区收集动作，也可以叫做 Minor GC。<ul>
<li>ParNew： Young GC 频繁，参见“场景四：过早晋升”。</li>
</ul>
</li>
<li>Old GC： 分代收集里面的 Old 区收集动作，也可以叫做 Major GC，有些也会叫做 Full GC，但其实这种叫法是不规范的，在 CMS 发生 Foreground GC 时才是 Full GC，CMSScavengeBeforeRemark 参数也只是在 Remark 前触发一次Young GC。<ul>
<li>CMS： Old GC 频繁，参见“场景五：CMS Old GC 频繁”。</li>
<li>CMS： Old GC 不频繁但单次耗时大，参见“场景六：单次 CMS Old GC 耗时长”。</li>
</ul>
</li>
</ul>
</li>
<li>Full GC： 全量收集的 GC，对整个堆进行回收，STW 时间会比较长，一旦发生，影响较大，也可以叫做 Major GC，参见“场景七：内存碎片&amp;收集器退化”。</li>
<li>MetaSpace： 元空间回收引发问题，参见“场景三：MetaSpace 区 OOM”。</li>
<li>Direct Memory： 直接内存（也可以称作为堆外内存）回收引发问题，参见“场景八：堆外内存 OOM”。</li>
<li>JNI： 本地 Native 方法引发问题，参见“场景九：JNI 引发的 GC 问题”。</li>
</ul>
<h3 id="参数基本策略"><a href="#参数基本策略" class="headerlink" title="参数基本策略"></a>参数基本策略</h3><p>分析活跃数据的大小是很好的切入点。</p>
<p>活跃数据的大小是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是Full GC后堆中老年代占用空间的大小。可以通过GC日志中Full GC之后老年代数据大小得出，比较准确的方法是在程序稳定后，多次获取GC数据，通过取平均值的方式计算活跃数据的大小。活跃数据和各分区之间的比例关系如下：<br>|空间|倍数|<br>|—|—|<br>|总大小|3-4 倍活跃数据的大小|<br>|新生代|1-1.5 活跃数据的大小|<br>|老年代|2-3 倍活跃数据的大小|<br>|永久代|1.2-1.5 倍Full GC后的永久代空间占用|</p>
<p>例如，根据GC日志获得老年代的活跃数据大小为300M，那么各分区大小可以设为：</p>
<p><code>总堆：1200MB = 300MB × 4* 新生代：450MB = 300MB × 1.5* 老年代： 750MB = 1200MB - 450MB*</code></p>
<h3 id="GC-Cause"><a href="#GC-Cause" class="headerlink" title="GC Cause"></a>GC Cause</h3><p>重点需要关注的几个GC Cause：</p>
<ul>
<li>System.gc()： 手动触发GC操作。</li>
<li>CMS： CMS GC 在执行过程中的一些动作，重点关注 CMS Initial Mark 和 CMS Final Remark 两个 STW 阶段。</li>
<li>Promotion Failure： Old 区没有足够的空间分配给 Young 区晋升的对象（即使总可用内存足够大）。</li>
<li>Concurrent Mode Failure： CMS GC 运行期间，Old 区预留的空间不足以分配给新的对象，此时收集器会发生退化，严重影响 GC 性能，下面的一个案例即为这种场景。</li>
<li>GCLocker Initiated GC： 如果线程执行在 JNI 临界区时，刚好需要进行 GC，此时 GC Locker 将会阻止 GC 的发生，同时阻止其他线程进入 JNI 临界区，直到最后一个线程退出临界区时触发一次 GC。</li>
</ul>
<h3 id="OutOfMemoryError"><a href="#OutOfMemoryError" class="headerlink" title="OutOfMemoryError"></a>OutOfMemoryError</h3><ul>
<li>java.lang.OutOfMemoryError: Java heap space：表示Java堆空间不够，当应用程序申请更多的内存，而Java堆内存已经无法满足应用程序对内存的需要，将抛出这种异常。</li>
<li>java.lang.OutOfMemoryError: PermGen space：表示Java永久带（方法区）空间不够，永久带用于存放类的字节码和长常量池，类的字节码加载后存放在这个区域，这和存放对象实例的堆区是不同的，大多数JVM的实现都不会对永久带进行垃圾回收，因此，只要类加载的过多就会出现这个问题。一般的应用程序都不会产生这个错误，然而，对于Web服务器来讲，会产生有大量的JSP，JSP在运行时被动态的编译成Java Servlet类，然后加载到方法区，因此，太多的JSP的Web工程可能产生这个异常。</li>
<li>java.lang.OutOfMemoryError: unable to create new native thread：本质原因是创建了太多的线程，而能创建的线程数是有限制的，导致了这种异常的发生。</li>
<li>java.lang.OutOfMemoryError：GC overhead limit exceeded：在并行或者并发回收器在GC回收时间过长、超过98%的时间用来做GC并且回收了不到2%的堆内存，然后抛出这种异常进行提前预警，用来避免内存过小造成应用不能正常工作。</li>
</ul>
<h3 id="常见场景分析与解决"><a href="#常见场景分析与解决" class="headerlink" title="常见场景分析与解决"></a>常见场景分析与解决</h3><h4 id="动态扩容引起的空间震荡"><a href="#动态扩容引起的空间震荡" class="headerlink" title="动态扩容引起的空间震荡"></a>动态扩容引起的空间震荡</h4><h5 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h5><p>服务刚刚启动时 GC 次数较多，最大空间剩余很多但是依然发生 GC，这种情况我们可以通过观察 GC 日志或者通过监控工具来观察堆的空间变化情况即可。GC Cause 一般为 Allocation Failure，且在 GC 日志中会观察到经历一次 GC ，堆内各个空间的大小会被调整，如下图所示：</p>
<p><img src="https://s3.ax1x.com/2020/11/18/DeqvQO.png" alt="DeqvQO.png"></p>
<h5 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h5><p>在 JVM 的参数中 -Xms 和 -Xmx 设置的不一致，在初始化时只会初始 -Xms 大小的空间存储信息，每当空间不够用时再向操作系统申请，这样的话必然要进行一次 GC。</p>
<p>另外，如果空间剩余很多时也会进行缩容操作，JVM 通过 -XX:MinHeapFreeRatio 和 -XX:MaxHeapFreeRatio 来控制扩容和缩容的比例，调节这两个值也可以控制伸缩的时机。</p>
<h5 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h5><p>定位：观察 CMS GC 触发时间点 Old/MetaSpace 区的 committed 占比是不是一个固定的值，或者像上文提到的观察总的内存使用率也可以。</p>
<p>解决：尽量将成对出现的空间大小配置参数设置成固定的，如 -Xms 和 -Xmx，-XX:MaxNewSize 和 -XX:NewSize，-XX:MetaSpaceSize 和 -XX:MaxMetaSpaceSize 等。</p>
<h5 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h5><p>一般来说，我们需要保证 Java 虚拟机的堆是稳定的，确保 -Xms 和 -Xmx 设置的是一个值（即初始值和最大值一致），获得一个稳定的堆，同理在 MetaSpace 区也有类似的问题。不过在不追求停顿时间的情况下震荡的空间也是有利的，可以动态地伸缩以节省空间，例如作为富客户端的 Java 应用。</p>
<h4 id="显式-GC-的去与留"><a href="#显式-GC-的去与留" class="headerlink" title="显式 GC 的去与留"></a>显式 GC 的去与留</h4><h5 id="现象-1"><a href="#现象-1" class="headerlink" title="现象"></a>现象</h5><p>除了扩容缩容会触发 CMS GC 之外，还有 Old 区达到回收阈值、MetaSpace 空间不足、Young 区晋升失败、大对象担保失败等几种触发条件，如果这些情况都没有发生却触发了 GC ？这种情况有可能是代码中手动调用了 System.gc 方法，此时可以找到 GC 日志中的 GC Cause 确认下。那么这种 GC 到底有没有问题，翻看网上的一些资料，有人说可以添加 -XX:+DisableExplicitGC 参数来避免这种 GC，也有人说不能加这个参数，加了就会影响 Native Memory 的回收。先说结论，笔者这里建议保留 System.gc，那为什么要保留？我们一起来分析下。</p>
<h5 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h5><p>找到 System.gc 在 Hotspot 中的源码，可以发现增加 -XX:+DisableExplicitGC 参数后，这个方法变成了一个空方法，如果没有加的话便会调用 Universe::heap()::collect 方法，继续跟进到这个方法中，发现 System.gc 会引发一次 STW 的 Full GC，对整个堆做收集。</p>
<p>保留 System.gc</p>
<p>此处补充一个知识点，CMS GC 共分为 Background 和 Foreground 两种模式，前者就是我们常规理解中的并发收集，可以不影响正常的业务线程运行，但 Foreground Collector 却有很大的差异，他会进行一次压缩式 GC。此压缩式 GC 使用的是跟 Serial Old GC 一样的 Lisp2 算法，其使用 Mark-Compact 来做 Full GC，一般称之为 MSC（Mark-Sweep-Compact），它收集的范围是 Java 堆的 Young 区和 Old 区以及 MetaSpace。 compact 的代价是巨大的，那么使用 Foreground Collector 时将会带来非常长的 STW。如果在应用程序中 System.gc 被频繁调用，那就非常危险了。</p>
<p>去掉 System.gc</p>
<p>如果禁用掉的话就会带来另外一个内存泄漏问题，此时就需要说一下 DirectByteBuffer，它有着零拷贝等特点，被 Netty 等各种 NIO 框架使用，会使用到堆外内存。堆内存由 JVM 自己管理，堆外内存必须要手动释放，DirectByteBuffer 没有 Finalizer，它的 Native Memory 的清理工作是通过 sun.misc.Cleaner 自动完成的，是一种基于 PhantomReference 的清理工具，比普通的 Finalizer 轻量些。</p>
<p>为 DirectByteBuffer 分配空间过程中会显式调用 System.gc ，希望通过 Full GC 来强迫已经无用的 DirectByteBuffer 对象释放掉它们关联的 Native Memory，下面为代码实现：</p>
<pre><code class="java">// These methods should be called whenever direct memory is allocated or
// freed.  They allow the user to control the amount of direct memory
// which a process may access.  All sizes are specified in bytes.
static void reserveMemory(long size) {

    synchronized (Bits.class) {
        if (!memoryLimitSet &amp;&amp; VM.isBooted()) {
            maxMemory = VM.maxDirectMemory();
            memoryLimitSet = true;
        }
        if (size &lt;= maxMemory - reservedMemory) {
            reservedMemory += size;
            return;
        }
    }

    System.gc();
    try {
        Thread.sleep(100);
    } catch (InterruptedException x) {
        // Restore interrupt status
        Thread.currentThread().interrupt();
    }
    synchronized (Bits.class) {
        if (reservedMemory + size &gt; maxMemory)
            throw new OutOfMemoryError(&quot;Direct buffer memory&quot;);
        reservedMemory += size;
    }

}
</code></pre>
<p>HotSpot VM 只会在 Old GC 的时候才会对 Old 中的对象做 Reference Processing，而在 Young GC 时只会对 Young 里的对象做 Reference Processing。Young 中的 DirectByteBuffer 对象会在 Young GC 时被处理，也就是说，做 CMS GC 的话会对 Old 做 Reference Processing，进而能触发 Cleaner 对已死的 DirectByteBuffer 对象做清理工作。但如果很长一段时间里没做过 GC 或者只做了 Young GC 的话, 则不会在 Old 触发 Cleaner 的工作，那么就可能让本来已经死亡，但已经晋升到 Old 的 DirectByteBuffer 关联的 Native Memory 得不到及时释放。这几个实现特征使得依赖于 System.gc 触发 GC 来保证 DirectByteMemory 的清理工作能及时完成。如果打开了 -XX:+DisableExplicitGC，清理工作就可能得不到及时完成，于是就有发生 Direct Memory 的 OOM。</p>
<h5 id="策略-1"><a href="#策略-1" class="headerlink" title="策略"></a>策略</h5><p>通过上面的分析看到，无论是保留还是去掉都会有一定的风险点，不过目前互联网中的 RPC 通信会大量使用 NIO，所以笔者在这里建议保留。此外 JVM 还提供了 -XX:+ExplicitGCInvokesConcurrent 和 -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses 参数来将 System.gc 的触发类型从 Foreground 改为 Background，同时 Background 也会做 Reference Processing，这样的话就能大幅降低了 STW 开销，同时也不会发生 NIO Direct Memory OOM。</p>
<h5 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h5><p>不止 CMS，在 G1 或 ZGC中开启 ExplicitGCInvokesConcurrent 模式，都会采用高性能的并发收集方式进行收集，不过还是建议在代码规范方面也要做好约束，规范好 System.gc 的使用。</p>
<h4 id="MetaSpace-区-OOM"><a href="#MetaSpace-区-OOM" class="headerlink" title="MetaSpace 区 OOM"></a>MetaSpace 区 OOM</h4><h5 id="现象-2"><a href="#现象-2" class="headerlink" title="现象"></a>现象</h5><p>JVM 在启动后或者某个时间点开始，MetaSpace 的已使用大小在持续增长，同时每次 GC 也无法释放，调大 MetaSpace 空间也无法彻底解决。</p>
<h5 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h5><p>在讨论为什么会 OOM 之前，我们先来看一下这个区里面会存什么数据，Java7 之前字符串常量池被放到了 Perm 区，所有被 intern 的 String 都会被存在这里，由于 String.intern 是不受控的，所以 -XX:MaxPermSize 的值也不太好设置，经常会出现 java.lang.OutOfMemoryError: PermGen space 异常，所以在 Java7 之后常量池等字面量（Literal）、类静态变量（Class Static）、符号引用（Symbols Reference）等几项被移到 Heap 中。而 Java8 之后 PermGen 也被移除，取而代之的是 MetaSpace。</p>
<p>在最底层，JVM 通过 mmap 接口向操作系统申请内存映射，每次申请 2MB 空间，这里是虚拟内存映射，不是真的就消耗了主存的 2MB，只有之后在使用的时候才会真的消耗内存。申请的这些内存放到一个链表中 VirtualSpaceList，作为其中的一个 Node。</p>
<p>在上层，MetaSpace 主要由 Klass Metaspace 和 NoKlass Metaspace 两大部分组成。</p>
<ul>
<li>Klass MetaSpace： 就是用来存 Klass 的，就是 Class 文件在 JVM 里的运行时数据结构，这部分默认放在 Compressed Class Pointer Space 中，是一块连续的内存区域，紧接着 Heap。Compressed Class Pointer Space 不是必须有的，如果设置了 -XX:-UseCompressedClassPointers，或者 -Xmx 设置大于 32 G，就不会有这块内存，这种情况下 Klass 都会存在 NoKlass Metaspace 里。</li>
<li>NoKlass MetaSpace： 专门来存 Klass 相关的其他的内容，比如 Method，ConstantPool 等，可以由多块不连续的内存组成。虽然叫做 NoKlass Metaspace，但是也其实可以存 Klass 的内容，上面已经提到了对应场景。</li>
</ul>
<p>MetaSpace 的对象为什么无法释放，我们看下面两点：</p>
<ul>
<li><p>MetaSpace 内存管理： 类和其元数据的生命周期与其对应的类加载器相同，只要类的类加载器是存活的，在 Metaspace 中的类元数据也是存活的，不能被回收。每个加载器有单独的存储空间，通过 ClassLoaderMetaspace 来进行管理 SpaceManager* 的指针，相互隔离的。</p>
</li>
<li><p>MetaSpace 弹性伸缩： 由于 MetaSpace 空间和 Heap 并不在一起，所以这块的空间可以不用设置或者单独设置，一般情况下避免 MetaSpace 耗尽 VM 内存都会设置一个 MaxMetaSpaceSize，在运行过程中，如果实际大小小于这个值，JVM 就会通过 -XX:MinMetaspaceFreeRatio 和 -XX:MaxMetaspaceFreeRatio 两个参数动态控制整个 MetaSpace 的大小。</p>
</li>
</ul>
<p>由场景一可知，为了避免弹性伸缩带来的额外 GC 消耗，我们会将 -XX:MetaSpaceSize 和 -XX:MaxMetaSpaceSize 两个值设置为固定的，但是这样也会导致在空间不够的时候无法扩容，然后频繁地触发 GC，最终 OOM。所以关键原因就是 ClassLoader 不停地在内存中 load 了新的 Class ，一般这种问题都发生在动态类加载等情况上。</p>
<h5 id="策略-2"><a href="#策略-2" class="headerlink" title="策略"></a>策略</h5><p>了解大概什么原因后，如何定位和解决就很简单了，可以 dump 快照之后通过 JProfiler 或 MAT 观察 Classes 的 Histogram（直方图） 即可，或者直接通过命令即可定位， jcmd 打几次 Histogram 的图，看一下具体是哪个包下的 Class 增加较多就可以定位了。不过有时候也要结合InstBytes、KlassBytes、Bytecodes、MethodAll 等几项指标综合来看下。</p>
<p>如果无法从整体的角度定位，可以添加 -XX:+TraceClassLoading 和 -XX:+TraceClassUnLoading 参数观察详细的类加载和卸载信息。</p>
<h5 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h5><p>原理理解比较复杂，但定位和解决问题会比较简单，经常会出问题的几个点有 Orika 的 classMap、JSON 的 ASMSerializer、Groovy 动态加载类等，基本都集中在反射、Javasisit 字节码增强、CGLIB 动态代理、OSGi 自定义类加载器等的技术点上。另外就是及时给 MetaSpace 区的使用率加一个监控，如果指标有波动提前发现并解决问题。</p>
<h4 id="过早晋升"><a href="#过早晋升" class="headerlink" title="过早晋升"></a>过早晋升</h4><h5 id="现象-3"><a href="#现象-3" class="headerlink" title="现象"></a>现象</h5><p>这种场景主要发生在分代的收集器上面，专业的术语称为“Premature Promotion”。90% 的对象朝生夕死，只有在 Young 区经历过几次 GC 的洗礼后才会晋升到 Old 区，每经历一次 GC 对象的 GC Age 就会增长 1，最大通过 -XX:MaxTenuringThreshold 来控制。</p>
<p>过早晋升一般不会直接影响 GC，总会伴随着浮动垃圾、大对象担保失败等问题，但这些问题不是立刻发生的，我们可以观察以下几种现象来判断是否发生了过早晋升。</p>
<p>分配速率接近于晋升速率，对象晋升年龄较小。</p>
<p>GC 日志中出现“Desired survivor size 107347968 bytes, new threshold 1(max 6)”等信息，说明此时经历过一次 GC 就会放到 Old 区。</p>
<p>Full GC 比较频繁，且经历过一次 GC 之后 Old 区的变化比例非常大。</p>
<p>比如说 Old 区触发的回收阈值是 80%，经历过一次 GC 之后下降到了 10%，这就说明 Old 区的 70% 的对象存活时间其实很短。</p>
<p>过早晋升的危害：</p>
<ul>
<li>Young GC 频繁，总的吞吐量下降。</li>
<li>Full GC 频繁，可能会有较大停顿。</li>
</ul>
<h5 id="原因-3"><a href="#原因-3" class="headerlink" title="原因"></a>原因</h5><p>主要的原因有以下两点：</p>
<ul>
<li><p>Young/Eden 区过小： 过小的直接后果就是 Eden 被装满的时间变短，本应该回收的对象参与了 GC 并晋升，Young GC 采用的是复制算法，copying 耗时远大于 mark，也就是 Young GC 耗时本质上就是 copy 的时间（CMS 扫描 Card Table 或 G1 扫描 Remember Set 出问题的情况另说），没来及回收的对象增大了回收的代价，所以 Young GC 时间增加，同时又无法快速释放空间，Young GC 次数也跟着增加。</p>
</li>
<li><p>分配速率过大： 可以观察出问题前后 Mutator 的分配速率，如果有明显波动可以尝试观察网卡流量、存储类中间件慢查询日志等信息，看是否有大量数据被加载到内存中。</p>
</li>
</ul>
<p>同时无法 GC 掉对象还会带来另外一个问题，引发动态年龄计算：JVM 通过 -XX:MaxTenuringThreshold 参数来控制晋升年龄，每经过一次 GC，年龄就会加一，达到最大年龄就可以进入 Old 区，最大值为 15（因为 JVM 中使用 4 个比特来表示对象的年龄）。设定固定的 MaxTenuringThreshold 值作为晋升条件：</p>
<ul>
<li><p>MaxTenuringThreshold 如果设置得过大，原本应该晋升的对象一直停留在 Survivor 区，直到 Survivor 区溢出，一旦溢出发生，Eden + Survivor 中对象将不再依据年龄全部提升到 Old 区，这样对象老化的机制就失效了。</p>
</li>
<li><p>MaxTenuringThreshold 如果设置得过小，过早晋升即对象不能在 Young 区充分被回收，大量短期对象被晋升到 Old 区，Old 区空间迅速增长，引起频繁的 Major GC，分代回收失去了意义，严重影响 GC 性能。</p>
</li>
</ul>
<p>相同应用在不同时间的表现不同，特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面问题，所以 Hotspot 会使用动态计算的方式来调整晋升的阈值。</p>
<h5 id="策略-3"><a href="#策略-3" class="headerlink" title="策略"></a>策略</h5><p>知道问题原因后我们就有解决的方向，如果是 Young/Eden 区过小，我们可以在总的 Heap 内存不变的情况下适当增大 Young 区，具体怎么增加？一般情况下 Old 的大小应当为活跃对象的 2~3 倍左右，考虑到浮动垃圾问题最好在 3 倍左右，剩下的都可以分给 Young 区。</p>
<p>拿笔者的一次典型过早晋升优化来看，原配置为 Young 1.2G + Old 2.8G，通过观察 CMS GC 的情况找到存活对象大概为 300~400M，于是调整 Old 1.5G 左右，剩下 2.5G 分给 Young 区。仅仅调了一个 Young 区大小参数（-Xmn），整个 JVM 一分钟 Young GC 从 26 次降低到了 11 次，单次时间也没有增加，总的 GC 时间从 1100ms 降低到了 500ms，CMS GC 次数也从 40 分钟左右一次降低到了 7 小时 30 分钟一次。</p>
<p>如果是分配速率过大：</p>
<ul>
<li>偶发较大：通过内存分析工具找到问题代码，从业务逻辑上做一些优化。</li>
<li>一直较大：当前的 Collector 已经不满足 Mutator 的期望了，这种情况要么扩容 Mutator 的 VM，要么调整 GC 收集器类型或加大空间。</li>
</ul>
<h5 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h5><p>过早晋升问题一般不会特别明显，但日积月累之后可能会爆发一波收集器退化之类的问题，所以我们还是要提前避免掉的，可以看看自己系统里面是否有这些现象，如果比较匹配的话，可以尝试优化一下。一行代码优化的 ROI 还是很高的。</p>
<p>如果在观察 Old 区前后比例变化的过程中，发现可以回收的比例非常小，如从 80% 只回收到了 60%，说明我们大部分对象都是存活的，Old 区的空间可以适当调大些。</p>
<h4 id="CMS-Old-GC-频繁"><a href="#CMS-Old-GC-频繁" class="headerlink" title="CMS Old GC 频繁"></a>CMS Old GC 频繁</h4><h5 id="现象-4"><a href="#现象-4" class="headerlink" title="现象"></a>现象</h5><p>Old 区频繁的做 CMS GC，但是每次耗时不是特别长，整体最大 STW 也在可接受范围内，但由于 GC 太频繁导致吞吐下降比较多。</p>
<h5 id="原因-4"><a href="#原因-4" class="headerlink" title="原因"></a>原因</h5><p>这种情况比较常见，基本都是一次 Young GC 完成后，负责处理 CMS GC 的一个后台线程 concurrentMarkSweepThread 会不断地轮询，使用 shouldConcurrentCollect() 方法做一次检测，判断是否达到了回收条件。如果达到条件，使用 collect_in_background() 启动一次 Background 模式 GC。轮询的判断是使用 sleepBeforeNextCycle() 方法，间隔周期为 -XX:CMSWaitDuration 决定，默认为2s。</p>
<p>分析其中逻辑判断是否触发 GC，分为以下几种情况：</p>
<ul>
<li><p>触发 CMS GC： 通过调用 _collector-&gt;collect_in_background() 进行触发 Background GC 。</p>
<ul>
<li><p>CMS 默认采用 JVM 运行时的统计数据判断是否需要触发 CMS GC，如果需要根据 -XX:CMSInitiatingOccupancyFraction 的值进行判断，需要设置参数 -XX:+UseCMSInitiatingOccupancyOnly。</p>
</li>
<li><p>如果开启了 -XX:UseCMSInitiatingOccupancyOnly 参数，判断当前 Old 区使用率是否大于阈值，则触发 CMS GC，该阈值可以通过参数 -XX:CMSInitiatingOccupancyFraction 进行设置，如果没有设置，默认为 92%。</p>
</li>
<li><p>如果之前的 Young GC 失败过，或者下次 Young 区执行 Young GC 可能失败，这两种情况下都需要触发 CMS GC。</p>
</li>
<li><p>CMS 默认不会对 MetaSpace 或 Perm 进行垃圾收集，如果希望对这些区域进行垃圾收集，需要设置参数 -XX:+CMSClassUnloadingEnabled。</p>
</li>
</ul>
</li>
<li><p>触发 Full GC： 直接进行 Full GC，这种情况到场景七中展开说明。</p>
<ul>
<li><p>如果 _full_gc_requested 为真，说明有明确的需求要进行 GC，比如调用 System.gc。</p>
</li>
<li><p>在 Eden 区为对象或 TLAB 分配内存失败，导致一次 Young GC，在 GenCollectorPolicy 类的 satisfy_failed_allocation() 方法中进行判断。</p>
</li>
</ul>
</li>
</ul>
<p>大家可以看一下源码中的日志打印，通过日志我们就可以比较清楚地知道具体的原因，然后就可以着手分析了。</p>
<h5 id="策略-4"><a href="#策略-4" class="headerlink" title="策略"></a>策略</h5><p>我们这里还是拿最常见的达到回收比例这个场景来说，与过早晋升不同的是这些对象确实存活了一段时间，Survival Time 超过了 TP9999 时间，但是又达不到长期存活，如各种数据库、网络链接，带有失效时间的缓存等。</p>
<p>处理这种常规内存泄漏问题基本是一个思路，主要步骤如下：</p>
<p><img src="https://s3.ax1x.com/2020/11/18/DmudMT.png" alt="DmudMT.png"></p>
<h4 id="单次-CMS-Old-GC-耗时长"><a href="#单次-CMS-Old-GC-耗时长" class="headerlink" title="单次 CMS Old GC 耗时长"></a>单次 CMS Old GC 耗时长</h4><h5 id="现象-5"><a href="#现象-5" class="headerlink" title="现象"></a>现象</h5><p>CMS GC 单次 STW 最大超过 1000ms，不会频繁发生，如下图所示最长达到了 8000ms。某些场景下会引起“雪崩效应”，这种场景非常危险，我们应该尽量避免出现。</p>
<h5 id="原因-5"><a href="#原因-5" class="headerlink" title="原因"></a>原因</h5><p>CMS 在回收的过程中，STW 的阶段主要是 Init Mark 和 Final Remark 这两个阶段，也是导致 CMS Old GC 最多的原因，另外有些情况就是在 STW 前等待 Mutator 的线程到达 SafePoint 也会导致时间过长，但这种情况较少，我们在此处主要讨论前者。发生收集器退化或者碎片压缩的场景请看场景七。</p>
<ul>
<li>CMS Init Mark执行步骤<br><img src="https://s3.ax1x.com/2020/11/18/DmKMf1.png" alt="DmKMf1.png"><br>整个过程比较简单，从 GC Root 出发标记 Old 中的对象，处理完成后借助 BitMap 处理下 Young 区对 Old 区的引用，整个过程基本都比较快，很少会有较大的停顿。</li>
<li>CMS Final Remark 执行步骤<br><img src="https://s3.ax1x.com/2020/11/18/DmK1l6.png" alt="DmK1l6.png"><br>Final Remark 是最终的第二次标记，这种情况只有在 Background GC 执行了 InitialMarking 步骤的情形下才会执行，如果是 Foreground GC 执行的 InitialMarking 步骤则不需要再次执行 FinalRemark。Final Remark 的开始阶段与 Init Mark 处理的流程相同，但是后续多了 Card Table 遍历、Reference 实例的清理并将其加入到 Reference 维护的 pend_list 中，如果要收集元数据信息，还要清理 SystemDictionary、CodeCache、SymbolTable、StringTable 等组件中不再使用的资源。</li>
</ul>
<h5 id="策略-5"><a href="#策略-5" class="headerlink" title="策略"></a>策略</h5><p>知道了两个 STW 过程执行流程，我们分析解决就比较简单了，由于大部分问题都出在 Final Remark 过程，这里我们也拿这个场景来举例，主要步骤：</p>
<p>【方向】 观察详细 GC 日志，找到出问题时 Final Remark 日志，分析下 Reference 处理和元数据处理 real 耗时是否正常，详细信息需要通过 -XX:+PrintReferenceGC 参数开启。基本在日志里面就能定位到大概是哪个方向出了问题，耗时超过 10% 的就需要关注。</p>
<p>【根因】 有了具体的方向我们就可以进行深入的分析，一般来说最容易出问题的地方就是 Reference 中的 FinalReference 和元数据信息处理中的 scrub symbol table 两个阶段，想要找到具体问题代码就需要内存分析工具 MAT 或 JProfiler 了，注意要 dump 即将开始 CMS GC 的堆。在用 MAT 等工具前也可以先用命令行看下对象 Histogram，有可能直接就能定位问题。</p>
<ul>
<li><p>对 FinalReference 的分析主要观察 java.lang.ref.Finalizer 对象的 dominator tree，找到泄漏的来源。经常会出现问题的几个点有 Socket 的 SocksSocketImpl 、Jersey 的 ClientRuntime、MySQL 的 ConnectionImpl 等等。</p>
</li>
<li><p>scrub symbol table 表示清理元数据符号引用耗时，符号引用是 Java 代码被编译成字节码时，方法在 JVM 中的表现形式，生命周期一般与 Class 一致，当 _should_unload_classes 被设置为 true 时在 CMSCollector::refProcessingWork() 中与 Class Unload、String Table 一起被处理。</p>
</li>
</ul>
<p>【策略】 知道 GC 耗时的根因就比较好处理了，这种问题不会大面积同时爆发，不过有很多时候单台 STW 的时间会比较长，如果业务影响比较大，及时摘掉流量，具体后续优化策略如下：</p>
<ul>
<li><p>FinalReference：找到内存来源后通过优化代码的方式来解决，如果短时间无法定位可以增加 -XX:+ParallelRefProcEnabled 对 Reference 进行并行处理。</p>
</li>
<li><p>symbol table：观察 MetaSpace 区的历史使用峰值，以及每次 GC 前后的回收情况，一般没有使用动态类加载或者 DSL 处理等，MetaSpace 的使用率上不会有什么变化，这种情况可以通过 -XX:-CMSClassUnloadingEnabled 来避免 MetaSpace 的处理，JDK8 会默认开启 CMSClassUnloadingEnabled，这会使得 CMS 在 CMS-Remark 阶段尝试进行类的卸载。</p>
</li>
</ul>
<h5 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h5><p>正常情况进行的 Background CMS GC，出现问题基本都集中在 Reference 和 Class 等元数据处理上，在 Reference 类的问题处理方面，不管是 FinalReference，还是 SoftReference、WeakReference 核心的手段就是找准时机 dump 快照，然后用内存分析工具来分析。Class 处理方面目前除了关闭类卸载开关，没有太好的方法。</p>
<p>在 G1 中同样有 Reference 的问题，可以观察日志中的 Ref Proc，处理方法与 CMS 类似。</p>
<h4 id="内存碎片-amp-收集器退化"><a href="#内存碎片-amp-收集器退化" class="headerlink" title="内存碎片&amp;收集器退化"></a>内存碎片&amp;收集器退化</h4><h5 id="现象-6"><a href="#现象-6" class="headerlink" title="现象"></a>现象</h5><p>并发的 CMS GC 算法，退化为 Foreground 单线程串行 GC 模式，STW 时间超长，有时会长达十几秒。其中 CMS 收集器退化后单线程串行 GC 算法有两种：</p>
<p>带压缩动作的算法，称为 MSC，上面我们介绍过，使用标记-清理-压缩，单线程全暂停的方式，对整个堆进行垃圾收集，也就是真正意义上的 Full GC，暂停时间要长于普通 CMS。<br>不带压缩动作的算法，收集 Old 区，和普通的 CMS 算法比较相似，暂停时间相对 MSC 算法短一些。</p>
<h5 id="原因-6"><a href="#原因-6" class="headerlink" title="原因"></a>原因</h5><p>CMS 发生收集器退化主要有以下几种情况：</p>
<ul>
<li>晋升失败（Promotion Failed）</li>
</ul>
<p>顾名思义，晋升失败就是指在进行 Young GC 时，Survivor 放不下，对象只能放入 Old，但此时 Old 也放不下。直觉上乍一看这种情况可能会经常发生，但其实因为有 concurrentMarkSweepThread 和担保机制的存在，发生的条件是很苛刻的，除非是短时间将 Old 区的剩余空间迅速填满，例如上文中说的动态年龄判断导致的过早晋升（见下文的增量收集担保失败）。另外还有一种情况就是内存碎片导致的 Promotion Failed，Young GC 以为 Old 有足够的空间，结果到分配时，晋级的大对象找不到连续的空间存放。</p>
<p>使用 CMS 作为 GC 收集器时，运行过一段时间的 Old 区, 清除算法导致内存出现多段的不连续，出现大量的内存碎片。</p>
<p>碎片带来了两个问题：</p>
<p>空间分配效率较低：上文已经提到过，如果是连续的空间 JVM 可以通过使用 pointer bumping 的方式来分配，而对于这种有大量碎片的空闲链表则需要逐个访问 freelist 中的项来访问，查找可以存放新建对象的地址。<br>空间利用效率变低：Young 区晋升的对象大小大于了连续空间的大小，那么将会触发 Promotion Failed ，即使整个 Old 区的容量是足够的，但由于其不连续，也无法存放新对象，也就是本文所说的问题。</p>
<ul>
<li>增量收集担保失败</li>
</ul>
<p>分配内存失败后，会判断统计得到的 Young GC 晋升到 Old 的平均大小，以及当前 Young 区已使用的大小也就是最大可能晋升的对象大小，是否大于 Old 区的剩余空间。只要 CMS 的剩余空间比前两者的任意一者大，CMS 就认为晋升还是安全的，反之，则代表不安全，不进行Young GC，直接触发Full GC。</p>
<ul>
<li>显式 GC</li>
</ul>
<p>这种情况参见场景二。</p>
<ul>
<li>并发模式失败（Concurrent Mode Failure）</li>
</ul>
<p>最后一种情况，也是发生概率较高的一种，在 GC 日志中经常能看到 Concurrent Mode Failure 关键字。这种是由于并发 Background CMS GC 正在执行，同时又有 Young GC 晋升的对象要放入到了 Old 区中，而此时 Old 区空间不足造成的。</p>
<p>为什么 CMS GC 正在执行还会导致收集器退化呢？主要是由于 CMS 无法处理浮动垃圾（Floating Garbage）引起的。CMS 的并发清理阶段，Mutator 还在运行，因此不断有新的垃圾产生，而这些垃圾不在这次清理标记的范畴里，无法在本次 GC 被清除掉，这些就是浮动垃圾，除此之外在 Remark 之前那些断开引用脱离了读写屏障控制的对象也算浮动垃圾。所以 Old 区回收的阈值不能太高，否则预留的内存空间很可能不够，从而导致 Concurrent Mode Failure 发生。</p>
<h5 id="策略-6"><a href="#策略-6" class="headerlink" title="策略"></a>策略</h5><p>分析到具体原因后，我们就可以针对性解决了，具体思路还是从根因出发，具体解决策略：</p>
<ul>
<li><p>内存碎片： 通过配置 -XX:UseCMSCompactAtFullCollection=true 来控制 Full GC的过程中是否进行空间的整理（默认开启，注意是Full GC，不是普通CMS GC），以及 -XX: CMSFullGCsBeforeCompaction=n 来控制多少次 Full GC 后进行一次压缩。</p>
</li>
<li><p>增量收集： 降低触发 CMS GC 的阈值，即参数 -XX:CMSInitiatingOccupancyFraction 的值，让 CMS GC 尽早执行，以保证有足够的连续空间，也减少 Old 区空间的使用大小，另外需要使用 -XX:+UseCMSInitiatingOccupancyOnly 来配合使用，不然 JVM 仅在第一次使用设定值，后续则自动调整。</p>
</li>
<li><p>浮动垃圾： 视情况控制每次晋升对象的大小，或者缩短每次 CMS GC 的时间，必要时可调节 NewRatio 的值。另外就是使用 -XX:+CMSScavengeBeforeRemark 在过程中提前触发一次 Young GC，防止后续晋升过多对象。</p>
</li>
</ul>
<h5 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h5><p>正常情况下触发并发模式的 CMS GC，停顿非常短，对业务影响很小，但 CMS GC 退化后，影响会非常大，建议发现一次后就彻底根治。只要能定位到内存碎片、浮动垃圾、增量收集相关等具体产生原因，还是比较好解决的，关于内存碎片这块，如果 -XX:CMSFullGCsBeforeCompaction 的值不好选取的话，可以使用 -XX:PrintFLSStatistics 来观察内存碎片率情况，然后再设置具体的值。</p>
<p>最后就是在编码的时候也要避免需要连续地址空间的大对象的产生，如过长的字符串，用于存放附件、序列化或反序列化的 byte 数组等，还有就是过早晋升问题尽量在爆发问题前就避免掉。</p>
<h4 id="堆外内存-OOM"><a href="#堆外内存-OOM" class="headerlink" title="堆外内存 OOM"></a>堆外内存 OOM</h4><h5 id="现象-7"><a href="#现象-7" class="headerlink" title="现象"></a>现象</h5><p>内存使用率不断上升，甚至开始使用 SWAP 内存，同时可能出现 GC 时间飙升，线程被 Block 等现象，通过 top 命令发现 Java 进程的 RES(常驻内存) 甚至超过了 -Xmx 的大小。出现这些现象时，基本可以确定是出现了堆外内存泄漏。</p>
<h5 id="原因-7"><a href="#原因-7" class="headerlink" title="原因"></a>原因</h5><p>JVM 的堆外内存泄漏，主要有两种的原因：</p>
<ul>
<li>通过 UnSafe#allocateMemory，ByteBuffer#allocateDirect 主动申请了堆外内存而没有释放，常见于 NIO、Netty 等相关组件。</li>
<li>代码中有通过 JNI 调用 Native Code 申请的内存没有释放。</li>
</ul>
<h5 id="策略-7"><a href="#策略-7" class="headerlink" title="策略"></a>策略</h5><p>哪种原因造成的堆外内存泄漏？</p>
<p>首先，我们需要确定是哪种原因导致的堆外内存泄漏。这里可以使用 NMT（NativeMemoryTracking） 进行分析。在项目中添加 -XX:NativeMemoryTracking=detail JVM参数后重启项目（需要注意的是，打开 NMT 会带来 5%~10% 的性能损耗）。使用命令 <code>jcmd pid VM.native_memory detail</code> 查看内存分布。重点观察 total 中的 committed，因为 jcmd 命令显示的内存包含堆内内存、Code 区域、通过 Unsafe.allocateMemory 和 DirectByteBuffer 申请的内存，但是不包含其他 Native Code（C 代码）申请的堆外内存。</p>
<p>如果 total 中的 committed 和 top 中的 RES 相差不大，则应为主动申请的堆外内存未释放造成的，如果相差较大，则基本可以确定是 JNI 调用造成的。</p>
<p>原因一：主动申请未释放</p>
<p>JVM 使用 -XX:MaxDirectMemorySize=size 参数来控制可申请的堆外内存的最大值。在 Java8 中，如果未配置该参数，默认和 -Xmx 相等。</p>
<p>NIO 和 Netty 都会取 -XX:MaxDirectMemorySize 配置的值，来限制申请的堆外内存的大小。NIO 和 Netty 中还有一个计数器字段，用来计算当前已申请的堆外内存大小，NIO 中是 <code>java.nio.Bits#totalCapacity</code>、Netty 中 <code>io.netty.util.internal.PlatformDependent#DIRECT_MEMORY_COUNTER</code>。</p>
<p>当申请堆外内存时，NIO 和 Netty 会比较计数器字段和最大值的大小，如果计数器的值超过了最大值的限制，会抛出 OOM 的异常。</p>
<p>NIO 中是：<code>OutOfMemoryError: Direct buffer memory</code>。</p>
<p>Netty 中是：<code>OutOfDirectMemoryError: failed to allocate capacity byte(s) of direct memory (used: usedMemory , max: DIRECT_MEMORY_LIMIT )</code>。</p>
<p>我们可以检查代码中是如何使用堆外内存的，NIO 或者是 Netty，通过反射，获取到对应组件中的计数器字段，并在项目中对该字段的数值进行打点，即可准确地监控到这部分堆外内存的使用情况。</p>
<p>此时，可以通过 Debug 的方式确定使用堆外内存的地方是否正确执行了释放内存的代码。另外，需要检查 JVM 的参数是否有 -XX:+DisableExplicitGC 选项，如果有就去掉，因为该参数会使 System.gc 失效。（场景二：显式 GC 的去与留）</p>
<p>原因二：通过 JNI 调用的 Native Code 申请的内存未释放</p>
<p>这种情况排查起来比较困难，我们可以通过 Google perftools + Btrace 等工具，帮助我们分析出问题的代码在哪里。</p>
<h5 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h5><p>首先可以使用 NMT + jcmd 分析泄漏的堆外内存是哪里申请，确定原因后，使用不同的手段，进行原因定位。</p>
<h4 id="JNI-引发的-GC-问题"><a href="#JNI-引发的-GC-问题" class="headerlink" title="JNI 引发的 GC 问题"></a>JNI 引发的 GC 问题</h4><h5 id="现象-8"><a href="#现象-8" class="headerlink" title="现象"></a>现象</h5><p>在 GC 日志中，出现 GC Cause 为 GCLocker Initiated GC。</p>
<h5 id="原因-8"><a href="#原因-8" class="headerlink" title="原因"></a>原因</h5><p>JNI（Java Native Interface）意为 Java 本地调用，它允许 Java 代码和其他语言写的 Native 代码进行交互。</p>
<p>JNI 如果需要获取 JVM 中的 String 或者数组，有两种方式：</p>
<ul>
<li>拷贝传递。</li>
<li>共享引用（指针），性能更高。</li>
</ul>
<p>由于 Native 代码直接使用了 JVM 堆区的指针，如果这时发生 GC，就会导致数据错误。因此，在发生此类 JNI 调用时，禁止 GC 的发生，同时阻止其他线程进入 JNI 临界区，直到最后一个线程退出临界区时触发一次 GC。</p>
<p>GC Locker可能导致的不良后果有：</p>
<ul>
<li><p>如果此时是 Young 区不够 Allocation Failure 导致的 GC，由于无法进行 Young GC，会将对象直接分配至 Old 区。</p>
</li>
<li><p>如果 Old 区也没有空间了，则会等待锁释放，导致线程阻塞。</p>
</li>
<li><p>可能触发额外不必要的 Young GC，JDK 有一个 Bug，有一定的几率，本来只该触发一次 GCLocker Initiated GC 的 Young GC，实际发生了一次 Allocation Failure GC 又紧接着一次 GCLocker Initiated GC。是因为 GCLocker Initiated GC 的属性被设为 full，导致两次 GC 不能收敛。</p>
</li>
</ul>
<h5 id="策略-8"><a href="#策略-8" class="headerlink" title="策略"></a>策略</h5><ul>
<li><p>添加 -XX+PrintJNIGCStalls 参数，可以打印出发生 JNI 调用时的线程，进一步分析，找到引发问题的 JNI 调用。</p>
</li>
<li><p>JNI 调用需要谨慎，不一定可以提升性能，反而可能造成 GC 问题。</p>
</li>
<li><p>升级 JDK 版本到 14，避免 JDK-8048556 导致的重复 GC。</p>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在这里，我们把整个文章内容总结一下，方便大家整体地理解回顾。</p>
<h4 id="处理流程（SOP）"><a href="#处理流程（SOP）" class="headerlink" title="处理流程（SOP）"></a>处理流程（SOP）</h4><p>下图为整体 GC 问题普适的处理流程，重点的地方下面会单独标注，其他的基本都是标准处理流程，此处不再赘述，最后在整个问题都处理完之后有条件的话建议做一下复盘。</p>
<p><img src="https://s3.ax1x.com/2020/11/18/Dm1s8s.png" alt="Dm1s8s.png"></p>
<ul>
<li><p>制定标准： 这块内容其实非常重要，但大部分系统都是缺失的，笔者过往面试的同学中只有不到一成的同学能给出自己的系统 GC 标准到底什么样，其他的都是用的统一指标模板，缺少预见性，需要结合应用系统的 TP9999 时间和延迟、吞吐量等设定具体的指标，而不是被问题驱动。</p>
</li>
<li><p>保留现场： 目前线上服务基本都是分布式服务，某个节点发生问题后，如果条件允许一定不要直接操作重启、回滚等动作恢复，优先通过摘掉流量的方式来恢复，这样我们可以将堆、栈、GC 日志等关键信息保留下来，不然错过了定位根因的时机，后续解决难度将大大增加。当然除了这些，应用日志、中间件日志、内核日志、各种 Metrics 指标等对问题分析也有很大帮助。</p>
</li>
<li><p>因果分析： 判断 GC 异常与其他系统指标异常的因果关系，可以参考笔者在 3.2 中介绍的时序分析、概率分析、实验分析、反证分析等 4 种因果分析法，避免在排查过程中走入误区。</p>
</li>
<li><p>根因分析： 确实是 GC 的问题后，可以借助上文提到的工具并通过 5 why 根因分析法以及跟第三节中的九种常见的场景进行逐一匹配，或者直接参考下文的根因鱼骨图，找出问题发生根因，最后再选择优化手段。</p>
</li>
</ul>
<h4 id="根因鱼骨图"><a href="#根因鱼骨图" class="headerlink" title="根因鱼骨图"></a>根因鱼骨图</h4><p>送上一张问题根因鱼骨图，一般情况下我们在处理一个 GC 问题时，只要能定位到问题的“病灶”，有的放矢，其实就相当于解决了 80%，如果在某些场景下不太好定位，大家可以借助这种根因分析图通过排除法去定位。</p>
<p><img src="https://s3.ax1x.com/2020/11/18/Dm39xI.png" alt="Dm39xI.png"></p>
<h4 id="调优建议"><a href="#调优建议" class="headerlink" title="调优建议"></a>调优建议</h4><ul>
<li><p>Trade Off： 与 CAP 注定要缺一角一样，GC 优化要在延迟（Latency）、吞吐量（Throughput）、容量（Capacity）三者之间进行权衡。</p>
</li>
<li><p>最终手段： GC 发生问题不是一定要对 JVM 的 GC 参数进行调优，大部分情况下是通过 GC 的情况找出一些业务问题，切记上来就对 GC 参数进行调整，当然有明确配置错误的场景除外。</p>
</li>
<li><p>控制变量： 控制变量法是在蒙特卡洛（Monte Carlo）方法中用于减少方差的一种技术方法，我们调优的时候尽量也要使用，每次调优过程尽可能只调整一个变量。</p>
</li>
<li><p>善用搜索： 理论上 99.99% 的 GC 问题基本都被遇到了，我们要学会使用搜索引擎的高级技巧，重点关注 StackOverFlow、Github 上的 Issue、以及各种论坛博客，先看看其他人是怎么解决的，会让解决问题事半功倍。能看到这篇文章，你的搜索能力基本过关了~</p>
</li>
<li><p>调优重点： 总体上来讲，我们开发的过程中遇到的问题类型也基本都符合正态分布，太简单或太复杂的基本遇到的概率很低，笔者这里将中间最重要的三个场景添加了“*”标识，希望阅读完本文之后可以观察下自己负责的系统，是否存在上述问题。</p>
</li>
<li><p>GC 参数： 如果堆、栈确实无法第一时间保留，一定要保留 GC 日志，这样我们最起码可以看到 GC Cause，有一个大概的排查方向。关于 GC 日志相关参数，最基本的 -XX:+HeapDumpOnOutOfMemoryError 等一些参数就不再提了，笔者建议添加以下参数，可以提高我们分析问题的效率。</p>
</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/18/Dm3eiQ.png" alt="Dm3eiQ.png"></p>
<ul>
<li><p>其他建议： 上文场景中没有提到，但是对 GC 性能也有提升的一些建议。</p>
</li>
<li><p>主动式 GC： 也有另开生面的做法，通过监控手段监控观测 Old 区的使用情况，即将到达阈值时将应用服务摘掉流量，手动触发一次 Major GC，减少 CMS GC 带来的停顿，但随之系统的健壮性也会减少，如非必要不建议引入。</p>
</li>
<li><p>禁用偏向锁： 偏向锁在只有一个线程使用到该锁的时候效率很高，但是在竞争激烈情况会升级成轻量级锁，此时就需要先消除偏向锁，这个过程是 STW 的。如果每个同步资源都走这个升级过程，开销会非常大，所以在已知并发激烈的前提下，一般会禁用偏向锁 -XX:-UseBiasedLocking 来提高性能。</p>
</li>
<li><p>虚拟内存： 启动初期有些操作系统（例如 Linux）并没有真正分配物理内存给 JVM ，而是在虚拟内存中分配，使用的时候才会在物理内存中分配内存页，这样也会导致 GC 时间较长。这种情况可以添加 -XX:+AlwaysPreTouch 参数，让 VM 在 commit 内存时跑个循环来强制保证申请的内存真的 commit，避免运行时触发缺页异常。在一些大内存的场景下，有时候能将前几次的 GC 时间降一个数量级，但是添加这个参数后，启动的过程可能会变慢。</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> jvm </category>
            
            <category> gc </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jvm </tag>
            
            <tag> gc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[tomcat classloader源码详解]]></title>
      <url>/2020/11/15/tomcat-classloader/</url>
      <content type="html"><![CDATA[<h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><pre><code class="java">public void init() throws Exception {

        // 初始化，后文会说这个方法
        initClassLoaders();

        // 设置线程类加载器
        Thread.currentThread().setContextClassLoader(catalinaLoader);

        SecurityClassLoad.securityClassLoad(catalinaLoader);

        // Load our startup class and call its process() method
        // 通过之前初始化的classloader反射实例化Catalina类的实例
        Class&lt;?&gt; startupClass =
            catalinaLoader.loadClass
            (&quot;org.apache.catalina.startup.Catalina&quot;);
        Object startupInstance = startupClass.newInstance();
        // Set the shared extensions class loader
        if (log.isDebugEnabled())
            log.debug(&quot;Setting startup class properties&quot;);
        String methodName = &quot;setParentClassLoader&quot;;
        Class&lt;?&gt; paramTypes[] = new Class[1];
        paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;);
        Object paramValues[] = new Object[1];
        paramValues[0] = sharedLoader;
        Method method =
            startupInstance.getClass().getMethod(methodName, paramTypes);

        // Catalina#setParentClassLoader为sharedLoader
        // 因为sharedLoader默认就是commonloader
        // 当然Catalina默认也是commonloader
        // 为啥不直接设置成commonclassloader呢？
        // 因为webappclassloader会把自己的parentclassloader设置成Catalina的ParentClassLoader
        // 注意是Catalina对象的爹是sharedLoader
        // catalinaLoader的爹仍旧是commonloader
        // 为啥这样？Catalina对象由catalinaLoader加载，Catalina对象的爹是sharedLoader，catalinaLoader的爹却是commonloader？ 求解
        method.invoke(startupInstance, paramValues);

        catalinaDaemon = startupInstance;

    }
</code></pre>
<p>initClassLoader()方法：</p>
<pre><code class="java">private void initClassLoaders() {
        try {
            // 默认情况下common.loader是有值的
            // common.loader=&quot;${catalina.base}/lib&quot;,&quot;${catalina.base}/lib/*.jar&quot;,&quot;${catalina.home}/lib&quot;,&quot;${catalina.home}/lib/*.jar&quot;
            commonLoader = createClassLoader(&quot;common&quot;, null);
            if( commonLoader == null ) {
                // no config file, default to this loader - we might be in a &#39;single&#39; env.
                commonLoader = this.getClass().getClassLoader();
            }
            // catalinaLoader和sharedLoader实际上有共同的父类加载器commonLoader
            // 而如果server.loader, shared.loader为空
            // 那么此时的catalinaLoader,sharedLoader其实是同一个ClassLoader ———— commonclassloader
            catalinaLoader = createClassLoader(&quot;server&quot;, commonLoader);
            sharedLoader = createClassLoader(&quot;shared&quot;, commonLoader);
        } catch (Throwable t) {
            log.error(&quot;Class loader creation threw exception&quot;, t);
            System.exit(1);
        }
}
</code></pre>
<p>createClassLoader()方法：</p>
<pre><code class="java">private ClassLoader createClassLoader(String name, ClassLoader parent) throws Exception {

    String value = CatalinaProperties.getProperty(name + &quot;.loader&quot;);
    // 判断如果catalina.properties中没有配置对应的loader属性的话，直接返回父加载器
    // 而默认情况下，server.loader, shared.loader为空，那么此时的catalinaLoader,sharedLoader其实是同一个ClassLoader ————commonloader
    if ((value == null) || (value.equals(&quot;&quot;)))
        return parent;

    value = replace(value);

    List&lt;Repository&gt; repositories = new ArrayList&lt;Repository&gt;();

    StringTokenizer tokenizer = new StringTokenizer(value, &quot;,&quot;);
    while (tokenizer.hasMoreElements()) {
        String repository = tokenizer.nextToken().trim();
        if (repository.length() == 0) {
            continue;
        }

        // Check for a JAR URL repository
        try {
            @SuppressWarnings(&quot;unused&quot;)
            URL url = new URL(repository);
            repositories.add(
                    new Repository(repository, RepositoryType.URL));
            continue;
        } catch (MalformedURLException e) {
            // Ignore
        }

        // Local repository
        if (repository.endsWith(&quot;*.jar&quot;)) {
            repository = repository.substring
                (0, repository.length() - &quot;*.jar&quot;.length());
            repositories.add(
                    new Repository(repository, RepositoryType.GLOB));
        } else if (repository.endsWith(&quot;.jar&quot;)) {
            repositories.add(
                    new Repository(repository, RepositoryType.JAR));
        } else {
            repositories.add(
                    new Repository(repository, RepositoryType.DIR));
        }
    }
    //这里返回的是一个UrlClassLoader实例
    //最终调用org.apache.catalina.startup.ClassLoaderFactory#createClassLoader静态工厂方法创建了URLClassloader的实例
    //而具体的URL其实就是*.loader属性配置的内容
    ClassLoader classLoader = ClassLoaderFactory.createClassLoader
        (repositories, parent);


    return classLoader;

}
</code></pre>
<p>查看org.apache.catalina.startup.Catalina#getParentClassLoader调用栈，我们看到在StandardContext的startInternal方法中调用了它，那么我们查看一下它的代码，包含了如下代码片段：</p>
<pre><code class="java">if (getLoader() == null) {
    // 初始化WebappLoader，把他的爹设置为sharedloader
            WebappLoader webappLoader = new WebappLoader(getParentClassLoader());
            webappLoader.setDelegate(getDelegate());
            setLoader(webappLoader);
}
try {

    if (ok) {

        // Start our subordinate components, if any
        if ((loader != null) &amp;&amp; (loader instanceof Lifecycle))
            ((Lifecycle) loader).start();
        //other code    
    }
catch(Exception e){
}
</code></pre>
<p>因为WebappLoader符合Tomcat组件生命周期管理的模板方法模式，因此会调用到它的startInternal方法。我们接下来就来看看WebappLoader的startInternal，我们摘取一部分与本篇相关的代码片段如下：</p>
<pre><code class="java">classLoader = createClassLoader();
classLoader.setResources(container.getResources());
// 设置是否配置委派模式
classLoader.setDelegate(this.delegate);
classLoader.setSearchExternalFirst(searchExternalFirst);
</code></pre>
<p>从上的代码可以看到调用了createClassLoader方法创建一个classLoader，那么我们再看来看看createClassLoader的代码：</p>
<pre><code class="java">private WebappClassLoader createClassLoader()
    throws Exception {

// classLoader是WebappLoader的实例变量，其值为org.apache.catalina.loader.WebappClassLoader，其实就是通过反射调用了WebappClassLoader的构造函数，然后传递了sharedLoader作为其父亲加载器。
    Class&lt;?&gt; clazz = Class.forName(loaderClass);
    WebappClassLoader classLoader = null;

    if (parentClassLoader == null) {
        parentClassLoader = container.getParentClassLoader();
    }
    Class&lt;?&gt;[] argTypes = { ClassLoader.class };
    Object[] args = { parentClassLoader };
    Constructor&lt;?&gt; constr = clazz.getConstructor(argTypes);
    classLoader = (WebappClassLoader) constr.newInstance(args);

    return classLoader;

}
</code></pre>
<p>进一步来分析一下WebAppClassLoader的代码，在Java自定义类加载器，一般情况下，我们只需要重写findClass方法就好了，而对于WebAppClassLoader，通过查看源代码，我们发现loadClass和findClass方法都进行了重写，那么我们首先就来看看它的loadClass方法,它的代码如下：</p>
<pre><code class="java">public synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)
    throws ClassNotFoundException {

    if (log.isDebugEnabled())
        log.debug(&quot;loadClass(&quot; + name + &quot;, &quot; + resolve + &quot;)&quot;);
    Class&lt;?&gt; clazz = null;

    // Log access to stopped classloader
    if (!started) {
        try {
            throw new IllegalStateException();
        } catch (IllegalStateException e) {
            log.info(sm.getString(&quot;webappClassLoader.stopped&quot;, name), e);
        }
    }

    // (0) Check our previously loaded local class cache
    // 首先从当前ClassLoader的本地缓存中加载类，如果找到则返回。
    clazz = findLoadedClass0(name);
    if (clazz != null) {
        if (log.isDebugEnabled())
            log.debug(&quot;  Returning class from cache&quot;);
        if (resolve)
            resolveClass(clazz);
        return (clazz);
    }

    // (0.1) Check our previously loaded class cache
    // 在本地缓存没有的情况下，调用ClassLoader的findLoadedClass方法查看jvm是否已经加载过此类，如果已经加载则直接返回。
    clazz = findLoadedClass(name);
    if (clazz != null) {
        if (log.isDebugEnabled())
            log.debug(&quot;  Returning class from cache&quot;);
        if (resolve)
            resolveClass(clazz);
        return (clazz);
    }

    // (0.2) Try loading the class with the system class loader, to prevent
    //       the webapp from overriding J2SE classes
    // 通过系统的来加载器加载此类，这里防止应用写的类覆盖了J2SE的类,这句代码非常关键，如果不写的话，就会造成你自己写的类有可能会把J2SE的类给替换调，另外假如你写了一个javax.servlet.Servlet类，放在当前应用的WEB-INF/class中，如果没有此句代码的保证，那么你自己写的类就会替换到Tomcat容器Lib中包含的类。
    try {
        clazz = system.loadClass(name);
        if (clazz != null) {
            if (resolve)
                resolveClass(clazz);
            return (clazz);
        }
    } catch (ClassNotFoundException e) {
        // Ignore
    }

    // (0.5) Permission to access this class when using a SecurityManager
    if (securityManager != null) {
        int i = name.lastIndexOf(&#39;.&#39;);
        if (i &gt;= 0) {
            try {
                securityManager.checkPackageAccess(name.substring(0,i));
            } catch (SecurityException se) {
                String error = &quot;Security Violation, attempt to use &quot; +
                    &quot;Restricted Class: &quot; + name;
                log.info(error, se);
                throw new ClassNotFoundException(error, se);
            }
        }
    }

    // 判断是否需要委托给父类加载器进行加载，delegate属性默认为false，那么delegatedLoad的值就取决于filter的返回值了，filter方法中根据包名来判断是否需要进行委托加载，默认情况下会返回false.因此delegatedLoad为false
    boolean delegateLoad = delegate || filter(name);

    // (1) Delegate to our parent if requested
    // 因为delegatedLoad为false,那么此时不会委托父加载器去加载，这里其实是没有遵循parent-first的加载机制。
    if (delegateLoad) {
        if (log.isDebugEnabled())
            log.debug(&quot;  Delegating to parent classloader1 &quot; + parent);
        ClassLoader loader = parent;
        if (loader == null)
            loader = system;
        try {
            clazz = Class.forName(name, false, loader);
            if (clazz != null) {
                if (log.isDebugEnabled())
                    log.debug(&quot;  Loading class from parent&quot;);
                if (resolve)
                    resolveClass(clazz);
                return (clazz);
            }
        } catch (ClassNotFoundException e) {
            // Ignore
        }
    }

    // (2) Search local repositories
    if (log.isDebugEnabled())
        log.debug(&quot;  Searching local repositories&quot;);
    // 调用findClass方法在webapp级别进行加载
    try {
        clazz = findClass(name);
        if (clazz != null) {
            if (log.isDebugEnabled())
                log.debug(&quot;  Loading class from local repository&quot;);
            if (resolve)
                resolveClass(clazz);
            return (clazz);
        }
    } catch (ClassNotFoundException e) {
        // Ignore
    }

    // (3) Delegate to parent unconditionally
    // 如果还是没有加载到类，并且不采用委托机制的话，则通过父类加载器去加载。
    if (!delegateLoad) {
        if (log.isDebugEnabled())
            log.debug(&quot;  Delegating to parent classloader at end: &quot; + parent);
        ClassLoader loader = parent;
        if (loader == null)
            loader = system;
        try {
            clazz = Class.forName(name, false, loader);
            if (clazz != null) {
                if (log.isDebugEnabled())
                    log.debug(&quot;  Loading class from parent&quot;);
                if (resolve)
                    resolveClass(clazz);
                return (clazz);
            }
        } catch (ClassNotFoundException e) {
            // Ignore
        }
    }

    throw new ClassNotFoundException(name);

}
</code></pre>
<p>接着在来分析一下findClass，通过分析findClass的代码，最终会调用org.apache.catalina.loader.WebappClassLoader#findClassInternal方法，那我们就来分析一下它的代码：</p>
<pre><code class="java">protected Class&lt;?&gt; findClassInternal(String name)
    throws ClassNotFoundException {

    //
    if (!validate(name))
        throw new ClassNotFoundException(name);

    String tempPath = name.replace(&#39;.&#39;, &#39;/&#39;);
    String classPath = tempPath + &quot;.class&quot;;

    ResourceEntry entry = null;

    if (securityManager != null) {
        PrivilegedAction&lt;ResourceEntry&gt; dp =
            new PrivilegedFindResourceByName(name, classPath);
        entry = AccessController.doPrivileged(dp);
    } else {
        // 通过名称去当前webappClassLoader的仓库中查找对应的类文件
        entry = findResourceInternal(name, classPath);
    }

    if (entry == null)
        throw new ClassNotFoundException(name);

    Class&lt;?&gt; clazz = entry.loadedClass;
    if (clazz != null)
        return clazz;

    synchronized (this) {
        clazz = entry.loadedClass;
        if (clazz != null)
            return clazz;

        if (entry.binaryContent == null)
            throw new ClassNotFoundException(name);

        try {
            // 将找到的类文件通过defineClass转变为Jvm可以识别的Class对象返回
            clazz = defineClass(name, entry.binaryContent, 0,
                    entry.binaryContent.length,
                    new CodeSource(entry.codeBase, entry.certificates));
        } catch (UnsupportedClassVersionError ucve) {
            throw new UnsupportedClassVersionError(
                    ucve.getLocalizedMessage() + &quot; &quot; +
                    sm.getString(&quot;webappClassLoader.wrongVersion&quot;,
                            name));
        }
        entry.loadedClass = clazz;
        entry.binaryContent = null;
        entry.source = null;
        entry.codeBase = null;
        entry.manifest = null;
        entry.certificates = null;
    }

    return clazz;

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> classLoader </category>
            
            <category> jvm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> classLoader </tag>
            
            <tag> jvm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[classloader详解]]></title>
      <url>/2020/11/14/classloader-classpath-hell/</url>
      <content type="html"><![CDATA[<h2 id="类加载的顺序"><a href="#类加载的顺序" class="headerlink" title="类加载的顺序"></a>类加载的顺序</h2><p><img src="https://s3.ax1x.com/2020/11/17/DVLBkt.png" alt="DVLBkt.png"></p>
<p>六种情况必须立即对类进行“初始化”(而加载、验证、准备自然需要在此之 前开始):</p>
<ul>
<li>遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始 化，则需要先触发其初始化阶段。能够生成这四条指令的典型Java代码场景有:<ul>
<li>使用new关键字实例化对象的时候。</li>
<li>读取或设置一个类型的静态字段(被final修饰、已在编译期把结果放入常量池的静态字段除外)<br>的时候。</li>
<li>调用一个类型的静态方法的时候。</li>
</ul>
</li>
<li>使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需 要先触发其初始化。</li>
<li>当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类(包含main()方法的那个类)，虚拟机会先初始化这个主类。</li>
<li>当使用JDK 7新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解 析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。</li>
<li>当一个接口中定义了JDK 8新加入的默认方法(被default关键字修饰的接口方法)时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。</li>
</ul>
<p><code>static{}</code>代码块会执行<code>&lt;clinit&gt;()</code>，并在方法构造器<code>&lt;init&gt;()</code>之前执行，注意<code>static{}</code>可以访问和赋值在他之前生命的静态变量，但对于其后生命的变量只能赋值，不能访问。父类永远先于子类执行。</p>
<h2 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h2><p>对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性。即，比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p>
<h3 id="双亲委派"><a href="#双亲委派" class="headerlink" title="双亲委派"></a>双亲委派</h3><p>站在Java虚拟机的角度来看，只存在两种不同的类加载器:</p>
<ul>
<li>一种是启动类加载器(Bootstrap ClassLoader)，这个类加载器使用C++语言实现，是虚拟机自身的一部分;</li>
<li>另外一种就是其他所有 的类加载器，这些类加载器都由Java语言实现，独立存在于虚拟机外部，并且全都继承自抽象类 java.lang.ClassLoader。</li>
</ul>
<p>站在Java开发者的角度来说，绝大多数Java程序都会使用到以下3个系统提供的类加载器来进行加载：</p>
<ul>
<li>启动类加载器(Bootstrap Class Loader):前面已经介绍过，这个类加载器负责加载存放在<code>&lt;JAVA_HOME&gt;\lib</code>目录，或者被<code>-Xbootclasspath</code>参数所指定的路径中存放的，而且是Java虚拟机能够识别的(按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载)类库加载到虚拟机的内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器去处理，那直接使用null代替即可。</li>
<li>扩展类加载器(Extension Class Loader):这个类加载器是在类<code>sun.misc.Launcher$ExtClassLoader</code>以Java代码的形式实现的。它负责加载<code>&lt;JAVA_HOM E&gt;\lib\ext</code>目录中，或者被<code>java.ext.dirs</code>系统变量所 指定的路径中所有的类库。根据“扩展类加载器”这个名称，就可以推断出这是一种Java系统类库的扩展机制，JDK的开发团队允许用户将具有通用性的类库放置在ext目录里以扩展Java SE的功能，在JDK 9之后，这种扩展机制被模块化带来的天然的扩展能力所取代。由于扩展类加载器是由Java代码实现的，开发者可以直接在程序中使用扩展类加载器来加载Class文件。</li>
<li>应用程序类加载器(Application Class Loader):这个类加载器由<br><code>sun.misc.Launcher$AppClassLoader</code>来实现。由于应用程序类加载器是ClassLoader类中的<code>getSystemClassLoader()</code>方法的返回值，所以也称它为“系统类加载器”。它负责加载用户类路径(ClassPath)上所有的类库，开发者同样可以直接在代码中使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/17/DZCFu6.png" alt="DZCFu6.png"></p>
<p>双亲委派模型的工作过程是:如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时，子加载器才会尝试自己去完成加载。</p>
<p>使用双亲委派模型来组织类加载器之间的关系，一个显而易见的好处就是Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。相同包名的同名类只能在一个类加载器中加载，从而避免混乱。</p>
<pre><code class="java">protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException {
    // 首先，检查请求的类是否已经被加载过了 
    Class c = findLoadedClass(name); 
    if (c == null) {
        try {
            if (parent != null) {
                c = parent.loadClass(name, false);
            } else {
            c = findBootstrapClassOrNull(name); }
        } catch (ClassNotFoundException e) {
        // 如果父类加载器抛出ClassNotFoundException 
        // 说明父类加载器无法完成加载请求
        }
        if (c == null) {
            // 在父类加载器无法加载时
            // 再调用本身的findClass方法来进行类加载 
            c = findClass(name);
        } 
    }
    if (resolve) { 
        resolveClass(c);
    }
    return c; 
}
</code></pre>
<h3 id="破坏双亲委派"><a href="#破坏双亲委派" class="headerlink" title="破坏双亲委派"></a>破坏双亲委派</h3><h4 id="自定义classloader"><a href="#自定义classloader" class="headerlink" title="自定义classloader"></a>自定义classloader</h4><p>类加载器的概念和抽象类java.lang.ClassLoader无法避免loadClass()被子类覆盖，只能通过protected方法findClass()，并引导用写的类加载逻辑时尽可能去重写这个方法，而不是在loadClass()中编写代码。按照loadClass()方法的逻辑，如果父类加载失败，会自动调用自己的findClass()方法来完成加载，这样既不影响用户按照自己的意愿去加载类，又可以保证新写出来的类加载器是符合双亲委派规则的。</p>
<h4 id="线程上下文类加载器-Thread-Context-ClassLoader"><a href="#线程上下文类加载器-Thread-Context-ClassLoader" class="headerlink" title="线程上下文类加载器 (Thread Context ClassLoader)"></a>线程上下文类加载器 (Thread Context ClassLoader)</h4><p>以jndi为例：<br>JNDI存在的目的就是对资源进行查找和集中管理，它需要调用由其他厂商实现并部署在应用程 序的ClassPath下的JNDI服务提供者接口(Service Provider Interface，SPI)的代码，但启动类加载器是绝不可能认识、加载这些代码的。</p>
<p>为了解决这个困境，Java的设计团队只好引入了一个不太优雅的设计:线程上下文类加载器(Thread Context ClassLoader)。这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。</p>
<p>如果不做任何的设置，Java 应用的线程的上下文类加载器默认就是系统上下文类加载器。在SPI接口的代码中使用线程上下文类加载器，就可以成功的加载到SPI实现的类。</p>
<p>JNDI服务使用这个线程上下文类加载器去加载所需的SPI服务代码，这是一种父类加载器去请求子类加载器完成类加载的行为，这种行为实际上是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型的一般性原则。</p>
<h4 id="OSGi"><a href="#OSGi" class="headerlink" title="OSGi"></a>OSGi</h4><p>OSGi实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块(OSGi中称为 Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实 现代码的热替换。在OSGi环境下，类加载器不再双亲委派模型推荐的树状结构，而是进一步发展为更加复杂的网状结构。</p>
<h4 id="Java9中的模块化"><a href="#Java9中的模块化" class="headerlink" title="Java9中的模块化"></a>Java9中的模块化</h4><p>一篇详细讲解模块化的文章<br><a href="http://seanthefish.com/2018/03/29/module-system/">http://seanthefish.com/2018/03/29/module-system/</a></p>
<p>jdk9提出了与“类路径”(ClassPath)相对应的“模块路径”(M odulePath)的概念。某个类库到底是模块还是传统的JAR包，只取决于它存放在哪种路径上。只要是放在类路径上的JAR文件，无论其中是否包含模块化信息(是否包含了module-info.class文件)，它都会被当作传统的JAR包来对待;相应地，只 要放在模块路径上的JAR文件，即使没有使用JMOD后缀，甚至说其中并不包含module-info.class文 件，它也仍然会被当作一个模块来对待。</p>
<ul>
<li>JAR文件在类路径的访问规则:所有类路径下的JAR文件及其他资源文件，都被视为自动打包在一个匿名模块(Unnamed Module)里，这个匿名模块几乎是没有任何隔离的，它可以看到和使用类路 径上所有的包、JDK系统模块中所有的导出包，以及模块路径上所有模块中导出的包。</li>
<li>模块在模块路径的访问规则:模块路径下的具名模块(Named Module)只能访问到它依赖定义中列明依赖的模块和包，匿名模块里所有的内容对具名模块来说都是不可见的，即具名模块看不见传统JAR包的内容。</li>
<li>JAR文件在模块路径的访问规则:如果把一个传统的、不包含模块定义的JAR文件放置到模块路径中，它就会变成一个自动模块(Automatic Module)。尽管不包含module-info.class，但自动模块将默认依赖于整个模块路径中的所有模块，因此可以访问到所有模块导出的包，自动模块也默认导出自己所有的包。</li>
</ul>
<p>在模块化的java9中：</p>
<ul>
<li>扩展类加载器(Extension Class Loader)被平台类加载器(Platform Class Loader)取代。</li>
<li>平台类加载器和应用程序类加载器都不再派生自java.net.URLClassLoader，如果有程序直接 依赖了这种继承关系，或者依赖了URLClassLoader类的特定方法，那代码很可能会在JDK 9及更高版 本的JDK中崩溃。</li>
<li>JDK 9中虽然仍然维持着三层类加载器和双亲委派的架构，但类加载的委派关系也发生了变动。当平台及应用程序类加载器收到类加载请求，在委派给父加载器加载前，要先判断该类是否能够归属到某一个系统模块中，如果可以找到这样的归属关系，就要优先委派给负责那个模块的加载器完成加载。</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/17/DZZ78S.png" alt="DZZ78S.png"></p>
<h2 id="tomcat"><a href="#tomcat" class="headerlink" title="tomcat"></a>tomcat</h2><p>Tomcat的类加载机制是违反了双亲委托原则的，对于一些未加载的非基础类(Object,String等)，各个web应用自己的类加载器(WebAppClassLoader)会优先加载，加载不到时再交给commonClassLoader走双亲委托。</p>
<p>首先要了解的是，tomcat有两中类加载器模式：</p>
<p>默认情况下：</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZJNi4.png" alt="DZJNi4.png"></p>
<p>高级模式：</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZJRWd.png" alt="DZJRWd.png"></p>
<p>根据conf/catalina.properties文件中common.loader，server.loader，shared.loader的值来初始化commonLoader,catalinaLoader,sharedLoader，其中catalinaLoader,sharedLoader的父亲加载器是commonLoader，默认情况下，这3个ClassLoader是同一个实例变量。</p>
<p>tomcat容器不希望它下面的webapps之间能互相访问到，所以不能用jvm中的appClassLoarder去加载。所以tomcat新建一个sharedClassLoader（它的parent是commonClassLoader，commonClassLoader的parent是jvm中的appClassLoarder，默认情况下，sharedClassLoader和commonClassLoader是同一个UrlClassLoader实例），这是catalina容器使用的ClassLoader。对于每个webapp，为其新建一个webappClassLoader，用于加载webapp下面的类，这样webapp之间就不能相互访问了。tomcat的ClassLoader不完全遵循双亲委派，首先用webappClassLoader去加载某个类，如果找不到，再交给parent。而对于java核心库，不在tomcat的ClassLoader的加载范围。</p>
<ul>
<li>commonLoader：Tomcat最基本的类加载器，加载路径（/common/*）中的class可以被Tomcat容器本身以及各个Webapp访问；</li>
<li>catalinaLoader：Tomcat容器私有的类加载器，加载路径（/server/*）中的class对于Webapp不可见；</li>
<li>sharedLoader：各个Webapp共享的类加载器，加载路径（/shared/*（在tomcat 6之后已经合并到根目录下的lib目录下））中的class对于所有Webapp可见，但是对于Tomcat容器不可见；</li>
<li>WebappClassLoader：各个Webapp私有的类加载器，加载路径（/WebApp/WEB-INF/*中的Java类库）中的class只对当前Webapp可见；</li>
</ul>
<p>当应用需要到某个类时，默认会按照下面的顺序进行类加载（不使用委派模式）：</p>
<ul>
<li>使用bootstrapclassloader加载器加载</li>
<li>使用webapppclassloader加载器在WEB-INF/classes中加载</li>
<li>使用webapppclassloader加载器在WEB-INF/lib中加载</li>
<li>使用appclassloader（systemclassloader）加载器加载</li>
<li>使用commonclassloader在CATALINA_HOME/lib中加载</li>
</ul>
<p>使用委派模式的话（配置<code>&lt;Loader delegate=&quot;true&quot;/&gt;</code>）:</p>
<ul>
<li>使用bootstrapclassloader加载器加载</li>
<li>使用appclassloader（systemclassloader）加载器加载</li>
<li>使用commonclassloader在CATALINA_HOME/lib中加载</li>
<li>使用webapppclassloader加载器在WEB-INF/classes中加载</li>
<li>使用webapppclassloader加载器在WEB-INF/lib中加载</li>
</ul>
<h2 id="was"><a href="#was" class="headerlink" title="was"></a>was</h2><p>简单说一下was，直接上图</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZ0PDs.png" alt="DZ0PDs.png"></p>
<p>was里分为Parent_first和Parent_last模式</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZ03Ux.png" alt="DZ03Ux.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZ0aKH.png" alt="DZ0aKH.png"></p>
<p>同时在was的appclassloader级别（即为ear）和webmoduleclassloader级别（即为war）都分别具备隔离和共享两种classloader模式。</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZ0LM4.png" alt="DZ0LM4.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZ0vZR.png" alt="DZ0vZR.png"></p>
<p>Shared Library模式</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZBALd.png" alt="DZBALd.png"></p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZBZdI.png" alt="DZBZdI.png"></p>
<p>独立的shared library模式（有自己的classloader，且必须为PARENT_LAST模式）</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZBJwn.png" alt="DZBJwn.png"></p>
<p>常见问题：<br>（图片里说的很清楚，故不做多余解释，这些问题也可以引申到其他的服务器中）</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZB0lF.png" alt="DZB0lF.png"><br>Solution:<br> Create a shared library to hold the test1.jar file and associate the shared library with both EAR1 and EAR2.</p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZB46e.png" alt="DZB46e.png"><br>Solution:<br> Place the dependent jars, test3.jar, in the same classloader as test1.jar so that both jar files are loaded by the same class loaderand visible to each other. </p>
<p><img src="https://s3.ax1x.com/2020/11/17/DZB7TI.png" alt="DZB7TI.png"><br>Solution:<br> Set the application class loader mode to parent_last so the correct version from the EAR file to be picked up first.<br> Or remove the duplicate class (wrong version) from the shared library.</p>
<p>又想起了曾经被was支配的恐惧。<br>打fatjar还是最简单有效的。</p>
]]></content>
      
        <categories>
            
            <category> classLoader </category>
            
            <category> jvm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> classLoader </tag>
            
            <tag> jvm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[gc调优]]></title>
      <url>/2020/11/13/improve-gc/</url>
      <content type="html"><![CDATA[<p>先贴个图</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAwfZ6.png" alt="DAwfZ6.png"></p>
<h2 id="如何阅读gclog："><a href="#如何阅读gclog：" class="headerlink" title="如何阅读gclog："></a>如何阅读gclog：</h2><p>以其中一行为例来解读下日志信息：</p>
<p>[GC (Allocation Failure) [ParNew: 367523K-&gt;1293K(410432K), 0.0023988 secs] 522739K-&gt;156516K(1322496K), 0.0025301 secs] [Times: user=0.04 sys=0.00, real=0.01 secs]</p>
<p>GC：<br>表明进行了一次垃圾回收，前面没有Full修饰，表明这是一次Minor GC ,注意它不表示只GC新生代，并且现有的不管是新生代还是老年代都会STW。</p>
<p>Allocation Failure：<br>表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了。</p>
<p>ParNew：<br>表明本次GC发生在年轻代并且使用的是ParNew垃圾收集器。ParNew是一个Serial收集器的多线程版本，会使用多个CPU和线程完成垃圾收集工作（默认使用的线程数和CPU数相同，可以使用-XX：ParallelGCThreads参数限制）。该收集器采用复制算法回收内存，期间会停止其他工作线程，即Stop The World。</p>
<p>367523K-&gt;1293K(410432K)：单位是KB<br>三个参数分别为：GC前该内存区域(这里是年轻代)使用容量，GC后该内存区域使用容量，该内存区域总容量。</p>
<p>0.0023988 secs：<br>该内存区域GC耗时，单位是秒</p>
<p>522739K-&gt;156516K(1322496K)：<br>三个参数分别为：堆区垃圾回收前的大小，堆区垃圾回收后的大小，堆区总大小。</p>
<p>0.0025301 secs：<br>该内存区域GC耗时，单位是秒</p>
<p>[Times: user=0.04 sys=0.00, real=0.01 secs]：<br>分别表示用户态耗时，内核态耗时和总耗时</p>
<p>分析下可以得出结论：</p>
<p>该次GC新生代减少了367523-1293=366239K</p>
<p>Heap区总共减少了522739-156516=366223K</p>
<p>366239 – 366223 =16K，说明该次共有16K内存从年轻代移到了老年代，可以看出来数量并不多，说明都是生命周期短的对象，只是这种对象有很多。</p>
<p>我们需要的是尽量避免Full GC的发生，让对象尽可能的在年轻代就回收掉，所以这里可以稍微增加一点年轻代的大小，让那17K的数据也保存在年轻代中。</p>
<h2 id="常见配置举例"><a href="#常见配置举例" class="headerlink" title="常见配置举例"></a>常见配置举例</h2><h3 id="堆大小设置"><a href="#堆大小设置" class="headerlink" title="堆大小设置"></a>堆大小设置</h3><p>JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统 下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。</p>
<p>典型设置：<br><code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k</code></p>
<p>-Xmx3550m：设置JVM最大可用内存为3550M。</p>
<p>-Xms3550m：设置JVM初始内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</p>
<p>-Xmn2g：设置年轻代大小为2G。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。</p>
<p>-Xss128k： 设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内 存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。</p>
<p><code>java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0</code></p>
<p>-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5</p>
<p>-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6</p>
<p>-XX:MaxPermSize=16m:设置持久代大小为16m。</p>
<p>-XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</p>
<h3 id="回收器选择"><a href="#回收器选择" class="headerlink" title="回收器选择"></a>回收器选择</h3><p>JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。</p>
<h4 id="吞吐量优先的并行收集器"><a href="#吞吐量优先的并行收集器" class="headerlink" title="吞吐量优先的并行收集器"></a>吞吐量优先的并行收集器</h4><p>如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。</p>
<p>典型配置：<br><code>java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20</code></p>
<p>-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。</p>
<p>-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。</p>
<p><code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC</code></p>
<p>-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。</p>
<p>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis=100</p>
<p>-XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。</p>
<p><code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy</code></p>
<p>-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。</p>
<h4 id="响应时间优先的并发收集器"><a href="#响应时间优先的并发收集器" class="headerlink" title="响应时间优先的并发收集器"></a>响应时间优先的并发收集器</h4><p>如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。</p>
<p>典型配置：<br><code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC</code></p>
<p>-XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。</p>
<p>-XX:+UseParNewGC:设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。</p>
<p><code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection</code></p>
<p>-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。</p>
<p>-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片。</p>
<h3 id="常见配置汇总"><a href="#常见配置汇总" class="headerlink" title="常见配置汇总"></a>常见配置汇总</h3><h4 id="堆设置"><a href="#堆设置" class="headerlink" title="堆设置"></a>堆设置</h4><p>-Xms:初始堆大小<br>-Xmx:最大堆大小<br>-XX:NewSize=n:设置年轻代大小<br>-XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4<br>-XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5<br>-XX:MaxPermSize=n:设置持久代大小</p>
<h4 id="收集器设置"><a href="#收集器设置" class="headerlink" title="收集器设置"></a>收集器设置</h4><p>-XX:+UseSerialGC:设置串行收集器<br>-XX:+UseParallelGC:设置并行收集器<br>-XX:+UseParalledlOldGC:设置并行年老代收集器<br>-XX:+UseConcMarkSweepGC:设置并发收集器</p>
<h5 id="垃圾回收统计信息"><a href="#垃圾回收统计信息" class="headerlink" title="垃圾回收统计信息"></a>垃圾回收统计信息</h5><p>-XX:+PrintGC<br>-XX:+Printetails<br>-XX:+PrintGCTimeStamps<br>-Xloggc:filename</p>
<h5 id="并行收集器设置"><a href="#并行收集器设置" class="headerlink" title="并行收集器设置"></a>并行收集器设置</h5><p>-XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。<br>-XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间<br>-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)<br>并发收集器设置<br>-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。<br>-XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。</p>
<h2 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h2><h3 id="年轻代大小选择"><a href="#年轻代大小选择" class="headerlink" title="年轻代大小选择"></a>年轻代大小选择</h3><p>响应时间优先的应用：设置接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。ps：并非堆越大越好，大堆full gc时间就长，停顿时间变长。在full gc发生不可控的情况下，大内存的物理机考虑使用集群化环境。</p>
<p>吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。</p>
<h3 id="年老代大小选择"><a href="#年老代大小选择" class="headerlink" title="年老代大小选择"></a>年老代大小选择</h3><p>响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得：</p>
<ul>
<li>并发垃圾收集信息</li>
<li>持久代并发收集次数</li>
<li>传统GC信息</li>
<li>花在年轻代和年老代回收上的时间比例</li>
<li>减少年轻代和年老代花费的时间，一般会提高应用的效率</li>
</ul>
<p>吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。</p>
<h3 id="较小堆引起的碎片问题"><a href="#较小堆引起的碎片问题" class="headerlink" title="较小堆引起的碎片问题"></a>较小堆引起的碎片问题</h3><p>因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出 现“碎片”，可能需要进行如下配置：<br>-XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。<br>-XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩。</p>
<h3 id="高分配速率-High-Allocation-Rate"><a href="#高分配速率-High-Allocation-Rate" class="headerlink" title="高分配速率(High Allocation Rate)"></a>高分配速率(High Allocation Rate)</h3><p>分配速率(Allocation rate)表示单位时间内分配的内存量。通常使用 MB/sec作为单位, 也可以使用 PB/year 等。</p>
<p>计算上一次垃圾收集之后,与下一次GC开始之前的年轻代使用量, 两者的差值除以时间,就是分配速率。</p>
<p>分配速率过高就会严重影响程序的性能。在JVM中会导致巨大的GC开销。</p>
<h4 id="分配速率的意义"><a href="#分配速率的意义" class="headerlink" title="分配速率的意义"></a>分配速率的意义</h4><p>分配速率的变化,会增加或降低GC暂停的频率, 从而影响吞吐量。但只有年轻代的 minor GC受分配速率的影响, 老年代GC的频率和持续时间不受分配速率(allocation rate)的直接影响, 而是受到提升速率(promotion rate)的影响, 请参见下文。</p>
<p>现在我们只关心Minor GC暂停, 查看年轻代的3个内存池。因为对象在Eden区分配, 所以我们一起来看Eden区的大小和分配速率的关系。看看增加Eden区的容量, 能不能减少Minor GC暂停次数, 从而使程序能够维持更高的分配速率。</p>
<p>经过我们的实验, 通过参数-XX:NewSize、 -XX:MaxNewSize以及 -XX:SurvivorRatio设置不同的Eden空间, 运行同一程序时, 可以发现:</p>
<ul>
<li>Eden 空间为 100 MB 时, 分配速率低于 100 MB/秒。</li>
<li>将 Eden 区增大为 1 GB, 分配速率也随之增长,大约等于 200 MB/秒。</li>
</ul>
<p>为什么会这样? —— 因为减少GC暂停,就等价于减少了任务线程的停顿，就可以做更多工作, 也就创建了更多对象, 所以对同一应用来说, 分配速率越高越好。</p>
<p>在得出 “Eden区越大越好” 这个结论前, 我们注意到, 分配速率可能会,也可能不会影响程序的实际吞吐量。吞吐量和分配速率有一定关系, 因为分配速率会影响 minor GC 暂停, 但对于总体吞吐量的影响, 还要考虑 Major GC(大型GC)暂停, 而且吞吐量的单位不是 MB/秒，而是系统所处理的业务量。</p>
<h4 id="高分配速率对JVM的影响"><a href="#高分配速率对JVM的影响" class="headerlink" title="高分配速率对JVM的影响"></a>高分配速率对JVM的影响</h4><p>demo：</p>
<pre><code class="java">public class BoxingFailure {
  private static volatile Double sensorValue;
  private static void readSensor() {
    while(true) sensorValue = Math.random();
  }
  private static void processSensorValue(Double value) {
    if(value != null) {
      //...
    }
  }
}
</code></pre>
<p>如同类名所示, 这个Demo是模拟 boxing 的。为了 null 值判断, 使用的是包装类型 Double。 程序基于传感器的最新值进行计算, 但从传感器取值是一个重量级操作, 所以采用了异步方式： 一个线程不断获取新值, 计算线程则直接使用暂存的最新值, 从而避免同步等待。</p>
<p>Demo 程序在运行的过程中, 由于分配速率太大而受到GC的影响。</p>
<p>首先，我们应该检查程序的吞吐量是否降低。如果创建了过多的临时对象, minor GC的次数就会增加。如果并发较大, 则GC可能会严重影响吞吐量。</p>
<p>遇到这种情况时, GC日志将会像下面这样，当然这是上面的示例程序 产生的GC日志。 JVM启动参数为 -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xmx32m:</p>
<pre><code>2.808: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003076 secs]
2.819: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003079 secs]
2.830: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0002968 secs]
2.842: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003374 secs]
2.853: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0004672 secs]
2.864: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003371 secs]
2.875: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003214 secs]
2.886: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003374 secs]
2.896: [GC (Allocation Failure) 
        [PSYoungGen: 9760K-&gt;32K(10240K)], 0.0003588 secs]
</code></pre><p>minor GC的频率过高，就说明创建了大量的对象。而年轻代在GC之后的使用量又很低, 也没有full GC发生。 因此，GC对吞吐量造成了严重的影响。</p>
<p>解决方案<br>在某些情况下,只要增加年轻代的大小, 即可降低分配速率过高所造成的影响。增加年轻代空间并不会降低分配速率, 但是会减少GC的频率。如果每次GC后只有少量对象存活, minor GC 的暂停时间就不会明显增加。</p>
<p>运行 示例程序 时, 增加堆内存大小,(同时也就增大了年轻代的大小), 使用的JVM参数为 -Xmx64m:</p>
<pre><code>2.808: [GC (Allocation Failure) 
        [PSYoungGen: 20512K-&gt;32K(20992K)], 0.0003748 secs]
2.831: [GC (Allocation Failure) 
        [PSYoungGen: 20512K-&gt;32K(20992K)], 0.0004538 secs]
2.855: [GC (Allocation Failure) 
        [PSYoungGen: 20512K-&gt;32K(20992K)], 0.0003355 secs]
2.879: [GC (Allocation Failure) 
        [PSYoungGen: 20512K-&gt;32K(20992K)], 0.0005592 secs]
</code></pre><p>但有时候增加堆内存的大小,并不能解决问题。通过前面学到的知识, 我们可以通过分配分析器找出大部分垃圾产生的位置。实际上在此示例中, 99%的对象属于 Double 包装类, 在readSensor 方法中创建。最简单的优化, 将创建的 Double 对象替换为原生类型 double, 而针对 null 值的检测, 可以使用 Double.NaN 来进行。由于原生类型不算是对象, 也就不会产生垃圾, 导致GC事件。优化之后, 不在堆中分配新对象, 而是直接覆盖一个属性域即可。</p>
<h3 id="过早提升-Premature-Promotion"><a href="#过早提升-Premature-Promotion" class="headerlink" title="过早提升(Premature Promotion)"></a>过早提升(Premature Promotion)</h3><p>提升速率(promotion rate), 用于衡量单位时间内从年轻代提升到老年代的数据量。一般使用 MB/sec 作为单位, 和分配速率类似。</p>
<p>JVM会将长时间存活的对象从年轻代提升到老年代。根据分代假设, 可能存在一种情况, 老年代中不仅有存活时间长的对象,也可能有存活时间短的对象。这就是过早提升：对象存活时间还不够长的时候就被提升到了老年代。</p>
<p>major GC 不是为频繁回收而设计的, 但 major GC 现在也要清理这些生命短暂的对象, 就会导致GC暂停时间过长。这会严重影响系统的吞吐量。</p>
<p>GC之前和之后的 年轻代使用量以及堆内存使用量。这样就可以通过差值算出老年代的使用量。请注意, 只能根据 minor GC 计算提升速率。 Full GC 的日志不能用于计算提升速率, 因为 major GC 会清理掉老年代中的一部分对象。</p>
<h4 id="提升速率的意义"><a href="#提升速率的意义" class="headerlink" title="提升速率的意义"></a>提升速率的意义</h4><p>和分配速率一样, 提升速率也会影响GC暂停的频率。但分配速率主要影响 minor GC, 而提升速率则影响 major GC 的频率。有大量的对象提升,自然很快将老年代填满。 老年代填充的越快, 则 major GC 事件的频率就会越高。</p>
<h4 id="过早提升的影响"><a href="#过早提升的影响" class="headerlink" title="过早提升的影响"></a>过早提升的影响</h4><p>demo:</p>
<pre><code class="java">public class PrematurePromotion {
   private static final Collection&lt;byte[]&gt; accumulatedChunks 
                = new ArrayList&lt;&gt;();
   private static void onNewChunk(byte[] bytes) {
       accumulatedChunks.add(bytes);
       if(accumulatedChunks.size() &gt; MAX_CHUNKS) {
           processBatch(accumulatedChunks);
           accumulatedChunks.clear();
       }
   }
}
</code></pre>
<p>一般来说,过早提升的症状表现为以下形式:</p>
<ul>
<li>短时间内频繁地执行 full GC。</li>
<li>每次 full GC 后老年代的使用率都很低, 在10-20%或以下。</li>
<li>提升速率接近于分配速率。</li>
</ul>
<p>要演示这种情况稍微有点麻烦, 所以我们使用特殊手段, 让对象提升到老年代的年龄比默认情况小很多。指定GC参数 -Xmx24m -XX:NewSize=16m -XX:MaxTenuringThreshold=1, 运行程序之后,可以看到下面的GC日志:</p>
<pre><code>2.176: [Full GC (Ergonomics) 
        [PSYoungGen: 9216K-&gt;0K(10752K)] 
        [ParOldGen: 10020K-&gt;9042K(12288K)] 
        19236K-&gt;9042K(23040K), 0.0036840 secs]
2.394: [Full GC (Ergonomics) 
        [PSYoungGen: 9216K-&gt;0K(10752K)] 
        [ParOldGen: 9042K-&gt;8064K(12288K)] 
        18258K-&gt;8064K(23040K), 0.0032855 secs]
2.611: [Full GC (Ergonomics) 
        [PSYoungGen: 9216K-&gt;0K(10752K)] 
        [ParOldGen: 8064K-&gt;7085K(12288K)] 
        17280K-&gt;7085K(23040K), 0.0031675 secs]
2.817: [Full GC (Ergonomics) 
        [PSYoungGen: 9216K-&gt;0K(10752K)] 
        [ParOldGen: 7085K-&gt;6107K(12288K)] 
        16301K-&gt;6107K(23040K), 0.0030652 secs]
</code></pre><p>乍一看似乎不是过早提升的问题。事实上,在每次GC之后老年代的使用率似乎在减少。但反过来想, 要是没有对象提升或者提升率很小, 也就不会看到这么多的Full GC了。</p>
<p>简单解释一下这里的GC行为: 有很多对象提升到老年代, 同时老年代中也有很多对象被回收了, 这就造成了老年代使用量减少的假象. 但事实是大量的对象不断地被提升到老年代, 并触发full GC。</p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>简单来说, 要解决这类问题, 需要让年轻代存放得下暂存的数据。有两种简单的方法:</p>
<p>一是增加年轻代的大小, 设置JVM启动参数, 类似这样: -Xmx64m -XX:NewSize=32m, 程序在执行时, Full GC 的次数自然会减少很多, 只会对 minor GC的持续时间产生影响:</p>
<p>二是减少每次批处理的数量, 也能得到类似的结果. 至于选用哪个方案, 要根据业务需求决定。在某些情况下, 业务逻辑不允许减少批处理的数量, 那就只能增加堆内存,或者重新指定年轻代的大小。</p>
<p>如果都不可行, 就只能优化数据结构, 减少内存消耗。但总体目标依然是一致的: 让临时数据能够在年轻代存放得下。</p>
<h3 id="Weak-Soft-及-Phantom-引用"><a href="#Weak-Soft-及-Phantom-引用" class="headerlink" title="Weak, Soft 及 Phantom 引用"></a>Weak, Soft 及 Phantom 引用</h3><ul>
<li>强引用：代码中普遍存在的类似<code>object obj = new object()</code>的引用，只要强引用存在，垃圾处理器就不会回收。</li>
<li>软引用：描述有些还有用但非必须的对象。在系统将要发生内存溢出时，会将这些对象列为回收范围进行二次回收，如果这次回收后还没有足够的内存，才会oom。Java中SoftReference类表示软引用。</li>
<li>弱引用：描述非必须对象，被弱引用关联的对象只能生存到下一次回收之前，垃圾收集器工作之后，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。Java中WeakReference类表示软引用。</li>
<li>虚引用：这个引用存在的唯一目的，就是在这个对象被收集器回收时得到一个系统通知，被虚引用关联的对象，和其生存时间完全没有关系。Java中PhantomReference类表示软引用。</li>
</ul>
<h4 id="弱引用的缺点"><a href="#弱引用的缺点" class="headerlink" title="弱引用的缺点"></a>弱引用的缺点</h4><p>首先, 弱引用(weak reference) 是可以被GC强制回收的。当垃圾收集器发现一个弱可达对象(weakly reachable,即指向该对象的引用只剩下弱引用) 时, 就会将其置入相应的ReferenceQueue 中, 变成可终结的对象. 之后可能会遍历这个 reference queue, 并执行相应的清理。典型的示例是清除缓存中不再引用的KEY。</p>
<p>当然, 在这个时候, 我们还可以将该对象赋值给新的强引用, 在最后终结和回收前, GC会再次确认该对象是否可以安全回收。因此, 弱引用对象的回收过程是横跨多个GC周期的。</p>
<p>实际上弱引用使用的很多。大部分缓存框架(caching solution)都是基于弱引用实现的, 所以虽然业务代码中没有直接使用弱引用, 但程序中依然会大量存在。</p>
<p>其次, 软引用(soft reference) 比弱引用更难被垃圾收集器回收. 回收软引用没有确切的时间点, 由JVM自己决定. 一般只会在即将耗尽可用内存时, 才会回收软引用,以作最后手段。这意味着, 可能会有更频繁的 full GC, 暂停时间也比预期更长, 因为老年代中的存活对象会很多。</p>
<p>最后, 使用虚引用(phantom reference)时, 必须手动进行内存管理, 以标识这些对象是否可以安全地回收。表面上看起来很正常, 但实际上并不是这样。 javadoc 中写道:</p>
<p>为了防止可回收对象的残留, 虚引用对象不应该被获取: phantom reference 的 get 方法返回值永远是 null。</p>
<p>令人惊讶的是, 很多开发者忽略了下一段内容(这才是重点):</p>
<p>与软引用和弱引用不同, 虚引用不会被 GC 自动清除, 因为他们被存放到队列中. 通过虚引用可达的对象会继续留在内存中, 直到调用此引用的 clear 方法, 或者引用自身变为不可达。</p>
<p>也就是说,我们必须手动调用 clear()) 来清除虚引用, 否则可能会造成 OutOfMemoryError 而导致 JVM 挂掉. 使用虚引用的理由是, 对于用编程手段来跟踪某个对象何时变为不可达对象, 这是唯一的常规手段。 和软引用/弱引用不同的是, 我们不能复活虚可达(phantom-reachable)对象。</p>
<p>建议使用JVM参数 -XX:+PrintReferenceGC 来看看各种引用对GC的影响。</p>
<h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>如果程序确实碰到了 mis-, ab- 问题或者滥用 weak, soft, phantom 引用, 一般都要修改程序的实现逻辑。每个系统不一样, 因此很难提供通用的指导建议, 但有一些常用的办法:</p>
<ul>
<li>弱引用(Weak references) —— 如果某个内存池的使用量增大, 造成了性能问题, 那么增加这个内存池的大小(可能也要增加堆内存的最大容量)。如, 增加堆内存的大小, 以及年轻代的大小, 可以减轻症状。</li>
<li>虚引用(Phantom references) —— 请确保在程序中调用了虚引用的 clear 方法。编程中很容易忽略某些虚引用, 或者清理的速度跟不上生产的速度, 又或者清除引用队列的线程挂了, 就会对GC 造成很大压力, 最终可能引起 OutOfMemoryError。</li>
<li>软引用(Soft references) —— 如果确定问题的根源是软引用, 唯一的解决办法是修改程序源码, 改变内部实现逻辑。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> jvm </category>
            
            <category> gc </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jvm </tag>
            
            <tag> gc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[总结下jvm gc的知识]]></title>
      <url>/2020/11/12/jvm-gc/</url>
      <content type="html"><![CDATA[<h2 id="jvm的内存模型"><a href="#jvm的内存模型" class="headerlink" title="jvm的内存模型"></a>jvm的内存模型</h2><p>jdk8之前</p>
<p><img src="https://s3.ax1x.com/2020/11/16/Dkodu6.png" alt="Dkodu6.png"></p>
<p>jdk8之后</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DABmHP.png" alt="DABmHP.png"></p>
<p>程序计数器，本地方法栈和虚拟机栈都是线程私有的，不需要回收。</p>
<p>堆是线程共享的，所有对象实例都应该在堆上分配内存。</p>
<p>方法区，用于存储已被虚拟机加载的类型信息、常量、静态变量等。在jdk8之前为永久带，8之后改为metaspace，（原因是永久带有最大限制，更容易出现oom），metaspace直接使用堆外内存（即本地内存）进行储存。</p>
<p>堆外内存，可以通过nio中的DirectByteBuffer.allocateDirect()直接申请内存空间。</p>
<h2 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h2><p>对象的分配会先检查类的加载，确定类加载后为对象从堆中分配出一块连续空间，然后再设置对象头信息，最后执行构造函数。</p>
<p>对象包含三部分：</p>
<p>对象头：包括两类信息。第一类是用于存储对象自身的运行时数据，如哈 希码(HashCode)、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。另外一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针 来确定该对象是哪个类的实例。</p>
<p>实例数据：对象真正存储的有效信息。</p>
<p>对齐填充：不是必须的，对象为8字节的整数倍，所以需要占位符。</p>
<h2 id="回收原则"><a href="#回收原则" class="headerlink" title="回收原则"></a>回收原则</h2><h3 id="对象的回收"><a href="#对象的回收" class="headerlink" title="对象的回收"></a>对象的回收</h3><p>引用计数：给对象添加一个引用计数器，引用时+1，引用失效时-1。java并没有选择这种方法，因为无法判断循环引用。</p>
<p>可达性分析：通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过 程所走过的路径称为“引用链”(Reference Chain)，如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAp7jO.png" alt="DAp7jO.png"></p>
<p>固定可作为GC Roots的对象包括以下几种:</p>
<ul>
<li>在虚拟机栈(栈帧中的本地变量表)中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等。</li>
<li>在方法区中类静态属性引用的对象，譬如Java类的引用类型静态变量。</li>
<li>在方法区中常量引用的对象，譬如字符串常量池(String Table)里的引用。</li>
<li>在本地方法栈中JNI(即通常所说的Native方法)引用的对象。</li>
<li>Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象(比如NullPointExcepiton、OutOfMemoryError)等，还有系统类加载器。</li>
<li>所有被同步锁(synchronized关键字)持有的对象。</li>
<li>反映Java虚拟机内部情况的JM XBean、JVM TI中注册的回调、本地代码缓存等。</li>
</ul>
<p>要真正宣告一个对象死亡，至少要经历两次标记过程:</p>
<p>如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。假如对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用 过，那么虚拟机将这两种情况都视为“没有必要执行”。</p>
<p>如果这个对象被判定为确有必要执行finalize()方法，那么该对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的Finalizer线程去执行它们的finalize()方法。这里所说的“执行”是指虚拟机会触发这个方法开始运行，但并不承诺一定会等待它运行结束。finalize()方法是对象逃脱死亡命运的最后一次机会，如果对象要在finalize()中成功拯救自己————只要重新与引用链上的任何一个对象建立关联即可，譬如把自己 (this关键字)赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的 合;如果对象这时候还没有逃脱，那基本上它就真的要被回收了。</p>
<h3 id="方法区的回收"><a href="#方法区的回收" class="headerlink" title="方法区的回收"></a>方法区的回收</h3><p>方法区的垃圾收集主要回收两部分内容:废弃的常量和不再使用的类型。</p>
<p>常量不再被引用跟对象的判定相似。</p>
<p>类的回收判定比较苛刻：</p>
<ul>
<li>该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。</li>
<li>加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的。</li>
<li>该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>
</ul>
<h3 id="堆外内存的回收"><a href="#堆外内存的回收" class="headerlink" title="堆外内存的回收"></a>堆外内存的回收</h3><p>JDK中使用DirectByteBuffer对象来表示堆外内存，每个DirectByteBuffer对象在初始化时，都会创建一个对应的Cleaner对象，用于保存堆外内存的元信息（开始地址、大小和容量等），当DirectByteBuffer被GC回收后，Cleaner对象被放入ReferenceQueue中，然后由ReferenceHandler守护线程调用unsafe.freeMemory(address)，回收堆外内存。 在Cleaner 内部中通过一个列表，维护了一个针对每一个 directBuffer 的一个回收堆外内存的 线程对象(Runnable)，回收操作是发生在 Cleaner 的 clean() 方法中。</p>
<p>Direct Memory是受GC控制的，例如ByteBuffer bb = ByteBuffer.allocateDirect(1024)，这段代码的执行会在堆外占用1k的内存，Java堆内只会占用一个对象的指针引用的大小，堆外的这1k的空间只有当bb对象被回收时，才会被回收，这里会发现一个明显的不对称现象，就是堆外可能占用了很多，而堆内没占用多少，导致还没触发GC，那就很容易出现Direct Memory造成物理内存耗光。</p>
<p>Direct ByteBuffer分配出去的内存其实也是由GC负责回收的，而不像Unsafe是完全自行管理的，Hotspot在GC时会扫描Direct ByteBuffer对象是否有引用，如没有则同时也会回收其占用的堆外内存。</p>
<p>主动回收（推荐）：对于Sun的JDK，只要从DirectByteBuffer里取出那个sun.misc.Cleaner，然后调用它的clean()就行；</p>
<p>基于 GC 回收：堆内的DirectByteBuffer对象被GC时，会调用cleaner回收其引用的堆外内存。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAD9rn.png" alt="DAD9rn.png"></p>
<p>堆外内存注意<br>java.nio.DirectByteBuffer对象在创建过程中会先通过Unsafe接口直接通过os::malloc来分配内存，然后将内存的起始地址和大小存到java.nio.DirectByteBuffer对象，这样就可以直接操作这些内存。这些内存只有在DirectByteBuffer回收掉之后才有机会被回收。</p>
<p>当我们基于GC回收时，YGC只会将新生代里的不可达的DirectByteBuffer对象及其堆外内存回收，如果有大量的DirectByteBuffer对象移到了old区，但是又一直没有做CMS GC或者FGC，而只进行YGC，物理内存会被慢慢耗光，触发OutOfMemoryError。</p>
<p>因此为了避免这种悲剧的发生，通过-XX:MaxDirectMemorySize来指定最大的堆外内存大小，当使用达到了阈值的时候将调用System.gc来做一次full gc，以此来回收掉没有被使用的堆外内存。</p>
<p>堆外内存优缺点<br>优点：</p>
<ul>
<li>提升了IO效率（避免了数据从用户态向内核态的拷贝）。堆内内存由JVM管理，属于“用户态”；而堆外内存由OS管理，属于“内核态”。如果从堆内向磁盘写数据时，数据会被先复制到堆外内存，即内核缓冲区，然后再由OS写入磁盘，使用堆外内存避免了数据从用户内向内核态的拷贝。</li>
<li>对垃圾回收停顿的改善因为full gc意味着彻底回收，彻底回收时，垃圾收集器会对所有分配的堆内内存进行完整的扫描，这意味着一个重要的事实——这样一次垃圾收集对Java应用造成的影响，跟堆的大小是成正比的。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理( 而不是虚拟机 )。这样做的结果就是能保持一个较小的堆内内存，以减少垃圾收集对应用的影响。</li>
<li>可以在进程间共享，减少JVM间的对象复制，使得JVM的分割部署更容易实现</li>
<li>可以扩展至更大的内存空间。比如超过1TB甚至比主存还大的空间</li>
<li>它的持久化存储可以支持快速重启，同时还能够在测试环境中重现生产数据</li>
</ul>
<p>缺点：</p>
<ul>
<li>分配和回收堆外内存比分配和回收堆内存耗时；（解决方案：通过对象池避免频繁地创建和销毁堆外内存）</li>
<li>堆外内存的泄漏问题</li>
<li>堆外内存的数据结构问题：堆外内存最大的问题就是你的数据结构变得不那么直观，如果数据结构比较复杂，就要对它进行串行化（serialization），而串行化本身也会影响性能。另一个问题是由于你可以使用更大的内存，你可能开始担心虚拟内存（即硬盘）的速度对你的影响了。</li>
</ul>
<h2 id="回收算法"><a href="#回收算法" class="headerlink" title="回收算法"></a>回收算法</h2><h3 id="分带与跨带"><a href="#分带与跨带" class="headerlink" title="分带与跨带"></a>分带与跨带</h3><p>设计者一般至少会把Java堆划分为新生代(Young Generation)和老年代(Old Generation)两个区域。顾名思义，在新生代中，对象是朝生夕灭的，每次垃圾收集时都发现有大批对象死去，而每次回收后存活的少量对象，将会逐步晋升到老年代中存放。</p>
<p>但是，对象不是孤立的，对象之间会存在跨代引用。如果老年代中引用了新生代的对象，在新生代中做可达性分析时就会带上老年代，反而降低效率。</p>
<p>所以有了 跨代引用假说(Intergenerational Reference Hypothesis):跨代引用相对于同代引用来说仅占极少数。</p>
<p>依据这条假说，我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录 每一个对象是否存在及存在哪些跨代引用，只需在新生代上建立一个全局的数据结构(该结构被称 为“记忆集”，Remembered Set)，这个结构把老年代划分成若干小块，标识出老年代的哪一块内存会 存在跨代引用。此后当发生Minor GC时，只有包含了跨代引用的小块内存里的对象才会被加入到GC Roots进行扫描。</p>
<p>一些常见的定义：<br>部分收集(Partial GC):指目标不是完整收集整个Java堆的垃圾收集，其中又分为:</p>
<ul>
<li>新生代收集(Minor GC/Young GC):指目标只是新生代的垃圾收集。</li>
<li>老年代收集(Major GC/Old GC):指目标只是老年代的垃圾收集。目前只有CMS收集器会有单独收集老年代的行为。</li>
<li>混合收集(Mixed GC):指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有G1收集器会有这种行为。</li>
<li>整堆收集(Full GC):收集整个Java堆和方法区的垃圾收集。</li>
</ul>
<p>Minor GC和Full GC的区别以及触发条件：</p>
<p>Minor GC:</p>
<p>对于复制算法来说，当年轻代Eden区域满的时候会触发一次Minor GC，将Eden和From Survivor的对象复制到另外一块To Survivor上。</p>
<p>注意：如果某个对象存活的时间超过一定Minor gc次数会直接进入老年代，不在分配到To Survivor上(默认15次，对应虚拟机参数 -XX:+MaxTenuringThreshold)。另外，如果单个 Survivor 区已经被占用了 50% (对应虚拟机参数: -XX:TargetSurvivorRatio)，那么较高复制次数的对象也会被晋升至老年代。</p>
<p>Full GC:</p>
<p>用于清理整个堆空间。它的触发条件主要有以下几种：</p>
<ul>
<li>显式调用System.gc方法(建议JVM触发)。</li>
<li>方法区空间不足(JDK8及之后不会有这种情况了)</li>
<li>老年代空间不足，引起Full GC。这种情况比较复杂，有以下几种：<ul>
<li>大对象直接进入老年代引起，由-XX:PretenureSizeThreshold参数定义</li>
<li>Minor GC时，经历过多次Minor GC仍存在的对象进入老年代。上面提过，由-XX:MaxTenuringThreashold参数定义</li>
<li>Minor GC时，动态对象年龄判定机制会将对象提前转移老年代。年龄从小到大进行累加，当加入某个年龄段后，累加和超过survivor区域 * -XX:TargetSurvivorRatio的时候，从这个年龄段往上的年龄的对象进入老年代</li>
<li>Minor GC时，Eden和From Space区向To Space区复制时，大于To Space区可用内存，会直接把对象转移到老年代</li>
</ul>
</li>
</ul>
<p>JVM的空间分配担保机制可能会触发Full GC：</p>
<p>空间担保分配是指在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。</p>
<p>如果大于，则此次Minor GC是安全的。如果小于，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的，失败后会重新发起一次Full gc；如果小于或者HandlePromotionFailure=false，则改为直接进行一次Full GC。</p>
<p>所有才会说一次Full GC很有可能是由一次Minor GC触发的。</p>
<h3 id="标记清楚算法"><a href="#标记清楚算法" class="headerlink" title="标记清楚算法"></a>标记清楚算法</h3><p>首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回 收所有未被标记的对象。标记过程就是对象是否属于垃圾的判定过程。</p>
<p>它的主要缺点有两个:</p>
<p>第一个是执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低;</p>
<p>第二个是内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找 到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAAXsx.png" alt="DAAXsx.png"></p>
<h3 id="标记-复制算法"><a href="#标记-复制算法" class="headerlink" title="标记-复制算法"></a>标记-复制算法</h3><p>它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。如果内存中多数对象都是存 活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复 制的就是占少数的存活对象，而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可。这样实现简单，运行高效，不过其缺陷也显而易见，这种复制回收算法的代价是将可用内存缩小为了原来的一半，空间浪费未免太多了一点。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAE1ln.png" alt="DAE1ln.png"></p>
<p>Appel式回收: HotSpot虚拟机的Serial、ParNew等新生代收集器均采用了这种策略来设计新生代的内存布局。Appel式回收的具体做法是把新生代分为一块较大的Eden空间和两块较小的 Survivor空间，每次分配内存只使用Eden和其中一块Survivor。发生垃圾搜集时，将Eden和Survivor中仍 然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也即每次新生代中可用内存空间为整个新 生代容量的90%(Eden的80%加上一个Survivor的10%)，只有一个Survivor空间，即10%的新生代是会 被“浪费”的。当Survivor空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域(实际上大多就是老年代)进行分配担保(Handle Promotion)。</p>
<p>新生代上对象朝生夕灭的特点决定了它更适用复制算法，而不用担心空间的损耗。</p>
<p>Survivor区的意义：</p>
<p>如果没有survivor,Eden每进行一次minor gc，存活的对象就会进入老年代，老年代很快被填满就会进入major gc。由于老年代空间一般很大，所以进行一次gc耗时要长的多！尤其是频繁进行full GC，对程序的响应和连接都会有影响！</p>
<p>Survivor存在就是减少被送到老年代的对象，进而减少Full gc的发生。默认设置是经历了16次minor gc还在新生代中存活的对象才会被送到老年代。</p>
<p>为什么要有两个Survivor：</p>
<p>主要是为了解决内存碎片化和效率问题。如果只有一个Survivor时，每触发一次minor gc都会有数据从Eden放到Survivor，一直这样循环下去。注意的是，Survivor区也会进行垃圾回收，这样就会出现内存碎片化问题。</p>
<h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><p>针对老年代对象的长时间存在的特征，“标记-整理”(Mark-Compact)算法诞生，其中的标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可 回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存。</p>
<p>移动存活对象，尤其是在老年代这种每次回收都有大量对象存活区域，移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作，而且这种对象移动操作必须全程暂停用户应用程序才能进行。</p>
<p>HotSpot虚拟机里面关注吞吐量的Parallel Scavenge收集器是基于标记-整理算法的，而关注延迟的CMS收集器则是基于标记-清除算法的。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAm2DI.png" alt="DAm2DI.png"></p>
<h3 id="根节点枚举"><a href="#根节点枚举" class="headerlink" title="根节点枚举"></a>根节点枚举</h3><p>根节点枚举，所有收集器在这一步骤时都是必须暂停用户线程的（stop the world）。当用户线程停顿下来之后，hotspot使用一组称为OopMap的数据结构来得到哪些地方存放着对象引用。</p>
<p>一旦类加载动作完成的时候， HotSpot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用。这样收集器在扫描时就可以直接得知这些信息了，并不需要真正一个不漏地从方法区等GC Roots开始查找。</p>
<h3 id="安全点"><a href="#安全点" class="headerlink" title="安全点"></a>安全点</h3><p>如果为每一条指令都生成对应的OopMap，那将会需要大量的额外存储空间。HotSpot只是在“特定的位置”记录了这些信息，这些位置被称为安全点(Safepoint)。</p>
<p>有了安全点的设定，也就决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是强制要求必须执行到达安全点后才能够暂停。</p>
<p>因此，安全点的选定既不能太少以至于让收集器等待时间过长，也不能太过频繁以至于过分增大运行时的内存负荷。具备“长时间执行”的特征的指令序列的复用，例如方法调用、循环跳转、异常跳转等才会产生安全点。</p>
<h3 id="安全区域"><a href="#安全区域" class="headerlink" title="安全区域"></a>安全区域</h3><p>安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任 意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。</p>
<h3 id="记忆集与卡表"><a href="#记忆集与卡表" class="headerlink" title="记忆集与卡表"></a>记忆集与卡表</h3><p>记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。</p>
<p>为解决对象跨代引用所带来的问题，垃圾收集器在新生代中建立了名为记忆集(Remembered Set)的数据结构，用以避免把整个老年代加进GC Roots扫描范围。</p>
<p>在垃圾收集的场景中，收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针。</p>
<p>HotSpot使用“卡精度”:每个记录精确到一块内存区域，该区域内有对象含有跨代指针。也称为称为“卡表”(Card Table)。</p>
<p>字节数组CARD_TABLE的每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称作“卡页”(Card Page)。</p>
<p>一个卡页的内存中通常包含不止一个对象，只要卡页内有一个(或更多)对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏(Dirty)，没有则标识为0。在垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把它们加入GC Roots中一并扫描。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAuY01.png" alt="DAuY01.png"></p>
<h3 id="写屏障"><a href="#写屏障" class="headerlink" title="写屏障"></a>写屏障</h3><p>卡表状态的维护：有其他分代区域中对象引用了本区域对象时，其对应的卡表元素就应该变脏，变脏时间点原则上应该发生在引用类型字段赋值的那一刻。</p>
<p>在HotSpot虚拟机里是通过写屏障(Write Barrier)技术维护卡表状态的。写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环形(Around)通知，供程序执行额外的动作，也就是说赋值的 前后都在写屏障的覆盖范畴内。</p>
<p>应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令，一旦收集器在写屏障中增加了更新 卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用进行更新，就会产生额外的开销。</p>
<h3 id="并发的可达性分析"><a href="#并发的可达性分析" class="headerlink" title="并发的可达性分析"></a>并发的可达性分析</h3><p>可达性分析算法理论上要求全过程都基于一个能保障一致性的快照中才能够进行分析， 这意味着必须全程冻结用户线程的运行。</p>
<p>我们引入三色标记(Tri-color Marking)作为工具来辅<br>助推导，把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成以下三种颜色:</p>
<ul>
<li>白色:表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。</li>
<li>黑色:表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接(不经过灰色对象)指向某个白色对象。</li>
<li>灰色:表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。</li>
</ul>
<p>如果用户线程与收集器是并发工作，收集器在对象图上标记颜色，同时用户线程在修改引用关系————即修改对象图的结构，这样可能出现两种后果。一种是把原本消亡的对象错误标记为存活。另一种是把原本存活的对象错误标记为已消亡，后者十分严重，会产生对象消失。</p>
<p>对象消失，即原本应该是黑色的对象被误标为白色，其产生条件：</p>
<ul>
<li>赋值器插入了一条或多条从黑色对象到白色对象的新引用;</li>
<li>赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/20/DlGbon.png" alt="DlGbon.png"></p>
<p>有两种解决方法：</p>
<ul>
<li>增量更新，增量更新要破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫 描一次。这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。</li>
<li>原始快照，原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删 除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索。</li>
</ul>
<p>以上无论是对引用关系记录的插入还是删除，虚拟机的记录操作都是通过写屏障实现的。在 HotSpot虚拟机中，增量更新和原始快照这两种解决方案都有实际应用，CMS是基于增量更新 来做并发标记的，G1、Shenandoah则是用原始快照来实现。</p>
<h2 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h2><p><img src="https://s3.ax1x.com/2020/11/16/DAQ36g.png" alt="DAQ36g.png"></p>
<h3 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h3><p>单线程工作的收集器，它进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAQB1U.png" alt="DAQB1U.png"></p>
<p>优于其他收集器的地方，那就是简单而高效(与其他收集器的单线程相比)，对于内<br>存资源受限的环境，它是所有收集器里额外内存消耗(Memory Footprint)最小的;对于单核处理器或处理器核心数较少的环境来说，Serial收集器没有线程交互的开销。</p>
<h3 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h3><p>Serial Old是Serial收集器的老年代版本，使用标记整理算法。</p>
<h3 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h3><p>吞吐量优先收集器。（吞吐量：每秒钟接待多少人；响应时间：每个人要等多长时间才能得到服务。）Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间 的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。</p>
<p>垃圾收集停顿时间缩短是以牺牲吞吐量和新生代空间为代价换取的: 系统把新生代调得小一些，收集300MB新生代肯定比收集500MB快，但这也直接导致垃圾收集发生得更频繁，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间 的确在下降，但吞吐量也降下来了。</p>
<h3 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h3><p>Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。</p>
<h3 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h3><p>ParNew收集器实质上是Serial收集器的多线程并行版本，除了同时使用多条线程进行垃圾收集之外，其余的行为包括Serial收集器可用的所有控制参数 、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一致。</p>
<p>除了Serial收集器外，目前只有它能与CMS收集器配合工作。自JDK 9开始，ParNew合并入CMS，成为它专门处理新生代的组成部分。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAlNKe.png" alt="DAlNKe.png"></p>
<h3 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h3><p>CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。基于标记-清除算法实现的。整个过程分为四个步骤：</p>
<ul>
<li>初始标记(CMS initial mark) ————“Stop The World”，标记GC Roots</li>
<li>并发标记(CMS concurrent mark) ————并发进行可达性分析</li>
<li>重新标记(CMS remark) ————“Stop The World”，增量更新</li>
<li>并发清除(CMS concurrent sweep)</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/16/DANS7F.png" alt="DANS7F.png"></p>
<p>缺点：</p>
<ul>
<li>CMS收集器对处理器资源非常敏感。事实上，面向并发设计的程序都对处理器资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分线程(或者说处理器的计算能力)而导致应用程序变慢，降低总吞吐量。</li>
<li>由于CMS收集器无法处理“浮动垃圾”(FloatingGarbage)。在CMS的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为“浮动垃圾”。</li>
<li>可能出现“Concurrent Mode Failure”失败进而导致另一次完全“Stop The World”的Full GC的产生。由于在垃圾收集阶段用户线程还需要持续运行，那就还需要预留足够内存空间提供给用户线程使用，因此CMS收集器不能像其他收集器那样等待到老年代几乎完全被填满了再进行收集，必须预留一部分空间供并发收集时的程序运作使用。要是CMS运行期间预留的内存无法满足程序分配新对象的需要，就会出现一次“并发失败”(Concurrent Mode Failure)，这时候虚拟机将不得不启动后备预案:冻结用户线程的执行，临时启用Serial Old收集器来重新进行老年代的垃圾收集，但这样停顿时间就很长了。</li>
<li>CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况。</li>
</ul>
<h3 id="g1收集器"><a href="#g1收集器" class="headerlink" title="g1收集器"></a>g1收集器</h3><p>全堆收集器，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式。</p>
<p>基于Region的堆内存布局，连续的Java堆划分为多个大小相等的独立区域(Region)，每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。虽然G1仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了，它们都是一系列区 域(不需要连续)的动态集合。收集器能够对扮演不同角色的Region采用不同的策略去处理。</p>
<p>每个Region的大小可以通过参数-XX:G1Heap RegionSize设定，取值范围为1M B~32MB，且应为2的N次幂。而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中，G1的大多数行为都把Humongous Region作为老年代 的一部分来进行看待。</p>
<p>g1将Region作为单次回收的最小单元，即每次收集到的内存空间都是Region大小的整数倍，这样可以有计划地避免在整个Java堆中进行全区域的垃圾收集。更具体的处理思路是让G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一 个优先级列表，每次根据用户设定允许的收集停顿时间(使用参数-XX:MaxGCPauseMillis指定，默认值是200毫秒)，优先处理回收价值收益最大的那些Region。</p>
<p>跨Region使用特殊的记忆集（双向卡表，Key是别的Region的起始地址，Value是一个集合，里面存储的元素是卡表的索引号。）通过写屏障来维护记忆集能处理跨代指针，得以实现Region的增量回收。</p>
<p><img src="https://s3.ax1x.com/2020/11/16/DAajXt.png" alt="DAajXt.png"></p>
<p>G1收集器的运作过程大致可划分为以下四个步骤:</p>
<ul>
<li>初始标记(Initial Marking):仅仅只是标记一下GC Roots能直接关联到的对象（stop the world）</li>
<li>并发标记(Concurrent Marking):从GC Root开始对堆中对象进行可达性分析，通过原始快照来处理并发问题。</li>
<li>最终标记(Final Marking):对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留 下来的最后那少量的原始快照记录。（stop the world）</li>
<li>筛选回收(Live Data Counting and Evacuation):负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region构成回收集（整理），然后把决定回收的那一部分Region的存活对象复制到空的Region中（复制），再清理掉整个旧Region的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。（stop the world）</li>
</ul>
<p><img src="https://s3.ax1x.com/2020/11/16/DAdYB6.png" alt="DAdYB6.png"></p>
<p>G1和CMS的比较:</p>
<ul>
<li>G1从整体上看是“标记-整理”算法，从局部（两个Region之间）上看是“标记-复制”算法，不会产生内存碎片，而CMS基于“标记-清除”算法会产生内存碎片。</li>
<li>G1在垃圾收集时产生的内存占用和程勋运行时的额外负载都比CMS高</li>
<li>G1支持动态指定停顿时间，而CMS无法指定</li>
<li>两者都利用了并发标记这个技术</li>
</ul>
<h3 id="ZGC收集器"><a href="#ZGC收集器" class="headerlink" title="ZGC收集器"></a>ZGC收集器</h3><p>ZGC收集器是一款基于Region内存布局的，(暂时) 不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器。接下来，笔者将逐项来介绍ZGC的这些技术特点。</p>
<p>（有点复杂，不展开了，记住Region分为大中小，整个收集过程都全程可并发，短暂停顿也只与GC Roots大小相关而与堆内存大小无关，完全没有使用记忆集，它甚至连分代都没有，不需要维护记忆集的写屏障，而用读屏障）</p>
<h2 id="gc调优"><a href="#gc调优" class="headerlink" title="gc调优"></a>gc调优</h2><p>单开一篇文章说吧，这一篇太长了</p>
]]></content>
      
        <categories>
            
            <category> jvm </category>
            
            <category> gc </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jvm </tag>
            
            <tag> gc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[k8s中的jvm]]></title>
      <url>/2020/11/11/jvm-in-container/</url>
      <content type="html"><![CDATA[<p>最近遇到了Java应用在k8s中频繁重启的问题，记录一下。</p>
<p>起因是因为一个bug，使我们的一个请求会大量申请许多新空对象，但这些空对象并没有被即使的回收，直接导致了pod级别的oomkille，或者直接被驱逐，于是开始了调查。</p>
<p>在Java 8u131和Java 9之前，JVM不能识别容器设置的内存或cpu限制。所以按照jvm的管理，最大堆的大小会设置为虚拟机内存的四分之一。我们当前node使用的虚拟机是64g的，因此xmx就被设置为了16g，但是我们并没有在pod中做memory limits的限制，当前node上又跑了许多其他的应用，这导致k8s无法给pod申请足够的内存，jvm的堆大小冲破了pod的实际可分配内存，直接被oomkilled并重启。被干掉的pod会留下一个Evicted状态的尸体，但这个pod尸体里没有events可以看，这增加了debug的难度。</p>
<p>仅仅在pod层面增加memory limits并不能解决问题，我们的jvm无法感知到容器的内存变化，仍旧以虚拟机内存的四分之一来设置最大堆的大小。<br>我们确实可以通过简单设置xmx和pod的resource limits来解决，但是并不优雅，应用资源与容器资源强耦合，忘改一处即可能带来灾难。因此我们来探索下有没有其他方式。</p>
<p>Java 8u131首先实现了称为的实验功能UseCGroupMemoryLimitForHeap。这是第一次尝试，但存在缺陷，为应用添加UnlockExperimentalVMOptions和UseCGroupMemoryLimitForHeap参数后，jvm确实可以感知到容器内存，并控制应用的实际堆大小。但是这并没有充分利用我们为容器分配的内存，jvm提供-XX:MaxRAMFraction标志来帮助更好的计算堆大小。</p>
<p>MaxRAMFraction默认值是4（即除以4），但不幸的是，它是一个分数，而不是一个百分比，因此很难设置一个能有效利用可用内存的值，但是为什么我们不设置MaxRAMFraction为1，使其使用100％的可用内存呢？因为容器中可能正在运行其他进程，或者一些通过shell链接到容器的工具。</p>
<p>Java 10附带了对容器环境的更好支持。如果你在Linux容器中运行Java应用程序，JVM将使用该UseContainerSupport选项自动检测内存限制。然后，您可以控制以下选项，InitialRAMPercentage，MaxRAMPercentage和MinRAMPercentage。这时，我们使用的是百分比而不是分数，这将更加准确。而这几个参数已经向下移植到Java 8u191。</p>
<p>UseContainerSupport默认情况下是激活的。MaxRAMPercentage是25%，MinRAMPercentage是50%。这里min竟然比max大，不知道为啥。<br>我们可以设置-XX:MinRAMPercentage=50.0，-XX:MaxRAMPercentage=80.0来是我们的应用感知，并充分利用pod的resource limits。<br>需要注意的是，UseCGroupMemoryLimitForHeap虽然仍可以在最新版本的Java8中使用，但是已经被视为弃用的参数了。</p>
<p>此外，在docker容器中运行JVM时，使用HeapDumpOnOutOfMemoryError参数可能是一个更明智的选择，因为，如果内存不足，jvm会将堆内存转储写入磁盘。默认情况下，堆内存会转储到VM的工作目录中的一个名为java_pid.hprof的文件中。您可以使用-XX:HeapDumpPath=来指定备用文件名或目录。例如，-XX:HeapDumpPath=/disk2/dumps将在/disk2/dumps目录中生成堆转储文件。请确保Java进程对堆转储的目录具有写入的访问权限。<br>接着在说一下cpu，pod可以给cpu的limits的限制，来确保pod可以调度到几个cpu核心，而jvm会根据cpu的核心数来设置是否使用ParallelGC，以及几个ParallelGCThreads。</p>
<p>但是如果我们不为pod设置cpu限制的话，jvm也并不能感知到虚拟机所有的可用cpu，而是认为只有一核，并关闭ParallelGC功能。因此在我们需要ParallelGC功能时，我们最好还设置cpu的限制。</p>
<p>而且通过查阅一些资料，发现cpu核数对jvm的工作线程也有着影响。<code>Runtime.getRuntime().availableProcessors()</code>，这段的代码常用于Java库，它会根据CPU的个数产生工作线程。如果没有正确设置docker中的参数，对实际的程序性能会产生很大的影响。availableProcessors就是根据核数而定的。</p>
<p>题外话：<br>一个完整的jdk对gc和jvm问题的排查十分重要。jinfo，jstat都是十分有用的工具，并且学会看gclog也十分重要。</p>
<p>一个小细节，我一直认为java -XX:+PrintFlagsFinal打印出的内容就是实际应用所在jvm进程的环境变量，但事实上，java -XX:+PrintFlagsFinal会单独建立一个进程，你打印出的东西都是这个命令所在进程的变量，而不是应用所在进程的变量。正确排查应用所在的jvm的进程的jvm变量还得用jinfo。</p>
<p>此外，我们安装了阿里的Arthas来进行jvm故障的排查，很有用。但考虑到有的时候我们也想在生产环境安装Arthas，但是不希望为生产环境的应用安装完整的jdk，怎么办？可以使用sidecar的方式来安装Arthas，然后通过shareProcessNamespace: true参数来在pod中share不同容器里的进程，这样sidecar里的Arthas就可以attach到你应用的pid了。详见：<a href="https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/。" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/。</a></p>
<p>先说到这，下回总结下gc的问题。</p>
]]></content>
      
        <categories>
            
            <category> k8s </category>
            
            <category> jvm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jvm </tag>
            
            <tag> k8s </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[微服务下的权限设计]]></title>
      <url>/2020/07/24/micro-service-authorization/</url>
      <content type="html"><![CDATA[<p><code>本文优先发表于CIO Talk微信公众号（微信号: CIO_China_Lab）</code></p>
<p>随着微服务架构的流行，越来越多的应用基于微服务架构设计和实现，同时带来了新的问题，传统单体应用架构下，认证和授权容易完成，但是微服务架构下，如何能更好的完成认证和授权，尤其在传统应用的微服务化转型过程中，如何更好的迁移，在不重新实现原有的权限管理系统的情况下，能够更优雅的实现复杂微服务架构下的认证和授权，本文将对上述问题做一些探讨。 </p>
<h1 id="微服务场景会为认证和授权带来哪些问题"><a href="#微服务场景会为认证和授权带来哪些问题" class="headerlink" title="微服务场景会为认证和授权带来哪些问题"></a>微服务场景会为认证和授权带来哪些问题</h1><p>在传统的单体架构应用中，当用户登录时，应用程序的安全模块验证用户的身份。在验证用户是合法的之后，为用户创建会话（session），并且将会话ID（session ID）与之相关联。服务器端会话存储登录用户信息，例如用户名，角色和权限。服务器将会话ID返回给客户端（浏览器）。客户端（浏览器）将会话ID记录为cookie，并在后续请求中将其发送到应用程序。然后，应用程序可以使用会话ID来验证用户的身份，而无需每次都输入用户名和密码进行身份验证。当客户端（浏览器）访问应用程序时，会话ID与HTTP请求一起发送到应用程序。程序的安全模块通常会使用授权拦截器，此拦截器首先确定会话ID是否存在。如果会话ID存在，则它知道用户已登录。然后，通过查询用户权限，确定用户是否可以执行请求。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQBGD.png" alt="UjQBGD.png"></p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQDRe.png" alt="UjQDRe.png"></p>
<p>在微服务架构下，应用由多个微服务组成，每个微服务在原始的单体应用程序中实现单一业务逻辑，并且前后端的分离使得客户端变成一个纯前端应用。在这种场景下，对每个微服务（包括纯前端的客户端应用）的访问请求进行身份验证和授权会面临以下问题： </p>
<ul>
<li>客户端拆分成独立的纯前端应用程序（单页应用），前端应用需要以一种安全的方式在浏览器中获取用户的身份信息和权限信息，并与服务端微服务程序共享。如果涉及到微前端的架构，前端由多个可独立部署的子应用组成，如何在多个微前端之间共享相同的登录信息、权限及其有效性？ </li>
<li>每个微服务需要处理相同的用户认证和授权信息，但是每个微服务又有独立的权限控制逻辑，相同用户在不同的微服务中，权限并不相同。微服务应遵循单一责任原则。微服务只处理单个业务逻辑。身份验证和授权的全局逻辑不应放在单个微服务实现中。 </li>
<li>HTTP是无状态协议。无状态意味着服务器可以根据需要将客户端请求发送到集群中的任何节点，HTTP的无状态设计对负载平衡有明显的好处。由于没有状态，用户请求可以分发到任何服务器。对于需要身份验证的服务，需要以基于HTTP协议的方式保存用户的登录状态。此时传统使用服务器端的会话来保存用户状态的方式就不适用了。 </li>
<li>微服务架构中的身份验证和授权涉及更复杂的场景，包括用户访问微服务应用程序，第三方应用程序访问微服务应用程序以及多个微服务应用程序之间的相互调用，在每种情况下，身份验证和授权方案都需要确保每个请求的安全性。 </li>
<li>尽管单点登录的可以确保用户的登录状态，但如何在微服务内部保持单点登录也会在无状态的微服务框架下带来挑战，微服务系统需要通过某种方式将用户的登录状态和权限在整个系统中共享。 </li>
</ul>
<p>下面我们来介绍一下认证和授权的区别，以及OAuth框架和OIDC协议的基本概念，以便更好的理解如何通过引入OAuth2.0框架和OIDC协议来解决上述问题。 </p>
<h1 id="认证和授权"><a href="#认证和授权" class="headerlink" title="认证和授权"></a>认证和授权</h1><p>首先，认证和授权是两个不同的概念，为了让我们的 API 更加安全和具有清晰的设计，理解认证和授权的不同就非常有必要了。 </p>
<ul>
<li><p>认证是 authentication，指的是当前用户的身份，解决 “我是谁？”的问题，当用户登陆过后系统便能追踪到他的身份并做出符合相应业务逻辑的操作。 </p>
</li>
<li><p>授权是 authorization，指的是什么样的身份被允许访问某些资源，解决“我能做什么？”的问题，在获取到用户身份后继续检查用户的权限。 </p>
</li>
<li><p>凭证（credentials）是实现认证和授权的基础，用来标记访问者的身份或权利，在现实生活中每个人都需要一张身份证才能访问自己的银行账户、结婚和办理养老保险等，这就是认证的凭证。在互联网世界中，服务器为每一个访问者颁发会话ID 存放到 cookie，这就是一种凭证技术。数字凭证还表现在方方面面，SSH 登录的密匙、JWT 令牌、一次性密码等。 </p>
</li>
</ul>
<p>单一的系统授权往往是伴随认证完成的，但是在开放 API 的多系统架构下，授权需要由不同的系统来完成，例如 OAuth2.0。 </p>
<p>在流行的技术和框架中，这些概念都无法孤立的被实现，因此在现实中使用这些技术时，大家往往对 OAuth2.0 是认证还是授权这种概念争论不休。下面我们会介绍在API开发中常常使用的几种认证和授权技术：OAuth2.0，OpenId Connect和JWT。 </p>
<h2 id="OAuth2-0、OpenId-Connect（OIDC）和JWT"><a href="#OAuth2-0、OpenId-Connect（OIDC）和JWT" class="headerlink" title="OAuth2.0、OpenId Connect（OIDC）和JWT"></a>OAuth2.0、OpenId Connect（OIDC）和JWT</h2><h3 id="OAuth2-0"><a href="#OAuth2-0" class="headerlink" title="OAuth2.0"></a>OAuth2.0</h3><h4 id="什么是OAuth2-0"><a href="#什么是OAuth2-0" class="headerlink" title="什么是OAuth2.0"></a>什么是OAuth2.0</h4><p>在第三方登录已经如此普遍的今天，相信大家一定都见过下面的这种界面： </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQcqI.png" alt="UjQcqI.png"></p>
<p>第三方登录让我们可以在一个app上无需注册新用户，就能使用我们的微信、qq等社交账号进行登录，app可以获取到我们社交账号上的头像、邮箱等信息。 </p>
<p>而这种现在看来已经非常普遍的操作，其背后就是OAuth2.0协议在支撑。 </p>
<p>在详细讲解OAuth2.0之前，需要了解几个专用名词。 </p>
<ul>
<li>Client：第三方应用程序，即客户端应用程序。 </li>
<li>HTTP service：HTTP服务提供商，即OAuth 服务提供商。 </li>
<li>Resource Owner：资源所有者，即终端用户。 </li>
<li>User Agent：用户代理，即浏览器。 </li>
<li>Authorization ：认证服务器，即服务提供商专门用来处理认证的服务器。 </li>
<li>Resource ：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。 </li>
<li>Token：包含用户身份或权限信息的令牌，通常为一串随机生成的字符，并具有时效性 </li>
</ul>
<p>OAuth2.0是一个关于授权的开放网络标准 <a href="https://tools.ietf.org/html/rfc6749" target="_blank" rel="noopener">rfc6749</a>，允许用户授权第三方应用访问服务授权者提供的信息，而不需要将用户名和密码提供给第三方应用或分享他们数据的所有内容。 </p>
<p>要理解OAuth2.0，让我们先从一个现实的场景开始： </p>
<p>如果要开发一个能检测代码质量的工具，面向的用户都是GitHub的使用者，那么如何才能让用户在不暴露GitHub的账号和密码的情况下，也能获得用户存储在GitHub的代码库的内容呢？ </p>
<p>简单来说，OAuth2.0就是让”Client”安全可控地获取”用户”的授权，与”Resource “进行互动。 </p>
<p>回到我们的场景中，我们要开发的代码检测工具就是Client，我们的用户就是Resource Owner，GitHub的登录系统就是Authorization ，GitHub的repo就是Resource 。在OAuth2.0框架下，用户在访问代码质量检查工具时，会先通过GitHub的Authorization 进行登录，GitHub的Authorization 会返回一个包含用户标识、且有时效性的token，通过这个token，代码质量检查工具可以访问GitHub的Resource 来获取用户代码库的内容。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQRdP.png" alt="UjQRdP.png"></p>
<h4 id="OAuth2-0的核心"><a href="#OAuth2-0的核心" class="headerlink" title="OAuth2.0的核心"></a>OAuth2.0的核心</h4><p>从我们的例子种不难发现，OAuth2.0的关键之处，在于Client如何和Authorization 进行交互，获取token。 </p>
<p>OAuth2.0协议为我们提供了以下endpoint： </p>
<ul>
<li>authorization endpoint：用于申请授权码的endpoint </li>
<li>token endpoint：用于申请token的endpoint </li>
<li>introspection endpoint：用于验证解析token的endpoint </li>
</ul>
<p>我们的client需要向OAuth2.0的提供商去申请一个client id和client secret，用于帮助OAuth2.0的提供商来验证client的合法性。（client id和client secret既可以在url param中验证，也可以携带于authorization basic token验证，这取决于你使用的Authorization 服务商） </p>
<p>OAuth2.0包含6种授权类型（Grant Type），用于client和Authorization 进行交互： </p>
<ul>
<li>授权码模式（Authorization  Grant Type) <ul>
<li>授权码模式是我们最常见的一种方式，传统的授权码模式通常使用在client为前后端一体的应用中。授权码模式与其他授权类型相比具有一些优势。当用户授权应用程序时，会带着URL中的授权码返回应用程序。应用程序用授权码来交换access token。当应用程序发出token请求时，该请求将使用client secret进行身份验证，从而降低攻击者拦截授权码并自行使用它的风险。这也意味着token永远不会被用户看到，因此这是将token传递回应用程序的最安全方式，从而降低token泄露给其他人的风险。（对于token endpoint的post请求参数有时也会以form-data的形式出现，这取决于你使用的Authorization 服务商） </li>
</ul>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQ5Rg.png" alt="UjQ5Rg.png"></p>
<ul>
<li>刷新模式（Refresh Token Grant Type） <ul>
<li>通常在请求到access token时，都会携带有一个refresh token，因为access token是有有效时长的，所以我们需要用一个不会过期的refresh token来刷新access token，在用户无需重新登录的情况下，让client也能保持使用正确有效的access token。 </li>
</ul>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQIzQ.png" alt="UjQIzQ.png"></p>
<ul>
<li>隐藏模式（Implict Grant Type） <ul>
<li>在前后端分离的架构中，client只有一个运行在浏览器上的前端的单页应用，不包含后端。因为JavaScript应用的特殊性，我们无法安全的将client secret存储在纯前端应用里，并且因为请求全部从浏览器发起，我们无法保证传统的授权码模式的两步请求中，是否会有中间人攻击。因此需要一种不通过client secret和两步请求就可以获取access token的方式，这就是隐藏模式。在此模式中，access token将作为redirect url的fragment返回到client，并且出于安全性考虑，将不会返回refresh token，因此我们不能用传统的refresh token模式来刷新access token，只能通过silent refresh的方式刷新。 </li>
</ul>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQTMj.png" alt="UjQTMj.png"></p>
<pre><code>* silent refresh 
* slient refresh是隐藏模式的一种特殊的刷新方式，其原理是运用html中iframe的特性，在access token过期之前，使用一个隐藏的iframe来重新用隐藏模式申请一次token，若authorization 的session不过期，便无需用户重新输入其登录信息就能获取一个新的access token。 
</code></pre><ul>
<li>PKCE模式（Proof Key for  Exchange by OAuth Public Clients） <ul>
<li>在隐藏模式介绍中我们可以发现，该模式是有明显的缺点的，即其silent refresh的刷新方式，authorization 所保存的用户登录session不可能永远不失效，一旦失效，我们还是需要用户重新登录才能确保client使用正确有效的token。为了解决这个缺点，PKCE模式应运而生。 PKCE模式通过改造传统的授权码模式，在请求authorization endpoint的同时，加入code_challenge和code_challenge_method参数，得到授权码后，在请求token endpoint时加入code_verifier参数，authorization 会验证code_challenge和code_verifier是否匹配，以此来防止两步请求中可能产生的中间人攻击。 </li>
</ul>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQHLn.png" alt="UjQHLn.png"></p>
<ul>
<li>密码模式（Password Grant Type） <ul>
<li>如果你高度信任某个应用，OAuth2.0也允许用户直接使用用户名和密码，该应用通过用户提供的密码，申请token，这种方式称为密码模式。密码模式无需浏览器作为代理，可以直接通过post请求获得token。 </li>
</ul>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQOoV.png" alt="UjQOoV.png"></p>
<ul>
<li>凭证模式（Client Credentials Grant Type） <ul>
<li>当你的应用只需要代表应用本身，而不是某个用户，来获取resource 的资源时，就可以使用凭证模式。这种模式不需要任何用户信息，返回的token也不携带任何用户信息。凭证模式也无需浏览器作为代理，可以直接通过post请求获得token。 </li>
</ul>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/UjQvJU.png" alt="UjQvJU.png"></p>
<p>而client在获取到access token之后，需要将access token携带于authorization bearer token header，再向resource 发出相应的资源请求。client也可以使用introspection endpoint来验证token是否有效。 </p>
<h3 id="OpenId-Connect（OIDC）"><a href="#OpenId-Connect（OIDC）" class="headerlink" title="OpenId Connect（OIDC）"></a>OpenId Connect（OIDC）</h3><p>尽管在今天很多OAuth2.0的使用中都包含身份信息，但OAuth2.0实际上是一个授权（authorization）的协议，并不包含认证（authentication）的内容。 </p>
<p>OAuth2.0框架明确不提供有关已授权应用程序的用户的任何信息。OAuth2.0是一个委派框架，允许第三方应用程序代表用户行事，而无需应用程序知道用户的身份。 </p>
<p>而OpenId的诞生就是为了解决认证问题的：OpenId基于OAuth2.0，在兼容OAuth2.0协议的基础上，它构建了一个身份层，用于验证并为client展示身份信息。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlpQJ.png" alt="UjlpQJ.png"></p>
<p>OpenID Connect的核心基于一个名为“ID token”的概念。authorization 将返回新的token类型，它对用户的身份验证信息进行编码。与仅旨在由资源服务器理解的access token相反，ID token旨在被第三方应用程序理解。当client发出OpenID Connect请求时，它可以请求ID token以及access token。 </p>
<p>OpenID Connect的ID token采用JSON Web Token（JWT）的形式，JWT是一个JSON有效负载，使用发行者的私钥进行签名，并且可以由应用程序进行解析和验证。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlCLR.png" alt="UjlCLR.png"></p>
<p>得益于JWT的自解析性，client可以不申请introspection endpoint就可以解析出ID token所包含的身份信息。JWT内部是一些定义的属性名称，它们为应用程序提供信息。它们用简写名称表示，以保持JWT的整体大小。这包括用户的唯一标识符（sub即“subject”的缩写），发出token的服务器的标识符（iss即“issuer”的缩写），请求此token的client的标识符（aud即“audience”的缩写），以及少数属性，例如token的生命周期，以及用户在多长时间之前获得主要身份验证提示。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlFdx.png" alt="UjlFdx.png"></p>
<h3 id="JWT（Json-Web-Token）"><a href="#JWT（Json-Web-Token）" class="headerlink" title="JWT（Json Web Token）"></a>JWT（Json Web Token）</h3><p>JWT（Json Web Token）是一个非常轻巧的规范。这个规范允许我们使用JWT在两个组织之间传递安全可靠的信息。 </p>
<p>首先，我们需要理解的是，JWT实际上是一个统称，它实际上是包含两部分JWS（Json Web Signature）和JWE（Json Web Encryption）。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlEFK.png" alt="UjlEFK.png"></p>
<h4 id="JWS（Json-Web-Signature）"><a href="#JWS（Json-Web-Signature）" class="headerlink" title="JWS（Json Web Signature）"></a>JWS（Json Web Signature）</h4><p>Json Web Signature是一个有着简单的统一表达形式的字符串： </p>
<p>JWS包含三部分： </p>
<ul>
<li><p>JOSE头（header）用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。JSON内容要经Base64编码生成字符串成为Header。 </p>
</li>
<li><p>JWS负载（payload）所必须的五个字段都是由JWT的标准所定义的。 </p>
<ul>
<li><p>iss(issuer): 该JWT的签发者（通常是authorization 的地址） </p>
</li>
<li><p>sub(subject): 该JWT所面向的用户（通常是用户名或用户ID） </p>
</li>
<li>aud(audience): 接收该JWT的一方（通常是client id） </li>
<li>exp(expires): 什么时候过期（Unix时间戳） </li>
<li>iat(issued at): 在什么时候签发的（Unix时间戳） </li>
</ul>
</li>
</ul>
<p>其他字段可以按需要补充。JSON内容要经Base64编码生成字符串成为PayLoad。 </p>
<ul>
<li>JWS签名（signature）使用密钥secret进行加密，生成签名。 </li>
</ul>
<p>JWS的主要目的是保证了数据在传输过程中不被修改，验证数据的完整性。但由于仅采用Base64对消息内容编码，因此不保证数据的不可泄露性。所以不适合用于传输敏感数据。并且加密数据只用于签名部分，所以JWS具有自解析性。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlmSe.png" alt="UjlmSe.png"></p>
<h4 id="JWE（Json-Web-Encryption）"><a href="#JWE（Json-Web-Encryption）" class="headerlink" title="JWE（Json Web Encryption）"></a>JWE（Json Web Encryption）</h4><p>Json Web Encryption是一个JWS的扩展，它是一串用加密算法加密过的token，在没有密钥的情况下，它能像JWS一样的解析。 </p>
<p>JWE包含五部分： </p>
<ul>
<li><p>JOSE头（header）：描述用于创建JWE加密密钥和JWE密文的加密操作，类似于JWS中的header。 </p>
</li>
<li><p>JWE加密密钥：用来加密文本内容所采用的算法。 </p>
</li>
<li><p>JWE初始化向量：加密明文时使用的初始化向量值，有些加密方式需要额外的或者随机的数据。这个参数是可选的。 </p>
</li>
<li><p>JWE密文：明文加密后产生的密文值。 </p>
</li>
<li><p>JWE认证标签：数字认证标签。 </p>
</li>
<li><p>JWE规范引入了两个新元素（enc和zip），它们包含在JWE令牌的JOSE头中，enc元素定义了秘文的加密算法，它应该是一个AEAD（Authenticated Encryption with Associated Data）模式的对称算法， zip元素定义了压缩算法，alg元素定义了用来加密cek（Content Encryption Key）的加密算法。 </p>
</li>
</ul>
<p><img src="https://s1.ax1x.com/2020/07/24/Ujluyd.png" alt="Ujluyd.png"></p>
<h1 id="微服务架构下的认证和授权的探讨"><a href="#微服务架构下的认证和授权的探讨" class="headerlink" title="微服务架构下的认证和授权的探讨"></a>微服务架构下的认证和授权的探讨</h1><p>通过对以上OAuth2.0，OIDC以及JWT/JWE的相关介绍，下面来探讨如何实现一个基于上述框架和协议的微服务认证和授权系统。 </p>
<p>在大型的系统架构中，往往存在多个产品共存的情况，网站因业务需求拆分成多个自成体系的微服务架构，但为了统一用户体验，这些独立的微服务架构往往共享一个身份认证服务。例如笔者所在的公司，拥有许多独立产品和服务，他们共享同一个认证服务器，支持OIDC协议，对用户身份认证，而每个产品和服务内部，在微服务架构下，则有着自己独立的授权逻辑。 </p>
<p>从传统单体架构到微服务架构的演变过程中，同一应用间的微服务调用，不同应用间的微服务调用，使得微服务组成了一个矩阵，相互之间存在交叉调用，每个独立的微服务又要对自己提供的服务实现权限控制，不止是系统权限，更多的是业务权限控制。如何能够基于原有的认证和权限管理系统，实现在同一微服务中，同时支持同应用之间的权限管理和不同应用之间的权限管理，是我们要探讨的主要问题。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlQeI.png" alt="UjlQeI.png"></p>
<h2 id="认证与授权的剥离"><a href="#认证与授权的剥离" class="headerlink" title="认证与授权的剥离"></a>认证与授权的剥离</h2><p>基于这样的架构基础，身份认证统一管理，应用和服务通过统一的身份认证服务完成用户登陆，剥离身份认证和用户授权，是构建微服务认证体系的第一步。 </p>
<p>现代应用中，前后端分离已是常态，独立的前端单页应用是用户进入站点的第一步，也扮演着client的角色，因此前端单页应用将会在微服务体系中扮演者获得身份信息的重要角色。由独立的前端应用（client）获取代表身份的token后，后端就无需再与身份验证服务做复杂的交互。 </p>
<p>我们可以使用前文所介绍的PKCE模式，安全的为前端应用授权。而后端只需要在网关层面拦截所有的请求验证身份即可，此时，前端应用就是身份验证服务（OIDC ）的client，后端网关将成为身份验证服务（OIDC ）的resource 。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/Ujl1TP.png" alt="Ujl1TP.png"></p>
<p>值得一提的是，在微前端概念高速发展的今天，我们同样需要在每个微前端项目中统一用户的身份和权限，借助浏览器localstorage对于不同域名的独立封闭性，我们可以使用类似cloudflare的工具帮助组装部署在不同服务器之上的前端应用共享同一域名，并以此来共享微前端不同系统之间的用户token。 </p>
<h2 id="服务端用户权限系统的建构"><a href="#服务端用户权限系统的建构" class="headerlink" title="服务端用户权限系统的建构"></a>服务端用户权限系统的建构</h2><p>在网关完成身份认证的工作后，整个认证（authentication）的流程就已完成，接下来我们要面临的则是如何在后端微服务之间统一用户权限。 </p>
<p>网关进行身份验证后，授权服务不需要让用户重新输入身份信息，因此应该由一个简单的api请求来完成。借助于OAuth2.0协议，我们可以使用密码流程（password grant type）来为用户进行授权。用户密码即为可自验证的ID token，而非用户的真正密码，我们借助密码流程的优势，构建一个支持解析用户ID token，并符合OAuth2.0协议标准的授权服务。 </p>
<p>前端应用在完成身份验证之后，会立即向服务端授权服务（OAuth ）发送获取权限的请求，授权服务（OAuth ）将权限压缩加密成一个JWE返回前端，以保证权限token的安全性，前端应用可以通过introspection endpoint来解析权限，而无需知道加密JWE的client secret。 </p>
<p>在得到JWE格式的权限token后，前端将携带着代表身份信息的ID token和代表权限的JWE token一同通过网关发往后端，后端网关在验证完ID token后会重新组装请求，只将权限token发往后端微服务进行单独验证。 </p>
<p>此时，后端网关是授权服务（OAuth ）的client，而后端其他的微服务将成为授权服务（OAuth ）的resource 。 </p>
<p>微服务在收到具体的业务请求后，会使用client secret解析JWE token，而无需再与授权服务进行交互。 </p>
<p>而之后的服务间调用，也将一直携带着此JWE token，以提供权限凭证。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlGY8.png" alt="UjlGY8.png"></p>
<h2 id="第三方系统间权限系统的建构"><a href="#第三方系统间权限系统的建构" class="headerlink" title="第三方系统间权限系统的建构"></a>第三方系统间权限系统的建构</h2><p>对于一个微服务系统来说，我们不仅仅要处理来自用户的请求，还经常会与其他系统进行交互，因此，我们的权限系统也需要提供一种在不提供用户身份访问系统的方式，这就是system-partner模式。 </p>
<p>得益于OAuth2.0协议中的凭证模式（client credentials grant type），我们可以要求对我们发起请求的第三方系统在身份认证服务（OIDC ）中去申请一个不包含用户信息的client credentials token，而后端网关会解析client credentials token，并从token解析出的grant_type=client_credentials字段来识别出system-partner的请求，并验证system-partner client id的白名单，之后去我们的授权服务（OAuth ）去申请一个system-partner的权限。 </p>
<p>通过OAuth token endpoint中携带的additional parameter，授权服务（OAuth ）会识别出system-partner的请求，赋予其一个system-partner的权限，并包装成JWE token，返回第三方系统。 </p>
<p>在第三方系统得到了client credentials token和JWE token后，可以以与之前相同的方式发往我们的微服务，微服务会在解析token时识别出其system partner的权限，执行相应的业务逻辑。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlNlQ.png" alt="UjlNlQ.png"></p>
<h2 id="基于OAuth2-0的授权中心实现"><a href="#基于OAuth2-0的授权中心实现" class="headerlink" title="基于OAuth2.0的授权中心实现"></a>基于OAuth2.0的授权中心实现</h2><p>在实现中，我们使用spring security作为技术基础，完全遵循OAuth2.0协议，将其进行改造，让spring security支持我们的自定义的token encode方式，并重新实现了user details provider来扩展权限系统。并且得益于JWE的使用，我们无需提供具体的storage来保存token，redis仅仅用于在token有效期内避免再次与权限服务交互，加速接口请求速度。 </p>
<p>一个好的微服务权限系统应该至少具有三层结构的权限体系： </p>
<ul>
<li>是否有权限访问此微服务 </li>
<li>是否有权限访问微服务中的某一个特定的endpoint </li>
<li>是否包含一些用户特定的权限数据 </li>
</ul>
<p>其中前两层只包含权限的名字和id，而第三层因为涉及到具体的权限数据，我们将其设计成为开放接口，由开发者自行封装响应的权限获取实现逻辑。这样做的好处是，我们可以在请求权限token时使用一些additional parameter来自主的切换我们想要的权限获取逻辑（例如system-partner的实现）。 </p>
<p>同时，additional parameter和开放权限接口相互配合，不同的微服务系统就可以使用同一个authorization 来提供不同的权限，这样可以更容易集中化管理用户权限，并节省开发资源。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlUyj.png" alt="UjlUyj.png"></p>
<p>秉承着避免与authorization 交互的原则，JWE token使用client secret作为密钥进行加密，因此resource 可以通过client secret对获得的JWE token进行自解析，并由全局的http intercepter来决定用户是否有权限访问服务或着服务的某个endpoint，以及endpoint背后与权限有关的业务逻辑。微服务可以自行用各种开源的JWE工具进行解析，也符合微服务跨语言的基本特性。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlrkV.png" alt="UjlrkV.png"></p>
<h2 id="一次性token"><a href="#一次性token" class="headerlink" title="一次性token"></a>一次性token</h2><p>对于一个庞大的微服务系统来说，可能不仅仅有浏览器、移动端，还包括类似于CLI（Command-Line Interface）的应用程序。因为此类应用程序的特殊性，他们无法正常的通过页面重定向的方式与认证服务和授权服务交流，因此，我们设计了一种一次性token的交互模式。 </p>
<p>用户会被要求用浏览器申请一个特殊的url，得到一个有限时长的一次性token，CLI应用可以使用这一个token来正常的从网关访问后端微服务。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlyfU.png" alt="UjlyfU.png"></p>
<p>其背后是一个独立的OAuth client在做支撑，这个OAuth client会以授权码模式先申请身份认证服务（OIDC ），得到ID token后再在后端直接申请授权服务（OAuth ）获取JWE token，并将两个token保存在redis中，并生成一个unique ID作为一次性token返回。同时用一个job来进行token过期前的刷新，以确保一次性token可以在其较长的有效时间内一直保持其有效性。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/UjlRX9.png" alt="UjlRX9.png"></p>
<p>而微服务网关在接收并识别出一次性token后，会直接请求这个特殊的OAuth client来获取其真正的ID token和JWE token，再进行验证并申请转发微服务。 </p>
<p><img src="https://s1.ax1x.com/2020/07/24/Ujlh01.png" alt="Ujlh01.png"></p>
<p>这种方式巧妙的避免了类似CLI应用在界面交互上的限制，并能以一个较长的时间使用一个token来作为用户凭证访问微服务，拓展了这个微服务系统的涵盖范围。 </p>
<h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>本文详细描写了在微服务架构下，针对不同的应用场景，如何实现基于OIDC协议和OAUTH2.0框架的认证和授权，通过引入JWE token，将用户授权信息在微服务架构下以自解析的方式完成权限传递，使得单个微服务能够更加容易的将用户权限用于自身的业务逻辑中。基于标准协议和框架的设计，使得该系统可以很容易的集成到现有的认证和授权系统中，而不需要对原有认证和授权系统做大的修改，这样的设计也减少了复杂微服务系统对于授权系统的依赖，更加简洁和高效。 </p>
<p>参考资料： </p>
<p><a href="https://insights.thoughtworks.cn/api-2/" target="_blank" rel="noopener">https://insights.thoughtworks.cn/api-2/</a></p>
<p><a href="https://www.oauth.com/" target="_blank" rel="noopener">https://www.oauth.com/</a> </p>
<p> <a href="https://www.cnblogs.com/linianhui/p/openid-connect-core.html" target="_blank" rel="noopener">https://www.cnblogs.com/linianhui/p/openid-connect-core.html</a> </p>
<p><a href="https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html</a></p>
<p><a href="https://www.jianshu.com/p/50ade6f2e4fd" target="_blank" rel="noopener">https://www.jianshu.com/p/50ade6f2e4fd</a></p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[前端login重构]]></title>
      <url>/2020/06/11/fe-login-refactor/</url>
      <content type="html"><![CDATA[<h1 id="记录一下前端login部分重构案例"><a href="#记录一下前端login部分重构案例" class="headerlink" title="记录一下前端login部分重构案例"></a>记录一下前端login部分重构案例</h1><p>前端是用的angular6搭建，因为需要连接ibmid登录，所以在网上找了一个符合openid connect标准的库<a href="https://github.com/manfredsteyer/angular-oauth2-oidc" target="_blank" rel="noopener">angular-oauth-oidc</a>, 结果就开始了长达一年的漫长重构之路。</p>
<p>enable前端的openid connect的登录倒还好说，熟悉openid connect标准的同学应该都清楚前端spa应用应该使用<a href="https://tools.ietf.org/html/rfc6749#section-4.2" target="_blank" rel="noopener">implicit flow</a>（因为oauth协议更新，现在已经不建议用implicit flow，而是<a href="https://tools.ietf.org/html/rfc7636" target="_blank" rel="noopener">PKCE auth code flow</a>，这是后话，我会在后文提及）。因此登录并不是难事，angular-oauth-oidc有详细的文档告诉我们怎么enable implicit flow。但坑体现在登录以外的地方。</p>
<h2 id="坑-1-有关discovery-endpoint的坑"><a href="#坑-1-有关discovery-endpoint的坑" class="headerlink" title="坑#1 - 有关discovery endpoint的坑"></a>坑#1 - 有关discovery endpoint的坑</h2><p>angular-oauth-oidc默认的推荐使用方式是应用自动通过<a href="https://openid.net/specs/openid-connect-discovery-1_0.html" target="_blank" rel="noopener">openid discovery endpoint</a>去加载所需的配置，对于我们开发者来说，只需要配clientid和redirecturl就可以。但是ibmid在之前使用idaas的一年时间里，都不提供discovery endpoint，因此我们只能hardcode在代码里这部分配置，因此也使得在启动框架的时候略显繁琐。代码如下：</p>
<pre><code class="typescript">this.oauthService.configure(authConfig);
this.oauthService.tokenValidationHandler = new JwksValidationHandler();
this.oauthService.setupAutomaticSilentRefresh();
this.oauthService.tryLogin();
</code></pre>
<pre><code class="typescript">export const authConfig: AuthConfig = {

  clientId: environment.clientId,
  redirectUri: window.location.origin + &#39;/it-infrastructure/z/resources/tools/danube/login&#39;,
  postLogoutRedirectUri: &#39;&#39;,
  loginUrl: environment.loginUrl,
  scope: &#39;openid&#39;,
  oidc: true,
  requestAccessToken: true,
  issuer: environment.issuer,
  tokenEndpoint: environment.tokenEndpoint,
  userinfoEndpoint: environment.userinfoEndpoint,
  responseType: &#39;id_token token&#39;,
  silentRefreshRedirectUri: window.location.origin + &#39;/it-infrastructure/z/resources/tools/danube/silent-refresh&#39;,
  requireHttps: &#39;remoteOnly&#39;,
  jwks: environment.jwks,
  timeoutFactor: 0.9,
  siletRefreshTimeout: 100000,
  useIdTokenHintForSilentRefresh: true,
  clearHashAfterLogin: false,
  silentRefreshShowIFrame: false,
  showDebugInformation: true
};
</code></pre>
<p>而现在，ibmid移到了cloud identity上，并且加了discovery endpoint，本以为以后就不用hardcode配置了，结果，新的ibmid的discovery endpoint竟然不支持cors，看起来ibmid在设计之初就没有考虑过前端spa或是移动端的使用，十分失望，我只能再继续hardcode。至于cors，我已经跟ibmid team的人说过要加上（一定得加上因为以后如果前端想要用PKCE auth code就必须支持cors），不知道他们什么时候跟进。</p>
<h2 id="坑-2-有关前端认证id-token的坑"><a href="#坑-2-有关前端认证id-token的坑" class="headerlink" title="坑#2 - 有关前端认证id-token的坑"></a>坑#2 - 有关前端认证id-token的坑</h2><p>同样是因为以前ibmid的idaas不支持jwkset endpoint，长时间以来我们都没办法在前端认证id-token（即<code>this.oauthService.tokenValidationHandler = new NullValidationHandler()</code>），只能靠后端验证，知道后来cloud identity加上jwkset endpoint才得已解决。但是，以为上文提到的cors的问题，我们只能把jwkset hardcode在environment文件里，十分丑陋。</p>
<pre><code class="typescript">    jwks:
      {
        &quot;keys&quot;: [
          {
            &quot;kty&quot;: &quot;xxx&quot;,
            &quot;kid&quot;: &quot;xxx&quot;,
            &quot;use&quot;: &quot;xxx&quot;,
            &quot;alg&quot;: &quot;xxx&quot;,
            &quot;n&quot;: &quot;xxx&quot;,
            &quot;e&quot;: &quot;xxx&quot;,
            &quot;x5c&quot;: [
              &quot;xxxx&quot;
            ],
            &quot;x5t#S256&quot;: &quot;xxx&quot;
          }
        ]
      },
</code></pre>
<h2 id="坑-3-关于回调URL的坑"><a href="#坑-3-关于回调URL的坑" class="headerlink" title="坑#3 - 关于回调URL的坑"></a>坑#3 - 关于回调URL的坑</h2><p>angular-oauth-oidc推荐使用静态页面的url作为回调url（即index.html），但这会导致一个问题，就是我们回调回应用后，都会有一个一闪而过的画面，因就是我们回调回index.html之后，还得route到我们当初访问的url上，这个就会出现index.html一闪而过的现象（一般来说一闪而过很快，肉眼看不见，但我们回调回应用后还有后续操作，所以变得很明显），解决这个坑就是不应静态的index.html来作为回调url，而是给一个route，我们这是/login，angular会捕获这个路由显示一个loading页面，知道后续操作完毕，跳转到当初访问的url。</p>
<p>同样是因为我们做了一些后续操作后再跳转，我们就必须保证这些后续操作无论成功失败都必须跳转，否则就会一直卡在loading页面了，所以必须对回调之后的操作进行异常捕捉，处理后再跳转。</p>
<h2 id="坑-4-有关同步代码的坑"><a href="#坑-4-有关同步代码的坑" class="headerlink" title="坑#4 - 有关同步代码的坑"></a>坑#4 - 有关同步代码的坑</h2><p>先说一下什么是ram-guards，这是我们的一个微服务的权限处理系统，接受一个oauth idtoken并认证，然后返回一个能代表权限的token。</p>
<p>这部分不是ibmid的锅，是我们自己的。我们在oauth server redirect回我们的应用后，需要作两件事情，一是去获得我们的权限ram-guards-token，二是跳转到当初我们希望route的url中去，这就要求跳转必须在后去权限之后发生，获取权限就不能异步请求，只能同步请求。<br>angular httpclient返回的是一个异步observable，把它变成同步很简单，只需要使用observable.toPromise，然后在套上aysnc/await语法糖就可以。但这块有两个问题需要注意，一是我长时间以为aysnc/await语法糖就可以保证代码同步，就像java的synchronized一样，结果并不是，aysnc/await只是一个语法糖，而且不论aysnc方法内是否返回promise，aysnc都会将整个方法包装成一个promise，真正想在同步后执行的代码还得放在.then()里面。因此得出教训，aysnc/await固然好用，但必须完全理解其含义并谨慎使用。</p>
<p>再就是我们在得到ram-guards-token后必须解析它，ram-guards-token是一个jwe所以我们用了另外一个库<a href="https://github.com/cisco/node-jose" target="_blank" rel="noopener">node-jose</a>, 这个库推荐我们这样解析jwe：</p>
<pre><code class="typescript">jose.JWK.asKey({
      &#39;kty&#39;: &#39;oct&#39;,
      &#39;use&#39;: &#39;enc&#39;,
      &#39;k&#39;: ramGuardsClientSecret,
      &#39;alg&#39;: &#39;A128CBC-HS256&#39;
    })
    .then(key =&gt; {
        jose.JWE.createDecrypt(key)
            .decrypt(ramGuardsResponse.access_token)
            .then(result =&gt; {
                const claims = new TextDecoder().decode(result.plaintext);
                localStorage.setItem(&#39;Ram-Guards-Details&#39;, claims);
            });
    });
</code></pre>
<p>那么问题来了，promise直接return后.then()就OK，那promise套一个promise呢？这种情况下想要同步必须给两个promise都套上return才行。</p>
<h2 id="坑-5-有关解析ram-guards-token的坑"><a href="#坑-5-有关解析ram-guards-token的坑" class="headerlink" title="坑#5 - 有关解析ram-guards-token的坑"></a>坑#5 - 有关解析ram-guards-token的坑</h2><p>其实不算坑，更多是一个bug，以为ram-guards-token用的是一个加密的jwe，前端要想解析据必须使用它的secret，而在spa里报漏secret是非常危险的，因此这一块需要改成使用oauth推荐的introspect endpoint来通过后端解析token，多加了一次请求，但保证了应用的安全性，这一部分已经加到了ram-guards里，后续我们需要改一下。</p>
<h2 id="坑-6-有关silent-refresh的坑"><a href="#坑-6-有关silent-refresh的坑" class="headerlink" title="坑#6 - 有关silent-refresh的坑"></a>坑#6 - 有关silent-refresh的坑</h2><p>天坑！！！</p>
<p>首先说一下什么是silent-refresh，以为implicit是不使用clientsecret申请token的方式，因此我们无法通过正常的refresh token的方式刷新token，所以才有了silent-refresh，即在前端临时加一个看不见的iframe，在iframe的src里指向authorize endpoint；然后通过auth server那一端未过期的session进行自动的登录并重定向回我们的iframe，然后iframe向parent window发通知更新应用存储的token，并把iframe自己给干掉。（about <a href="https://www.scottbrady91.com/OpenID-Connect/Silent-Refresh-Refreshing-Access-Tokens-when-using-the-Implicit-Flow" target="_blank" rel="noopener">slient-refresh</a>）</p>
<p>所以说这一连串骚操作都是建立在iframe的基础上的，但是偏偏ibmid也有它的骚操作，不允许从iframe申请的跨域请求，回报Refused to display in a iframe的错，即response里面会有<code>Content-Security-Policy: frame-ancestors &#39;self&#39;</code>(<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Security-Policy/frame-ancestors" target="_blank" rel="noopener">CSP: frame-ancestors</a>)，这说明ibmid压根就没考虑过silent-refresh的场景啊，再次验证了我之前的推测，ibmid就没想过前端spa和移动端应用会用它。</p>
<p>因此，我们必须想办法进行silent-refresh，我做了一个实验，发现只有在iframe的src中请求的是静态页面（即xxx.html）的时候，浏览器才会报Refused to display in a iframe的错，而非静态页面的url，即使response中包含<code>Content-Security-Policy: frame-ancestors &#39;self&#39;</code>，也不会报错（暂不清楚这是为啥，希望有大神可以帮忙解答），因此我们就可以通过把silent-refresh的回调URL交给angular的route来捕获处理。到这为止，angular-oauth-oidc的slient-refresh部分的文档就完全没啥用了，我们需要按照我们的思路来实验。</p>
<p>既然silent-refresh的回调URL交给angular的route来捕获处理，我们就要给silent-refresh的回调URL一个component，当然这个component啥也不用做，我们要做的是在appcomponent中区分出监听tokenreceived事件，区分出哪些是iframe内部接收的，那些事iframe外部接受的。</p>
<p>最开始是没有iframe的，只有页面进行登录，登录成功后我们要开始一个timer去检查token啥时候会过期，以便我们在token过期之前去开始slient-refresh。</p>
<p>当token过期时，token_expires事件将会被触发，然后angular-oauth-oidc框架会自动创建一个看不见的iframe去申请我们的silent-refresh url /silent-refresh，然后authserver会重定向回iframe，而iframe内部接收的，就是一次silent-refresh的请求，也就不需要开始timer去看它是否会过期（因为iframe内部的只作为refresh token之用），我们在接收到之后需要同样的去refresh ram-guards-token，然后手动通知iframe的parent window token已经刷新成功，再把这个iframe自己干掉。</p>
<p>而iframe外部在接收到token更新成功的事件后，就会出发silently_refreshed的事件，从而使这一次slient-refresh流程成功。</p>
<p>因此，我们代码的关键就是：</p>
<p>1.在appcomponent中区分出哪次token-received事件是第一次申请token的，哪一次是silent-refresh token的。</p>
<p>2.区分出当前appcomponent是在iframe内部还是在iframe外部。</p>
<p>3.处理所有的silent-refresh异常，以避免silent-refresh失败</p>
<p>这里需要重点说一下的是silent-refresh异常，总结了一下，大概分四种：</p>
<p>1.silent_refresh_error，即auth-server返回了login_required的error，通常是因为auth-server那一端session过期的缘故(<a href="https://openid.net/specs/openid-connect-session-1_0.html#ChangeNotification" target="_blank" rel="noopener">about1</a>, <a href="https://openid.net/specs/openid-connect-core-1_0.html#AuthError" target="_blank" rel="noopener">about2</a>)</p>
<p>2.token_error，原因同上，只是silent_refresh_error一定伴随着token_error，但token_error不一定是silent-refresh造成的，也有可能是第一次申请token造成的</p>
<p>3.silent_refresh_timeout，在silent-refresh的timeout时间内，iframe没能通知到parent window refresh成功</p>
<p>4.invalid_nonce_in_state，两次authorize申请同时发生，框架不能正确的验证nonce，通常是因为一次silent_refresh没有成功而又开始了一次authorize请求</p>
<p>按道理来说，我们应该根据这四种不同的error去设计不同的解决方案，silent_refresh_timeout，invalid_nonce_in_state是重启timer，silent_refresh_error，token_error是强制用户重新登录，但angular-oauth-oidc框架无法重启timer，我们就只能粗暴的都强制用户重新登录了。这个可以通过后续更改源码来实现。</p>
<p>还有一点需要注意的是，虽然文档中说angular-oauth-oidc的trylogin的几个回调方法都已经过时了，要使用events来监听事件，但我发现events监听到的事件并不能返回token的info，所以我们还得用trylogin的回调，这个也可以通过改源码来解决。</p>
<p>大概就是这些个坑，还有一些细节优化啥的就不一一概述了，我这里贴一下关键的源码：</p>
<p>app.component.ts:</p>
<pre><code class="typescript">private configureIbmId() {
    this.oauthService.configure(authConfig);
    this.oauthService.tokenValidationHandler = new JwksValidationHandler();
    let iframeOrNot;
    if (window.location !== window.parent.location) {
      iframeOrNot = &#39;inside-iframe&#39;;
    } else {
      iframeOrNot = &#39;outside-iframe&#39;;
      // only need auto silent refresh outside the iframe
      this.oauthService.setupAutomaticSilentRefresh();
    }
    this.oauthService.events.subscribe( event =&gt; {
      if (event instanceof OAuthErrorEvent) {
        // normally , we will face four kind of errors:
        //
        // silent_refresh_error: response login_required error, force user to re login
        // token_error: response response login_required error, force user to re login
        // silent_refresh_timeout: iframe failed to notify parent window, kill old RefreshTimer, setup a new RefreshTimer
        // invalid_nonce_in_state: two authorize post happens at the same time, kill old RefreshTimer, setup a new RefreshTimer
        //
        // TODO: when received error, auto silent refresh will stop, we can make it restart by modify setupRefreshTimer() in angular-oauth2-oidc to subscribe a error event for different conditions
        // since setupAutomaticSilentRefresh() cannot produce the same behaviour as setupRefreshTimer() (will cause invalid_nonce_in_state error), for now, we will force user to re login in all error conditions
        console.error(iframeOrNot, event.type, event);
        this.oauthService.logOut();
        this.authorizationService.removeStorage();
      } else {
        console.log(iframeOrNot, event.type, event);
      }
    });
    this.oauthService.tryLogin({
      onTokenReceived: (info) =&gt; {
        this.isLogged = this.loginService.isLoggedIn();
        if (!this.authorizationService.neverCallRamGuardsBefore()) {
          // refresh logs will always be:
          //
          // outside-iframe token_expires
          // inside-iframe token_received
          // inside-iframe id token refreshed
          // inside-iframe ram-guards token refreshed
          // outside-iframe token_received
          // outside-iframe silently_refreshed
          //
          // if these logs appear:
          //
          // outside-iframe id token refreshed
          // outside-iframe ram-guards token refreshed
          //
          // this means for some unknown reason, oauth server redirect to out client at outside iframe and ram guards tokens are still in local storage
          // for example: id token expired or not valid while ram guards token still there outside iframe
          // not sure why this happens but we should be able to handle this situation
          //
          // refresh token in a iframe
          console.log(iframeOrNot, &#39;id token refreshed&#39;, info);
          this.authorizationService.syncRefreshAuthorization()
            .then(res =&gt; {
              const ramGuardsResponse: RamGuardsResponse = res.body;
              this.authorizationService.setStorage(ramGuardsResponse).then(() =&gt; {
                console.log(iframeOrNot, &#39;ram-guards token refreshed&#39;, ramGuardsResponse);
                // notify parent and remove iframe
                window.parent.postMessage(location.hash , location.origin + &#39;/it-infrastructure/z/resources/tools/danube&#39;);
                if (iframeOrNot === &#39;inside-iframe&#39; &amp;&amp; frameElement) {
                  frameElement.remove();
                } else {
                  // handle the unexpected situation mentioned before
                  this.router.navigate([info &amp;&amp; info.state ? info.state : &#39;dashboard&#39;]);
                }
              });
            })
            .catch(err =&gt; {
              // do nothing wait for next time refresh
              console.error(iframeOrNot, &#39;ram-guards token refreshed error, waiting for next time refresh&#39;, err);
              // notify parent and remove iframe
              window.parent.postMessage(location.hash , location.origin + &#39;/it-infrastructure/z/resources/tools/danube&#39;);
              if (iframeOrNot === &#39;inside-iframe&#39; &amp;&amp; frameElement) {
                frameElement.remove();
              } else {
                // handle the unexpected situation mentioned before
                this.router.navigate([info &amp;&amp; info.state ? info.state : &#39;dashboard&#39;]);
              }
            });
        } else {
          // get token first time
          console.log(iframeOrNot, &#39;id token received&#39;, info);
          this.authorizationService.syncAuthorization()
            .then(res =&gt; {
              const ramGuardsResponse: RamGuardsResponse = res.body;
              this.authorizationService.setStorage(ramGuardsResponse).then(() =&gt; {
                console.log(iframeOrNot, &#39;ram-guards token received&#39;, ramGuardsResponse);
                this.router.navigate([info &amp;&amp; info.state ? info.state : &#39;dashboard&#39;]);
              });
            }).catch(err =&gt; {
              this.authorizationService.setRamGuardsError(err.body);
              console.error(iframeOrNot, &#39;ram-guards token received error&#39;, err);
              this.router.navigate([&#39;dashboard&#39;]);
            });
        }
      }
    });
  }
</code></pre>
<p>login.service.ts:</p>
<pre><code class="typescript">import { Injectable } from &#39;@angular/core&#39;;
import { OAuthService } from &#39;angular-oauth2-oidc&#39;;
import { RouterStateSnapshot } from &#39;@angular/router&#39;;


@Injectable({
  providedIn: &#39;root&#39;
})
export class LoginService {

  constructor(private oauthService: OAuthService) { }

  public login() {
    this.oauthService.initImplicitFlow();
  }

  public loginWithRedirectUrl(redirectUrl: string) {
    this.oauthService.initImplicitFlow(redirectUrl);
  }

  public getIdToken() {
    return this.oauthService.getIdToken();
  }

  public isLoggedIn() {
    return this.oauthService.hasValidIdToken();
  }

  public async syncRefreshIdToken() {
    return await this.oauthService.silentRefresh();
  }
}
</code></pre>
<p>authorization.service.ts:</p>
<pre><code class="typescript">declare var TextDecoder: any;

import {Injectable} from &#39;@angular/core&#39;;
import {HttpClient, HttpResponse} from &#39;@angular/common/http&#39;;
import {Observable} from &#39;rxjs&#39;;
import {timeout} from &#39;rxjs/operators&#39;;
import {RamGuardsResponse} from &#39;./RamGuardsResponse&#39;;
import * as jose from &#39;node-jose&#39;;
import {environment} from &#39;src/environments/environment&#39;;

const authorizationServiceUrl  = environment.authorizationServiceUrl;
const ramGuardsClientSecret  = environment.ramGuardsClientSecret;

@Injectable({
  providedIn: &#39;root&#39;
})
export class AuthorizationService {

  constructor(private http: HttpClient) {
  }

  public authorize(): Observable&lt;HttpResponse&lt;RamGuardsResponse&gt;&gt; {
    return this.http.post&lt;RamGuardsResponse&gt;(
      authorizationServiceUrl + &#39;/oauth/token?grant_type=password&#39;,
      null,
      {
        observe: &#39;response&#39;
      }
    ).pipe(timeout(120000));
  }

  public refreshToken(token: String): Observable&lt;HttpResponse&lt;RamGuardsResponse&gt;&gt; {
    return this.http.post&lt;RamGuardsResponse&gt;(
      authorizationServiceUrl + &#39;/oauth/token?grant_type=refresh_token&amp;refresh_token=&#39; + token,
      null,
      {
        observe: &#39;response&#39;
      }
    ).pipe(timeout(120000));
  }

  public async syncAuthorization() {
    return await this.authorize().toPromise();
  }

  public checkAuthorization(id: number) {
    if (localStorage.getItem(&#39;Ram-Guards-Details&#39;)) {
      return JSON.parse(localStorage.getItem(&#39;Ram-Guards-Details&#39;)).authorities.some(auth =&gt; {
        return auth.roles.some(role =&gt; {
          return role.id === id;
        });
      });
    }
    return false;
  }

  public isAuthorized() {
    if (localStorage.getItem(&#39;Ram-Guards-Access-Token&#39;) &amp;&amp; localStorage.getItem(&#39;Ram-Guards-Refresh-Token&#39;)) {
      const expiresAt = localStorage.getItem(&#39;Ram-Guards-Expire-At&#39;);
      const now = new Date();
      return !(expiresAt &amp;&amp; parseInt(expiresAt, 10) &lt; now.getTime());
    }
    return false;
  }

  public isRamGuardsError() {
    return !!localStorage.getItem(&#39;Ram-Guards-Error&#39;);
  }

  public setRamGuardsError(msg: any) {
    localStorage.setItem(&#39;Ram-Guards-Error&#39;, &#39;Error: &#39; + msg);
  }

  public isAnonymous() {
    if (localStorage.getItem(&#39;Ram-Guards-Details&#39;)) {
      return JSON.parse(localStorage.getItem(&#39;Ram-Guards-Details&#39;)).authorities[0].name === &#39;anonymous&#39;;
    }
    return true;
  }

  public setStorage (ramGuardsResponse: RamGuardsResponse) {
    this.removeStorage();
    this.setAuthorizationBasicStorage(ramGuardsResponse);
    return jose.JWK.asKey({
      &#39;kty&#39;: &#39;oct&#39;,
      &#39;use&#39;: &#39;enc&#39;,
      &#39;k&#39;: ramGuardsClientSecret,
      &#39;alg&#39;: &#39;A128CBC-HS256&#39;
    })
    .then(key =&gt; {
      return jose.JWE.createDecrypt(key)
      .decrypt(ramGuardsResponse.access_token)
      .then(result =&gt; {
        const claims = new TextDecoder().decode(result.plaintext);
        localStorage.setItem(&#39;Ram-Guards-Details&#39;, claims);
      });
    });
  }

  public setAuthorizationBasicStorage(ramGuardsResponse: RamGuardsResponse) {
    localStorage.setItem(&#39;Ram-Guards-Access-Token&#39;, ramGuardsResponse.access_token);
    localStorage.setItem(&#39;Ram-Guards-Refresh-Token&#39;, ramGuardsResponse.refresh_token);
    localStorage.setItem(
      &#39;Ram-Guards-Expire-At&#39;,
      (new Date().valueOf() + Math.floor(ramGuardsResponse.expires_in * 1000)).toString()
    );
    localStorage.setItem(
      &#39;Ram-Guards-Expire-Time&#39;,
      ramGuardsResponse.expires_in.toString()
    );
  }

  public removeStorage () {
    localStorage.removeItem(&#39;Ram-Guards-Error&#39;);
    localStorage.removeItem(&#39;Ram-Guards-Access-Token&#39;);
    localStorage.removeItem(&#39;Ram-Guards-Refresh-Token&#39;);
    localStorage.removeItem(&#39;Ram-Guards-Expire-At&#39;);
    localStorage.removeItem(&#39;Ram-Guards-Expire-Time&#39;);
    localStorage.removeItem(&#39;Ram-Guards-Details&#39;);
  }

  public async syncRefreshAuthorization() {
    return await this.refreshToken(localStorage.getItem(&#39;Ram-Guards-Refresh-Token&#39;)).toPromise();
  }

  public getRamGuardsToken() {
    return localStorage.getItem(&#39;Ram-Guards-Access-Token&#39;);
  }

  public getRamGuardsRefreshToken() {
    return localStorage.getItem(&#39;Ram-Guards-Refresh-Token&#39;);
  }

  public neverCallRamGuardsBefore() {
    return !localStorage.getItem(&#39;Ram-Guards-Refresh-Token&#39;);
  }
}
</code></pre>
<h2 id="后记-解决silent-refresh的更优方案"><a href="#后记-解决silent-refresh的更优方案" class="headerlink" title="后记 - 解决silent-refresh的更优方案"></a>后记 - 解决silent-refresh的更优方案</h2><p>虽然silent-refresh可以解决refresh token的问题，但只是在oauthserver那一端session不过期的情况下，而且因为在iframe中申请authorize endpoint时添加了prompt=none的参数，ibmid的login的页面不会出现，一旦session过期，silent refresh必然会失败。那么有没有更优的方案呢？很简单，就是用上问提到的pkce auth code flow，这部分我问过ibmid的人了，说他们实现了，但没有默认enable，需要申请，考虑到他们还没加cors，现在就没申请，就看他们什么时候加cors了，到时候在申请使用pkce auth code flow。</p>
<p>关于pkce auth code flow的学习看<a href="https://espressocoder.com/2019/10/28/secure-your-spa-with-authorization-code-flow-with-pkce/" target="_blank" rel="noopener">这篇教程</a>，我就不展开了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>实践论，实践出真知，照着文档一知半解的写肯定会出错，要想写好代码就要了解全局，oauth oidc协议得懂，angular-oauth-oidc的源码也得阅读，有了这些认识后还得加以大量的实践来验证，不断的重构和完善，才能搞出好的代码。</p>
]]></content>
      
        <categories>
            
            <category> fe </category>
            
            <category> oauth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> fe </tag>
            
            <tag> oauth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一次艰难的troubleshooting]]></title>
      <url>/2020/05/11/troubleshooting-ram-guards/</url>
      <content type="html"><![CDATA[<h1 id="一次艰难的troubleshooting"><a href="#一次艰难的troubleshooting" class="headerlink" title="一次艰难的troubleshooting"></a>一次艰难的troubleshooting</h1><h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>先说一下什么是ram-guards，这是我们的一个微服务的权限处理系统，接受一个oauth idtoken并认证，然后返回一个能代表权限的token。</p>
<p>起因是最近对ram-guards做升级，增加了切换application id的功能，使ram-guards可以通过ram系统为不同的app提供不同的权限服务（以前只服务于一个项目）。</p>
<p>本身这只是个微小的改动，加一个参数就好，但是在spring security的设计体系中，下面的这个简单的接口承担着装配用户以及权限的核心</p>
<pre><code class="java">public interface UserDetailsService {
    UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;
}
</code></pre>
<p>但这个接口有个很大的缺点，就是只有一个string做参数，为了满足我们多个参数的需求，又不想丑陋的在string里split，我决定把这个接口用我自定义的接口代替。简单来说就是写一个能接收自定义object的接口，并为这个自定义接口提供一个AuthenticationProvider，注册到spring security的AuthenticationManager中，同时重写DefaultTokenServices中refreshtoken所用的PreAuthenticatedAuthenticationProvider，并将tokenservice和AuthenticationManager注册到AuthorizationServerEndpointsConfigurer中。</p>
<p>因为这部分改动不是本文的重点，在这里不展开说了。</p>
<p>从代码角度来说我对这部分改动还是很自信的，因为自己经过多轮测试并且其他team也一直在使用这套代码进行权限获取，但就是这些很自信的改动，在dev环境上跑出了问题。</p>
<h2 id="troubleshooting"><a href="#troubleshooting" class="headerlink" title="troubleshooting"></a>troubleshooting</h2><p>新版本的ram-guards上了dev环境之后，测试在dev上跑了bdd，结果大批量的fail掉了，报的错误是前端没有拿到用户的权限。但是奇怪的是，手工测试却并没有出现问题，而且老版本的ram-guards bdd也从来没有fail过。因为对自己的盲目自信以及function测试并没有出现问题，我最先把怀疑指向了bdd的代码会不会有问题，但经过一番查验，并没有发现bdd的代码有问题。</p>
<p>此时我便陷入了僵局，一般情况下，系统有问题通常都会要求有稳定的复现，但这是一个复现不了，只会在bdd中才发生的问题。在不断的查验中，终于意识到bdd场景是并发进行的，十多个bdd脚本在一秒内并发，这是手工测试所不能复现的场景，会不会是新版本代码在并发场景下会出问题？带着这种怀疑，我决定做一次压测。</p>
<p>压测工具为ab，进行API压测，以单秒并发100次请求为标准进行压测，果然，dev上的新版本出现了大批量的API fail，test上的老版本则全部通过。</p>
<p>既然是压测出的问题，首先想到的肯定是不同环境上的资源分配是不是影响因素，于是便在dev上也部署了一份老版本ram-guards的代码到同一个node上，在进行压测，发现并没有问题。</p>
<p>那这样来看就不是环境资源配置的问题了，那代码会哪里出问题呢，功能都OK，但一上并发就挂。我便仔细分析了下log，发现压测中，最先挂的是数据库连接池，总会报出数据库连接失败的错误。先说明下，ram-guards本身是不需要数据库的支持的，这里的数据库只是用来记录audit log用的。我们处于成本控制，使用了最大连结数只能有100个的cloud db，而每个service都有记录audit log的需求，所以我限制了每个service在log db上只能开2个active连接的连接池。那么会不会是连接池数量太少引起的性能问题呢？</p>
<p>如果仅仅是连接池数量太少导致的，那么老版本的代码在并发场景下应该也会出问题，虽然增加连接数也可能解决问题，但这并不像是rootcause。那会不会是代码优化后执行速度过快，导致单秒写入数据库的请求增多，进而把连接池压垮？亦或者是代码重构后，写入数据库的次数和内容增多，导致单个commit处理时间过长，把数据库连接池压垮？翻来覆去没想出问题所在，我决定开debug log看一下，因为全局的debug log太多，反而不好定位问题，这里我只开启跟log db有关的debug：</p>
<pre><code class="yaml">logging:
  level:
    ROOT: info
    com.ibm.ram.guards: debug
    org.springframework.orm.jpa: debug
    org.hibernate: debug
    org.postgresql: debug
    com.zaxxer.hikari: debug
</code></pre>
<p>在开启debug后，仔细对着了log的不同，发现了蹊跷。</p>
<p>这是老版本代码在并发场景下的log：</p>
<pre><code class="log">2020-06-16 07:13:49.971 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = false
2020-06-16 07:13:49.982 DEBUG 1 --- [nio-8080-exec-5] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Reset (autoCommit) on connection org.postgresql.jdbc.PgConnection@100d71db
2020-06-16 07:13:49.971  INFO 1 --- [nio-8080-exec-5] g.a.o.c.RamGuardsJweAccessTokenConverter : CP01-log user: ...
2020-06-16 07:13:49.981 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = true
</code></pre>
<p>这是新版本代码在并发场景下的log：</p>
<pre><code class="log">2020-06-16 07:13:31.550 DEBUG 1 --- [l-1 housekeeper] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Pool stats (total=2, active=0, idle=2, waiting=0)
2020-06-16 07:13:49.886 DEBUG 1 --- [nio-8080-exec-5] o.s.orm.jpa.JpaTransactionManager        : Creating new transaction with name [org.springframework.security.oauth2.provider.token.DefaultTokenServices.createAccessToken]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT
2020-06-16 07:13:49.887 DEBUG 1 --- [nio-8080-exec-5] o.s.orm.jpa.JpaTransactionManager        : Opened new EntityManager [SessionImpl(256287368&lt;open&gt;)] for JPA transaction
2020-06-16 07:13:49.887 DEBUG 1 --- [nio-8080-exec-5] o.h.e.t.internal.TransactionImpl         : On TransactionImpl creation, JpaCompliance#isJpaTransactionComplianceEnabled == false
2020-06-16 07:13:49.887 DEBUG 1 --- [nio-8080-exec-5] o.h.e.t.internal.TransactionImpl         : begin
2020-06-16 07:13:49.891 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = false
2020-06-16 07:13:49.891 DEBUG 1 --- [nio-8080-exec-5] o.s.orm.jpa.JpaTransactionManager        : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@1ee8f5f6]
2020-06-16 07:13:49.892  INFO 1 --- [nio-8080-exec-5] c.i.d.s.authorization.aop.AuditLogAop    : CP01-log user: ...
2020-06-16 07:13:49.913 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = false
2020-06-16 07:13:49.934 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = true
2020-06-16 07:13:49.934 DEBUG 1 --- [nio-8080-exec-5] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Reset (autoCommit) on connection org.postgresql.jdbc.PgConnection@100d71db
2020-06-16 07:13:49.908  INFO 1 --- [nio-8080-exec-5] g.a.o.c.RamGuardsJweAccessTokenConverter : user: ...
2020-06-16 07:13:49.935 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = false
2020-06-16 07:13:49.955 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = true
2020-06-16 07:13:49.955 DEBUG 1 --- [nio-8080-exec-5] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Reset (autoCommit) on connection org.postgresql.jdbc.PgConnection@100d71db
2020-06-16 07:13:49.935  INFO 1 --- [nio-8080-exec-5] g.a.o.c.RamGuardsJweAccessTokenConverter : CP01-log user: ...
2020-06-16 07:13:49.958 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = false
2020-06-16 07:13:49.969 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = true
2020-06-16 07:13:49.969 DEBUG 1 --- [nio-8080-exec-5] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Reset (autoCommit) on connection org.postgresql.jdbc.PgConnection@100d71db
2020-06-16 07:13:49.958  INFO 1 --- [nio-8080-exec-5] g.a.o.c.RamGuardsJweAccessTokenConverter : user: ...
2020-06-16 07:13:49.971 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = false
2020-06-16 07:13:49.981 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = true
2020-06-16 07:13:49.982 DEBUG 1 --- [nio-8080-exec-5] com.zaxxer.hikari.pool.PoolBase          : HikariPool-1 - Reset (autoCommit) on connection org.postgresql.jdbc.PgConnection@100d71db
2020-06-16 07:13:49.971  INFO 1 --- [nio-8080-exec-5] g.a.o.c.RamGuardsJweAccessTokenConverter : CP01-log user: ...
2020-06-16 07:13:49.984 DEBUG 1 --- [nio-8080-exec-5] o.s.orm.jpa.JpaTransactionManager        : Initiating transaction commit
2020-06-16 07:13:49.984 DEBUG 1 --- [nio-8080-exec-5] o.s.orm.jpa.JpaTransactionManager        : Committing JPA transaction on EntityManager [SessionImpl(256287368&lt;open&gt;)]
2020-06-16 07:13:49.984 DEBUG 1 --- [nio-8080-exec-5] o.h.e.t.internal.TransactionImpl         : committing
2020-06-16 07:13:49.984 DEBUG 1 --- [nio-8080-exec-5] org.postgresql.jdbc.PgConnection         :   setAutoCommit = true
2020-06-16 07:13:49.985 DEBUG 1 --- [nio-8080-exec-5] o.s.orm.jpa.JpaTransactionManager        : Closing JPA EntityManager [SessionImpl(256287368&lt;open&gt;)] after transaction
</code></pre>
<p>可以明显的看到，在代码更新后，每次向数据库写log的时候都加上了声明式事务，而在这个事务中我们一共写了5次log，才将数据库连接释放。而在并发场景下，后进来的线程也会开启事务，但是数据库连接池却没有可有连接给支撑，在timeout时间过了之后，就会报大批量连接不上数据库的错误。这是rootcause，那为什么莫名其妙会加上事务呢？</p>
<p>经过仔细研读spring security代码，发现一个以前没有注意到的事情，就是DefaultTokenService重的createAccessToken()方法上有@Transactional注解，而我们写log的代码又正好是在这个方法内执行的：</p>
<pre><code class="java">public class DefaultTokenServices implements AuthorizationServerTokenServices, ResourceServerTokenServices,
        ConsumerTokenServices, InitializingBean {

    @Transactional
    public OAuth2AccessToken createAccessToken(OAuth2Authentication authentication) throws AuthenticationException {

        OAuth2AccessToken existingAccessToken = tokenStore.getAccessToken(authentication);
        OAuth2RefreshToken refreshToken = null;
        if (existingAccessToken != null) {
            if (existingAccessToken.isExpired()) {
                if (existingAccessToken.getRefreshToken() != null) {
                    refreshToken = existingAccessToken.getRefreshToken();
                    // The token store could remove the refresh token when the
                    // access token is removed, but we want to
                    // be sure...
                    tokenStore.removeRefreshToken(refreshToken);
                }
                tokenStore.removeAccessToken(existingAccessToken);
            }
            else {
                // Re-store the access token in case the authentication has changed
                tokenStore.storeAccessToken(existingAccessToken, authentication);
                return existingAccessToken;
            }
        }

        // Only create a new refresh token if there wasn&#39;t an existing one
        // associated with an expired access token.
        // Clients might be holding existing refresh tokens, so we re-use it in
        // the case that the old access token
        // expired.
        if (refreshToken == null) {
            refreshToken = createRefreshToken(authentication);
        }
        // But the refresh token itself might need to be re-issued if it has
        // expired.
        else if (refreshToken instanceof ExpiringOAuth2RefreshToken) {
            ExpiringOAuth2RefreshToken expiring = (ExpiringOAuth2RefreshToken) refreshToken;
            if (System.currentTimeMillis() &gt; expiring.getExpiration().getTime()) {
                refreshToken = createRefreshToken(authentication);
            }
        }

        OAuth2AccessToken accessToken = createAccessToken(authentication, refreshToken);
        tokenStore.storeAccessToken(accessToken, authentication);
        // In case it was modified
        refreshToken = accessToken.getRefreshToken();
        if (refreshToken != null) {
            tokenStore.storeRefreshToken(refreshToken, authentication);
        }
        return accessToken;

    }
}
</code></pre>
<p>为什么createAccessToken方法要加事务呢？因为在许多场景下，accesstoken是有持久化的需求的。因为ram-guards用的是jwt(jwe)格式的，它能够自解析，所以我们不需要持久化。但如果是一个普通的token，就需要使用JdbcTokenStore来存库了。</p>
<p>那么现在有三个问题：</p>
<ol>
<li>为什么我们的代码里开启了事务（还是log-db上的事务）</li>
</ol>
<p>spring boot在引入任何db的datasource时，会自动通过HibernateJpaAutoConfiguration-&gt;HibernateJpaConfiguration-&gt;JpaBaseConfiguration.transactionManager()来建立一个transactionManager的bean，并通过TransactionAutoConfiguration去进行自动配置。transactionManager会扫描所有bean中有@Transactional注解的方法，并以aop的方式去开启事务。</p>
<ol>
<li>为什么以前的代码没有使用事务，现在的代码却使用了</li>
</ol>
<p>这就得直接上代码了。</p>
<p>老版本的代码：</p>
<pre><code class="java">    @Bean
    @Primary
    public DefaultTokenServices tokenServices() throws Exception {
        final DefaultTokenServices defaultTokenServices = new DefaultTokenServices();
        defaultTokenServices.setTokenStore(tokenStore());
        defaultTokenServices.setSupportRefreshToken(true);
        return defaultTokenServices;
    }

    @Override
    public void configure(final AuthorizationServerEndpointsConfigurer endpoints) throws Exception {
        final TokenEnhancerChain tokenEnhancerChain = new TokenEnhancerChain();
        tokenEnhancerChain.setTokenEnhancers(Collections.singletonList(accessTokenConverter()));
        endpoints
                .requestValidator(requestValidator())
                .tokenStore(tokenStore())
                .tokenEnhancer(tokenEnhancerChain)
                .authenticationManager(authenticationManagerBean)
                .userDetailsService(refreshUserDetailsService);
    }
</code></pre>
<p>新版本的代码：</p>
<pre><code class="java">    @Bean
    @Primary
    public DefaultTokenServices tokenServices() throws Exception {
        final DefaultTokenServices defaultTokenServices = new DefaultTokenServices();
        defaultTokenServices.setTokenStore(tokenStore());
        defaultTokenServices.setSupportRefreshToken(true);
        PreAuthenticatedAuthenticationProvider provider = new PreAuthenticatedAuthenticationProvider();
        provider.setPreAuthenticatedUserDetailsService(token -&gt; {
            UsernamePasswordAuthenticationToken authenticationToken = (UsernamePasswordAuthenticationToken) token.getPrincipal();
            RamGuardsUser ramGuardsUser = new RamGuardsUser();
            ramGuardsUser.setUsername(authenticationToken.getPrincipal().toString());
            Map&lt;String, Object&gt; details = (Map&lt;String, Object&gt;) authenticationToken.getDetails();
            if (details!=null){
                ramGuardsUser.setIsSystemPartner(Boolean.parseBoolean(details.get(&quot;system_partner&quot;).toString()));
            }
            ramGuardsUser.setDetails(details);
            ramGuardsUser.setCredentials(authenticationToken.getCredentials());
            return refreshUserDetailsService.loadUserByRamGuardsUser(ramGuardsUser);
        });
        defaultTokenServices.setAuthenticationManager(new ProviderManager(Collections.singletonList(provider)));
        defaultTokenServices.setTokenEnhancer(accessTokenConverter());
        defaultTokenServices.setTokenStore(tokenStore());
        return defaultTokenServices;
    }

    @Override
    public void configure(final AuthorizationServerEndpointsConfigurer endpoints) throws Exception {
        endpoints
                .tokenServices(tokenServices())
                .requestValidator(requestValidator())
                .authenticationManager(authenticationManagerBean);
    }
</code></pre>
<p>打眼一看好像没什么不同，但仔细看一下就会发现，老版本代码中，DefaultTokenServices虽然注册成为了bean，但却并没有把这个bean提供给AuthorizationServerEndpointsConfigurer，而当AuthorizationServerEndpointsConfigurer中的tokenservice没有值的时候，事实上会调用createDefaultTokenServices方法去创建一个不是bean的DefaultTokenServices实例，代码如下：</p>
<pre><code class="java">   public AuthorizationServerTokenServices getDefaultAuthorizationServerTokenServices() {
        if (defaultTokenServices != null) {
            return defaultTokenServices;
        }
        this.defaultTokenServices = createDefaultTokenServices();
        return this.defaultTokenServices;
    }

    private DefaultTokenServices createDefaultTokenServices() {
        DefaultTokenServices tokenServices = new DefaultTokenServices();
        tokenServices.setTokenStore(tokenStore());
        tokenServices.setSupportRefreshToken(true);
        tokenServices.setReuseRefreshToken(reuseRefreshToken);
        tokenServices.setClientDetailsService(clientDetailsService());
        tokenServices.setTokenEnhancer(tokenEnhancer());
        addUserDetailsService(tokenServices, this.userDetailsService);
        return tokenServices;
    }
</code></pre>
<p>而我们代码中所使用的tokenservice，恰恰就是AuthorizationServerEndpointsConfigurer中的tokenservice。</p>
<p>所以说，在老版本代码中，我们使用的tokenservice并不是spring的一个bean，所以事务也就不会开启，而新版本代码中使用的是一个bean，所以也就启用了事务。</p>
<ol>
<li>我们既然不需要事务，如何把这个事务去掉</li>
</ol>
<p>找到了rootcause之后，解决就变得简单了许多，摆在我面前有两个方案：1、将TransactionAutoConfiguration给exclude出去，不让spring boot自动装配。2、不把DefaultTokenServices注册为bean。</p>
<p>最后选择了方案2，因为我认为既然ram-guards没有被持久化的需求，就不应该被任何transactionManager扫描到。同时，我也把记录auditlog的方法从createAccessToken方法中拿了出来，在TokenEndpoint中以aop的方式切入记log，这样也减少了数据库的写入次数。</p>
<p>至此，这个issue算是解决了。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>说一下我们记audit log的方式，直接通过db log appender去写入数据库事实上是一个开销很大的方式，尤其是在我们log db可用连接资源还十分有限的情况下。这个我们暂时讨论，会在后期优化中用kafka，批量记入到kafka中，在批量写入db进行持久化，减小db的开销。</p>
<p>以后要多做一些API压测（ab或者jmeter），来保证接口在一个标准下不挂，可以以单实例qps为多少来制定这个标准，来保证我们接口的稳定性。</p>
<p>个人认为很有价值的一次troubleshooting，后记中提出的问题都值得我们进行实践。</p>
]]></content>
      
        <categories>
            
            <category> fe </category>
            
            <category> oauth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> fe </tag>
            
            <tag> oauth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JPA在多表联查上的一些坑]]></title>
      <url>/2020/04/11/jpa-improve/</url>
      <content type="html"><![CDATA[<h2 id="JPA的使用场景-（仅针对查询）"><a href="#JPA的使用场景-（仅针对查询）" class="headerlink" title="JPA的使用场景 （仅针对查询）"></a>JPA的使用场景 （仅针对查询）</h2><p>最基本的场景</p>
<p>这种情况比较简单，一般针对一张数据库表建立对应的Java \@Entity class，把针对表的SQL操作转化为JPA 的JPQL / Native SQL / Criteria API 即可。</p>
<p>如果表有单一主键就更简单了，把它作为JPA的\@Id字段。如果没有单一主键，需要确定一个唯一性索引（可能是一列或多列）来作为JPA 的\Id 字段或字段组合。</p>
<p>多表联查的场景</p>
<p>对于多张表的联合查询，就没法做到Java \@Entity class和数据库表(\@Table)一一对应了。这个时候可以针对多张数据库表建立一个数据库视图View, 然后使</p>
<p>Java \@Entity class和 View (\@Table) 对应，其中\@Table里指定View的名字。</p>
<p>有些时候，可能会因为权限或其他原因，没法对数据库表建View。这个时候可以仅把\@Entity class作为对接SQL 查询结果的实体类。在这个实体类中只加\@Entity 不加\@Table 的annation.</p>
<p>如果是用JPA Native SQL 的方式，此用法有点类似于Mybatis。</p>
<h2 id="多表联查中的一些坑"><a href="#多表联查中的一些坑" class="headerlink" title="多表联查中的一些坑"></a>多表联查中的一些坑</h2><p>确定JPA \@Id 字段或字段组合<br>对于多表联查的情况，如果多个表中有一个是主表，并且主表有主键或唯一性索引的话，比较简单，其实和单表查询的情况相同；</p>
<p>如果多个表中没有明显的主表，而且联合查询的结果集的唯一性字段来自于多个表，就稍微复杂了，需要基于对业务数据的理解 / 猜测 + 排除法多次尝试了。从而确定一个最小的字段组合来代表结果集的唯一性索引。</p>
<p>(系统的遗留代码中有很多多表联查，且表没有主键的情况)</p>
<p>实践中发现，如果指定的\@Id字段或字段组合不唯一，JPA返回的数据记录总数看似正确，数据其实是不准确的。</p>
<p>\@Id 字段组合中有字段/列有空值的情况<br>JPA \@Id 字段组合中有字段为NULL 值会导致JPA返回一个NULL Object，这种情况下，如果直接对JPA返回的结果做操作，则会抛出意想不到的NullPointerException。</p>
<p>对于\@Id 字段组合中有字段为NULL 值的情况，其实可以分为两种：</p>
<p>错误数据 - 判断错误数据的标准是什么呢？在全部数据中占比很小（比如1 万条数据里有十几条某列为空值的情况）；基于对业务的理解，某些值为空是业务无意义的。<br>有效数据 - 占比高，比如80%的数据某个列都是NULL，这个肯定不是错误数据了 (也可能是当初数据库设计的问题？？？)<br>其实针对以上两种情况，处理方式也有区别：</p>
<p>对于错误数据，可以考虑在做SQL查询的时候去过滤。<br>对于有效数据，可能需要借助 SQL COALESCE() 函数 来对数据进行转换。</p>
]]></content>
      
        <categories>
            
            <category> jpa </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jpa </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[解读HashMap]]></title>
      <url>/2019/11/24/hashmap/</url>
      <content type="html"><![CDATA[<p>美团技术网站上有一篇很好的文章，我就不自己总结了，直接搬运过来，原文链接： <a href="https://tech.meituan.com/2016/06/24/java-hashmap.html" target="_blank" rel="noopener">https://tech.meituan.com/2016/06/24/java-hashmap.html</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Java为数据结构中的映射定义了一个接口java.util.Map，此接口主要有四个常用的实现类，分别是HashMap、Hashtable、LinkedHashMap和TreeMap，类继承关系如下图所示：</p>
<p><img src="https://i.loli.net/2020/11/24/9GyFcNUtm1MIRaK.png" alt="image.png"></p>
<p>下面针对各个实现类的特点做一些说明：</p>
<ul>
<li><p>HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。</p>
</li>
<li><p>Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。</p>
</li>
<li><p>LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。</p>
</li>
<li><p>TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。</p>
</li>
</ul>
<p>对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。</p>
<p>通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。</p>
<h2 id="内部实现"><a href="#内部实现" class="headerlink" title="内部实现"></a>内部实现</h2><p>搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。</p>
<h3 id="存储结构-字段"><a href="#存储结构-字段" class="headerlink" title="存储结构-字段"></a>存储结构-字段</h3><p>从结构实现来讲，HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的，如下如所示。</p>
<p><img src="https://i.loli.net/2020/11/24/UXtuioLwsT3MHSv.png" alt="image.png"></p>
<p>这里需要讲明白两个问题：数据底层具体存储的是什么？这样的存储方式有什么优点呢？</p>
<p>(1) 从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。</p>
<pre><code class="java">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
        final int hash;    //用来定位数组索引位置
        final K key;
        V value;
        Node&lt;K,V&gt; next;   //链表的下一个node

        Node(int hash, K key, V value, Node&lt;K,V&gt; next) { ... }
        public final K getKey(){ ... }
        public final V getValue() { ... }
        public final String toString() { ... }
        public final int hashCode() { ... }
        public final V setValue(V newValue) { ... }
        public final boolean equals(Object o) { ... }
}
</code></pre>
<p>Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。</p>
<p>(2) HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码：</p>
<pre><code class="java">    map.put(&quot;美团&quot;,&quot;小美&quot;);
</code></pre>
<p>系统将调用”美团”这个key的hashCode()方法得到其hashCode值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。</p>
<p>如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的Hash算法和扩容机制。</p>
<p>在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：</p>
<pre><code class="java">int threshold;             // 所能容纳的key-value对极限 
final float loadFactor;    // 负载因子
int modCount;  
int size;
</code></pre>
<p>首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。</p>
<p>结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。</p>
<p>size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。</p>
<p>在HashMap中，哈希桶数组table的长度length大小必须为2的n次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考<a href="https://blog.csdn.net/liuqiyao_01/article/details/14475159" target="_blank" rel="noopener">这篇文章</a>，Hashtable初始化桶大小为11，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。</p>
<p>这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考<a href="https://blog.csdn.net/liuqiyao_01/article/details/14475159" target="_blank" rel="noopener">这篇文章</a>。</p>
<h2 id="功能实现-方法"><a href="#功能实现-方法" class="headerlink" title="功能实现-方法"></a>功能实现-方法</h2><p>HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方法的详细执行、扩容过程三个具有代表性的点深入展开讲解。</p>
<h3 id="确定哈希桶数组索引位置"><a href="#确定哈希桶数组索引位置" class="headerlink" title="确定哈希桶数组索引位置"></a>确定哈希桶数组索引位置</h3><p>不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):</p>
<pre><code class="java">// 方法一：
static final int hash(Object key) {   //jdk1.8 &amp; jdk1.7
     int h;
     // h = key.hashCode() 为第一步 取hashCode值
     // h ^ (h &gt;&gt;&gt; 16)  为第二步 高位参与运算
     return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
}
// 方法二：
static int indexFor(int h, int length) {  //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的
     return h &amp; (length-1);  //第三步 取模运算
}
</code></pre>
<p>这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。</p>
<p>对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。</p>
<p>这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。</p>
<p>在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。</p>
<h3 id="分析HashMap的put方法"><a href="#分析HashMap的put方法" class="headerlink" title="分析HashMap的put方法"></a>分析HashMap的put方法</h3><p>HashMap的put方法执行过程可以通过下图来理解，自己有兴趣可以去对比源码更清楚地研究学习。</p>
<p><img src="https://i.loli.net/2020/11/24/zGOp29gRYDSmLqA.png" alt="image.png"></p>
<ol>
<li>判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； </li>
<li>根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； </li>
<li>判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； </li>
<li>判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； </li>
<li>遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； </li>
<li>插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。</li>
</ol>
<p>JDK1.8HashMap的put方法源码如下:</p>
<pre><code class="java"> 1 public V put(K key, V value) {
 2     // 对key的hashCode()做hash
 3     return putVal(hash(key), key, value, false, true);
 4 }
 5 
 6 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
 7                boolean evict) {
 8     Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
 9     // 步骤①：tab为空则创建
10     if ((tab = table) == null || (n = tab.length) == 0)
11         n = (tab = resize()).length;
12     // 步骤②：计算index，并对null做处理 
13     if ((p = tab[i = (n - 1) &amp; hash]) == null) 
14         tab[i] = newNode(hash, key, value, null);
15     else {
16         Node&lt;K,V&gt; e; K k;
17         // 步骤③：节点key存在，直接覆盖value
18         if (p.hash == hash &amp;&amp;
19             ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
20             e = p;
21         // 步骤④：判断该链为红黑树
22         else if (p instanceof TreeNode)
23             e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
24         // 步骤⑤：该链为链表
25         else {
26             for (int binCount = 0; ; ++binCount) {
27                 if ((e = p.next) == null) {
28                     p.next = newNode(hash, key,value,null);
                        //链表长度大于8转换为红黑树进行处理
29                     if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st  
30                         treeifyBin(tab, hash);
31                     break;
32                 }
                    // key已经存在直接覆盖value
33                 if (e.hash == hash &amp;&amp;
34                     ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) 
35                            break;
36                 p = e;
37             }
38         }
39         
40         if (e != null) { // existing mapping for key
41             V oldValue = e.value;
42             if (!onlyIfAbsent || oldValue == null)
43                 e.value = value;
44             afterNodeAccess(e);
45             return oldValue;
46         }
47     }

48     ++modCount;
49     // 步骤⑥：超过最大容量 就扩容
50     if (++size &gt; threshold)
51         resize();
52     afterNodeInsertion(evict);
53     return null;
54 }
</code></pre>
<h3 id="扩容机制"><a href="#扩容机制" class="headerlink" title="扩容机制"></a>扩容机制</h3><p>扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。</p>
<p>我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。</p>
<pre><code class="java"> 1 void resize(int newCapacity) {   //传入新的容量
 2     Entry[] oldTable = table;    //引用扩容前的Entry数组
 3     int oldCapacity = oldTable.length;         
 4     if (oldCapacity == MAXIMUM_CAPACITY) {  //扩容前的数组大小如果已经达到最大(2^30)了
 5         threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了
 6         return;
 7     }
 8  
 9     Entry[] newTable = new Entry[newCapacity];  //初始化一个新的Entry数组
10     transfer(newTable);                         //！！将数据转移到新的Entry数组里
11     table = newTable;                           //HashMap的table属性引用新的Entry数组
12     threshold = (int)(newCapacity * loadFactor);//修改阈值
13 }
</code></pre>
<p>这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。</p>
<pre><code class="java"> 1 void transfer(Entry[] newTable) {
 2     Entry[] src = table;                   //src引用了旧的Entry数组
 3     int newCapacity = newTable.length;
 4     for (int j = 0; j &lt; src.length; j++) { //遍历旧的Entry数组
 5         Entry&lt;K,V&gt; e = src[j];             //取得旧Entry数组的每个元素
 6         if (e != null) {
 7             src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）
 8             do {
 9                 Entry&lt;K,V&gt; next = e.next;
10                 int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置
11                 e.next = newTable[i]; //标记[1]
12                 newTable[i] = e;      //将元素放在数组上
13                 e = next;             //访问下一个Entry链上的元素
14             } while (e != null);
15         }
16     }
17 }
</code></pre>
<p>newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。</p>
<p>下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。</p>
<p><img src="https://i.loli.net/2020/11/24/R9AmsVTv6JtzgPj.png" alt="image.png"></p>
<p>下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。</p>
<p><img src="https://i.loli.net/2020/11/24/Ubw8YtrnmCZxj16.png" alt="image.png"></p>
<p>元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：</p>
<p><img src="https://i.loli.net/2020/11/24/QueCvaZqNIsWX1h.png" alt="image.png"></p>
<p>因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图：</p>
<p><img src="https://i.loli.net/2020/11/24/i9nQ6MlOqXKW5zI.png" alt="image.png"></p>
<p>这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下:</p>
<pre><code class="java"> 1 final Node&lt;K,V&gt;[] resize() {
 2     Node&lt;K,V&gt;[] oldTab = table;
 3     int oldCap = (oldTab == null) ? 0 : oldTab.length;
 4     int oldThr = threshold;
 5     int newCap, newThr = 0;
 6     if (oldCap &gt; 0) {
 7         // 超过最大值就不再扩充了，就只好随你碰撞去吧
 8         if (oldCap &gt;= MAXIMUM_CAPACITY) {
 9             threshold = Integer.MAX_VALUE;
10             return oldTab;
11         }
12         // 没超过最大值，就扩充为原来的2倍
13         else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;
14                  oldCap &gt;= DEFAULT_INITIAL_CAPACITY)
15             newThr = oldThr &lt;&lt; 1; // double threshold
16     }
17     else if (oldThr &gt; 0) // initial capacity was placed in threshold
18         newCap = oldThr;
19     else {               // zero initial threshold signifies using defaults
20         newCap = DEFAULT_INITIAL_CAPACITY;
21         newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
22     }
23     // 计算新的resize上限
24     if (newThr == 0) {
25 
26         float ft = (float)newCap * loadFactor;
27         newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?
28                   (int)ft : Integer.MAX_VALUE);
29     }
30     threshold = newThr;
31     @SuppressWarnings({&quot;rawtypes&quot;，&quot;unchecked&quot;})
32         Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];
33     table = newTab;
34     if (oldTab != null) {
35         // 把每个bucket都移动到新的buckets中
36         for (int j = 0; j &lt; oldCap; ++j) {
37             Node&lt;K,V&gt; e;
38             if ((e = oldTab[j]) != null) {
39                 oldTab[j] = null;
40                 if (e.next == null)
41                     newTab[e.hash &amp; (newCap - 1)] = e;
42                 else if (e instanceof TreeNode)
43                     ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);
44                 else { // 链表优化重hash的代码块
45                     Node&lt;K,V&gt; loHead = null, loTail = null;
46                     Node&lt;K,V&gt; hiHead = null, hiTail = null;
47                     Node&lt;K,V&gt; next;
48                     do {
49                         next = e.next;
50                         // 原索引
51                         if ((e.hash &amp; oldCap) == 0) {
52                             if (loTail == null)
53                                 loHead = e;
54                             else
55                                 loTail.next = e;
56                             loTail = e;
57                         }
58                         // 原索引+oldCap
59                         else {
60                             if (hiTail == null)
61                                 hiHead = e;
62                             else
63                                 hiTail.next = e;
64                             hiTail = e;
65                         }
66                     } while ((e = next) != null);
67                     // 原索引放到bucket里
68                     if (loTail != null) {
69                         loTail.next = null;
70                         newTab[j] = loHead;
71                     }
72                     // 原索引+oldCap放到bucket里
73                     if (hiTail != null) {
74                         hiTail.next = null;
75                         newTab[j + oldCap] = hiHead;
76                     }
77                 }
78             }
79         }
80     }
81     return newTab;
82 }
</code></pre>
<h2 id="1-7和1-8有哪些区别不同点："><a href="#1-7和1-8有哪些区别不同点：" class="headerlink" title="1.7和1.8有哪些区别不同点："></a>1.7和1.8有哪些区别不同点：</h2><ul>
<li><p>JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，那么他们为什么要这样做呢？因为JDK1.7是用单链表进行的纵向延伸，当采用头插法时会容易出现逆序且环形链表死循环问题。但是在JDK1.8之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。</p>
</li>
<li><p>扩容后数据存储位置的计算方式也不一样：</p>
<ul>
<li>在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&amp;（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）（hash值 &amp; length-1）</li>
<li>而在JDK1.8的时候直接用了JDK1.7的时候计算的规律，也就是扩容前的原始位置+扩容的大小值=JDK1.8的计算方式，而不再是JDK1.7的那种异或的方法。但是这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的储存方式。</li>
<li>在计算hash值的时候，JDK1.7用了9次扰动处理=4次位运算+5次异或，而JDK1.8只用了2次扰动处理=1次位运算+1次异或。<br><img src="https://i.loli.net/2020/11/25/wEXOd2IC6FoTLga.png" alt="image.png"></li>
</ul>
</li>
<li><p>JDK1.7的时候使用的是数组+ 单链表的数据结构。但是在JDK1.8及之后时，使用的是数组+链表+红黑树的数据结构（当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O（n）变成O（logN）提高了效率）</p>
</li>
</ul>
<p>这里在重新进行补充几个问题：</p>
<ul>
<li>为什么在JDK1.7的时候是先进行扩容后进行插入，而在JDK1.8的时候则是先插入后进行扩容的呢？</li>
</ul>
<p>其实这个问题也是JDK8对HashMap中，主要是因为对链表转为红黑树进行的优化，因为你插入这个节点的时候有可能是普通链表节点，也有可能是红黑树节点，但是为什么1.8之后HashMap变为先插入后扩容的原因，我也有点不是很理解？欢迎来讨论这个问题？</p>
<p>但是在JDK1.7中的话，是先进行扩容后进行插入的，就是当你发现你插入的桶是不是为空，如果不为空说明存在值就发生了hash冲突，那么就必须得扩容，但是如果不发生Hash冲突的话，说明当前桶是空的（后面并没有挂有链表），那就等到下一次发生Hash冲突的时候在进行扩容，但是当如果以后都没有发生hash冲突产生，那么就不会进行扩容了，减少了一次无用扩容，也减少了内存的使用</p>
<ul>
<li>为什么在JDK1.8中进行对HashMap优化的时候，把链表转化为红黑树的阈值是8,而不是7或者不是20呢？</li>
</ul>
<p>如果选择6和8（如果链表小于等于6树还原转为链表，大于等于8转为树），中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。</p>
<p>还有一点重要的就是由于treenodes的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们，当它们变得太小（由于移除或调整大小）时，它们会被转换回普通的node节点，容器中节点分布在hash桶中的频率遵循泊松分布，桶的长度超过8的概率非常非常小。所以作者应该是根据概率统计而选择了8作为阀值</p>
<ul>
<li>哈希表如何解决Hash冲突？</li>
</ul>
<p><img src="https://i.loli.net/2020/11/25/UsL9D1hfxbV3eCO.png" alt="image.png"></p>
<ul>
<li>为什么HashMap具备下述特点：键-值（key-value）都允许为空、线程不安全、不保证有序、存储位置随时间变化</li>
</ul>
<p><img src="https://i.loli.net/2020/11/25/XT3e1bj6O2MWUgc.png" alt="image.png"></p>
<ul>
<li>为什么 HashMap 中 String、Integer 这样的包装类适合作为 key 键</li>
</ul>
<p><img src="https://i.loli.net/2020/11/25/zq3kX8thHebcpRm.png" alt="image.png"></p>
<ul>
<li>HashMap 中的 key若 Object类型， 则需实现哪些方法？</li>
</ul>
<p><img src="https://i.loli.net/2020/11/25/SxZD3OReq26rEyl.png" alt="image.png"></p>
]]></content>
      
        <categories>
            
            <category> 基础 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[在spring中使用cors]]></title>
      <url>/2018/11/06/spring-cors/</url>
      <content type="html"><![CDATA[<p>网上有很多教程，基本上都是清一色的<code>@CrossOrigin</code>，<code>@CrossOrigin</code>在和spring security一起用的时候不生效，因为filter chain order的原因。</p>
<p>解决方案：</p>
<pre><code class="java">import org.springframework.boot.web.servlet.FilterRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.Ordered;
import org.springframework.web.cors.CorsConfiguration;
import org.springframework.web.cors.UrlBasedCorsConfigurationSource;
import org.springframework.web.filter.CorsFilter;


@Configuration
public class WebCorsConfig {

    @Bean
    public FilterRegistrationBean customCorsFilter() {
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
        CorsConfiguration config = new CorsConfiguration();
        config.setAllowCredentials(true);
        config.addAllowedOrigin(&quot;*&quot;);
        config.addAllowedHeader(&quot;*&quot;);
        config.addAllowedMethod(&quot;*&quot;);
        source.registerCorsConfiguration(&quot;/**&quot;, config);
        FilterRegistrationBean bean = new FilterRegistrationBean(new CorsFilter(source));
        bean.setOrder(Ordered.HIGHEST_PRECEDENCE);
        return bean;
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[使用oidc id token验证spring security resource server]]></title>
      <url>/2018/11/06/spring-security-jwt/</url>
      <content type="html"><![CDATA[<p>在前后端分离的项目中，前端因为不能保证密钥的安全，通常会使用oidc implicit grant type来获取access token和id token，后端会验证token的合法性并获得用户信息。</p>
<p>后端使用spring，如果后端是验证access token，那好说，使用spring-security-oauth2-autoconfigure，详见<a href="https://docs.spring.io/spring-security-oauth2-boot/docs/current-SNAPSHOT/reference/htmlsingle/" target="_blank" rel="noopener">文档</a>。</p>
<p>如果后端是验证id token，并且提供jwks url，那也好说，详见<a href="https://spring.io/blog/2018/08/21/spring-security-5-1-0-rc1-released#oauth2-resource-server" target="_blank" rel="noopener">文档</a>。</p>
<p>可惜的是IBM ID OAuth server暂时还没有提供jwks url，只给了一个rsa public key的证书，因此记录一下解决方案。</p>
<p><strong>版本：spring boot 2.1.0.RELEASE</strong></p>
<pre><code class="gradle">dependencies{
    compile(&#39;org.springframework.boot:spring-boot-starter-security&#39;)
    compile(&#39;org.springframework.security:spring-security-oauth2-jose:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-oauth2-client:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-oauth2-resource-server:5.1.1.RELEASE&#39;)
    compile(&#39;org.bouncycastle:bcprov-jdk15on:1.60&#39;)
}
</code></pre>
<pre><code class="java">import org.bouncycastle.util.io.pem.PemObject;
import org.bouncycastle.util.io.pem.PemReader;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.oauth2.jwt.JwtDecoder;
import org.springframework.security.oauth2.jwt.NimbusReactiveJwtDecoder;

import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileReader;
import java.io.InputStream;
import java.security.cert.CertificateFactory;
import java.security.cert.X509Certificate;
import java.security.interfaces.RSAPublicKey;


@EnableWebSecurity
public class WebSecurityConfig extends WebSecurityConfigurerAdapter {

    @Value(&quot;${JWK-certificate}&quot;)
    String jwkCertificate;

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http
                .authorizeRequests()
                .anyRequest().authenticated()
                .and()
                .oauth2ResourceServer()
                .jwt();
    }

    @Bean
    JwtDecoder getJwtDecoder() throws Exception {
        NimbusReactiveJwtDecoder nimbusReactiveJwtDecoder = new NimbusReactiveJwtDecoder(WebSecurityConfig.get(jwkCertificate));
        return token -&gt; nimbusReactiveJwtDecoder.decode(token).block();
    }

    public static RSAPublicKey get(String filePath) throws Exception {
        PemReader pemReader = new PemReader(new FileReader(new File(WebSecurityConfig.class.getResource(filePath).getPath())));
        PemObject pemObject = pemReader.readPemObject();
        pemReader.close();
        CertificateFactory fact = CertificateFactory.getInstance(&quot;X.509&quot;);
        InputStream input = new ByteArrayInputStream(pemObject.getContent());
        X509Certificate cert = (X509Certificate) fact.generateCertificate(input);
        return (RSAPublicKey)cert.getPublicKey();
    }

}
</code></pre>
<p><strong>版本：spring boot 2.0.6.RELEASE</strong></p>
<pre><code class="gradle">dependencies{
    compile(&#39;org.springframework.security:spring-security-oauth2-core:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-oauth2-jose:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-oauth2-client:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-oauth2-resource-server:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-core:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-config:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-web:5.1.1.RELEASE&#39;)
    compile(&#39;org.springframework.security:spring-security-crypto&#39;:5.1.1.RELEASE)
    compile(&#39;org.bouncycastle:bcprov-jdk15on:1.60&#39;)
}
</code></pre>
<pre><code class="java">import org.bouncycastle.util.io.pem.PemObject;
import org.bouncycastle.util.io.pem.PemReader;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.Bean;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.config.annotation.web.configurers.oauth2.server.resource.OAuth2ResourceServerConfigurer;
import org.springframework.security.oauth2.jwt.JwtDecoder;
import org.springframework.security.oauth2.jwt.NimbusReactiveJwtDecoder;

import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileReader;
import java.io.InputStream;
import java.security.cert.CertificateFactory;
import java.security.cert.X509Certificate;
import java.security.interfaces.RSAPublicKey;



@EnableWebSecurity
public class WebSecurityConfig extends WebSecurityConfigurerAdapter {

    @Value(&quot;${JWK-certificate}&quot;)
    String jwkCertificate;

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        OAuth2ResourceServerConfigurer&lt;HttpSecurity&gt; oauth2ResourceServerConfigurer = new OAuth2ResourceServerConfigurer&lt;&gt;(http.getSharedObject(ApplicationContext.class));
        oauth2ResourceServerConfigurer.jwt();
        http
                .authorizeRequests()
                .anyRequest().authenticated()
                .and()
                .apply(oauth2ResourceServerConfigurer);
    }

    @Bean
    JwtDecoder getJwtDecoder() throws Exception {
        NimbusReactiveJwtDecoder nimbusReactiveJwtDecoder = new NimbusReactiveJwtDecoder(WebSecurityConfig.get(jwkCertificate));
        return token -&gt; nimbusReactiveJwtDecoder.decode(token).block();
    }

    public static RSAPublicKey get(String filePath) throws Exception {
        PemReader pemReader = new PemReader(new FileReader(new File(WebSecurityConfig.class.getResource(filePath).getPath())));
        PemObject pemObject = pemReader.readPemObject();
        pemReader.close();
        CertificateFactory fact = CertificateFactory.getInstance(&quot;X.509&quot;);
        InputStream input = new ByteArrayInputStream(pemObject.getContent());
        X509Certificate cert = (X509Certificate) fact.generateCertificate(input);
        return (RSAPublicKey)cert.getPublicKey();
    }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
            <category> OIDC </category>
            
            <category> spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
            <tag> spring </tag>
            
            <tag> OIDC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[倒鸭子]]></title>
      <url>/2018/09/30/daoyazi/</url>
      <content type="html"><![CDATA[<h1 id="倒鸭子台词"><a href="#倒鸭子台词" class="headerlink" title="倒鸭子台词"></a>倒鸭子台词</h1><ul>
<li>你好，请问有什么可以帮到您？</li>
<li><strong>喂，您好</strong></li>
<li>您好</li>
<li><strong>你这边有杂音，我听不清楚，那个，我的车，刚才，我这才买的车，刚才，那个，在那个，马路边，低大梁擦道牙子擦了个坑</strong></li>
<li>先生您好，您的车辆出保险了，现在要报案是么？</li>
<li><strong>对对对</strong></li>
<li>唉，先生你好，是什么时候出的事情？</li>
<li><strong>刚刚时间，刚刚出的</strong></li>
<li>大概有几分钟了</li>
<li><strong>嗯，就刚刚的事</strong></li>
<li>半个小时是么？</li>
<li><strong>五，十分钟</strong></li>
<li>十分钟？</li>
<li><strong>对</strong></li>
<li>是在哪里出的事情？是在大连吗？</li>
<li><strong>在革镇堡</strong></li>
<li>是在辽宁，辽宁省的大连市，是吗？</li>
<li><strong>对，甘井子，革镇堡</strong></li>
<li>是在大连市的那条路？</li>
<li><strong>甘井子，革镇堡！</strong></li>
<li>干警市</li>
<li><strong>甘井子区，革镇堡镇</strong></li>
<li>先生您好，是在大连市的干警，干警两个字是怎么写的？</li>
<li><strong>甘井子区，甘井子开发区，呃，甘井子区</strong></li>
<li>干警市区是么？</li>
<li><strong>对</strong></li>
<li>干警市区，那个干是两横一竖那个干吗？警是警察的警吗？</li>
<li><strong>对对对</strong></li>
<li>干警市区哪里？</li>
<li><strong>甘井子区，就是大连市甘井子区革镇堡镇</strong></li>
<li>革陈铺，是吗？</li>
<li><strong>革镇堡</strong></li>
<li>啊，好啦，先生我知道了，您在那边发生什么事情了</li>
<li><strong>刚刚，开车，不小心，刮在底下道，刮在道牙子上了，倒车刮道牙子上了，那个，低保险，低杠，低大梁，大，大梁，大架子，底下大架子，刮那个保险杠刮了个坑</strong></li>
<li>先生您好，是您的车在直行的时候，还是倒车的时候？</li>
<li><strong>倒车</strong></li>
<li>倒车的时候是吧？</li>
<li><strong>对</strong></li>
<li>倒车的时候刮到哪个部位了？</li>
<li><strong>就是车，左侧地盘，低杆那个大梁，大架子</strong></li>
<li>左侧，就是您的车的左侧地盘受损了，是吗？</li>
<li><strong>对对对，底下，大架子，侧面大架子</strong></li>
<li>还有没有其他地方受损么？</li>
<li><strong>嗯，别的地方没有。</strong></li>
<li>其他地方没有啦，是您的车擦到哪里了？擦到墙了还是擦到哪里了？</li>
<li><strong>擦到就是道边的那个道牙子</strong></li>
<li>倒鸭子？</li>
<li><strong>对呀</strong></li>
<li>是一个什么物体呢？</li>
<li><strong>道牙子，什么物体，哎呀妈呀，就是道边的，公路道边不是有道牙子吗？</strong></li>
<li>是，是那个是墙还是铁杆还是怎么的？</li>
<li><strong>石头</strong></li>
<li>是土是吗？</li>
<li><strong>石块，就是道边铺道牙子的那个石块，那个，每个公路道边不都有那个道边那个道牙子么？</strong></li>
<li>倒鸭子？</li>
<li><strong>就是道边道牙子的那个石块，你叫那个，过来，出险的过来看一下就知道了</strong></li>
<li>那我想请问一下，对方的那个道牙子有没有什么事情呀？</li>
<li><strong>那些都不要紧，那都是大道，那个道边，那都不要紧，就是我车出事了</strong></li>
<li>就是您的车受损了，对方不要求您赔的，是吗？</li>
<li><strong>没有对方，就是车受损了</strong></li>
<li>呃，就是您的车受损了，然后对方的那个不需要您赔是吗？</li>
<li><strong>啊，那些都没有没有，就是我车有点，有毛病，你让过来看一下，要不，我这才买的新车</strong></li>
<li>唉，先生您好，我再跟您核对一下当时的信息，是您的车在倒车的时候刮到了倒鸭子，造成您本车的左侧底盘受损，对方没事是吧？</li>
<li><strong>对对对对，呵呵</strong></li>
<li>啊好叻，那那个麻烦您先在现场暂时不要移动好吗？</li>
<li><strong>啊，行</strong></li>
<li>啊好，感谢您的配合，再见</li>
<li><strong>哎呀妈呀，这女的</strong></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 台词 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 台词 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程]]></title>
      <url>/2018/07/14/oauth-guide/</url>
      <content type="html"><![CDATA[<p>翻译了oauth.com上的教程，地址：<a href="http://seanthefish.com/oauth-guide/#/">http://seanthefish.com/oauth-guide/#/</a></p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--附录]]></title>
      <url>/2018/07/14/oauth-guide-26/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<h3 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h3><ul>
<li><a href="http://tools.ietf.org/html/rfc6749" target="_blank" rel="noopener">OAuth 2.0 RFC 6749</a></li>
<li><a href="http://tools.ietf.org/html/rfc6750" target="_blank" rel="noopener">承载令牌使用RFC 6750</a></li>
<li><a href="http://tools.ietf.org/html/rfc6819" target="_blank" rel="noopener">OAuth 2.0威胁模型和安全注意事项RFC 6819</a></li>
<li><a href="https://tools.ietf.org/html/draft-ietf-oauth-device-flow" target="_blank" rel="noopener">OAuth 2.0设备流程</a></li>
<li><a href="https://tools.ietf.org/html/draft-ietf-oauth-native-apps" target="_blank" rel="noopener">适用于原生应用的OAuth 2.0</a></li>
<li><a href="https://tools.ietf.org/html/rfc7636" target="_blank" rel="noopener">代码交换RFC 7636的证明密钥</a></li>
<li><a href="http://tools.ietf.org/html/rfc7519" target="_blank" rel="noopener">JSON Web Token RFC 7519</a></li>
<li><a href="https://openid.net/connect/" target="_blank" rel="noopener">OpenID Connect</a></li>
<li><a href="https://www.w3.org/TR/indieauth/" target="_blank" rel="noopener">IndieAuth</a></li>
<li><a href="https://tools.ietf.org/wg/oauth/" target="_blank" rel="noopener">所有OAuth工作组规范</a></li>
</ul>
<h3 id="供应商文档"><a href="#供应商文档" class="headerlink" title="供应商文档"></a>供应商文档</h3><ul>
<li><a href="https://developers.google.com/identity/protocols/OAuth2" target="_blank" rel="noopener">Google OAuth 2.0</a></li>
<li><a href="https://developers.facebook.com/" target="_blank" rel="noopener">Facebook开发者</a></li>
<li><a href="https://developer.github.com/apps/" target="_blank" rel="noopener">GitHub文档</a></li>
<li><a href="https://developer.foursquare.com/overview/auth" target="_blank" rel="noopener">Foursquare文档</a></li>
</ul>
<h3 id="社区资源"><a href="#社区资源" class="headerlink" title="社区资源"></a>社区资源</h3><ul>
<li><a href="https://aaronparecki.com/oauth/" target="_blank" rel="noopener">由Aaron Parecki提供的OAuth资源</a></li>
<li><a href="https://alexbilbie.com/tag/oauth/" target="_blank" rel="noopener">Alex Bilbie撰写的OAuth文章</a></li>
<li><a href="https://hueniverse.com/tagged/oauth" target="_blank" rel="noopener">Eran Hammer撰写的OAuth文章</a></li>
<li><a href="https://oauth.net/articles/authentication/" target="_blank" rel="noopener">使用OAuth 2.0进行用户身份验证</a></li>
<li><a href="https://www.ietf.org/mailman/listinfo/oauth" target="_blank" rel="noopener">OAuth IETF邮件列表</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--工具和帮助文档]]></title>
      <url>/2018/07/14/oauth-guide-25/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<h3 id="OAuth-2-0游乐场"><a href="#OAuth-2-0游乐场" class="headerlink" title="OAuth 2.0游乐场"></a>OAuth 2.0游乐场</h3><p><code>https://www.oauth.com/playground/</code></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftoj9ztdrzj30sg0kw41k.jpg" alt="play"></p>
<p>OAuth 2.0 Playground通过与真正的OAuth 2.0授权服务器交互，引导您完成各种OAuth流程。</p>
<p>它包含授权码流，PKCE，设备流以及OpenID Connect的简单示例。</p>
<h3 id="Google-OAuth-2-0-Playground"><a href="#Google-OAuth-2-0-Playground" class="headerlink" title="Google OAuth 2.0 Playground"></a>Google OAuth 2.0 Playground</h3><p><code>https://developers.google.com/oauthplayground/</code></p>
<p>Google的OAuth 2.0 Playground允许您手动逐步完成从此测试应用程序访问您自己的Google帐户的授权过程。</p>
<p>您可以从可用范围列表中进行选择，点击“授权”以转到标准Google授权页面，重定向会将您返回到OAuth 2.0 Playground。在那里，您可以查看交换访问令牌的授权代码的请求，然后使用访问令牌进行测试以发出API请求。</p>
<p>该工具还允许您通过自定义授权和令牌endpoint来对其他OAuth 2.0服务器进行授权。</p>
<h3 id="OpenID-Connect-Debugger"><a href="#OpenID-Connect-Debugger" class="headerlink" title="OpenID Connect Debugger"></a>OpenID Connect Debugger</h3><p><code>https://oidcdebugger.com</code></p>
<p>OpenID Connect Debugger允许您测试OpenID Connect请求并调试来自服务器的响应。您可以将该工具配置为与任何OpenID服务器（如Google）配合使用。</p>
<h3 id="服务器和客户端库目录"><a href="#服务器和客户端库目录" class="headerlink" title="服务器和客户端库目录"></a>服务器和客户端库目录</h3><p><code>https://oauth.net/code/</code></p>
<p>oauth.net网站包含支持OAuth 2.0的服务器，客户端和服务的目录。您可以找到从完整的OAuth 2.0服务器实现到促进流程的每个步骤的库的任何内容，以及客户端库和代理服务。</p>
<p>如果您要提供任何库或服务，也可以将它们添加到目录中。</p>
<h3 id="jsonwebtoken-io"><a href="#jsonwebtoken-io" class="headerlink" title="jsonwebtoken.io"></a>jsonwebtoken.io</h3><p><code>https://jsonwebtoken.io</code></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1ftojc727cbj30sg0ovahn.jpg" alt="jwt"></p>
<p>jsonwebtoken.io是一个用于调试JSON Web令牌的工具。它允许您粘贴JWT，它将对其进行解码并显示各个组件。如果您向其提供用于签署JWT的秘钥，它还可以验证签名。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--OAuth 2.0规范]]></title>
      <url>/2018/07/14/oauth-guide-24/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>OAuth 2.0核心框架（RFC 6749）定义了角色和基本功能级别，但未指定大量实现细节。自RFC发布以来，OAuth工作组已经发布了许多基于此框架构建的其他规范，以填补缺失的部分。查看该小组正在进行的完整规范列表可能有点困难。本章列出了各种规范如何相互关联。</p>
<h3 id="核心规格"><a href="#核心规格" class="headerlink" title="核心规格"></a>核心规格</h3><h4 id="OAuth-2-0核心（RFC-6749）"><a href="#OAuth-2-0核心（RFC-6749）" class="headerlink" title="OAuth 2.0核心（RFC 6749）"></a>OAuth 2.0核心（RFC 6749）</h4><p><code>https://tools.ietf.org/html/rfc6749</code></p>
<p>RFC 6749是核心OAuth 2.0框架。这描述了角色（资源所有者，客户端，授权服务器等，在术语参考中有更详细的描述，几个授权流程和几个错误定义。重要的是要记住这是一个“框架”，因为有很多方面未指明您在构建完整实施时需要填写。其中大部分细节已记录为扩展规范。</p>
<h4 id="承载令牌使用（RFC-6750）"><a href="#承载令牌使用（RFC-6750）" class="headerlink" title="承载令牌使用（RFC 6750）"></a>承载令牌使用（RFC 6750）</h4><p><code>https://tools.ietf.org/html/rfc6750</code></p>
<p>核心规范没有定义访问令牌的格式或如何使用它们。在开发核心规范的早期，访问令牌是争论的主要问题，结果是访问令牌完全取自核心规范，而不是让人们在不受欢迎的令牌上妥协。但是，从那时起，大多数实现已经标准化使用承载令牌。RFC 6750描述了使用承载令牌访问API的语法和方法。</p>
<h4 id="威胁模型和安全注意事项（RFC-6819）"><a href="#威胁模型和安全注意事项（RFC-6819）" class="headerlink" title="威胁模型和安全注意事项（RFC 6819）"></a>威胁模型和安全注意事项（RFC 6819）</h4><p><code>https://tools.ietf.org/html/rfc6819</code></p>
<p>编写威胁模型和安全注意事项文档是为了提供超出核心文档所述内容的其他指导。在主要提供商具有真正的实施经验之后，添加了大部分文档。该文件描述了许多已知的攻击，无论是理论攻击还是已经被证明的攻击。它描述了每种方法的对策。</p>
<p>实施OAuth 2.0服务器的每个人都应该阅读本文档，以避免陷入已经探索和解决过的陷阱。</p>
<h3 id="令牌"><a href="#令牌" class="headerlink" title="令牌"></a>令牌</h3><h4 id="令牌自解析（RFC-7662）"><a href="#令牌自解析（RFC-7662）" class="headerlink" title="令牌自解析（RFC 7662）"></a>令牌自解析（RFC 7662）</h4><p><code>https://tools.ietf.org/html/rfc7662</code></p>
<p>令牌自解析规范定义了资源服务器获取有关访问令牌的信息的机制。如果没有此规范，资源服务器必须有一种定制方式来检查访问令牌是否有效，并找出有关它们的用户数据等。这通常发生在自定义API endpoint上，或者因为资源服务器和授权服务器共享一个数据库或其他一些常见的存储。</p>
<p>使用此规范，资源服务器可以检查访问令牌的有效性，并通过HTTP API调用查找其他信息，从而更好地分离授权服务器与任何资源服务器之间的关注点。</p>
<h4 id="令牌绑定"><a href="#令牌绑定" class="headerlink" title="令牌绑定"></a>令牌绑定</h4><p><code>https://tools.ietf.org/html/draft-ietf-oauth-token-binding</code></p>
<p>令牌绑定扩展描述了一种将令牌加密绑定到客户端的技术，以保护令牌免受中间人和重放攻击。标准承载令牌和授权码与使用它们的客户端没有加密连接，这是OAuth 1中OAuth 2的重大变化。</p>
<h3 id="移动和其他设备"><a href="#移动和其他设备" class="headerlink" title="移动和其他设备"></a>移动和其他设备</h3><p>编写这些规范是为了在更广泛的设备上支持OAuth。</p>
<h4 id="适用于原生应用的OAuth-2-0"><a href="#适用于原生应用的OAuth-2-0" class="headerlink" title="适用于原生应用的OAuth 2.0"></a>适用于原生应用的OAuth 2.0</h4><p><code>https://tools.ietf.org/html/draft-ietf-oauth-native-apps</code></p>
<p>本文档更多的是一组准则而不是协议更改。在本文档中，您将找到针对这些环境特有的原生应用程序和安全建议的建议。它描述了诸如不允许第三方应用程序打开更容易受到网络钓鱼攻击的嵌入式Web视图以及有关如何执行此操作的特定于平台的建议。它还建议使用PKCE扩展，如下所述。</p>
<h4 id="PKCE：代码交换的证明密钥（RFC-7636）"><a href="#PKCE：代码交换的证明密钥（RFC-7636）" class="headerlink" title="PKCE：代码交换的证明密钥（RFC 7636）"></a>PKCE：代码交换的证明密钥（RFC 7636）</h4><p><code>https://tools.ietf.org/html/rfc7636</code></p>
<p>移动和桌面应用等公共客户端缺少使授权流程安全的Web应用程序的许多功能。Web应用程序具有使用HTTPS URL访问的好处，因此授权服务器可以合理地确信它在生成授权代码后,将用户的浏览器重定向到正确的应用程序。在用授权码交换访问令牌时，Web应用程序还能够利用客户端秘钥。由于移动和桌面应用程序都没有这些功能，因此授权服务器无法确定它是否将用户返回到正确的应用程序。</p>
<p>PKCE扩展描述了应用程序首先生成在请求访问令牌时使用秘钥的方式，以便拦截授权代码的攻击者无法使用被盗代码。</p>
<p>PKCE中详细介绍了PKCE扩展。</p>
<h4 id="设备流程"><a href="#设备流程" class="headerlink" title="设备流程"></a>设备流程</h4><p><code>https://tools.ietf.org/html/draft-ietf-oauth-device-flow</code></p>
<p>设备流是一种扩展，它使没有浏览器或有限输入功能的设备能够获得用户授权。您通常会在没有网络浏览器的Apple TV等设备上看到这种情况，或者除了几个按钮之外没有输入机制的流式视频编码器。</p>
<p>该流程的工作原理是让用户访问辅助设备（如智能手机）上的URL并输入设备上显示的代码。</p>
<h4 id="身份验证和会话管理"><a href="#身份验证和会话管理" class="headerlink" title="身份验证和会话管理"></a>身份验证和会话管理</h4><p>这些规范用于促进身份验证和会话管理，这两者都不是核心OAuth规范的一部分。</p>
<h4 id="OpenID-Connect"><a href="#OpenID-Connect" class="headerlink" title="OpenID Connect"></a>OpenID Connect</h4><p><code>https://openid.net/connect/</code></p>
<p>由于OAuth框架仅描述授权方法，并且未提供有关用户的任何详细信息，因此OpenID Connect通过描述身份验证和会话管理机制来填补这一空白。</p>
<h4 id="IndieAuth"><a href="#IndieAuth" class="headerlink" title="IndieAuth"></a>IndieAuth</h4><p><code>https://www.w3.org/TR/indieauth/</code></p>
<p>IndieAuth是一个基于OAuth 2.0构建的分散式身份协议，使用URL来识别用户和应用程序。这样就无需事先注册客户端，因为所有客户端都有内置的客户端ID：应用程序的URL。</p>
<h4 id="令牌撤销（RFC-7009）"><a href="#令牌撤销（RFC-7009）" class="headerlink" title="令牌撤销（RFC 7009）"></a>令牌撤销（RFC 7009）</h4><p><code>https://tools.ietf.org/html/rfc7009</code></p>
<p>本文档描述了授权服务器的新endpoint，客户端可以使用该endpoint通知服务器不再需要访问令牌或刷新令牌。这用于在客户端中启用“注销”功能，允许授权服务器清除与该会话关联的任何凭据。</p>
<h3 id="交互操作"><a href="#交互操作" class="headerlink" title="交互操作"></a>交互操作</h3><p>为了支持创建可以与任何OAuth 2.0服务器一起使用的完全通用的客户端，需要对发现和客户端注册等内容进行标准化，因为它们超出了核心规范的范围。</p>
<h4 id="授权服务器元数据"><a href="#授权服务器元数据" class="headerlink" title="授权服务器元数据"></a>授权服务器元数据</h4><p><code>https://tools.ietf.org/html/rfc8414</code></p>
<p>授权服务器元数据规范（也称为发现）定义了客户端用于查找与特定OAuth服务器交互所需的信息的格式。这包括查找授权endpoint和列出支持的范围等内容。</p>
<h4 id="动态客户端注册（RFC-7591）"><a href="#动态客户端注册（RFC-7591）" class="headerlink" title="动态客户端注册（RFC 7591）"></a>动态客户端注册（RFC 7591）</h4><p><code>https://tools.ietf.org/html/rfc7591</code></p>
<p>通常，开发人员将手动在服务中注册应用程序以获取客户端ID，并提供有关将在授权接口上使用的应用程序的信息。此规范提供了动态或以编程方式注册客户端的机制。此规范源自OpenID Connect动态客户端注册规范，并且仍与OpenID Connect服务器兼容。</p>
<h4 id="动态客户端管理（RFC-7592）"><a href="#动态客户端管理（RFC-7592）" class="headerlink" title="动态客户端管理（RFC 7592）"></a>动态客户端管理（RFC 7592）</h4><p><code>https://tools.ietf.org/html/rfc7592</code></p>
<p>在需要更新客户端信息的情况下，此规范提供了以编程方式执行此操作的机制。此规范扩展了动态注册RFC 7591。</p>
<h3 id="企业"><a href="#企业" class="headerlink" title="企业"></a>企业</h3><p>这些规范支持更高级的企业用例。</p>
<h4 id="断言框架（RFC-7521）"><a href="#断言框架（RFC-7521）" class="headerlink" title="断言框架（RFC 7521）"></a>断言框架（RFC 7521）</h4><p><code>https://tools.ietf.org/html/rfc7521</code></p>
<p>此规范提供了使用OAuth 2.0断言的框架。它定义了新的客户端身份验证机制和新的授权授予类型。由于此规范也是一个框架，因此它仅适用于下面描述的特定断言类型之一。</p>
<h4 id="JWT断言（RFC-7523）"><a href="#JWT断言（RFC-7523）" class="headerlink" title="JWT断言（RFC 7523）"></a>JWT断言（RFC 7523）</h4><p><code>https://tools.ietf.org/html/rfc7523</code></p>
<p>此规范描述了当JWT的内容与客户端存在信任关系时，如何使用JWT来请求访问令牌。它还描述了如何将JWT用作核心OAuth授权的客户端身份验证。</p>
<h4 id="SAML断言（RFC-7522）"><a href="#SAML断言（RFC-7522）" class="headerlink" title="SAML断言（RFC 7522）"></a>SAML断言（RFC 7522）</h4><p><code>https://tools.ietf.org/html/rfc7522</code></p>
<p>此规范描述了当与客户端存在信任关系时，如何使用SAML断言来请求访问令牌。例如，这可用于将旧版SAML工作流与新的OAuth 2.0系统集成。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--IndieAuth]]></title>
      <url>/2018/07/13/oauth-guide-23/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>IndieAuth是一个基于OAuth 2.0的分散式身份协议，它使用URL来识别用户和应用程序。它允许人们在使用该身份登录和授权应用程序时使用其控制下的域作为其身份。该规范可以在<code>https://www.w3.org/TR/indieauth/</code>找到。</p>
<p>所有用户ID都是URL，并且应用程序也通过其URL而不是预先注册的客户端ID进行标识。这使得它非常适用于您不希望开发人员在每个授权服务器上注册帐户的情况，例如在WordPress安装中对用户进行身份验证的应用程序。</p>
<p>IndieAuth分离授权服务器和发布访问令牌的角色，以便可以为流程的每个部分使用完全独立的实现和服务。</p>
<p>当应用程序只需要识别用户进行登录时，IndieAuth可以用作身份验证机制，或者应用程序可以使用IndieAuth来获取用户使用的访问令牌。</p>
<p>例如，Micropub客户端使用IndieAuth获取访问令牌，然后用于在用户的网站上创建内容。</p>
<p>IndieAuth建立在OAuth 2.0框架之上，如下所示：</p>
<ul>
<li>指定用于标识用户的机制和格式（可解析的URL）</li>
<li>指定在给定profile URL的情况下发现授权和令牌endpoint的方法</li>
<li>指定客户端ID的格式（也作为可解析的URL）</li>
<li>所有客户都是公共客户，因为不使用客户秘钥</li>
<li>客户端注册不是必需的，因为所有客户端都必须使用可解析的URL作为其客户端ID</li>
<li>重定向URI注册是由应用程序在其网站上公布其有效的重定向URL来完成的</li>
<li>指定令牌endpoint和授权endpoint进行通信的机制，类似于令牌自解析这是针对授权码的</li>
</ul>
<p>更多信息和规范可以在<a href="IndieAuth">indieauth.net</a>找到。下面是两个工作流程的简要概述。</p>
<h3 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h3><p>在应用程序可以重定向到授权服务器之前，应用程序需要知道将用户引导到哪个授权服务器！这是因为每个用户都由URL标识，并且用户的URL指示其授权服务器所在的位置。</p>
<p>应用程序首先需要提示用户输入其URL，或以其他方式获取其URL。通常，应用程序将包含一个URL字段，供用户输入其URL。</p>
<p>该应用程序将向用户的URL发出HTTP GET请求，查找HTTP Link header或HTML <code>&lt;link&gt;</code>的标记的<code>authorization_endpoint</code>的<code>rel</code>值。在客户端也试图为用户获取访问令牌的情况下，它还将查找<code>token_endpoint</code>的<code>rel</code>值。</p>
<p>例如，GET请求<code>https://aaronparecki.com/</code>可能会返回以下内容，显示为缩写的HTTP请求。</p>
<pre><code class="http">HTTP/2 200
content-type: text/html; charset=UTF-8
link: &lt;https://aaronparecki.com/auth&gt;; rel=&quot;authorization_endpoint&quot;
link: &lt;https://aaronparecki.com/token&gt;; rel=&quot;token_endpoint&quot;
link: &lt;https://aaronparecki.com/micropub&gt;; rel=&quot;micropub&quot;

&lt;!doctype html&gt;
&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;Aaron Parecki&lt;/title&gt;
&lt;link rel=&quot;authorization_endpoint&quot; href=&quot;/auth&quot;&gt;
&lt;link rel=&quot;token_endpoint&quot; href=&quot;/token&quot;&gt;
&lt;link rel=&quot;micropub&quot; href=&quot;/micropub&quot;&gt;
</code></pre>
<p>请注意，endpoint URL可以是相对URL或绝对URL，并且可以位于与用户endpoint相同的域或不同的域上。这允许用户为任何组件使用托管服务。</p>
<p>有关发现的更多详细信息，请访问<br><code>https://www.w3.org/TR/indieauth/#discovery-by-clients</code>。</p>
<h3 id="登录工作流程"><a href="#登录工作流程" class="headerlink" title="登录工作流程"></a>登录工作流程</h3><p>用户登录应用程序的基本流程如下。</p>
<ul>
<li>用户以应用程序的登录形式输入其个人URL。</li>
<li>发现：应用程序获取URL并查找用户的授权endpoint。</li>
<li>授权请求：应用程序将用户的浏览器定向到发现的授权endpoint，作为标准OAuth 2.0授权以及在第一步中输入的用户URL。</li>
<li>身份验证/批准：用户在其授endpoint进行身份验证并批准登录请求。授权服务器生成授权代码并重定向回应用程序的重定向URL。</li>
<li>验证：应用程序检查授权endpoint处的代码，类似于交换访问令牌的代码，但不返回访问令牌，因为这只是对身份验证的检查。授权endpoint使用经过身份验证的用户的完整URL进行响应。</li>
</ul>
<h4 id="认证请求"><a href="#认证请求" class="headerlink" title="认证请求"></a>认证请求</h4><p>当应用程序构建URL以对用户进行身份验证时，该请求看起来与OAuth授权请求非常相似，除了不需要预先注册客户端，并且该请求还将包括用户的profile URL。URL将如下所示。</p>
<pre><code class="http">https://user.example.net/auth?
    me=https://user.example.net/
    &amp;amp;redirect_uri=https://example-app.com/redirect
    &amp;amp;client_id=https://example-app.com/
    &amp;amp;state=1234567890
</code></pre>
<p>然后授权服务器会要求用户登录，就像OAuth流程一样，然后询问用户是否要继续登录应用程序，如下所示。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftoifez6zej311g0fywm8.jpg" alt="auth"></p>
<p>如果用户批准，将使用查询字符串中的授权码（和应用程序的状态值）将它们重定向回应用程序。</p>
<p>然后，应用程序将获取授权码并使用授权endpoint对其进行验证，以确认登录用户的身份。应用程序向授权endpoint发出POST请求code，<code>client_id</code>并且<code>redirect_uri</code>就像正常的授权码一样交换。</p>
<pre><code class="http">POST /auth
Host: user.example.net
Content-type: application/x-www-form-urlencoded

code=xxxxxxxx
&amp;amp;client_id=https://example-app.com/
&amp;amp;redirect_uri=https://example-app.com/redirect
</code></pre>
<p>响应将是一个简单的JSON对象，其中包含用户的完整profile URL。</p>
<pre><code class="http">HTTP/1.1 200 OK
Content-Type: application/json

{
  &quot;me&quot;: &quot;https://user.example.net/&quot;
}
</code></pre>
<p>有关处理请求和响应的更多详细信息，请参阅<br><code>https://www.w3.org/TR/indieauth/#authorization-code-verification</code>。</p>
<h3 id="授权工作流程"><a href="#授权工作流程" class="headerlink" title="授权工作流程"></a>授权工作流程</h3><p>当应用程序尝试获取用户的访问令牌以修改或访问用户的数据时，将使用授权工作流程。这类似于访问数据中描述的OAuth 2.0授权码工作流程，但不使用预先注册客户端，因为使用了URL。</p>
<p>下面是授权应用程序的用户的基本流程。</p>
<ul>
<li>用户以应用程序的登录形式输入其个人URL。</li>
<li>发现：应用程序获取URL并查找用户的授权和令牌endpoint。</li>
<li>授权请求：应用程序将用户的浏览器定向到发现的授权endpoint，作为标准OAuth 2.0授权授予和请求的范围，以及在第一步中输入的用户URL。</li>
<li>身份验证/批准：用户在其授权endpoint进行身份验证，查看请求的范围并批准请求。授权服务器生成授权代码并重定向回应用程序的重定向URL。</li>
<li>令牌交换：应用程序向令牌端点发出请求用授权码交换访问令牌。令牌端点使用访问令牌和经过身份验证的用户的完整URL进行响应。</li>
</ul>
<h4 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h4><p>当应用程序构建URL以对用户进行身份验证时，该请求看起来与OAuth授权请求非常相似，除了不需要预先注册客户端，并且该请求还将包括用户的profile URL。URL将如下所示。</p>
<pre><code class="http">https://user.example.net/auth?
    me=https://user.example.net/
    &amp;amp;response_type=code
    &amp;amp;redirect_uri=https://example-app.com/redirect
    &amp;amp;client_id=https://example-app.com/
    &amp;amp;state=1234567890
    &amp;amp;scope=create+update
</code></pre>
<p>请注意，与上述身份验证请求不同，此请求包括<code>response_type=code</code>和应用程序请求的请求范围列表。</p>
<p>授权服务器将要求用户登录，然后向他们提供授权提示。</p>
<p>不同的IndieAuth服务器可能会以不同的方式显示此提示，如我网站的授权服务器和下面显示的WordPress IndieAuth插件的屏幕截图所示。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1ftoininhyaj31020y47fr.jpg" alt="me"></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftoio589r3j30bd0hrt9i.jpg" alt="wordpress"></p>
<p>当用户批准该请求时，服务器将用户重定向回具有查询字符串中的授权码的应用程序。</p>
<p>为了获得访问令牌，应用程序使用授权码和其他所需数据向用户的令牌endpoint（在第一个发现步骤中发现的endpoint）发出POST请求。</p>
<pre><code class="http">POST /token
Host: user.example.net
Content-type: application/x-www-form-urlencoded&lt;/pre&gt;

&lt;pre class=&quot;break-before&quot;&gt;grant_type=authorization_code
&amp;amp;code=xxxxxxxx
&amp;amp;client_id=https://example-app.com/
&amp;amp;redirect_uri=https://example-app.com/redirect
&amp;amp;me=https://user.example.net/
</code></pre>
<p>令牌endpoint将为用户生成访问令牌，并使用正常的OAuth 2.0令牌响应进行响应，并添加授权应用程序的用户的profile URL。</p>
<pre><code class="http">HTTP/1.1 200 OK
Content-Type: application/json

{
  &quot;me&quot;: &quot;https://user.example.net/&quot;,
  &quot;token_type&quot;: &quot;Bearer&quot;,
  &quot;access_token&quot;: &quot;XXXXXX&quot;,
  &quot;scope&quot;: &quot;create update&quot;
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--OpenID Connect]]></title>
      <url>/2018/07/13/oauth-guide-22/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>OAuth 2.0框架明确不提供有关已授权应用程序的用户的任何信息。OAuth 2.0是一个委派框架，允许第三方应用程序代表用户行事，而无需应用程序知道用户的身份。</p>
<p>OpenID Connect采用OAuth 2.0框架并在顶部添加标识层。它提供有关用户的信息，并使客户端能够建立登录会话。虽然本章并不是OpenID Connect的完整指南，但它旨在阐明OAuth 2.0和OpenID Connect如何相互关联。</p>
<h3 id="授权与身份验证"><a href="#授权与身份验证" class="headerlink" title="授权与身份验证"></a>授权与身份验证</h3><p>OAuth 2.0被称为授权“框架”而不是“协议”，因为核心规范实际上为各种实现留下了相当大的空间，根据其用例不同地执行操作。具体来说，OAuth 2.0不提供说明用户是谁或如何进行身份验证的机制，它只是说用户委托应用程序代表他们行事。OAuth 2.0框架以访问令牌的形式提供此委派，应用程序可以使用该令牌代表用户执行操作。访问令牌被呈现给API（“资源服务器”），其知道如何验证访问令牌是否是活动的。从应用程序的角度来看，它是一个不透明的字符串。</p>
<p>当您入住酒店时，您将获得一张钥匙卡，您可以使用该卡进入指定的房间。您可以将钥匙卡视为访问令牌。钥匙卡上没有说明您的身份，也没有说明您在前台的身份验证，但您可以在入住期间使用该卡进入酒店房间。同样，OAuth 2.0访问令牌不会指示用户是谁，它只是您可以用来访问数据的东西，它可能会在将来某个时候到期。</p>
<p>OAuth 2.0有意设计为在不提供用户身份和身份验证的情况下提供授权，因为这些问题具有非常不同的安全注意事项，这些注意事项不一定与授权协议的安全注意事项重叠。分别处理身份验证和身份允许是OAuth 2.0框架用作构建身份验证协议的一部分。</p>
<h3 id="构建身份验证框架"><a href="#构建身份验证框架" class="headerlink" title="构建身份验证框架"></a>构建身份验证框架</h3><p>OAuth 2.0框架是作为构建身份验证和身份协议的基础。</p>
<p>要使用OAuth 2.0作为身份验证协议的基础，您至少需要做一些事情。</p>
<ul>
<li>定义endpoint以返回有关用户的属性</li>
<li>定义第三方应用程序可用于进行请求用户身份信息的一个或多个范围</li>
<li>在处理身份验证时，需要定义其错误代码和必要的扩展参数，例如当会话超时重新提示用户输入凭据，或者如何允许用户选择新帐户登录应用程序。</li>
</ul>
<p>通常，当单个提供商尝试向OAuth 2.0添加内容以创建身份验证和身份协议时，这会导致另一个API具有不同程度的安全性。OpenID Connect从许多不同的实现中获取共享，并将其标准化为适合企业级实现的协议。</p>
<h3 id="ID令牌"><a href="#ID令牌" class="headerlink" title="ID令牌"></a>ID令牌</h3><p>OpenID Connect的核心基于一个名为“ID令牌”的概念。这是授权服务器将返回的新令牌类型，它对用户的身份验证信息进行编码。与仅旨在由资源服务器理解的访问令牌相反，ID令牌旨在被第三方应用程序理解。当客户端发出OpenID Connect请求时，它可以请求ID令牌以及访问令牌。</p>
<p>OpenID Connect的ID令牌采用JWT（JSON Web令牌）的形式，JWT是一个JSON有效负载，使用发行者的私钥进行签名，并且可以由应用程序进行解析和验证。</p>
<p>JWT内部是一些定义的属性名称，它们为应用程序提供信息。它们用简写名称表示，以保持JWT的整体大小。这包括用户的唯一标识符（sub即“subject”的缩写），发出令牌的服务器的标识符（iss即“issuer”的缩写），请求此令牌的客户端的标识符（aud即“audience”的缩写），以及少数属性，例如令牌的生命周期，以及用户在多长时间之前获得主要身份验证提示。</p>
<pre><code class="json">{
  &quot;iss&quot;: &quot;https://server.example.com&quot;,
  &quot;sub&quot;: &quot;24400320&quot;,
  &quot;aud&quot;: &quot;s6BhdRkqt3&quot;,
  &quot;nonce&quot;: &quot;n-0S6_WzA2Mj&quot;,
  &quot;exp&quot;: 1311281970,
  &quot;iat&quot;: 1311280970,
  &quot;auth_time&quot;: 1311280969,
  &quot;acr&quot;: &quot;urn:mace:incommon:iap:silver&quot;
}
</code></pre>
<p>标准化endpoint，名称和元数据有助于减少实现错误，并允许传递共享关于安全性考虑的知识。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>OpenID Connect在OAuth 2.0框架之上提供用户身份和身份验证。您可以使用OpenID Connect建立登录会话，并使用OAuth访问受保护资源。</p>
<p>您可以是有与OAuth 2.0相同的流程，以便同时请求ID令牌和访问令牌两种认证，以及获得授权访问受保护的资源。</p>
<p>OpenID Connect由OpenID Foundation维护。可以在<code>https://openid.net/connect/</code>上完整阅读核心OpenID Connect规范以及许多扩展。</p>
<p><a href="https://oidcdebugger.com/" target="_blank" rel="noopener">OpenID Connect Debugger</a>是一个奇妙的资源，帮助您构建OpenID Connect请求。此外，<a href="https://www.oauth.com/playground/" target="_blank" rel="noopener">OAuth 2.0 Playground</a>还提供了针对实时服务器的OpenID Connect流程演练。</p>
<p>在使用Google登录时，我们将使用OpenID Connect构建一个示例应用。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--OAuth 1和2之间的差异]]></title>
      <url>/2018/07/13/oauth-guide-21/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>OAuth 2.0从头开始就完全重写了OAuth 1.0，仅共享总体目标和一般用户体验。OAuth 2.0不向后兼容OAuth 1.0或1.1，应该被视为一个全新的协议。</p>
<p>OAuth 1.0主要基于两个现有的专有协议：Flickr的授权API和Google的AuthSub。OAuth 1.0的工作是基于当时实际实施经验的最佳解决方案。在许多公司构建OAuth 1 API的过程中，以及许多编写代码来使用API​​的开发人员和社区了解到协议在哪些方面对人们产生了挑战。几个特定领域被确定为需要改进，因为它们要么限制API的能力，要么实施起来太具挑战性。</p>
<p>OAuth 2.0代表了多家公司和个人之间多年的讨论，包括Yahoo！，Facebook，Salesforce，Microsoft，Twitter，Deutsche Telekom，Intuit，Mozilla和Google。</p>
<p>本节介绍OAuth 1.0和2.0之间的主要差异，以及它们背后的动机。如果您熟悉OAuth 1.0，这是快速了解OAuth 2.0中主要更改的良好起点。</p>
<h3 id="术语和角色"><a href="#术语和角色" class="headerlink" title="术语和角色"></a>术语和角色</h3><p>OAuth 2.0定义了四个角色（客户端，授权服务器，资源服务器和资源所有者），OAuth 1对这些角色使用不同的术语集。OAuth 2.0的“客户端”被称为“消费者”，“资源所有者”被简称为“用户”，“资源服务器”被称为“服务提供者”。OAuth 1也未明确区分资源服务器和授权服务器的角色。</p>
<p>“two-legged”和“three-legged”这两个术语已被授权类型的概念所取代，例如客户凭证授权类型和授权码授权类型。</p>
<h3 id="身份验证和签名"><a href="#身份验证和签名" class="headerlink" title="身份验证和签名"></a>身份验证和签名</h3><p>由于协议的加密要求，大多数OAuth 1.0实施尝试都失败了。对于任何来自简单用户名/密码身份验证的人来说，OAuth 1.0签名的复杂性是一个主要的痛点。</p>
<p>过去，开发人员只需使用用户名和密码即可快速编写Twitter脚本以执行有用的操作。随着迁移到OAuth 1.0，这些开发人员被迫查找，安装和配置库，以便向Twitter API发出请求，因为它需要对每个请求进行加密签名。</p>
<p>随着OAuth 2.0承载令牌的引入，再次可以通过cURL命令快速进行API调用。使用访问令牌而不是使用用户名和密码。</p>
<p>例如，在OAuth之前，您可能已经看过API文档中的示例，例如：</p>
<pre><code class="bash">curl --user bob:pa55 https://api.example.com/profile
</code></pre>
<p>使用OAuth 1 API，不再可能对此类示例进行硬编码，因为请求必须使用应用程序的密钥进行签名。Twitter等一些服务开始在其开发者网站中提供“签名生成器”工具，这样您就可以在不使用库的情况下从网站生成curl命令。例如，Twitter上的工具生成一个curl命令，例如：</p>
<pre><code class="bash">curl --get &#39;https://api.twitter.com/1.1/statuses/show.json&#39; \
--data &#39;id=210462857140252672&#39; \
--header &#39;Authorization: OAuth oauth_consumer_key=&quot;xRhHSKcKLl9VF7fbyP2eEw&quot;, oauth_nonce=&quot;33ec5af28add281c63db55d1839d90f1&quot;, oauth_signature=&quot;oBO19fJO8imCAMvRxmQJsA6idXk%3D&quot;, oauth_signature_method=&quot;HMAC-SHA1&quot;, oauth_timestamp=&quot;1471026075&quot;, oauth_token=&quot;12341234-ZgJYZOh5Z3ldYXH2sm5voEs0pPXOPv8vC0mFjMFtG&quot;, oauth_version=&quot;1.0&quot;&#39;
</code></pre>
<p>使用OAuth 2.0承载令牌，请求中只需要令牌本身，因此示例再次变得非常简单：</p>
<pre><code class="bash">curl https://api.example.com/profile -H &quot;Authorization: Bearer XXXXXXXXXXX&quot;
</code></pre>
<p>这在API的易用性和良好的安全实践之间提供了良好的平衡。</p>
<h3 id="用户体验和备用令牌颁发选项"><a href="#用户体验和备用令牌颁发选项" class="headerlink" title="用户体验和备用令牌颁发选项"></a>用户体验和备用令牌颁发选项</h3><p>OAuth 2.0有两个主要部分：用户获取授权（最终结果是应用程序具有该用户的访问令牌），并使用访问令牌代表用户发出请求。获取访问令牌的方法称为流程。</p>
<p>OAuth 1.0最初有3个流程，适用于基于Web的应用程序，桌面客户端以及移动或“有限”设备。但是，随着规范的发展，这三个流程合并为一个理论上支持所有三种客户端类型的流程。在实践中，流程适用于基于Web的应用程序，但在其他地方提供了较差的体验。</p>
<p>随着越来越多的网站开始使用OAuth，尤其是Twitter，开发人员意识到OAuth提供的单一流程非常有限，并且通常会产生糟糕的用户体验。另一方面，Facebook Connect提供了更丰富的流程，适用于Web应用程序，移动设备和游戏控制台。</p>
<p>OAuth 2.0通过再次定义多个流程来解决这个问题，称为“授权类型”，可以灵活地支持各种应用程序类型。还有一种机制来开发扩展来处理以前没想过的用例。</p>
<p>服务器端应用程序使用“授权码”授权类型和客户端秘钥，提示用户授权应用程序，并生成一个授权码，该代码将传回应用程序。然后，应用程序的服务器用授权码交换访问令牌。服务器端应用程序使用其秘钥来和授权码交换访问令牌，可以获得此流程的安全性。</p>
<p>单页或移动应用程序使用相同的授权类型，但不使用客户机秘钥。相反，安全性在于验证重定向URL以及可选的PKCE扩展。</p>
<p>OAuth 2.0正式定义了“密码”授权类型，允许应用程序收集用户的用户名和密码，并将其交换为访问令牌。虽然这是规范的一部分，但它仅供受信任的客户端使用，例如服务自己的第一方应用程序。它不应该被第三方应用程序使用，因为这将允许第三方应用程序访问用户的用户名和密码。</p>
<p>当应用程序访问其自己的资源时，将使用“客户端凭据”授予。此授权类型只是交换<code>client_id</code>和<code>client_secret</code>来获取访问令牌。</p>
<p>OAuth 2.0还支持扩展授予类型，允许组织定义自己的自定义授权类型以支持其他客户端类型或在OAuth与现有系统之间提供桥接。</p>
<p>其中一个扩展是用于在没有Web浏览器的设备上授权应用程序的设备流程。</p>
<h3 id="规模表现"><a href="#规模表现" class="headerlink" title="规模表现"></a>规模表现</h3><p>随着较大的提供商开始使用OAuth 1.0，社区意识到该协议有一些限制，使得难以扩展到大型系统。OAuth 1.0需要跨不同步骤进行状态管理，并且通常跨不同服务器进行。它需要生成临时凭证，这些凭证通常被丢弃未使用，并且通常需要发布安全性较低且难以管理的持久凭证。</p>
<p>此外，OAuth 1.0要求受保护资源endpoint可以访问客户端凭据以验证请求。这打破了大多数大型提供商的典型架构，其中集中授权服务器用于颁发凭证，并且单独的服务器用于处理API调用。由于OAuth 1.0需要使用客户端凭据来验证签名，因此这种分离非常困难。</p>
<p>OAuth 2.0仅在应用程序从用户获取授权时使用客户端凭据来解决此问题。在授权步骤中使用凭据后，在进行API调用时仅使用生成的访问令牌。这意味着API服务器不需要知道客户端凭据，因为它们可以自己验证访问令牌。</p>
<h3 id="承载令牌（Bearer-Tokens）"><a href="#承载令牌（Bearer-Tokens）" class="headerlink" title="承载令牌（Bearer Tokens）"></a>承载令牌（Bearer Tokens）</h3><p>在OAuth 1中，访问令牌有两个组件，即公共字符串和私有字符串。签名请求时使用私有字符串，并且从不通过网络发送。</p>
<p>访问OAuth 2.0 API的最常用方法是使用“承载令牌”。这是一个单个字符串，用作API请求的身份验证，在HTTP“授权”header中发送。该字符串对于使用它的客户来说毫无意义，并且可能具有不同的长度。</p>
<p>承载令牌是一种更简单的API请求方式，因为它们不需要对每个请求进行加密签名。权衡是所有API请求必须通过HTTPS连接进行，因为请求包含一个明文标记，如果被截获，任何人都可以使用该标记。优点是它不需要复杂的库来发出请求，并且客户端和服务器实现起来要简单得多。</p>
<p>承载令牌的缺点是没有任何东西阻止其他应用程序使用Bearer令牌，如果这个应用程序可以访问它。这是对OAuth 2.0的常见批评，尽管大多数提供商仍然只使用Bearer令牌。在正常情况下，当应用程序正确保护其控制下的访问令牌时，这不是问题，尽管从技术上讲它不太安全。如果您的服务需要更安全的方法，则可以使用可满足安全要求的其他访问令牌类型。</p>
<h3 id="具有长期授权的短期令牌"><a href="#具有长期授权的短期令牌" class="headerlink" title="具有长期授权的短期令牌"></a>具有长期授权的短期令牌</h3><p>OAuth 1.0 API通常会发布极其持久的访问令牌。这些令牌可以无限期地持续，或者大约一年。虽然对开发人员来说很方便，但在某些情况下，这证明限制了一些服务。</p>
<p>负责任的API提供商应允许用户查看他们已授权使用其帐户的第三方应用，并且应该能够根据需要撤消应用。如果用户撤消了应用，则API应该停止尽快结束发布到该应用的访问令牌。根据API的实现方式，这可能具有挑战性，或者需要系统内部部件之间的其他联系。</p>
<p>使用OAuth 2.0，授权服务器可以发出短期访问令牌和长期刷新令牌。这允许应用程序在不涉及用户的情况下获得新的访问令牌，但也增加了服务器更容易撤销令牌的能力。此功能是从Yahoo！的BBAuth协议和后来的OAuth 1.0会话扩展中采用的。</p>
<h3 id="角色分离"><a href="#角色分离" class="headerlink" title="角色分离"></a>角色分离</h3><p>OAuth 2.0的设计决策之一是明确地将授权服务器的角色与API服务器分开。这意味着您可以将授权服务器构建为独立组件，该组件仅负责从用户获取授权并向客户端发送令牌。这两个角色可以位于物理上独立的服务器上，甚至可以位于不同的域名上，从而允许系统的每个部分独立扩展。某些提供程序有许多资源服务器，每个服务器位于不同的子域中。</p>
<p>授权服务器需要了解应用程序的<code>client_id</code>和<code>client_secret</code>，但API服务器将只需要接受访问令牌。通过将授权服务器构建为独立组件，您可以避免与API服务器共享数据库，从而可以更轻松地独立于授权服务器扩展API服务器，因为它们不需要共享公共数据存储。</p>
<p>例如，Google的OAuth 2.0实施使用“accounts.google.com”上的服务器进行授权请求，但在向Google+ API发出请求时使用“www.gooogleapis.com”。</p>
<p>服务提供商的好处是这些系统的开发可以完全独立地由不同的团队和不同的时间线发生。由于它们是完全独立的，因此可以独立扩展，升级或更换，而无需考虑系统的其他部分。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--术语参考]]></title>
      <url>/2018/07/13/oauth-guide-20/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p>OAuth定义了四个角色：</p>
<ul>
<li>资源所有者（用户）</li>
<li>资源服务器（API）</li>
<li>授权服务器（可以是与API相同的服务器）</li>
<li>客户端（第三方应用）</li>
</ul>
<h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><p>OAuth 2.0规范将用户称为“资源所有者”。资源所有者是能够允许访问其部分帐户的人员。在这种情况下，资源可以是数据（照片，文档，联系人），服务（发布博客条目，转移资金）或任何其他需要访问限制的资源。任何想要代表用户行事的系统必须首先获得他们的许可。</p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>规范指的是您通常认为的主要API作为“资源服务器”。资源服务器是包含用户信息的服务器，用于第三方应用程序的访问。资源服务器必须能够接受并验证访问令牌，并在用户允许的情况下授予请求。资源服务器不一定需要了解第三方的应用程序。</p>
<h3 id="授权服务器"><a href="#授权服务器" class="headerlink" title="授权服务器"></a>授权服务器</h3><p>授权服务器是用户在请求访问其帐户时与之交互的内容。这是显示OAuth提示的服务器，以及用户批准或拒绝访问请求的位置。授权服务器还负责在用户授权应用程序后授予访问令牌。因此，授权服务器通常具有两个主URL，一个用于授权请求，一个用于用于授予访问令牌的应用程序。这些通常是这样的：</p>
<ul>
<li><code>https://authorization-server.com/authorize</code></li>
<li><code>https://authorization-server.com/token</code></li>
</ul>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>客户端是试图代表用户行动或访问用户资源的应用程序。在客户端可以访问用户的帐户之前，它需要获得许可。客户端通过将用户引导至授权服务器或通过直接与授权服务器断言权限，来实现无需用户交互来获得许可。</p>
<h3 id="私密客户端（Confidential-Clients）"><a href="#私密客户端（Confidential-Clients）" class="headerlink" title="私密客户端（Confidential Clients）"></a>私密客户端（Confidential Clients）</h3><p>私密客户端是能够保持client_secret（客户端密钥）机密性的客户端。通常，这些客户端只是在开发人员控制下的服务器上运行的应用程序，用户无法访问源代码。这些类型的应用程序通常称为“Web应用程序”，因为它们通常由Web浏览器访问。</p>
<h3 id="公共客户端（Public-Clients）"><a href="#公共客户端（Public-Clients）" class="headerlink" title="公共客户端（Public Clients）"></a>公共客户端（Public Clients）</h3><p>公共客户端无法保持client_secret（客户端密钥）的机密性，因此密钥不会用于这些应用程序。移动应用和Javascript应用都被视为公共客户端。由于运行Javascript应用程序的任何人都可以轻松查看应用程序的源代码，因此可以轻松地看到密钥。对于移动应用程序，可以反编译二进制文件以提取字符串。</p>
<h3 id="访问令牌（Access-Token）"><a href="#访问令牌（Access-Token）" class="headerlink" title="访问令牌（Access Token）"></a>访问令牌（Access Token）</h3><p>访问令牌是向API发出经过身份验证的请求时使用的字符串。令牌表示用户已授权第三方应用程序访问该用户的帐户。令牌具有相应的访问持续时间，范围和可能的其他信息。令牌可以是自解析的（服务器可以从令牌字符串中检索所有必要的信息），也可以是数据库中的密钥。</p>
<h3 id="刷新令牌（Refresh-Token）"><a href="#刷新令牌（Refresh-Token）" class="headerlink" title="刷新令牌（Refresh Token）"></a>刷新令牌（Refresh Token）</h3><p>刷新令牌是一个字符串，用于在访问令牌过期时获取新的访问令牌。并非所有API都使用刷新令牌。</p>
<h3 id="授权码（Authorization-Code）"><a href="#授权码（Authorization-Code）" class="headerlink" title="授权码（Authorization Code）"></a>授权码（Authorization Code）</h3><p>授权码是在服务器端应用程序流程中使用的中间令牌，更详细地描述服务器端应用程序。授权步骤后，授权码返回给客户端，然后客户端将其交换为访问令牌。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--创建文档]]></title>
      <url>/2018/07/13/oauth-guide-19/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>正如您在阅读完这篇文章后可能已经注意到的那样，OAuth 2.0规范中有很多地方需要做出决策。其中许多事情都没有明确规定，以便允许根据自己的安全要求做出不同的实现。最终结果是大多数OAuth 2.0实现都不可互操作，尽管在实践中，许多实现仍然做出了相同的决策，并且非常相似。</p>
<p>由于实现可以有许多不同的方式，因此为您的服务构建良好的文档至关重要。</p>
<p>本节介绍了您需要记录的内容，以便开发人员能够使用您的API。其中一些项目可以在适当的界面中内联记录（例如开发人员用于客户端注册的界面），有些更适合在API文档的“概述”部分中进行记录。</p>
<h3 id="客户注册"><a href="#客户注册" class="headerlink" title="客户注册"></a>客户注册</h3><p>开发人员如何注册新的客户端应用程序以获取客户端ID和可选的秘钥？</p>
<ul>
<li>提供注册页面的链接。</li>
<li>您的服务可能会实施<a href="https://tools.ietf.org/html/rfc7591" target="_blank" rel="noopener">动态客户端注册规范</a>，或者拥有用于注册应用程序的专有API</li>
<li>您是否为开发人员注册应用程序提供了其他机制？如果是这样，您将需要描述注册应用程序的其他方法。</li>
</ul>
<p>您的服务应至少询问开发人员他们的应用程序是私密客户端还是公共客户端，并提供注册重定向URI的方法。除此之外，您还应记录您收集的有关应用程序的其他信息，并指出在授权请求期间向最终用户显示哪些信息。</p>
<ul>
<li>应用名称</li>
<li>有关应用程序的网页</li>
<li>描述</li>
<li>logo或其他图像</li>
<li>有关应用程序使用条款的网页</li>
<li>其他信息</li>
</ul>
<h3 id="endpoint"><a href="#endpoint" class="headerlink" title="endpoint"></a>endpoint</h3><p>开发人员将在OAuth流程中使用两个主要endpoint。您的授权endpoint是指导用户开始授权流程的位置。在应用程序获得授权码后，它将在令牌endpoint处交换该代码以获取访问令牌。令牌endpoint还负责为其他授权类型发出访问令牌。</p>
<p>您需要让开发人员知道他们将使用的这两个endpoint的URL。</p>
<h3 id="客户端认证"><a href="#客户端认证" class="headerlink" title="客户端认证"></a>客户端认证</h3><p>如果请求中需要客户端身份验证（例如授权码授权），则服务可以通过两种方式接受请求中的客户端ID和秘钥。您的服务可以使用客户端ID作为用户名和秘钥作为密码接受HTTP Basic Auth header中的身份验证，或者接受post body中的字符串作为<code>client_id</code>和<code>client_secret</code>。无论您是要接受这些方法中的一种还是两种，都取决于您的服务，因此您需要告诉开发人员您希望他们如何在请求中包含此身份验证。</p>
<p>此外，您的服务可能支持其他形式的客户端身份验证，例如公钥/私钥对。这在当前部署的OAuth 2.0实现中相对不常见，但是规范保留了开放的可能性。</p>
<p>对发布给应用程序的客户端ID和秘钥的最大或最小长度没有要求，因此通常最好让开发人员知道这些字符串有多大，以便他们可以适当地存储它们。</p>
<h3 id="字符串的大小"><a href="#字符串的大小" class="headerlink" title="字符串的大小"></a>字符串的大小</h3><p>由于开发人员在开始编写代码之前不会看到授权码或访问令牌，因此您应该记录他们将遇到的字符串的最大大小。</p>
<ul>
<li>客户端ID</li>
<li>客户端秘钥</li>
<li>授权码</li>
<li>访问令牌</li>
</ul>
<h3 id="响应类型"><a href="#响应类型" class="headerlink" title="响应类型"></a>响应类型</h3><p>您的服务支持哪些响应类型？通常，服务仅支持基于Web和本机应用程序的“code”响应类型。但是，如果您的服务还支持“token”响应类型（在没有中间授权码的情况下发出令牌），那么在文档中指出是很重要的。您应该记录您的服务是否支持其中一个或两个，以及您是否还有其他支持的响应类型。</p>
<h3 id="重定向URL限制"><a href="#重定向URL限制" class="headerlink" title="重定向URL限制"></a>重定向URL限制</h3><p>您的服务可能会对开发人员可以使用的已注册重定向URL进行限制。例如，服务通常会禁止开发人员使用非TLS httpendpoint，或限制非生产应用程序使用的endpoint。虽然支持自定义方案对于支持原生应用程序很重要，但某些服务也不允许这些。您应该记录您在注册重定向URL时的任何要求。</p>
<h3 id="默认范围"><a href="#默认范围" class="headerlink" title="默认范围"></a>默认范围</h3><p>如果开发人员在授权请求期间未指定范围，则服务可以假定该请求的默认范围。如果是这种情况，您应该记录默认范围。</p>
<p>授权服务器可以忽略开发人员请求的范围，或者添加超出请求范围的其他范围。服务器还可以允许用户根据请求改变范围。这些中的任何一种都是可能的，因此服务应该明确为开发人员指明，以便他们可以考虑访问令牌可能具有不同于他们请求的范围。</p>
<p>该服务还应记录授权码的生命周期，因此开发人员可以了解代码在发布和使用之间的持续时间。授权服务器还可以防止代码被多次使用，并且如果是这样则应该记录该代码。</p>
<h3 id="访问令牌响应"><a href="#访问令牌响应" class="headerlink" title="访问令牌响应"></a>访问令牌响应</h3><p>当您发出访问令牌时，访问令牌响应会列出许多可选的参数。您应该记录您的服务支持哪些，以便开发人员知道会发生什么。</p>
<p>响应何时包含<code>expires_in</code>参数？如果令牌会过期，您的服务可能始终包含它，如果没有此参数，您的服务应该可以记录开发人员应该期望的默认过期时间。</p>
<p>响应是否始终包含授予的访问令牌的范围？在响应中返回它通常是一个好主意，但是如果授权范围与请求的范围匹配，许多服务会将其遗漏。无论哪种方式，您都应该记录服务器对此参数的行为方式。</p>
<h3 id="刷新令牌"><a href="#刷新令牌" class="headerlink" title="刷新令牌"></a>刷新令牌</h3><p>OAuth 2.0 API开发人员面临的一个更令人困惑或令人沮丧的方面是刷新令牌。重要的是要非常清楚地了解您的服务如何处理刷新令牌（如果有的话）。</p>
<p>如果您的访问令牌过期，您可能希望支持刷新令牌，以便开发人员可以构建继续访问用户帐户的应用程序，而无需用户不断重新授权该应用程序。</p>
<p>您应该清楚地记录哪些受支持的授权类型在响应中应该包含刷新令牌。</p>
<p>当您的服务发出新的访问令牌以响应刷新令牌授权时，您的服务可以同时发出新的刷新令牌，并使之前的刷新令牌到期。这意味着刷新令牌经常刷新，这可能是您的应用程序所需要的。如果是这种情况，请确保开发人员知道这将发生，因此他们不会错误地假设他们获得的第一个刷新令牌将继续无限期地工作。</p>
<h3 id="扩展授权"><a href="#扩展授权" class="headerlink" title="扩展授权"></a>扩展授权</h3><p>除了四种基本授权类型（授权码，密码，客户端凭据和隐式）之外，您的服务还可以支持其他授权类型。</p>
<p>某些授权类型标准化为OAuth 2.0的扩展，例如设备流和SAML。某些服务还实现了自己的自定义授权类型，例如将旧版API迁移到OAuth 2.0时。记录您的服务支持的其他授权类型非常重要，并提供有关如何使用它们的文档。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--令牌自解析endpoint（Token Introspection Endpoint）]]></title>
      <url>/2018/07/13/oauth-guide-18/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>当OAuth 2.0客户端向资源服务器发出请求时，资源服务器需要某种方式来验证访问令牌。OAuth 2.0核心规范没有定义资源服务器应如何验证访问令牌，只是提到它需要在资源和授权服务器之间协调。在某些情况下，特别是对于小型服务，两个endpoint都是同一系统的一部分，并且可以在内部共享令牌信息，例如在数据库中。在两个endpoint位于不同服务器上的较大系统中，这导致了两个服务器之间通信的专有和非标准协议。</p>
<p>OAuth 2.0 令牌自解析扩展定义了一个协议，该协议返回有关访问令牌的信息，供资源服务器或其他内部服务器使用。</p>
<h3 id="令牌自解析规范"><a href="#令牌自解析规范" class="headerlink" title="令牌自解析规范"></a>令牌自解析规范</h3><p>令牌自解析规范可以在<code>https://tools.ietf.org/html/rfc7662</code>找到</p>
<h3 id="自解析endpoint"><a href="#自解析endpoint" class="headerlink" title="自解析endpoint"></a>自解析endpoint</h3><p>令牌自解析endpoint需要能够返回有关令牌的信息，因此您很可能将其构建在令牌endpoint所在的相同位置。两个endpoint需要共享数据库，或者如果您已实现自编码令牌，则需要共享密钥。</p>
<h3 id="令牌信息请求"><a href="#令牌信息请求" class="headerlink" title="令牌信息请求"></a>令牌信息请求</h3><p>该请求将是一个POST请求，仅包含名为“token”的参数。预计此endpoint不会公开给开发人员。不应允许最终用户客户端使用此endpoint，因为响应可能包含开发人员无权访问的特权信息。保护endpoint的一种方法是将其放在无法从外部访问的内部服务器上，或者可以使用HTTP basic auth证进行保护。</p>
<pre><code class="http">POST /token_info HTTP/1.1
Host: authorization-server.com
Authorization: Basic Y4NmE4MzFhZGFkNzU2YWRhN

token=c1MGYwNDJiYmYxNDFkZjVkOGI0MSAgLQ
</code></pre>
<h3 id="令牌信息响应"><a href="#令牌信息响应" class="headerlink" title="令牌信息响应"></a>令牌信息响应</h3><p>令牌自解析Endpoint应该使用具有下面列出的属性的JSON对象进行响应。必须的只有“active”属性，其余属性是可选的。自解析规范中的一些属性专门用于JWT令牌，因此我们将仅在此处介绍基本的属性。如果您有关于可能有用的令牌的其他信息，您还可以在响应中添加其他属性。</p>
<blockquote>
<p><strong>active</strong><br>必须。这是所呈现的令牌当前是否处于活动状态的布尔值。如果此授权服务器已发出令牌，用户尚未撤消该令牌且未过期，则该值应为“true”。</p>
<p><strong>scope</strong><br>一个JSON字符串，以空格分隔,包含与此标记关联的范围列表。</p>
<p><strong>client_id</strong><br>颁发令牌的OAuth 2.0客户端的客户端标识符。</p>
<p><strong>username</strong><br>授权此令牌的用户的可读标识符。</p>
<p><strong>exp</strong><br>unix时间戳（整数时间戳，UTC自1970年1月1日以来的秒数），指示此令牌何时到期。</p>
</blockquote>
<h3 id="示例响应"><a href="#示例响应" class="headerlink" title="示例响应"></a>示例响应</h3><p>下面是自解析endpoint返回的响应示例。</p>
<pre><code class="http">HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

{
  &quot;active&quot;: true,
  &quot;scope&quot;: &quot;read write email&quot;,
  &quot;client_id&quot;: &quot;J8NFmU4tJVgDxKaJFmXTWvaHO&quot;,
  &quot;username&quot;: &quot;aaronpk&quot;,
  &quot;exp&quot;: 1437275311
}
</code></pre>
<h3 id="错误响应"><a href="#错误响应" class="headerlink" title="错误响应"></a>错误响应</h3><p>如果自解析endpoint可公开访问，则endpoint必须首先验证身份验证。如果身份验证无效，则endpoint应使用<code>HTTP 401</code>状态代码和<code>invalid_client</code>响应进行响应。</p>
<pre><code class="http">HTTP/1.1 401 Unauthorized
Content-Type: application/json; charset=utf-8

{
  &quot;error&quot;: &quot;invalid_client&quot;,
  &quot;error_description&quot;: &quot;The client authentication was invalid&quot;
}
</code></pre>
<p>任何其他错误都被视为“inactive”令牌。</p>
<ul>
<li>请求的令牌不存在或无效</li>
<li>令牌已过期</li>
<li>令牌发送给不同的客户端而不是发出此请求</li>
</ul>
<p>在任何这些情况下，它都不被视为错误响应，并且endpoint仅返回非活动标志。</p>
<pre><code class="http">HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8

{
  &quot;active&quot;: false
}
</code></pre>
<h3 id="安全考虑因素"><a href="#安全考虑因素" class="headerlink" title="安全考虑因素"></a>安全考虑因素</h3><p>使用令牌自解析endpoint意味着,任何资源服务器都将依赖endpoint来确定访问令牌当前是否处于活动状态。这意味着自解析endpoint独自负责决定API请求是否成功。因此，endpoint必须针对令牌的状态执行所有适用的检查，例如检查令牌是否已过期，验证签名等。</p>
<h4 id="令牌钓鱼攻击"><a href="#令牌钓鱼攻击" class="headerlink" title="令牌钓鱼攻击"></a>令牌钓鱼攻击</h4><p>如果自解析endpoint保持打开且不受限制，则它为攻击者提供了一种方法，用于轮询endpoint捕获有效令牌。为防止这种情况发生，服务器必须要求使用endpoint对客户端进行身份验证，或者仅通过其他方式（如防火墙）使endpoint只用于内部服务器。</p>
<p>请注意，资源服务器也是钓鱼攻击的潜在目标，并且应该采取诸如速率限制之类的对策来防止这种情况。</p>
<h4 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h4><p>自解析endpoint的使用者可能希望出于性能原因缓存endpoint的响应。因此，在决定缓存时考虑性能和安全性权衡非常重要。例如，较短的缓存到期时间将导致更高的安全性，因为资源服务器将不得不更频繁地查询自解析endpoint，但是这将导致endpoint上的负载增加。较长的到期时间会使一个窗口打开，其中令牌可能实际上已过期或被撤销，但由于缓存时间有剩余，仍然能够在资源服务器上被查到。</p>
<p>缓解问题的一种方法是，使用者永远不会缓存至超出令牌的到期时间，这将在自解析响应的“exp”参数中返回。</p>
<h4 id="限制信息"><a href="#限制信息" class="headerlink" title="限制信息"></a>限制信息</h4><p>自解析endpoint不一定需要为同一令牌的所有查询返回相同的信息。例如，两个不同的资源服务器（如果它们在进行自解析请求时进行身份验证）可能会获得令牌状态的不同视图。这可用于限制有关返回到特定资源服务器的令牌的信息。这使得多个资源服务器在互不知情上可以使用相同的令牌。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--使用PKCE保护移动应用程序]]></title>
      <url>/2018/07/13/oauth-guide-17/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>用于代码交换的证明密钥（PKCE，发音为pixie）扩展描述了一种,公共客户端用于减轻拦截授权代码的威胁的技术。该技术涉及客户端首先创建秘钥，然后在交换访问令牌的授权码时再次使用该秘钥。这样，如果代码被截获，它将不能被使用，因为令牌请求依赖于初始秘钥。</p>
<p>完整规范以<a href="https://tools.ietf.org/html/rfc7636" target="_blank" rel="noopener">RFC7636</a>的形式提供。我们将在下面介绍协议的摘要。</p>
<h3 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h3><p>当原生应用程序开始授权请求时，客户端首先创建所谓的“代码验证程序” ，而不是立即启动浏览器。这是使用随机字符串A-Z，a-z，0-9和标点字符-._~（连字符，期间，下划线和波浪线）来进行加密，长字符43和128之间。</p>
<p>一旦应用程序生成了代码验证程序，它就会使用它来创建代码验证。对于可以执行SHA256哈希的设备，代码验证是代码验证程序的SHA256哈希的BASE64-URL编码字符串。允许无法执行SHA256哈希的客户端使用普通代码验证程序字符串作为验证。</p>
<p>现在客户端有一个代码验证字符串，它包含了一个参数，该参数指示用于生成验证的方法（plain或S256）以及授权请求的标准参数。这意味着完整的授权请求将包括以下参数。</p>
<blockquote>
<p><strong>response_type = code</strong> - 表示您的服务器希望收到授权代码<br><strong>client_id =</strong> - 首次创建应用程序时收到的客户端ID<br><strong>redirect_uri =</strong> - 表示授权完成后返回用户的URL，例如org.example.app://redirect<br><strong>state = 1234zyx</strong> - 应用程序生成的随机字符串，稍后您将验证该字符串<br><strong>code_challenge = XXXXXXXXX</strong> - 如前所述生成的代码验证<br><strong>code_challenge_method = S256</strong> - plain或者S256，取决于验证是普通验证者字符串还是字符串的SHA256哈希。如果省略此参数，则服务器将采用plain。</p>
</blockquote>
<p>授权服务器应识别code_challenge请求中的参数，并将其与其生成的授权码相关联。将其与授权码一起存储在数据库中，或者如果您使用自编码授权码，则可以将其包含在代码本身中。服务器正常返回授权码，并且不包括返回数据中的验证。</p>
<h4 id="错误响应"><a href="#错误响应" class="headerlink" title="错误响应"></a>错误响应</h4><p>授权服务器可以要求公共客户端必须使用PKCE扩展。这实际上是允许公共客户端在不使用客户端密钥的情况下拥有安全授权流的唯一方法。由于对应于公共客户端，授权服务器应该知道特定客户端ID，因此它可以拒绝对不包含代码验证的公共客户端的授权请求。</p>
<p>如果授权服务器要求公共客户端使用PKCE，并且授权请求缺少代码验证，则服务器应返回错误响应，<code>error=invalid_request</code>并且应该使用<code>error_description</code>或者<code>error_uri</code>解释错误的性质。</p>
<h3 id="授权码交换"><a href="#授权码交换" class="headerlink" title="授权码交换"></a>授权码交换</h3><p>本机应用程序将用授权码交换访问令牌。除了授权码请求中定义的参数之外，客户端还将发送<code>code_verifier</code>参数。完整的访问令牌请求将包括以下参数：</p>
<blockquote>
<p><strong>grant_type = authorization_code</strong> - 表示此令牌请求的授权类型<br><strong>code</strong> - 客户端将发送它在重定向中获得的授权代码<br><strong>redirect_uri</strong> - 初始授权请求中使用的重定向URL<br><strong>client_id</strong> - 应用程序注册的客户端ID<br><strong>code_verifier</strong> - 应用程序最初在授权请求之前生成的PKCE请求的代码验证程序。</p>
</blockquote>
<p>除了验证标准参数之外，授权服务器还将验证<code>code_verifier</code>请求中的内容。由于<code>code_challenge</code>和<code>code_challenge_method</code>用授权码相关联，因此服务器应该已经知道使用哪种方法（普通或SHA256）验证<code>code_verifier</code>。</p>
<p>如果方法是plain，那么授权服务器只需要检查提供的<code>code_verifier</code>是否与预期的<code>code_challenge</code>字符串匹配。</p>
<p>如果方法是S256，那么授权服务器应该使用提供的<code>code_verifier</code>, 并使用客户端最初使用的相同方法对其进行转换。这意味着计算其SHA256哈希值并对其进行base64-url编码，然后将其与存储的<code>code_challenge</code>字符串进行比较。</p>
<p>如果验证程序与期望值匹配，则服务器可以正常继续，发出访问令牌并进行适当响应。如果出现问题，则服务器会响应<code>invalid_grant</code>错误。</p>
<p>PKCE扩展不会添加任何新响应，因此即使授权服务器不支持，客户端也可以始终使用PKCE扩展。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--无浏览器和输入约束设备的OAuth]]></title>
      <url>/2018/07/13/oauth-guide-16/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>OAuth 2.0“设备流”扩展程序可在具有Internet连接但没有浏览器或简单方法输入文本的设备上启用OAuth。如果您曾在Apple TV等设备上登录过自己的YouTube帐户，那么您已经遇到过此工作流程。谷歌参与了这个扩展的开发，并且也是它在生产中的早期实现者。</p>
<p>此流程也可在智能电视，媒体控制台，相框，打印机或硬件视频编码器等设备上看到。在该流程中，设备指示用户在诸如智能电话或计算机的辅助设备上打开URL以完成授权。用户的两个设备之间不需要通信通道。</p>
<h3 id="用户流程"><a href="#用户流程" class="headerlink" title="用户流程"></a>用户流程</h3><p>当您开始登录设备（例如此硬件视频编码器）时，设备会与Google通话以获取设备代码，如下所示。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto9emscc3j30sg07nwf7.jpg" alt="设备发出API请求以获取设备代码"></p>
<p>接下来，我们看到设备会显示代码以及URL。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto9f6gvy7j30sg07nt9h.jpg" alt="设备显示设备代码和URL"></p>
<p>登录Google帐户后访问该网址会显示一个界面，提示您输入设备上显示的代码。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fto9frx7oxj30me0jdgm9.jpg" alt="Google会提示用户输入代码"></p>
<p>输入代码并单击“下一步”后，您将看到标准OAuth授权提示，该提示描述了应用程序请求的范围，如下所示。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fto9g4x5oxj30ok0dhaay.jpg" alt="Google会显示应用程序请求的范围"></p>
<p>一旦您允许该请求，Google就会显示一条消息，说明要返回您的设备，如下所示。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fto9gir6bij30lp0izmxt.jpg" alt="Google会指示用户返回设备"></p>
<p>几秒钟后，设备完成并且您已登录。</p>
<p>总的来说，这是一次非常轻松的体验。由于您可以使用任何想要打开URL的设备，因此可以使用您可能已登录的授权服务器的主计算机或电话。这也使您在设备上无需输入数据！</p>
<p>让我们逐步了解设备所需的功能。</p>
<h3 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h3><p>首先，客户端向授权服务器发出请求以请求设备代码的请求。</p>
<pre><code class="http">POST /token HTTP/1.1
Host: authorization-server.com
Content-type: application/x-www-form-urlencoded

client_id=a17c21ed
</code></pre>
<p>请注意，某些授权服务器将允许设备在此请求中指定范围，稍后将在授权界面上向用户显示该范围。</p>
<p>授权服务器使用JSON进行响应，该json包含设备代码，用户将输入的代码，用户应访问的URL以及轮询间隔。</p>
<pre><code class="json">HTTP/1.1 200 OK
Content-Type: application/json
Cache-Control: no-store
{
    &quot;device_code&quot;: &quot;NGU5OWFiNjQ5YmQwNGY3YTdmZTEyNzQ3YzQ1YSA&quot;,
    &quot;user_code&quot;: &quot;BDWP-HQPK&quot;,
    &quot;verification_uri&quot;: &quot;https://authorization-server.com/device&quot;,
    &quot;interval&quot;: 5,
    &quot;expires_in&quot;: 1800
}
</code></pre>
<p>设备在其显示屏上向用户显示<code>verification_uri</code>和<code>user_code</code>，指示用户输入该URL处的代码。</p>
<h3 id="令牌请求"><a href="#令牌请求" class="headerlink" title="令牌请求"></a>令牌请求</h3><p>当设备等待用户在他们自己的计算机或电话上完成授权流程时，设备同时开始轮询令牌端点以请求访问令牌。</p>
<p>设备以<code>device_code</code>指定的速率发出POST请求轮询。设备应继续请求访问令牌，直到<code>authorization_pending</code>返回，显示用户授予或拒绝请求或设备代码到期。</p>
<pre><code class="http">POST /token HTTP/1.1
Host: authorization-server.com
Content-type: application/x-www-form-urlencoded

grant_type=urn:ietf:params:oauth:grant-type:device_code&amp;amp;
client_id=a17c21ed&amp;amp;
device_code=NGU5OWFiNjQ5YmQwNGY3YTdmZTEyNzQ3YzQ1YSA
</code></pre>
<p>授权服务器将回复错误或访问令牌。设备流程规范定义了两个额外的错误代码，这超越了OAuth 2.0用户核心定义，即<code>authorization_pending</code>和<code>slow_down</code>。</p>
<p>如果设备过于频繁地轮询，授权服务器将返回<code>slow_down</code>错误。</p>
<pre><code class="http">HTTP/1.1 400 Bad Request
Content-Type: application/json
Cache-Control: no-store

{
  &quot;error&quot;: &quot;slow_down&quot;
}
</code></pre>
<p>如果用户尚未允许或拒绝该请求，则授权服务器将返回<code>authorization_pending</code>错误。</p>
<pre><code class="http">HTTP/1.1 400 Bad Request
Content-Type: application/json
Cache-Control: no-store

{
  &quot;error&quot;: &quot;authorization_pending&quot;
}
</code></pre>
<p>如果用户拒绝请求，授权服务器将返回<code>access_denied</code>错误。</p>
<pre><code class="http">HTTP/1.1 400 Bad Request
Content-Type: application/json
Cache-Control: no-store

{
  &quot;error&quot;: &quot;access_denied&quot;
}
</code></pre>
<p>如果设备代码已过期，授权服务器将返回<code>expired_token</code>错误。设备可以立即请求新的设备代码。</p>
<pre><code class="http">HTTP/1.1 400 Bad Request
Content-Type: application/json
Cache-Control: no-store

{
  &quot;error&quot;: &quot;expired_token&quot;
}
</code></pre>
<p>最后，如果用户允许请求，则授权服务器像正常一样发出访问令牌并返回标准访问令牌响应。</p>
<pre><code class="json">HTTP/1.1 200 OK
Content-Type: application/json
Cache-Control: no-store

{
  &quot;access_token&quot;: &quot;AYjcyMzY3ZDhiNmJkNTY&quot;,
  &quot;refresh_token&quot;: &quot;RjY2NjM5NzA2OWJjuE7c&quot;,
  &quot;token_type&quot;: &quot;bearer&quot;,
  &quot;expires&quot;: 3600
}
</code></pre>
<h3 id="授权服务器要求"><a href="#授权服务器要求" class="headerlink" title="授权服务器要求"></a>授权服务器要求</h3><p>支持设备流并不是授权服务器的大量额外工作。在向现有授权服务器添加对设备流的支持时，请记住以下几点。</p>
<h4 id="设备代码请求"><a href="#设备代码请求" class="headerlink" title="设备代码请求"></a>设备代码请求</h4><p>设备将向授权服务器发出请求以获取该流程所需的验证码集合。以下参数是请求的一部分。</p>
<blockquote>
<p><strong>client_id</strong> - 必需，客户端注册中描述的客户端标识符。<br><strong>scope</strong> - 可选，范围中描述的请求范围。</p>
</blockquote>
<p>验证客户端ID和范围后，授权服务器返回带有验证码的URL，设备代码和用户代码的响应。除了上面给出的示例之外，授权服务器还可以返回一些可选参数。</p>
<blockquote>
<p><strong>device_code</strong> - 必需，授权服务器生成的验证码。<br><strong>user_code</strong> - 必需的，用户将在设备屏幕上输入的代码应该相对较短。通常使用6-8个数字和字母。<br><strong>verification_uri</strong> - 必需，用户应访问的授权服务器上的URL以开始授权。用户需要在他们的计算机或移动电话上手动输入此URL。<br><strong>expires_in</strong> - 可选，设备代码和用户代码的生命周期（以秒为单位）。<br><strong>interval</strong> - 可选，客户端轮询令牌端点的请求之间应等待的最短时间（以秒为单位）。</p>
</blockquote>
<h4 id="用户代码（user-code）"><a href="#用户代码（user-code）" class="headerlink" title="用户代码（user code）"></a>用户代码（user code）</h4><p>在许多情况下，用户的设备将是他们的移动电话。通常，这些界面比完整的计算机键盘更受限制，例如iPhone需要额外的选项来切换到数字输入。为了帮助减少数据输入错误并加快代码输入，用户代码的字符集应考虑到这些限制，例如仅使用大写字母。</p>
<p>用于设备代码的合理字符集是不区分大小写的AZ字符的，而且没有元音，以避免意外拼写单词。最好使用base-20字符集BCDFGHJKLMNPQRSTVWXZ。比较输入的代码时，最好忽略字符集中没有的任何字符，如标点符号。例如用户码为BDWP-HQPK，授权服务器应该不区分大小写忽略标点符号来比较输入的字符串，所以应该允许以下匹配：bdwphqpk。</p>
<h4 id="验证网址"><a href="#验证网址" class="headerlink" title="验证网址"></a>验证网址</h4><p>设备将显示的验证URL应尽可能短，并且易于记忆。它将显示在可能非常小的屏幕上，用户必须在他们的计算机或手机上手动输入。</p>
<p>请注意，服务器应返回包含URL方案的完整URL，但某些设备可能会在显示URL时选择对其进行修剪。因此，服务器应配置为将http重定向到https，并在普通域和www前缀上提供服务，以防用户输入错误或设备省略该部分URL。</p>
<p>Google的授权服务器是一个很容易输入的短网址的很好的例子。代码请求的响应是<code>https://www.google.com/device</code>, 但所有显示<code>google.com/device</code>的设备，Google都会相应地重定向。</p>
<h4 id="非文本接口的优化"><a href="#非文本接口的优化" class="headerlink" title="非文本接口的优化"></a>非文本接口的优化</h4><p>没有显示或具有非文本显示的客户端显然无法向用户显示URL。因此，可以使用一些其他方法将验证URL和用户代码传达给用户。</p>
<p>该设备可能能够通过NFC或蓝牙或甚至通过显示QR码来广播验证URL。在这些情况下，设备可以使用参数将用户代码包括为验证URL的一部分。例如：<br><code>https://authorization-server.com/device?user_code=BDWP-HQPK</code><br>这样，当用户启动URL时，可以在验证界面中预填充用户代码。建议授权服务器仍然要求用户确认代码而不是自动进行。</p>
<p>如果设备能够显示代码，即使它无法显示URL，也可以通过提示用户确认验证界面上的代码与其设备上显示的代码相匹配来获得额外的安全性。如果这不是一个必需项，那么授权服务器至少可以要求用户确认他们刚刚请求授权的设备。</p>
<h3 id="安全考虑因素"><a href="#安全考虑因素" class="headerlink" title="安全考虑因素"></a>安全考虑因素</h3><h4 id="用户代码暴力攻击"><a href="#用户代码暴力攻击" class="headerlink" title="用户代码暴力攻击"></a>用户代码暴力攻击</h4><p>由于用户有可能手动将用户代码输入到尚未了解的等待授权设备的界面中，因此应采取预防措施以避免对用户代码进行暴力攻击的可能性。</p>
<p>通常使用具有比授权码所使用的熵少得多的短代码，以便容易地手动输入。因此，建议授权服务器对用于验证用户代码的端点进行速率限制。</p>
<p>速率限制应基于用户代码的熵，以使暴力攻击变得不可行。例如，在上述20个字符集中有8个字符，它提供大约34位的熵。在选择可接受的速率限制时，您可以使用此公式计算熵的位数。log2(208) = 34.57</p>
<h4 id="远程网络钓鱼"><a href="#远程网络钓鱼" class="headerlink" title="远程网络钓鱼"></a>远程网络钓鱼</h4><p>设备流程可能在攻击者拥有的设备上启动，以欺骗用户授权攻击者的设备。例如，攻击者可能发送短信指示用户访问URL并输入用户代码。</p>
<p>为了降低此风险，除了用户界面中描述的授权界面中包含的标准信息之外，建议授权界面要让用户非常清楚他们正在授权物理设备访问其帐户。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--原生应用的OAuth]]></title>
      <url>/2018/07/13/oauth-guide-15/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>本章介绍了在为原生应用程序支持OAuth时要记住的一些特殊注意事项。与基于浏览器的应用程序一样，原生应用程序无法在开发人员注册后保留客户端密钥，因为这需要开发人员在其应用程序的二进制版本中保存秘钥。目前已经证明，通过反编译提取秘钥是相对容易。因此，原生应用必须使用不需要秘钥的OAuth流程。</p>
<p>当前的行业最佳实践是在省略客户端密钥的同时使用授权流程，并使用外部用户代理来完成流程。外部用户代理通常是设备的原生浏览器（具有与原生应用程序不同的安全域），因此应用程序无法访问cookie存储或检查或修改浏览器内的页面内容。由于应用程序无法访问此情况下使用内部浏览器，因此这为设备提供了在授权不同应用程序时让用户保持登录的机会，这样他们无需在每次授权新应用程序时输入密码。</p>
<p>近年来，像iOS这样的平台一直在努力通过提供可以从应用程序内部启动的原生用户代理来进一步改善原生应用程序的OAuth用户体验，同时仍然与启动它的应用程序隔离。结果是用户不再需要离开应用程序以启动共享系统cookie的原生浏览器。这在iOS上称为SFSafariViewController。</p>
<p>针对原生应用程序的这些建议被发布为<a href="https://tools.ietf.org/html/rfc8252" target="_blank" rel="noopener">RFC 8252</a>，这其中更详细地描述了这些概念。</p>
<h3 id="使用系统浏览器"><a href="#使用系统浏览器" class="headerlink" title="使用系统浏览器"></a>使用系统浏览器</h3><p>截至撰写本文时，许多原生应用程序仍然在应用程序内部的Web视图中嵌入OAuth界面。此方法存在多个问题，包括客户端应用程序可能会在登录时窃听用户输入其凭据，甚至提供虚假授权页面。以操作系统级别安全性的实现方式是嵌入式Web视图不与系统的原生浏览器共享cookie，因此用户的体验更糟糕，因为他们每次都需要输入密码。</p>
<p>完成授权流程的更安全和可信的方法是启动系统浏览器。然而，直到最近，这还有一个缺点，即应用程序弹出并启动浏览器，然后重定向回应用程序，这也不是一个理想的用户体验。</p>
<p>值得庆幸的是，移动平台一直在解决这个问题。在iOS 9和10中，开发人员现在可以使用SFSafariViewControllerAPI启动从应用程序内共享系统cookie的系统浏览器。这是通过API实现的，不允许客户端应用程序窥视浏览器，从而获得使用外部浏览器的安全优势以及用户在整个过程中保留在应用程序中的优秀用户体验。</p>
<p>强烈建议为iOS编写应用程序的原生应用程序开发人员使用SFSafariViewControllerAPI，如果API不可用，则启动外部Safari窗口（例如，如果应用程序需要支持iOS 8及更低版本）。</p>
<p>授权服务器应通过尝试检测授权URL是否在嵌入式Web视图中启动来强制执行此行为，如果是，则拒绝该请求。用于检测页面是否在嵌入式Web视图中与系统浏览器进行访问的特定技术将取决于平台，但通常涉及检查用户代理haeder。</p>
<h3 id="重定向原生应用程序的URL"><a href="#重定向原生应用程序的URL" class="headerlink" title="重定向原生应用程序的URL"></a>重定向原生应用程序的URL</h3><p>为了支持各种类型的原生应用程序，您的服务器需要支持注册三种类型的重定向URL，每种URL都支持稍微不同的用例。</p>
<h4 id="自定义URL方案"><a href="#自定义URL方案" class="headerlink" title="自定义URL方案"></a>自定义URL方案</h4><p>某些平台（如iOS）允许应用程序注册自定义URL方案，只要在浏览器或其他应用程序中打开具有该方案的URL，该方案就会启动应用程序。支持具有自定义URL方案的重定向URL允许客户端启动外部浏览器以完成授权流程，然后在授权完成后重定向回应用程序。</p>
<p>应用程序开发人员应该选择全局唯一的URL方案，以及他们可以断言控制权的URL方案。由于操作系统通常没有关于特定应用程序是否已声明这种URL方案的注册的汇总，因此理论上两种应用程序可以独立地选择相同的方案，例如<code>myapp://</code>。如果您希望帮助防止应用程序开发人员使用自定义方案时发生冲突，您应该建议（甚至强制执行）他们使用的方案是他们的反向域名模式。至少，您可以要求重定向URL至少包含一个<code>.</code>以免与其他系统方案（如mailto或ftp）冲突。</p>
<p>例如，如果某个应用程序有一个相应的网站<code>photoprintr.example.org</code>，则可以使用反向域名作为其URL方案<code>org.example.photoprintr</code>。然后开发人员将注册<code>org.example.photoprintr://</code>开头的重定向URL。通过强制执行此操作，您可以帮助鼓励开发人员选择不会与其他已安装的应用程序冲突的显式URL方案。</p>
<p>使用自定义URL方案的应用程序将正常启动授权请求，如授权请求中所述，但将提供具有其自定义URL方案的重定向URL。授权服务器仍应验证此URL是否已注册为允许的重定向URL，并且可将其视为Web应用程序注册的重定向URL一样的URL。</p>
<p>当授权服务器使用自定义方案将原生应用程序重定向到URL时，操作系统将启动应用程序并使原始应用程序可以访问整个重定向URL。该应用可以像常规OAuth 2.0客户端一样提取授权代码。</p>
<h4 id="HTTPS-URL匹配"><a href="#HTTPS-URL匹配" class="headerlink" title="HTTPS URL匹配"></a>HTTPS URL匹配</h4><p>某些平台允许应用程序注册URL模式，当系统浏览器访问的URL与注册模式的URL匹配时，应启动应用程序。这通常被应用程序用于“深层链接”到原生应用程序，例如在浏览器中查看Yelp URL时打开到Yelp应用程序的餐厅页面。</p>
<p>应用程序也可以使用此技术向URL注册一个模式，该模式将在授权服务器重定向回应用程序时启动应用程序。如果平台提供此功能，则这是原生应用程序的推荐选择，因为这提供了应用程序属于其匹配的URL的最大完整性。在平台不支持应用程序声明URL的情况下，这也提供了合理的后备选择。</p>
<h4 id="loopback-URL"><a href="#loopback-URL" class="headerlink" title="loopback URL"></a>loopback URL</h4><p>原生应用程序可用于支持无缝重定向的另一种技术是在loopback接口的随机端口上打开新的HTTP服务器。这通常仅在桌面操作系统上完成，因为移动操作系统通常不向应用开发者提供此功能。</p>
<p>这种方法适用于命令行应用程序以及桌面GUI应用程序。该应用程序将启动HTTP服务器，然后开始授权请求，将重定向URL设置为loopback地址，例如<code>http://127.0.0.1:49152/redirect</code>启动浏览器。当授权服务器将浏览器重定向回loopback地址时，应用程序可以从请求中获取授权代码。</p>
<p>为了支承实这种使用情况，授权服务器必须支持注册重定向URL以<code>http://127.0.0.1:[port]/</code>或<code>http://::1:[port]/</code>或<code>http://localhost:[port]/</code>开始。授权服务器应允许任意路径组件以及任意端口号。请注意，在这种情况下，可以使用HTTP方案而不是HTTPS，因为请求永远不会离开设备。</p>
<h4 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h4><p>与服务器端应用程序一样，原生应用程序还必须使用授权服务器注册其重定向URL。这意味着除了服务器端应用程序的传统HTTPS URL之外，授权服务器还需要允许注册与上述所有模式匹配的重定向URL。</p>
<p>在授权服务器上启动授权请求时，服务器将验证所有请求参数，包括给定的重定向URL。授权应拒绝请求中无法识别的URL，以帮助避免授权代码拦截攻击。</p>
<h3 id="PKCE扩展"><a href="#PKCE扩展" class="headerlink" title="PKCE扩展"></a>PKCE扩展</h3><p>由于原生平台上的重定向URL的强制执行能力是有限的，因此还有另一种获得额外安全性的技术，称为代码交换的证明秘钥，或简称PKCE。</p>
<p>此技术涉及原生应用程序创建初始随机密钥，并在交换访问令牌的授权代码时再次使用该秘密。这样，如果另一个应用程序截获授权代码，则在没有原始秘钥的情况下它将无法使用。</p>
<h3 id="本地应用程序的服务器支持清单"><a href="#本地应用程序的服务器支持清单" class="headerlink" title="本地应用程序的服务器支持清单"></a>本地应用程序的服务器支持清单</h3><p>要总结本章，您的授权服务器应支持以下内容，以便完全支持原生应用程序的安全授权。</p>
<ul>
<li>允许客户为其重定向URL注册自定义URL方案。</li>
<li>支持loopback IP重定向具有任意端口号的URL，以支持桌面应用程序。</li>
<li>不要假设本机应用程序可以保守秘钥。要求所有应用程序声明它们是公开的还是保密的，并且只向机密应用程序发出客户秘钥。</li>
<li>支持PKCE扩展，并要求公共客户端使用它。</li>
<li>尝试检测并拒绝授权界面嵌入原生应用程序的Web视图的请求，要求其在系统浏览器中启动请求。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--资源服务器]]></title>
      <url>/2018/07/13/oauth-guide-14/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>资源服务器是API服务器的OAuth 2.0术语。资源服务器在应用程序获取访问令牌后处理经过身份验证的请求。</p>
<p>大规模部署可能有多个资源服务器。例如，Google的服务拥有数十种资源服务器，例如Google云平台，Google地图，Google云端硬盘，Youtube，Google +等等。这些资源服务器中的每一个都明显是分开的，但它们都共享相同的授权服务器。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftiyxmx2rrj30ox0dbgoc.jpg" alt="谷歌的一些API"></p>
<p>较小的部署通常只有一个资源服务器，并且通常构建为与授权服务器相同的代码库或相同部署的一部分。</p>
<h3 id="验证访问令牌"><a href="#验证访问令牌" class="headerlink" title="验证访问令牌"></a>验证访问令牌</h3><p>资源服务器将从应用发出的请求中的具有的HTTP Authorization header获取访问令牌。资源服务器需要能够验证访问令牌以确定是否处理请求，并找到关联的用户帐户等。</p>
<p>如果您使用的是自编码访问令牌，则可以在资源服务器中完全验证令牌，而无需与数据库或外部服务器交互。</p>
<p>如果您的令牌存储在数据库中，则验证令牌需要在数据库中查找。</p>
<p>另一种选择是使用令牌自解析规范来构建API以验证访问令牌。这是处理在大量资源服务器上验证访问令牌的好方法，因为这意味着您可以将访问令牌的所有逻辑封装在单个服务器中，通过API将信息暴露给系统的其他部分。令牌自解析endpoint仅供内部使用，因此您需要使用某些内部授权来保护它，或者仅在系统防火墙内的服务器上启用它。</p>
<h3 id="验证范围"><a href="#验证范围" class="headerlink" title="验证范围"></a>验证范围</h3><p>资源服务器需要知道与访问令牌关联的范围列表。如果访问令牌中的作用域不包含执行指定操作所需的作用域，则服务器负责拒绝请求。</p>
<p>OAuth 2.0规范本身没有定义任何范围，也没有范围的注册表。范围列表由服务决定。</p>
<h3 id="错误代码和未经授权的访问"><a href="#错误代码和未经授权的访问" class="headerlink" title="错误代码和未经授权的访问"></a>错误代码和未经授权的访问</h3><p>如果访问令牌不允许访问所请求的资源，或者请求中没有访问令牌，则服务器必须回复HTTP 401响应并在相应header中包含WWW-Authenticate。</p>
<p>最简单的WWW-Authenticate标头包括字符串Bearer，表示需要承载令牌。标题还可以指示附加信息，例如“realm”和“scope”。“realm”值用于传统的<a href="https://tools.ietf.org/html/rfc2617" target="_blank" rel="noopener">HTTP身份验证</a>。“scope”值允许资源服务器指示访问资源所需的作用域列表，因此应用程序可以在启动授权流时请求适当的作用域。响应还应包括适当的“error”值，具体取决于发生的错误类型。</p>
<blockquote>
<p><strong>invalid_request （HTTP 400）</strong> - 请求缺少参数，否则会出现格式错误。<br><strong>invalid_token（HTTP 401）</strong> - 由于其他原因，访问令牌已过期，已撤销，格式错误或无效。客户端可以获取新的访问令牌，然后重试。<br><strong>insufficient_scope （HTTP 403）</strong> - 访问令牌请求范围错误</p>
</blockquote>
<p>例如：</p>
<pre><code class="http">HTTP/1.1 401 Unauthorized
WWW-Authenticate: Bearer realm=&quot;example&quot;,
                  scope=&quot;delete&quot;,
                  error=&quot;insufficient_scope&quot;
</code></pre>
<p>如果请求没有身份验证，则不需要错误代码或其他错误信息。</p>
<pre><code class="http">HTTP/1.1 401 Unauthorized
WWW-Authenticate: Bearer realm=&quot;example&quot;
</code></pre>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--授权列表与撤销]]></title>
      <url>/2018/07/13/oauth-guide-13/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<h3 id="授权列表"><a href="#授权列表" class="headerlink" title="授权列表"></a>授权列表</h3><p>一旦用户开始授权多个应用程序，让许多应用程序访问其帐户，就有必要提供一种方法来允许用户管理具有访问权限的应用程序。这通常在帐户设置页面或帐户隐私页面中呈现给用户。</p>
<p>OAuth 2.0规范中没有任何内容要求用户能够撤销访问权限，或者对如何执行此操作的建议，因此我们将查看几个主要的API提供商，以获取有关如何实现此目的的灵感。</p>
<p>大多数提供商都有一个页面，其中列出了用户授权其帐户的所有应用程序。通常会显示有关应用程序的一些信息，以及用于向用户提供有关此应用程序何时以及为何具有访问权限的上下文的信息。</p>
<h4 id="谷歌"><a href="#谷歌" class="headerlink" title="谷歌"></a>谷歌</h4><p>Google会在<code>https://security.google.com/settings/security/permissions</code>上提供您在帐户中授权的应用程序列表。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftgh6j6yqmj30mm0iiq4r.jpg" alt="google"></p>
<p>该列表显示应用程序图标，名称以及授予应用程序范围的摘要。单击其中一个将展开以显示更多详细信息。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ftgha78weuj30j40ijq4c.jpg" alt="一个授权访问您的Google帐户的应用程序的详细信息"></p>
<p>此视图提供了已授予范围的更详细列表，以及您授权应用程序的日期。</p>
<h4 id="Twitter"><a href="#Twitter" class="headerlink" title="Twitter"></a>Twitter</h4><p>Twitter在<code>https://twitter.com/settings/applications</code>上提供了您授权的应用程序列表。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1ftghc5l2bmj30sg0jz79r.jpg" alt="您授权访问Twitter帐户的应用程序列表"></p>
<p>Twitter显示授予的范围（只读，读/写，读/写/直接消息），以及应用程序是否可以看到您的电子邮件地址。该列表包括您授权申请的日期。这使用户可以轻松地从他们暂时未使用的应用程序中撤消凭据。</p>
<h4 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h4><p>GitHub在<code>https://github.com/settings/applications</code>上提供了您授权的应用程序列表。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftghef8w6qj30sg0cu40n.jpg" alt="您授权访问GitHub帐户的应用程序列表"></p>
<p>GitHub提供的列表包括上次使用应用程序的描述，以便您了解是否可以安全地撤销应用程序的授权（如果它在一段时间内没有使用过）。</p>
<p>单击应用程序可提供有关该应用程序访问权限的更多详细信息。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ftghezcvrqj30kw0cmab1.jpg" alt="一个授权访问您的GitHub帐户的应用程序的详细信息"></p>
<p>在这里，您可以看到应用程序对您帐户的权限（范围）。</p>
<p>您可以在此处找到指向其他服务授权页面的<a href="https://indieweb.org/appaccess" target="_blank" rel="noopener">链接</a>。</p>
<h3 id="撤销访问权限"><a href="#撤销访问权限" class="headerlink" title="撤销访问权限"></a>撤销访问权限</h3><p>您可能需要撤销应用程序对用户帐户的访问权限的原因有几个。</p>
<ul>
<li>用户明确希望撤销应用程序的访问权限，例如，如果他们在授权页面上找到了他们不再想要使用的应用程序</li>
<li>开发人员想要撤消其应用程序的所有用户令牌</li>
<li>开发者删除了他们的申请</li>
<li>您作为服务提供商已确定应用程序已被盗用或恶意，并希望禁用它</li>
</ul>
<p>根据您实现生成访问令牌的方式，将用不同的方式撤销他们。</p>
<h4 id="令牌数据库"><a href="#令牌数据库" class="headerlink" title="令牌数据库"></a>令牌数据库</h4><p>如果将访问令牌存储在数据库中，则撤销属于特定用户的所有令牌相对容易。您可以轻松编写查找和删除属于该用户的令牌的查询，例如查找令牌表中的令牌user_id。假设您的资源服务器通过在数据库中查找它们来验证访问令牌，那么下次被撤销的客户端发出请求时，其令牌将无法验证。</p>
<h4 id="自编码令牌"><a href="#自编码令牌" class="headerlink" title="自编码令牌"></a>自编码令牌</h4><p>如果授权服务器发出自编码令牌，则撤销对特定应用程序的访问会稍微困难一些。</p>
<p>如果您有一个真正的无状态机制来验证令牌，并且您有资源服务器正在验证令牌而不与另一个系统共享服务，那么唯一的选择是等待所有未完成的令牌过期，并阻止应用程序生成新令牌。这是当您使用自编码令牌时，使用极短期令牌的主要原因。</p>
<p>由于没有使单个访问令牌无效的机制，因此您需要使特定用户的应用程序刷新令牌无效。这样，下次应用程序尝试刷新访问令牌时，将拒绝对新访问令牌的请求。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--访问令牌]]></title>
      <url>/2018/07/13/oauth-guide-12/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>访问令牌是应用程序用于代表用户发出API请求的内容。访问令牌表示特定应用程序访问用户数据的特定部分的授权。</p>
<p>访问令牌必须在运输和存储过程中保密。应该看到访问令牌的唯一方是应用程序本身，授权服务器和资源服务器。应用程序应确保同一设备上的其他应用程序无法访问访问令牌的存储。访问令牌只能在https连接上使用，因为通过非加密通道传递它会使第三方拦截变得非常容易。</p>
<p>令牌endpoint是应用程序发出请求以获取用户访问令牌的位置。本节介绍如何验证令牌请求以及如何返回相应的响应和错误。</p>
<h3 id="授权码请求"><a href="#授权码请求" class="headerlink" title="授权码请求"></a>授权码请求</h3><p>当应用试图交换访问令牌时，将使用授权码交换授予。用户通过重定向URL返回应用程序后，应用程序将从URL获取授权码并使用它来请求访问令牌。此请求将发送到令牌endpoint。</p>
<h4 id="请求参数"><a href="#请求参数" class="headerlink" title="请求参数"></a>请求参数</h4><p>访问令牌请求将包含以下参数。</p>
<blockquote>
<p><strong>grant_type （需要）</strong><br>grant_type参数必须设置为“authorization_code”。</p>
<p><strong>code （需要）</strong><br>code参数是客户端先前从授权服务器接收的授权码。</p>
<p><strong>redirect_uri （可能需要）</strong><br>如果重定向URI包含在初始授权请求中，则服务也必须在令牌请求中要求它。令牌请求中的重定向URI必须与生成授权代码时使用的重定向URI完全匹配。 否则服务必须拒绝该请求。</p>
<p><strong>client_id （如果不存在其他客户端身份验证，则需要）</strong><br>如果客户端通过HTTP Basic Auth或其他方法进行身份验证，则不需要此参数。否则，此参数是必需的。</p>
</blockquote>
<p>如果客户端发出了客户端密钥，则服务器必须对客户端进行身份验证。验证客户端的一种方法是接受此请求中的另一个参数client_secret。或者，授权服务器可以使用HTTP Basic Auth。从技术上讲，规范允许授权服务器支持任何形式的客户端身份验证，甚至提到公钥/私钥对作为选项。但实际上，大多数服务器都支持使用此处提到的方法之一或两者共同来验证客户端的简单方法。</p>
<h4 id="验证授权码"><a href="#验证授权码" class="headerlink" title="验证授权码"></a>验证授权码</h4><p>在检查所有必需参数并在客户端被发出秘钥时验证客户端之后，授权服务器可以继续验证请求的其他部分。</p>
<p>然后，服务器检查授权码是否有效，并且尚未过期。然后，该服务必须验证请求中提供的授权码是否已发送给所标识的客户端。最后，服务必须确保存的重定向URI参数与用于请求授权代码的重定向URI匹配。</p>
<p>如果所有内容都检出，该服务可以生成访问令牌并进行响应。</p>
<p>例<br>以下示例显示了私密客户端的授权授予请求。</p>
<pre><code class="http">POST /oauth/token HTTP/1.1
Host: authorization-server.com

grant_type=authorization_code
&amp;code=xxxxxxxxxxx
&amp;redirect_uri=https://example-app.com/redirect
&amp;client_id=xxxxxxxxxx
&amp;client_secret=xxxxxxxxxx
</code></pre>
<h4 id="安全考虑因素"><a href="#安全考虑因素" class="headerlink" title="安全考虑因素"></a>安全考虑因素</h4><h5 id="防止重复攻击"><a href="#防止重复攻击" class="headerlink" title="防止重复攻击"></a>防止重复攻击</h5><p>如果多次使用授权码，授权服务器必须拒绝后续请求。授权码存储在数据库中是很容易实现，因为它们可以简单地标记为已使用。</p>
<p>如果要实现自编码授权码（如我们的示例代码中所示），则需要跟踪已在令牌生命周期中使用的令牌。一种方法是通过生命周期之内，将授权码缓存在缓存中来实现此目的（具有过期时间的缓存）。这样在验证时，我们可以通过检查授权码的缓存来检查它们是否已被使用。一旦授权码到达其到期日期，它将不再在缓存中，但我们可以根据到期日期拒绝它。</p>
<p>如果授权码被多次使用，则应将其视为攻击。如果可能，服务应撤销此授权码发出的先前访问令牌。</p>
<h3 id="密码授予"><a href="#密码授予" class="headerlink" title="密码授予"></a>密码授予</h3><p>当应用程序交换用户的访问令牌的用户名和密码时，将使用密码授予。这正是首先要创建的OAuth，因此您绝不允许第三方应用使用此授权。</p>
<p>此授权类型的常见用途是用您的服务为应用启用密码登录。用户使用他们的用户名和密码登录来登录网站或原生应用程序，但绝不允许第三方应用程序直接询问用户的密码。</p>
<h4 id="请求参数-1"><a href="#请求参数-1" class="headerlink" title="请求参数"></a>请求参数</h4><p>访问令牌请求将包含以下参数。</p>
<blockquote>
<p><strong>grant_type（必填）</strong> - grant_type参数必须设置为“password”。<br><strong>username （必填）</strong> - 用户的用户名。<br><strong>password （必填）</strong> - 用户的密码。<br><strong>scope （可选）</strong> - 应用程序请求的范围。<br><strong>客户端身份验证</strong>（如果客户端被授予秘钥，则需要）</p>
</blockquote>
<p>如果客户端被授予秘钥，则必须验证此请求。通常，服务将允许其他请求参数如client_id和client_secret，或接受在HTTP Basic auth header中的客户端ID和秘钥。</p>
<p>例<br>以下是服务将接收的示例密码授予。</p>
<pre><code class="http">POST /oauth/token HTTP/1.1
Host: authorization-server.com

grant_type=password
&amp;username=user@example.com
&amp;password=1234luggage
&amp;client_id=xxxxxxxxxx
&amp;client_secret=xxxxxxxxxx
</code></pre>
<h3 id="客户端凭据"><a href="#客户端凭据" class="headerlink" title="客户端凭据"></a>客户端凭据</h3><p>当应用程序请求访问令牌来访问其自己的资源，而不是代表用户访问他们的资源时，将使用客户端凭据授予。</p>
<h4 id="请求参数-2"><a href="#请求参数-2" class="headerlink" title="请求参数"></a>请求参数</h4><blockquote>
<p><strong>grant_type （需要）</strong><br>grant_type参数必须设置为client_credentials。</p>
<p><strong>scope （可选的）</strong><br>您的服务可以支持客户端凭据授予的不同范围。实际上，实际上并没有多少服务支持这一点。</p>
<p><strong>客户端验证（必填）</strong><br>客户端需要为此请求进行身份验证。通常，服务将接受请求参数client_id和client_secret，或接受在HTTP Basic auth header中的客户端ID和秘钥。</p>
</blockquote>
<p>例<br>以下是客户端凭据的请求例子。</p>
<pre><code class="http">POST /token HTTP/1.1
Host: authorization-server.com

grant_type=client_credentials
&amp;client_id=xxxxxxxxxx
&amp;client_secret=xxxxxxxxxx
</code></pre>
<h3 id="访问令牌响应"><a href="#访问令牌响应" class="headerlink" title="访问令牌响应"></a>访问令牌响应</h3><h4 id="响应成功"><a href="#响应成功" class="headerlink" title="响应成功"></a>响应成功</h4><p>如果访问令牌的请求有效，则授权服务器需要生成访问令牌（和可选的刷新令牌）并将这些令牌返回给客户端，通常还有一些有关授权的其他属性。</p>
<p>具有访问令牌的响应应包含以下属性：</p>
<blockquote>
<p><strong>access_token （必需）</strong> 授权服务器发出的访问令牌字符串。<br><strong>token_type （必需）</strong> 这是令牌的类型，通常只是字符串“bearer”。<br><strong>expires_in （推荐）</strong> 如果访问令牌会过期，服务器应回复授予访问令牌的持续时间。<br><strong>refresh_token（可选）</strong> 如果访问令牌会过期，则应该返回刷新令牌，应用程序可以使用该令牌来获取新的访问令牌。但是，使用隐式授权发出的令牌无法发出刷新令牌。<br><strong>scope（可选）</strong> 如果用户授予的范围与应用程序请求的范围相同，则此参数是可选的。如果授予的范围与请求的范围不同，例如，如果用户修改了范围，则此参数是必需的。</p>
</blockquote>
<p>使用访问令牌进行响应时，服务器还必须包含附加<code>Cache-Control: no-store</code>和<code>Pragma: no-cache</code>的HTTP header，以确保客户端不会缓存此请求。</p>
<p>例如，成功的令牌响应可能如下所示：</p>
<pre><code class="json">HTTP/1.1 200 OK
Content-Type: application/json
Cache-Control: no-store
Pragma: no-cache

{
  &quot;access_token&quot;:&quot;MTQ0NjJkZmQ5OTM2NDE1ZTZjNGZmZjI3&quot;,
  &quot;token_type&quot;:&quot;bearer&quot;,
  &quot;expires_in&quot;:3600,
  &quot;refresh_token&quot;:&quot;IwOGYzYTlmM2YxOTQ5MGE3YmNmMDFkNTVk&quot;,
  &quot;scope&quot;:&quot;create&quot;
}
</code></pre>
<p>####访问令牌</p>
<p>OAuth 2.0 Bearer Token的格式实际上是在单独的规范<a href="https://tools.ietf.org/html/rfc6750" target="_blank" rel="noopener">RFC 6750</a>中描述的。规范要求的令牌没有已定义的结构，因此您可以生成任意字符串并实现所需的令牌。令牌中的有效字符是字母数字，和标点字符：-._~+/</p>
<p>通常，服务将生成随机字符串并将其与相关的用户和范围信息一起存储在数据库中，或者将使用自编码令牌，其中令牌字符串本身包含所有必要的信息。</p>
<h4 id="响应失败"><a href="#响应失败" class="headerlink" title="响应失败"></a>响应失败</h4><p>如果访问令牌请求无效，例如重定向URL与授权期间使用的URL不匹配，则服务器需要返回错误响应。</p>
<p>使用HTTP 400状态代码（除非另有说明）返回错误响应，带有<code>error</code>和<code>error_description</code>参数。该<code>error</code>参数将始终是下面列出的值之一。</p>
<blockquote>
<p><strong>invalid_request</strong> - 请求缺少参数，因此服务器无法继续执行请求。如果请求包含不受支持的参数或重复参数，也可能会返回此信息。<br><strong>invalid_client</strong> - 客户端身份验证失败，例如请求包含无效的客户端ID或秘钥。在这种情况下发送HTTP 401响应。<br><strong>invalid_grant</strong> - 授权码（或密码授予类型的用户密码）无效或已过期。或者授权中给出的重定向URL与此访问令牌请求中提供的URL不匹配，也将返回这个的错误。<br><strong>invalid_scope</strong> - 对于包含范围（密码或client_credentials授权）的访问令牌请求，此错误表示请求中的范围值无效。<br><strong>unauthorized_client</strong> - 此客户端无权使用请求的授权类型。例如，如果限制哪些应用程序可以使用隐式授权，则会为其他应用程序返回此错误。<br><strong>unsupported_grant_type</strong> - 如果请求授权服务器无法识别的授权类型，请使用此代码。请注意，未知的授权类型也使用此特定错误代码而不是使用invalid_request。</p>
</blockquote>
<p>返回错误响应时有两个可选参数，<code>error_description</code>和<code>error_uri</code>。这些旨在为开发人员提供有关错误的更多信息，而不是向最终用户显示。但是，请记住，无论您多么警告，许多开发人员都会将此错误文本直接传递给最终用户，因此最好确保它对最终用户至少有所帮助。</p>
<p>该<code>error_description</code>参数只能包含ASCII字符，最多应该是一两句话来描述错误的情况。这<code>error_uri</code>是链接到API文档的好地方，可以获取有关如何更正遇到的特定错误的信息。</p>
<p>整个错误响应作为JSON字符串返回，类似于成功响应。以下是错误响应的示例。</p>
<pre><code class="json">HTTP/1.1 400 Bad Request
Content-Type: application/json;charset=UTF-8
Cache-Control: no-store
Pragma: no-cache

{
  &quot;error&quot;: &quot;invalid_request&quot;,
  &quot;error_description&quot;: &quot;Request was missing the &#39;redirect_uri&#39; parameter.&quot;,
  &quot;error_uri&quot;: &quot;See the full API docs at https://authorization-server.com/docs/access_token&quot;
}
</code></pre>
<h3 id="自编码访问令牌"><a href="#自编码访问令牌" class="headerlink" title="自编码访问令牌"></a>自编码访问令牌</h3><p>自编码令牌提供了一种通过编码令牌字符串中的所有必要信息来避免在数据库中存储令牌的方法。这样做的主要好处是API服务器能够在不对每个API请求进行数据库查找的情况下验证访问令牌，从而使API更容易扩展。</p>
<p>OAuth 2.0 Bearer Tokens的好处是应用程序无需了解服务中如何实现访问令牌。这意味着可以在不影响客户端的情况下更改令牌的实现规则。</p>
<p>如果您已经拥有可水平扩展的分布式数据库系统，那么使用自编码令牌可能无法获得任何好处。实际上，如果已经解决了分布式数据库问题，使用自编码令牌只会引入新问题，因为使自编码令牌失效会成为额外的障碍。</p>
<p>有许多方法可以自编码令牌。您选择的实际方法仅对您的实现很重要，因为令牌信息不会暴露给外部开发人员。</p>
<p>创建自编码标记的一种方法是创建序列化的json串来包含在token中的所有数据，并使用仅为您的服务器知道的密钥对结果字符串进行签名。</p>
<p>一种常见的技术是使用<a href="https://tools.ietf.org/html/rfc7515" target="_blank" rel="noopener">JSON Web Signature（JWS）</a>标准来处理令牌的编码，解码和验证。 <a href="https://tools.ietf.org/html/rfc7519" target="_blank" rel="noopener">JSON Web Token (JWT)</a>规范定义了一些字段，你可以在JWS中使用，或定义一些时间戳字段来确定令牌是否有效。我们将在此示例中使用JWT库，因为它提供了时间到期的内置处理。</p>
<h4 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h4><p>下面的代码是用PHP编写的，使用Firebase PHP-JWT库来编码和验证令牌。您需要包含该库才能运行示例代码</p>
<pre><code class="php">&lt;?php
use \Firebase\JWT\JWT;

# Define the secret key used to create and verify the signature
$jwt_key = &#39;secret&#39;;

# Set the user ID of the user this token is for
$user_id = 1000;

# Set the client ID of the app that is generating this token
$client_id = &#39;https://example-app.com&#39;;

# Provide the list of scopes this token is valid for
$scope = &#39;read write&#39;;

$token_data = array(

  # Subject (The user ID)
  &#39;sub&#39; =&gt; $user_id,

  # Issuer (the token endpoint)
  &#39;iss&#39; =&gt; &#39;https://&#39; . $_SERVER[&#39;PHP_SELF&#39;],

  # Client ID (this is a non-standard claim)
  &#39;cid&#39; =&gt; $client_id,

  # Issued At
  &#39;iat&#39; =&gt; time(),

  # Expires At
  &#39;exp&#39; =&gt; time()+7200, // Valid for 2 hours

  # The list of OAuth scopes this token includes
  &#39;scope&#39; =&gt; $scope
);
$token_string = JWT::encode($token_data, $jwt_key);
</code></pre>
<p>这将产生一个字符串，如：</p>
<pre><code class="jwt">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOjEwMDAsI
mlzcyI6Imh0dHBzOi8vYXV0aG9yaXphdGlvbi1zZXJ2ZXIuY29tIiw
iY2lkIjoiaHR0cHM6Ly9leGFtcGxlLWFwcC5jb20iLCJpYXQiOjE0N
zAwMDI3MDMsImV4cCI6MTUyOTE3NDg1MSwic2NvcGUiOiJyZWFkIHd
yaXRlIn0.QiIrnmaC4VrbAYAsu0YPeuJ992p20fSxrXWPLw-gkFA
</code></pre>
<p>此令牌由三部分组成，以句点分隔。第一部分描述了使用的签名方法。第二部分包含令牌数据。第三部分是签名。</p>
<p>例如，此令牌的第一个部分是JSON对象：</p>
<pre><code class="json">{
   &quot;typ&quot;:&quot;JWT&quot;,
   &quot;alg&quot;:&quot;HS256”
}
</code></pre>
<p>第二个部分包含API端点处理请求所需的实际数据，例如用户标识和范围访问。</p>
<pre><code class="json">{
  &quot;sub&quot;: 1000,
  &quot;iss&quot;: &quot;https://authorization-server.com&quot;,
  &quot;cid&quot;: &quot;https://example-app.com&quot;,
  &quot;iat&quot;: 1470002703,
  &quot;exp&quot;: 1470009903,
  &quot;scope&quot;: &quot;read write&quot;
}
</code></pre>
<p>Base64编码前两个部分产生以下两个字符串：</p>
<pre><code class="jwt">eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9
</code></pre>
<pre><code class="jwt">eyJzdWIiOjEwMDAsImlzcyI6Imh0dHBzOi8vYXV0aG9yaXphdGlvbi1z
ZXJ2ZXIuY29tIiwiY2lkIjoiaHR0cHM6Ly9leGFtcGxlLWFwcC5jb20i
LCJpYXQiOjE0NzAwMDI3MDMsImV4cCI6MTUyOTE3NDg1MSwic2NvcGUi
OiJyZWFkIHdyaXRlIn0
</code></pre>
<p>然后我们计算两个字符串和秘钥的散列，从而产生另一个字符串：</p>
<pre><code class="jwt">QiIrnmaC4VrbAYAsu0YPeuJ992p20fSxrXWPLw-gkFA
</code></pre>
<p>最后，将所有三个字符串连接在一起，用句点分隔。</p>
<pre><code class="jwt">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOjEwMDAsI
mlzcyI6Imh0dHBzOi8vYXV0aG9yaXphdGlvbi1zZXJ2ZXIuY29tIiw
iY2lkIjoiaHR0cHM6Ly9leGFtcGxlLWFwcC5jb20iLCJpYXQiOjE0N
zAwMDI3MDMsImV4cCI6MTUyOTE3NDg1MSwic2NvcGUiOiJyZWFkIHd
yaXRlIn0.QiIrnmaC4VrbAYAsu0YPeuJ992p20fSxrXWPLw-gkFA
</code></pre>
<h4 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h4><p>可以使用相同的JWT库来验证访问令牌。库将同时解码和验证签名，如果签名无效，或者令牌的过期日期已经过去，则会抛出异常。</p>
<p>注意：任何人都可以通过base64解码令牌信息来解码令牌字符串的中间部分。因此，您不要存储您不希望用户或开发人员在令牌中看到的私人信息或信息，这一点很重要。如果要隐藏令牌信息，可以使用JSON Web加密规范加密令牌中的数据。</p>
<pre><code class="php">try {
  # Note: You must provide the list of supported algorithms in order to prevent 
  # an attacker from bypassing the signature verification. See:
  # https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/
  $token = JWT::decode($token_string, $jwt_key, [&#39;HS256&#39;]);
  $error = false;
} catch(\Firebase\JWT\ExpiredException $e) {
  $token = false;
  $error = &#39;expired&#39;;
  $error_description = &#39;The token has expired&#39;;
} catch(\Firebase\JWT\SignatureInvalidException $e) {
  $token = false;
  $error = &#39;invalid&#39;;
  $error_description = &#39;The token provided was malformed&#39;;
} catch(Exception $e) {
  $token = false;
  $error = &#39;unauthorized&#39;;
  $error_description = $e-&gt;getMessage();
}

if($error) {
  header(&#39;HTTP/1.1 401 Unauthorized&#39;);
  echo json_encode(array(
    &#39;error&#39;=&gt;$error, 
    &#39;error_description&#39;=&gt;$error_description
  ));
  die();
} else {
  // Now $token has all the data that we encoded in it originally
  print_r($token);
}
</code></pre>
<p>此时，该服务具有所需的所有信息，例如可用的用户ID，范围等，并且不必进行数据库查找。接下来，它可以检查以确保访问令牌未过期，可以验证范围是否足以执行所请求的操作，然后可以处理该请求。</p>
<p>因为可以在不进行数据库查找的情况下验证令牌，所以在令牌过期之前无法使令牌无效。您需要采取其他步骤来使自编码的令牌无效。</p>
<h3 id="访问令牌生命周期"><a href="#访问令牌生命周期" class="headerlink" title="访问令牌生命周期"></a>访问令牌生命周期</h3><p>当您的服务发出访问令牌时，您需要做出一些关于您希望令牌持续多久的决定。不幸的是，每项服务都没有全面的解决方案。不同的选项会有各种权衡，因此您应该选择最适合您应用需求的选项（或选项组合）。</p>
<h4 id="短期访问令牌和长期刷新令牌"><a href="#短期访问令牌和长期刷新令牌" class="headerlink" title="短期访问令牌和长期刷新令牌"></a>短期访问令牌和长期刷新令牌</h4><p>授予令牌的常用方法是使用访问令牌和刷新令牌的组合，以获得最大的安全性和灵活性。OAuth 2.0规范建议使用此选项，并且一些实现已采用此方法。</p>
<p>通常，使用此方法的服务将发出持续时间从几小时到几周的访问令牌。当服务发出访问令牌时，它还会生成一个永不过期的刷新令牌，并在响应中返回该令牌。（请注意，无法使用隐式授权发布刷新令牌。）</p>
<p>当访问令牌到期时，应用程序可以使用刷新令牌来获取新的访问令牌。它可以在幕后进行，无需用户参与，因此对用户来说是一个无缝的过程。</p>
<p>这种方法的主要好处是该服务可以使用自编码访问令牌，无需数据库查找即可对其进行验证。但是，这意味着没有办法直接使这些令牌过期，因此，令牌的发布时间很短，因此应用程序被迫不断刷新它们，从而使服务有机会在需要时撤销应用程序的访问权限。</p>
<p>从第三方开发人员的角度来看，处理刷新令牌往往令人沮丧。开发人员非常喜欢不会过期的访问令牌，因为处理的代码要少得多。为了帮助缓解这些问题，服务通常会在其SDK中构建令牌刷新逻辑，以便该流程对开发人员而言是透明的。</p>
<p>总之，在以下情况下使用短期访问令牌和长期刷新令牌：</p>
<ul>
<li>您想使用自编码访问令牌</li>
<li>您希望限制泄露访问令牌的风险</li>
<li>您将提供给开发人员处理刷新逻辑的SDK</li>
</ul>
<h4 id="短期访问令牌，没有刷新令牌"><a href="#短期访问令牌，没有刷新令牌" class="headerlink" title="短期访问令牌，没有刷新令牌"></a>短期访问令牌，没有刷新令牌</h4><p>如果要确保用户了解正在访问其帐户的应用程序，则该服务可以在不刷新令牌的情况下发出相对短期的访问令牌。访问令牌可以持续从当前应用程序会话到几周。当访问令牌到期时，应用程序将被强制使用户再次登录，以便您作为服务知道用户不断参与重新授权应用程序。</p>
<p>通常，此选项由服务使用，如果第三方应用程序意外或恶意泄漏访问令牌，则存在高风险。通过要求用户不断重新授权应用程序，如果攻击者从服务中窃取访问权限，则该服务可以确保潜在的损害受到限制。</p>
<p>通过不发布刷新令牌，这使得应用程序无法在用户不在屏幕前的情况下持续使用访问令牌。这使得连续同步数据的应用程序将无法在此方法下执行此操作。</p>
<p>从用户的角度来看，这是最有可能让人感到沮丧的选项，因为用户必须不断重新授权应用程序。</p>
<p>总之，在以下情况下使用没有刷新令牌的短期访问令牌：</p>
<ul>
<li>您希望最大程度地防范泄露访问令牌的风险</li>
<li>您希望强制用户了解他们授予的第三方访问权限</li>
<li>您不希望第三方应用程序对用户数据进行脱机访问</li>
</ul>
<h4 id="非过期访问令牌"><a href="#非过期访问令牌" class="headerlink" title="非过期访问令牌"></a>非过期访问令牌</h4><p>非过期访问令牌是开发人员最简单的方法。如果您选择此选项，请务必考虑您所做的权衡。</p>
<p>如果你想能够任意撤销它们，那么使用自编码令牌是不切实际的。因此，您需要将这些令牌存储在某种数据库中，因此可以根据需要删除它们或将其标记为无效。</p>
<p>请注意，即使服务打算发布非过期访问令牌以供正常使用，您仍需要提供一种机制，以便在特殊情况下使其过期，例如，如果用户明确要撤消应用程序的访问权限，或者用户帐户已删除。</p>
<p>对于测试自己的应用程序的开发人员来说，非过期访问令牌就更容易。您甚至可以为开发人员预生成一个或多个非过期访问令牌，并在应用程序详细信息页面上显示给他们。通过这种方式，他们可以立即开始使用令牌发出API请求，而不必担心设置OAuth流程以开始测试API。</p>
<p>总之，在以下情况下使用非过期访问令牌：</p>
<ul>
<li>你有一个机制来随时撤销访问令牌</li>
<li>如果令牌泄露，你没有巨大的风险</li>
<li>您希望为开发人员提供简单的身份验证机制</li>
<li>您希望第三方应用程序可以脱机访问用户的数据</li>
</ul>
<h3 id="刷新访问令牌"><a href="#刷新访问令牌" class="headerlink" title="刷新访问令牌"></a>刷新访问令牌</h3><p>本节介绍如何允许开发人员使用刷新令牌获取新的访问令牌。如果您的服务与访问令牌一起发布刷新令牌，那么您需要实现此处描述的刷新授权类型。</p>
<h4 id="请求参数-3"><a href="#请求参数-3" class="headerlink" title="请求参数"></a>请求参数</h4><p>访问令牌请求将包含以下参数。</p>
<blockquote>
<p><strong>grant_type （需要）</strong><br>grant_type参数必须设置为“refresh_token”。</p>
<p><strong>refresh_token （需要）</strong><br>先前发布给客户端的刷新令牌。</p>
<p><strong>scope （可选的）</strong><br>请求的范围不得包含原始访问令牌中未发布的其他范围。通常，这不会包含在请求中，如果省略，服务应发出一个访问令牌，其范围与先前发布的相同。</p>
<p><strong>客户端身份验证（如果客户端被授予秘钥，则需要）</strong><br>通常，刷新令牌仅用于私密客户端。但是，由于可以在没有客户端秘钥的情况下使用授权码流程，因此刷新授权也可以给没有秘钥的客户端使用。如果客户端被授予秘钥，则客户端必须验证此请求。通常，该服务将允许额外的查询参数client_id和client_secret，或接受在HTTP Basic auth header中的客户端ID和秘钥。如果客户端没有秘钥，则此请求中不会出现客户端身份验证。</p>
</blockquote>
<h4 id="验证刷新令牌授权"><a href="#验证刷新令牌授权" class="headerlink" title="验证刷新令牌授权"></a>验证刷新令牌授权</h4><p>在检查所有必需参数并在客户端被授予秘钥时验证客户端之后，授权服务器可以继续验证请求的其他部分。</p>
<p>然后，服务器检查刷新令牌是否有效，并且尚未过期。如果向私密客户端发出刷新令牌，则服务必须确保将请求中的刷新令牌发送给经过身份验证的客户端。</p>
<p>如果所有内容都检出，该服务可以生成访问令牌并进行响应。服务器可以在响应中发出新的刷新令牌，但是如果响应不包括新的刷新令牌，则客户端假定现有的刷新令牌仍然有效。</p>
<p>例<br>以下是服务将接收的示例刷新授权。</p>
<pre><code class="http">POST /oauth/token HTTP/1.1
Host: authorization-server.com

grant_type=refresh_token
&amp;refresh_token=xxxxxxxxxxx
&amp;client_id=xxxxxxxxxx
&amp;client_secret=xxxxxxxxxx
</code></pre>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--重定向URI]]></title>
      <url>/2018/07/13/oauth-guide-11/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>重定向网址是OAuth流程的重要组成部分。用户成功授权应用程序后，授权服务器将带着URL中的授权码或访问令牌将用户重定向回应用程序。由于重定向URL将包含敏感信息，因此服务不会将用户重定向到任意位置就显得至关重要。</p>
<p>确保用户仅被定向到适当位置的最佳方法是要求开发人员在创建应用程序时注册一个或多个重定向URL。在这些部分中，我们将介绍如何处理移动应用程序的重定向URL，如何验证重定向URL以及如何处理错误。</p>
<h3 id="重定向URI注册"><a href="#重定向URI注册" class="headerlink" title="重定向URI注册"></a>重定向URI注册</h3><p>为了确保服务的安全性，您必须要求开发人员为应用程序注册一个或多个重定向URL。授权服务器绝不能重定向到任何其他位置。注册新应用程序包括创建注册表单，以允许开发人员为其应用程序注册重定向URL。</p>
<p>如果攻击者可以在用户到达授权服务器之前操纵重定向URL，则可能导致服务器将用户重定向到恶意服务器，恶意服务器会将授权码发送给攻击者。对于没有client_secret的公共客户端，只需要client_id和授权码就可以获取访问令牌。如果攻击者可以获得授权码，则可以将其交换为公共客户端的访问令牌。这是授权服务器在应用程序注册期间就应该知道应用程序是公共还是私有的另一个重要原因。</p>
<h4 id="有效的重定向网址"><a href="#有效的重定向网址" class="headerlink" title="有效的重定向网址"></a>有效的重定向网址</h4><p>在构建表单以允许开发人员注册重定向URL时，您应该对他们输入的URL进行一些基本验证。</p>
<p>已注册的重定向URL可能包含查询字符串参数，但不得在fragment中包含任何内容。如果开发人员尝试注册包含fragment的重定向URL，则注册服务器应拒绝该请求。</p>
<p>请注意，对于原生和移动应用程序，该平台可能允许开发人员注册URL方案<code>myapp://</code>，然后可以在重定向URL中使用该方案。这意味着授权服务器应允许注册任意URL方案，以支持为原生应用程序注册重定向URL。</p>
<h4 id="按请求自定义"><a href="#按请求自定义" class="headerlink" title="按请求自定义"></a>按请求自定义</h4><p>通常，开发人员会认为他们需要能够在每个授权请求上使用不同的重定向URL，并且会尝试更改每个请求的查询字符串参数。这不是重定向URL的预期用途，授权服务器不应该允许这样的URL。服务器应拒绝任何具有与注册URL不完全匹配的重定向URL的授权请求。</p>
<p>如果客户端希望在重定向URL中包含特定于请求的数据，则可以使用“state”参数来存储在重定向用户之后将包括的数据。可以在state参数本身中对数据进行编码，也可以使用state参数作为会话ID来在服务器上存储状态。</p>
<h3 id="原生应用程序的重定向URI"><a href="#原生应用程序的重定向URI" class="headerlink" title="原生应用程序的重定向URI"></a>原生应用程序的重定向URI</h3><p>原生应用程序是安装在设备上的客户端，例如桌面应用程序或移动应用程序。在支持与安全性和用户体验相关的原生应用程序时，需要记住一些事项。</p>
<p>授权endpoint通常会将用户重定向回客户端注册的重定向URL。根据平台，应用程序可以声明URL模式，也可以注册启动应用程序的自定义URL方案。例如，iOS应用程序可以注册自定义协议，例如<code>myapp://</code>，然后使用redirect_uri <code>myapp://callback</code>。</p>
<h4 id="应用程序声明的https-URL重定向"><a href="#应用程序声明的https-URL重定向" class="headerlink" title="应用程序声明的https URL重定向"></a>应用程序声明的https URL重定向</h4><p>某些平台（从iOS 9开始的Android和iOS）允许应用程序覆盖特定的URL模式以启应用程序而不是Web浏览器。例如，应用程序可以注册<code>https://app.example.com/auth</code>，只要Web浏览器尝试重定向到该URL，操作系统就会启动应用程序。</p>
<p>如果操作系统支持声明URL，则应使用此方法。这允许操作系统保证应用程序的标识。如果操作系统不支持此操作，则应用程序必须使用自定义URL方案。</p>
<h4 id="自定义URL方案"><a href="#自定义URL方案" class="headerlink" title="自定义URL方案"></a>自定义URL方案</h4><p>大多数移动和桌面操作系统允许应用注册自定义URL方案，当从系统浏览器访问具有该方案的URL时，该方案将启动应用程序。</p>
<p>使用此方法，本机应用程序正常启动OAuth流，方法是使用标准授权码参数启动系统浏览器。唯一的区别是重定向URL将是具有应用程序自定义方案的URL。</p>
<p>当授权服务器发送打算将用户重定向到<code>myapp://callback#token=....</code>的Location header时，手机将启动应用程序，应用程序将能够恢复授权过程，从URL解析访问令牌并在内部存储它。</p>
<h4 id="自定义URL方案命名空间"><a href="#自定义URL方案命名空间" class="headerlink" title="自定义URL方案命名空间"></a>自定义URL方案命名空间</h4><p>由于没有集中注册URL方案的方法，因此应用程序必须尽力选择不会相互冲突的URL方案。</p>
<p>您的服务可以通过要求URL方案遵循特定模式来提供帮助，并且只允许开发人员注册与该模式匹配的自定义方案。</p>
<p>例如，Facebook根据应用的客户端ID为每个应用生成一个URL方案。例如，<code>fb00000000://</code>数字对应于应用程序的客户端ID。这提供了一种生成全局唯一URL方案的合理可靠方法，因为其他应用程序不太可能使用具有此模式的URL方案。</p>
<p>应用程序的另一个选项是将反向域名模式与应用程序发布者控制的域一起使用。这也可以由服务强制执行。</p>
<h3 id="重定向URI验证"><a href="#重定向URI验证" class="headerlink" title="重定向URI验证"></a>重定向URI验证</h3><p>有三种情况需要验证重定向网址。</p>
<ul>
<li>当开发人员将重定向URL注册为创建应用程序的一部分时</li>
<li>在授权请求中（授权码类型和隐式授权类型）</li>
<li>当应用程序交换访问令牌的授权码时</li>
</ul>
<h4 id="重定向URL注册"><a href="#重定向URL注册" class="headerlink" title="重定向URL注册"></a>重定向URL注册</h4><p>如创建应用程序中所述，该服务应允许开发人员在创建应用程序时注册一个或多个重定向URL。重定向URL的唯一限制是它不能包含fragment组件。该服务必须允许开发人员使用自定义URL方案注册重定向URL，以便在某些平台上支持应用程序。</p>
<h4 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h4><p>当应用程序启动OAuth流程时，它会将用户定向到您服务的授权endpoint。该请求将在URL中包含多个参数，包括重定向URL。</p>
<p>此时，授权服务器必须验证重定向URL，以确保请求中的URL与应用程序的一个已注册URL匹配。请求还将有一个client_id参数，因此服务应该根据该id查找重定向URL。攻击者完全有可能使用一个应用程序的客户端ID和攻击者的重定向URL来创建授权请求，这就是需要注册的原因。</p>
<p>服务应查找URL的完全匹配，并避免仅匹配特定URL的一部分。（如果需要自定义每个请求，客户端可以使用state参数。）简单的字符串匹配就足够了，因为无法根据请求自定义重定向URL。服务器需要做的就是检查请求中的重定向URL是否与开发人员在注册其应​​用程序时输入的重定向URL相匹配。</p>
<p>如果重定向URL不是已注册的重定向URL之一，则服务器必须立即显示指示此类的错误，而不是重定向用户。这样可以避免将授权服务器用作打开的重定向程序。</p>
<h4 id="授予访问令牌"><a href="#授予访问令牌" class="headerlink" title="授予访问令牌"></a>授予访问令牌</h4><p>令牌endpoint时用授权码交换访问令牌的的请求。此请求将包含重定向URL以及授权码。作为安全性的附加度量，服务器应验证此请求中的重定向URL是否与授权码的初始授权请求中包含的重定向URL完全匹配。如果重定向URL不匹配，则服务器会拒绝该请求并显示错误。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--范围]]></title>
      <url>/2018/07/13/oauth-guide-10/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>本章是对OAuth服务提供商的指导。</p>
<p>范围(scope)是一种限制应用访问用户数据的方法。与授予对用户帐户的完全访问权限相比，为应用程序提供一种方式，来限制他们代表用户访问和操作的范围，通常是一种更有效的方式。</p>
<p>某些应用仅使用OAuth来识别用户，因此他们只需要访问用户ID和基本配置文件信息。其他应用可能需要知道更敏感的信息，例如用户的生日，或者他们可能需要能够代表用户发布内容，或修改个人资料数据。如果用户确切知道应用程序可以和不能对他们的帐户做什么，他们将更愿意授权应用程序。范围是一种控制访问权限的方法，可帮助用户识别他们授予应用程序的权限。</p>
<h3 id="定义范围"><a href="#定义范围" class="headerlink" title="定义范围"></a>定义范围</h3><p>定义范围的好地方是分别定义读取与写入。这适用于Twitter，因为并非所有应用程序实际上都希望能够将内容发布到您的Twitter帐户，有些只需要访问您的个人资料信息。</p>
<p>定义服务范围时的挑战是不要因定义太多范围而被忽略。用户需要能够理解他们授予的授权范围，并且这将在列表中呈现给用户。当呈现给用户时，他们需要真正了解正在发生的事情。如果您为用户设计的过度复杂，他们可能会单击“确定”直到应用程序正常工作，并忽略任何警告。</p>
<h4 id="读与写"><a href="#读与写" class="headerlink" title="读与写"></a>读与写</h4><p>通常，在定义服务范围时，读取和写入访问是一个很好的起点。通常，对想要更新配置文件信息的应用程序，使用单独的访问控制来处理对用户的私有配置文件信息的读访问。</p>
<p>需要能够代表用户创建内容的应用程序（例如，将推文发布到用户的时间线的第三方Twitter应用程序），与仅需要读取用户的公共数据的应用程序相比，需要获得不同级别的访问权限。</p>
<h4 id="限制对敏感信息的访问"><a href="#限制对敏感信息的访问" class="headerlink" title="限制对敏感信息的访问"></a>限制对敏感信息的访问</h4><p>通常，对于不同安全级别的用户，服务将具有不同的配置。例如，GitHub有一个单独的范围，允许应用程序访问私有存储库。默认情况下，应用程序无权访问私有存储库，除非他们要求该范围，因此用户可以放心地知道他们选择的应用只能访问属于其组织的私有存储库。</p>
<p>GitHub提供了一个单独的范围，允许应用程序删除repos，因此用户可以放心，随机应用程序无法绕过这个范围删除其存储库。</p>
<p>Dropbox为应用程序提供了一种限制自己只能编辑单个文件夹中文件的方法。这为尝试使用Dropbox作为存储或同步机制的应用程序提供了一种方法，用户无需担心应用程序可能会读取其所有文件。</p>
<h4 id="通过功能选择性地启用访问"><a href="#通过功能选择性地启用访问" class="headerlink" title="通过功能选择性地启用访问"></a>通过功能选择性地启用访问</h4><p>范围的一个很好的用途是根据所需的功能选择性地启用对用户帐户的访问。例如，Google为其各种服务提供了一组范围，例如Google云端硬盘，Gmail，YouTube等。这意味着需要访问YouTube API的应用程序也不一定能够访问用户的Gmail帐户。</p>
<p>谷歌的API是有效使用范围的一个很好的例子。有关Google OAuth API支持的范围的完整列表，请访问<code>https://developers.google.com/oauthplayground/</code>上的 OAuth 2.0 Playground。</p>
<h4 id="限制对可结算资源的访问"><a href="#限制对可结算资源的访问" class="headerlink" title="限制对可结算资源的访问"></a>限制对可结算资源的访问</h4><p>如果您的服务提供的API可能会导致用户产生费用，那么设定范围是防止滥用此功能的应用程序的好方法。</p>
<p>例如，在提供使用许可内容的高级功能的情况下，提供用于聚合给定区域的人口统计数据的API。用户在使用服务时收取费用，费用取决于要查询的区域的大小。当用户登录使用完全不同的API部分的应用时，用户希望确保此应用无法使用人口统计信息API，因为这会导致该用户产生费用。在这种情况下，服务应定义一个特殊范围，例如“人口统计”。人口统计信息API应仅响应来自包含此范围的令牌的API请求。</p>
<p>在此示例中，人口统计信息API可以使用<a href="https://www.oauth.com/oauth2-servers/token-introspection-endpoint/" target="_blank" rel="noopener">令牌自解析端点</a>来查找对此令牌有效的范围列表。如果响应在范围列表中不包含“人口统计”，则端点将使用HTTP 403响应拒绝该请求。</p>
<h3 id="用户界面"><a href="#用户界面" class="headerlink" title="用户界面"></a>用户界面</h3><p>用户在授权应用程序时看到的界面需要清楚地显示应用程序请求的范围列表。用户可能不知道服务提供的范围的所有可能性，因此最好使该文本尽可能清晰明了，避免使用行话和缩写。</p>
<p>如果请求授予应用程序对用户帐户的完全访问权限，或访问其帐户的大部分内容，例如除了更改密码之外能够执行所有操作，则该服务应该非常清楚。例如，Dropbox授权用户界面上的第一句话是“示例OAuth应用程序希望访问Dropbox中的文件和文件夹”，其中包含“了解更多”链接，该链接指向帮助页面，该帮助页面准确描述了应用程序将具有哪些访问权限。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/dropbox.png" alt="dropbox"></p>
<p>Flickr授权界面显示用户在登录时授予应用程序的三件事，并清楚地显示应用程序不具有的权限。显示这一点的好处是，用户可以放心，他们授权的应用程序将无法进行潜在的破坏性操作。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/flickr.png" alt="flickr"></p>
<p>GitHub在提供有关用户授予范围的详细信息方面做得非常出色。请求的每个范围都会在页面上显示一个部分，其中包含名称，图标，突出显示是只读还是读写的简短说明，以及下拉列表以查看更详细的说明。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/github.png" alt="github"></p>
<p>Google为其所有服务提供单一授权终端，包括Gmail API，Google云端硬盘，Youtube等。其授权界面会在列表中显示每个范围，并包含一个“信息”图标，您可以点击该图标以获取有关特定内容的详细信息范围。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/google.png" alt="google"></p>
<p>单击信息图标会显示一个叠加层，详细描述此范围允许的内容。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/google-scope-popup.png" alt="google_scope"></p>
<p>您可以看到有多种方法可以为用户提供有关OAuth授权范围的信息，并且各种服务采用了截然不同的方法。在您定义范围时，请务必考虑应用程序的隐私和安全要求。</p>
<h3 id="复选框"><a href="#复选框" class="headerlink" title="复选框"></a>复选框</h3><p>虽然这是一个看似未充分利用的功能，但OAuth 2.0规范明确允许授权服务器授予访问令牌的范围小于应用程序的请求。这为一些有趣的可能性留下了空间。</p>
<p>在开始开发OAuth 2.0规范之前，OAuth 1已部署在Twitter上，Twitter应用程序生态系统正在迅速发展。在创建Twitter应用程序时，您可以选择您的应用程序是需要读取+写入权限还是只读取对用户帐户的访问权限。这是一种开发OAuth 2.0范围概念的机制。但是，这种实现是相当有限的，因为应用程序要么不请求写访问权限，要么用户可能只是拒绝该请求，如果他们不想授予应用程序写访问权限。</p>
<p>很快就开发了一种常见的Twitter应用程序的反模式，它只使用写访问权来发布推文给应用程序做广告。其中一个更臭名昭着的事件发生在2010年，当时应用程序“Twifficiency”声称“根据你的推特活动计算你的推特效率”，但这却很快失控。您将使用您的Twitter帐户登录该应用程序，它会抓取您过去的推文并对其进行分析。但是，它也自动发推文“我的Twifficiency得分是__％。你的是多少？”从而链接到第三方网站。许多人甚至不知道应用程序正在执行此操作，或者他们已授予此应用程序权限以发布到其帐户。这导致应用程序变成病毒式传播，因为使用该应用程序的任何人的关注者都会在他们的时间轴中看到它。</p>
<p>许多人对此感到不安，并在Twitter上大声抱怨。当时雅虎的开发人员Ben Ward更进一步，创建了一个可以解决这个问题的潜在用户界面的模型，并写了一篇简短的博客文章解释它。<code>https://benward.uk/blog/tumblr-968515729</code></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1ftfc4um00ij30lp0cftat.jpg" alt="twitter"></p>
<p>在帖子中，Ward描述了一个允许应用程序请求特定权限的用户界面，用户可以选择授予或不授予每个权限。这将允许用户登录应用程序但不允许其首先发布到其帐户。稍后，如果用户确实想要允许该应用发布，则该应用可以提供在Twitter上重新授权用户的机制。几个月后，沃德在Twitter被聘用。</p>
<p>这篇文章引发了一些参与OAuth规范开发的人们之间的讨论，这个讨论现在只存在于archive.org上的Google Buzz主题：<code>http://web.archive.org/web/20100823114908/</code>,<code>http://www.google.com/buzz/tantek/5YHAAmztLcD/t-Look-BenWard-schools-Twitter-on-OAuth</code>。</p>
<p>直到今天，Twitter仍然没有提供这种细粒度的授权。但是，其他服务已经开始实现类似的功能，在授权流程中为用户提供更多控制，而不是使其看起来像“单击确定以继续”对话框。</p>
<p>Facebook推出了最近的更新，为初始页面提供了一个简单的用户界面，允许用户点击编辑应用程序将被授予的范围，如下所示。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1ftfc74seznj30sc0f7jso.jpg" alt="facebook"></p>
<p>如果单击“编辑您提供的信息”，则会转到一个界面，列出应用程序请求的每个范围，您可以根据需要取消选中它们。在下面的屏幕截图中，我选择不允许应用程序查看我的朋友列表。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftfc7yma0rj30si0f775b.jpg" alt="facebook checkbox"></p>
<p>只有应用程序请求的范围才会出现在此列表中。这为用户提供了更好的体验，因为他们能够保持控制并更好地了解应用程序如何使用其帐户。</p>
<p>FitBit跟踪用户健康的许多方面，例如步数，心率，消耗的食物和饮料，睡眠质量，体重等。FitBit API对第三方应用程序提供对所有这些数据的访问。由于许多第三方应用程序只会读取或写入某些类型的数据，FitBit会提供精细的范围，以便用户只能授予对其配置文件的某些部分的访问权限。</p>
<p>FitBit的授权页面（如下所示）允许用户有选择地授予或拒绝访问应用程序请求的每个特定范围。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftfcao2nejj30pw0r4n14.jpg" alt="fitbit"></p>
<p>GitHub 在2013 年的博客文章中描述了他们计划允许用户编辑范围，但截至2018年，依旧没有后续跟进。</p>
<p>使用户能够选择授予哪些范围是让人们对使用第三方应用感到更舒服的好方法。每个范围旁边加复选框就足够了，或者您可以将控件移动到像Facebook这样的单独屏幕。您需要确保在发送访问令牌响应时，它包括用户所授予的范围列表，而不是应用程序请求的。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--授权]]></title>
      <url>/2018/07/13/oauth-guide-9/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>本章是对OAuth服务提供商的指导。</p>
<p>授权界面是用户在授予应用程序访问其帐户时看到的页面。以下部分介绍如何构建授权页面，界面中包含哪些组件以及如何最好地向用户显示界面。</p>
<p>在实施OAuth服务时，您正在使开发人员能够构建利用您的平台的应用程序，允许应用程序访问并可能修改私有用户内容，或代表用户行事。因此，您需要确保为用户提供尽可能多的信息以保护其帐户，并确保他们了解应用程序对其帐户执行的操作。</p>
<h3 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h3><p>客户端会将用户的浏览器定向到授权服务器以开始OAuth流程。客户端可以使用授权码授予类型或隐式授权。除了response_type参数指定的授权类型外，请求还有许多其他参数来指示请求的细节。</p>
<p><a href="http://seanthefish.com/2018/06/29/oauth-guide-2/">OAuth 2.0客户端</a>描述了客户端如何为您的服务构建授权URL。授权服务器第一次看到用户申请此授权请求时，将使用客户端设置的查询参数将用户定向到服务器。此时，授权服务器将需要验证请求并提供授权接口，允许用户批准或拒绝该请求。</p>
<h4 id="请求参数"><a href="#请求参数" class="headerlink" title="请求参数"></a>请求参数</h4><p>以下参数用于开始授权请求。例如，如果授权服务器URL是<code>https://authorization-server.com/auth</code>, 客户端将创建如下的URL并将用户的浏览器指向它：</p>
<pre><code class="html">https://authorization-server.com/auth?response_type=code
&amp;client_id=29352735982374239857
&amp;redirect_uri=https://example-app.com/callback
&amp;scope=create+delete
&amp;state=xcoivjuywkdkhvusuye3kch
</code></pre>
<blockquote>
<p><strong>response_type</strong><br>response_type将设置为code，表示应用程序希望在成功时收到授权码。</p>
<p><strong>client_id</strong><br>client_id是应用程序的公共标识符。</p>
<p><strong>redirect_uri （可选的）</strong><br>redirect_uri不规范所要求的，但你的服务应该需要它。此URL必须与开发人员在创建应用程序时注册的其中一个URL匹配，如果请求不匹配，授权服务器应拒绝该请求。</p>
<p><strong>scope （可选的）</strong><br>请求可以具有一个或多个scope值，指示应用程序请求的附加访问。授权服务器需要向用户显示请求的scope。</p>
<p><strong>state （推荐的）</strong><br>state应用程序使用该参数来存储特定于请求的数据和/或防止CSRF攻击。授权服务器必须将未修改的state值返回给应用程序。</p>
</blockquote>
<h4 id="授予类型"><a href="#授予类型" class="headerlink" title="授予类型"></a>授予类型</h4><p>当客户端应用程序期望授权码作为响应时，授权码授予类型将与密钥和公共客户端一起工作。要启动授权码授予，客户端将使用查询参数response_type=code以及其他所需参数将用户的浏览器定向到授权服务器。</p>
<h4 id="验证授权请求"><a href="#验证授权请求" class="headerlink" title="验证授权请求"></a>验证授权请求</h4><p>授权服务器必须首先验证client_id请求中的对应的有效的应用程序。</p>
<p>如果您的服务器允许应用程序注册多个重定向URL，则验证重定向URL有两个步骤。如果请求包含redirect_uri参数，则服务器必须确认它是此应用程序的有效重定向URL。如果redirect_uri请求中没有参数，并且只注册了一个URL，则服务器使用先前注册的重定向URL。否则，如果请求中没有重定向URL，并且没有注册重定向URL，就将会返回一个错误。</p>
<p>如果client_id无效，服务器应立即拒绝请求并向用户显示错误。</p>
<h4 id="无效的重定向网址"><a href="#无效的重定向网址" class="headerlink" title="无效的重定向网址"></a>无效的重定向网址</h4><p>如果授权服务器检测到重定向URL有问题，则需要通知用户该问题。由于多种原因，重定向网址可能无效，包括：</p>
<ul>
<li>缺少重定向URL参数</li>
<li>重定向URL参数无效，例如，如果它是不解析为URL的字符串</li>
<li>重定向URL与应用程序的已注册重定向URL之一不匹配</li>
</ul>
<p>在这些情况下，授权服务器应向用户显示错误，通知他们问题。服务器不得将用户重定向回应用程序。这避免了所谓的“<a href="https://oauth.net/advisories/2014-1-covert-redirect/" target="_blank" rel="noopener">开放重定向器攻击</a>”。如果已注册重定向URL，则服务器应仅将用户重定向到重定向URL。</p>
<h4 id="其他错误"><a href="#其他错误" class="headerlink" title="其他错误"></a>其他错误</h4><p>通过将用户重定向到重定向URL，并使用查询字符串中的错误代码来处理所有其他错误。有关如何响应错误的详细信息，请参阅“<a href="https://www.oauth.com/oauth2-servers/authorization/the-authorization-response/" target="_blank" rel="noopener">授权响应</a>”部分。</p>
<p>如果请求缺少response_type参数，或者该参数的值是除了code和token之外的任何内容，则服务器会返回invalid_request错误。</p>
<p>由于授权服务器可能要求客户端指定它们是公共的还是机密的，因此它可以拒绝不允许的授权请求。例如，如果客户端指定它们是机密客户端，则服务器可以拒绝使用令牌授权类型的请求。拒绝时，请使用错误代码unauthorized_client。</p>
<p>如果存在无法识别的scope值，授权服务器应拒绝该请求。在这种情况下，服务器可以使用invalid_scope错误代码重定向到回调URL 。</p>
<p>授权服务器需要存储此请求的“state”值，以便将其包含在访问令牌响应中。服务器不得修改或对state值包含的内容做出任何假设，因为它纯粹是为了客户端的便利。</p>
<h3 id="用户登录"><a href="#用户登录" class="headerlink" title="用户登录"></a>用户登录</h3><p>用户在单击应用程序的“登录”或“连接”按钮后将看到的第一件事是您的授权服务器UI。由授权服务器决定是否在每次访问授权屏幕时要求用户登录，或者让用户登录一段时间。如果授权服务器要在请求之间记住用户，那么它将需要请求用户在将来访问时授权该应用程序。</p>
<p>通常像Twitter或Facebook这样的网站希望他们的用户在大多数时间都是签名的，因此他们为他们的授权屏幕提供了一种方式，通过不要求他们每次登录来为用户提供简化的体验。但是，根据服务以及第三方应用程序的安全要求，可能需要或允许开发人员选择要求用户在每次访问授权屏幕时登录。</p>
<p>在Google的API中，应用程序可以添加prompt=login到授权请求，这会导致授权服务器在显示授权提示之前强制用户再次登录。</p>
<p>在任何情况下，如果用户已退出，或者在您的服务上还没有帐户，则需要为他们提供在此屏幕上登录或创建帐户的方法。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/twitter_logged_out_auth_screen.png" alt="Twitter的授权屏幕的退出视图"></p>
<p>因为OAuth 2.0规范中未指定，您可以按照您希望的方式对用户进行身份验证。大多数服务使用传统的用户名/密码登录来验证其用户，但这绝不是解决问题的唯一方法。在企业环境中，常见的技术是使用SAML（一种基于XML的身份验证标准）来利用组织中的现有身份验证机制，同时避免创建另一个用户名/密码数据库。</p>
<p>一旦用户使用授权服务器进行身份验证，它就可以继续处理授权请求并将用户重定向回应用程序。通常，服务器将认为成功登录也意味着用户授权该应用程序。在这种情况下，具有登录提示的授权页面将需要包括描述以下事实的文本：通过登录，用户正在批准该授权请求。这将导致以下用户流程。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/github_create_new_application_1.png" alt="登录和未登录的用户流程"></p>
<p>如果授权服务器需要通过SAML或其他内部系统对用户进行身份验证，则用户流程将如下所示</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/okta_oauth-diagrams_2.png" alt="用于单独验证服务器的用户流"></p>
<p>在此流程中，用户在登录后被定向回授权服务器，在那里他们看到授权请求，就像他们已经登录一样。</p>
<h3 id="授权接口"><a href="#授权接口" class="headerlink" title="授权接口"></a>授权接口</h3><p>授权界面是用户在收到来自第三方应用程序的授权请求时将看到的屏幕。由于第三方应用程序会要求用户授予某种级别的访问权限，因此您需要确保用户在授权应用程序权限时做出明智决策所需的所有信息。授权接口通常具有以下组件：</p>
<h4 id="网站名称和logo"><a href="#网站名称和logo" class="headerlink" title="网站名称和logo"></a>网站名称和logo</h4><p>该服务应该易于用户识别，因为他们需要知道他们授予哪些服务访问权限。但是，您确定主页上的网站应与授权界面一致。通常，这通过在屏幕的一定的位置显示应用程序名称和logo，或在整个网站上使用一致的颜色方案来完成。</p>
<h4 id="用户识别"><a href="#用户识别" class="headerlink" title="用户识别"></a>用户识别</h4><p>如果用户已登录，则应向用户指明。这可能就像在屏幕的右上角显示他们的名字和照片一样，就像在网站的其他部分一样。</p>
<p>重要的是，用户知道他们当前登录的帐户，以防他们管理多个帐户，以便他们不会错误地授权不同的用户帐户。</p>
<h5 id="申请细节"><a href="#申请细节" class="headerlink" title="申请细节"></a>申请细节</h5><p>授权接口应清楚地标识发出请求的应用程序。除了开发人员提供的应用程序名称之外，通常还应该显示网站和应用程序的logo，这是开发人员注册应用程序时收集的信息。我们在<a href="http://seanthefish.com/2018/07/08/oauth-guide-7/">客户端注册</a>中详细讨论了这一点。</p>
<h4 id="要求的范围"><a href="#要求的范围" class="headerlink" title="要求的范围"></a>要求的范围</h4><p>应该向用户清楚地显示授权请求中提供的范围值。范围值通常是表示特定访问的短字符串，因此应向用户显示更易于阅读的版本。</p>
<p>例如，如果服务将“私有”范围定义为对私有配置文件数据的读取访问权限，则授权服务器应该说“此应用程序将能够查看您的私有配置文件数据”。如果范围明确允许写入访问，也应该在描述中标识，例如“此应用程序将能够编辑您的配置文件数据”。</p>
<p>如果没有范围，但您的服务仍然授予对用户帐户的一些基本访问级别，则应该包含描述应用程序将访问的内容的消息。如果省略范围意味着应用程序获得的唯一内容是用户标识，则可以包含一条消息，以表示“此应用程序希望您登录”。</p>
<p>有关如何在服务中有效使用范围的更多信息，请参阅<a href="https://www.oauth.com/oauth2-servers/scope/" target="_blank" rel="noopener">范围</a>。</p>
<h4 id="请求的或有效的生命周期"><a href="#请求的或有效的生命周期" class="headerlink" title="请求的或有效的生命周期"></a>请求的或有效的生命周期</h4><p>授权服务器必须决定授权的有效期，访问令牌的持续时间以及刷新令牌的持续时间。</p>
<p>大多数服务不会自动使授权失效，而是希望用户定期查看和撤消对他们不再想要使用的应用的访问权限。但是，默认情况下，某些服务提供有限的令牌生存期，并允许应用程序请求更长的持续时间，或强制用户在授权过期后重新授权应用程序。</p>
<p>无论您对授权的有效期做出何种决定，都应该向用户明确说明应用程序能够代表用户执行多长时间。这可能是一个句子，加单的表明：“这个应用程序将能够访问您的帐户，直到您撤销访问”或者“这个应用程序将能够访问您的帐户，时效为一个星期。”关于令牌生命周期的更多信息请参见<a href="https://www.oauth.com/oauth2-servers/access-tokens/access-token-lifetime/" target="_blank" rel="noopener">访问令牌生命周期</a>。</p>
<h4 id="允许否认"><a href="#允许否认" class="headerlink" title="允许否认"></a>允许否认</h4><p>最后，授权服务器应该向用户提供两个按钮，以允许或拒绝该请求。如果用户未登录，则应提供登录提示而不是“允许”按钮。</p>
<p>如果用户批准该请求，则授权服务器将生成访问令牌并使用令牌信息重定向到应用程序。如果用户单击“拒绝”，则服务器会重定向到应用程序，并在URL中显示错误代码。</p>
<h3 id="授权响应"><a href="#授权响应" class="headerlink" title="授权响应"></a>授权响应</h3><p>根据授权类型，授权服务器将使用授权码或访问令牌进行响应。</p>
<h4 id="授权码响应"><a href="#授权码响应" class="headerlink" title="授权码响应"></a>授权码响应</h4><p>如果请求有效并且用户授予授权请求，则授权服务器生成授权码并将用户重定向回应用程序，将代码和先前的“state”值添加到重定向URL。</p>
<h4 id="生成授权码"><a href="#生成授权码" class="headerlink" title="生成授权码"></a>生成授权码</h4><p>授权码必须在颁发后不久到期。OAuth 2.0规范建议最长生命周期为10分钟，但实际上，大多数服务设置的到期时间要短得多，大约30-60秒。授权代码本身可以是任意长度，但应记录代码的长度。</p>
<p>因为授权代码是短暂的并且是单次使用的，所以它们是实现自编码的很好的候选者。使用此技术，您可以避免将授权代码存储在数据库中，而是将所有必要的信息编码到代码本身中。您可以使用服务器端环境的内置加密库，也可以使用JSON Web Signature（JWS）等标准。由于此字符串只需要您的授权服务器可以理解，因此不需要使用JWS等标准来实现此字符串。也就是说，如果您没有可以轻松访问的已经可用的加密库，JWS是一个很好的候选者，因为有许多语言的库可用。</p>
<p>需要与授权代码关联的信息如下。</p>
<blockquote>
<p><strong>client_id</strong><br>请求此代码的客户端ID（或其他客户端标识符）</p>
<p><strong>redirect_uri</strong><br>使用的重定向网址。需要存储，因为访问令牌请求必须包含相同的重定向URL，以便在发出访问令牌时进行验证。</p>
<p><strong>用户信息(User info)</strong><br>用于标识此授权代码所针对的用户的某种方式，例如用户ID。</p>
<p><strong>到期日期(Expiration Date)</strong><br>代码需要包含到期日期，以便使它能只持续很短的时间。</p>
<p><strong>唯一ID(Unique ID)</strong><br>代码需要其自己的某种ID，以便能够检查代码之前是否已被使用过。数据库ID或随机字符串就足够了。</p>
</blockquote>
<p>通过创建JWS令牌或生成随机字符串并将关联信息存储在数据库中生成授权码后，您需要将用户重定向到指定的应用程序重定向URL。要添加到重定向URL的查询字符串的参数如下：</p>
<blockquote>
<p><strong>code</strong><br>此参数包含客户端稍后将为访问令牌交换的授权码。</p>
<p><strong>state</strong><br>如果初始请求包含state参数，则响应还必须包含请求中的确切值。客户端将使用此将此响应与初始请求相关联。</p>
</blockquote>
<p>例如，授权服务器通过发送以下HTTP响应来重定向用户。</p>
<pre><code class="http">HTTP/1.1 302 Found
Location: https://oauth2client.com/redirect?code=g0ZGZmNjVmOWI&amp;state=dkZmYxMzE2
</code></pre>
<h4 id="隐式授权类型响应"><a href="#隐式授权类型响应" class="headerlink" title="隐式授权类型响应"></a>隐式授权类型响应</h4><p>使用隐式授权，授权服务器立即生成访问令牌，并使用令牌和其他参数重定向到回调URL。有关生成访问令牌的详细信息以及响应中所需参数的详细信息，请参阅访问<a href="https://www.oauth.com/oauth2-servers/access-tokens/access-token-response/" target="_blank" rel="noopener">令牌响应</a>。</p>
<p>例如，授权服务器通过发送以下HTTP响应来重定向用户（出于显示目的，需要额外的换行符）。</p>
<pre><code class="http">HTTP/1.1 302 Found
Location: https://example-app.com/redirect#access_token=MyMzFjNTk2NTk4ZTYyZGI3
 &amp;state=dkZmYxMzE2
 &amp;token_type=bearer
 &amp;expires_in=86400
</code></pre>
<h5 id="错误响应"><a href="#错误响应" class="headerlink" title="错误响应"></a>错误响应</h5><p>在两种情况下，授权服务器应直接显示错误消息，而不是将用户重定向到应用程序：如果client_id无效，或者redirect_uri无效。在所有其他情况下，可以将用户重定向到应用程序的重定向URL以及描述错误的查询字符串参数。</p>
<p>重定向到应用程序时，服务器会将以下参数添加到重定向URL：</p>
<blockquote>
<p><strong>error</strong><br>通常是以下列表中的一个ASCII错误代码：</p>
<ul>
<li><em>invalid_request</em> - 请求缺少参数，包含无效参数，多次包含参数，或者无效。</li>
<li><em>access_denied</em> - 用户或授权服务器拒绝该请求</li>
<li><em>unauthorized_client</em> - 不允许客户端使用此方法请求授权码，例如，如果机密客户端尝试使用隐式授权类型。</li>
<li><em>unsupported_response_type8</em> - 服务器不支持使用此方法获取授权代码，例如，如果授权服务器从未实现隐式授权类型。</li>
<li><em>invalid_scope</em> - 请求的范围无效或未知。</li>
<li><em>server_error</em> - 服务器可以使用此错误代码重定向，而不是向用户显示500内部服务器错误页面。</li>
<li><em>temporarily_unavailable</em> - 如果服务器正在进行维护或不可用，则可以返回此错误代码，而不是使用503 Service Unavailable状态代码进行响应。</li>
</ul>
<p><strong>error_description</strong><br>授权服务器可以可选地包括错误的描述。此参数旨在供开发人员理解错误，而不是要向最终用户显示。除双引号和反斜杠外，此参数的有效字符是ASCII字符集，特别是十六进制代码20-21,23-5B和5D-7E。</p>
<p><strong>error_uri</strong><br>服务器还可以将URL返回到人类可读的网页，其中包含有关错误的信息。这是为了让开发人员获得有关错误的更多信息，而不是要向最终用户显示。</p>
<p><strong>state</strong><br>如果请求包含状态参数，则错误响应还必须包含请求中的确切值。客户端可以使用它将此响应与初始请求相关联。</p>
</blockquote>
<p>例如，如果用户拒绝授权请求，服务器将构造以下URL并发送HTTP重定向响应（如下所示）（URL中的换行符用于说明目的）。</p>
<pre><code class="http">HTTP/1.1 302 Found
Location: https://example-app.com/redirect?error=access_denied
 &amp;error_description=The+user+denied+the+request
 &amp;error_uri=https%3A%2F%2Foauth2server.com%2Ferror%2Faccess_denied
 &amp;state=wxyz1234
</code></pre>
<h3 id="安全考虑因素"><a href="#安全考虑因素" class="headerlink" title="安全考虑因素"></a>安全考虑因素</h3><p>以下是构建授权服务器时应考虑的一些已知问题。</p>
<p>除了此处列出的注意事项外，<a href="https://tools.ietf.org/html/rfc6819" target="_blank" rel="noopener">OAuth 2.0线程模型和安全注意事项草案</a>中还提供了更多信息。</p>
<h4 id="网络钓鱼攻击"><a href="#网络钓鱼攻击" class="headerlink" title="网络钓鱼攻击"></a>网络钓鱼攻击</h4><p>针对OAuth服务器的一种潜在攻击是网络钓鱼攻击。这是攻击者创建一个看起来与服务授权页面相同的网页的地方，该页面通常包含用户名和密码字段。然后，通过各种手段，攻击者可以诱骗用户访问该页面。除非用户可以检查浏览器的地址栏，否则该页面可能看起来与真正的授权页面相同，并且用户可以输入他们的用户名和密码。</p>
<p>攻击者可以尝试诱骗用户访问伪造服务器的一种方法是将此网络钓鱼页面嵌入到本机应用程序中的嵌入式Web视图中。由于嵌入式Web视图不显示地址栏，因此用户无法直观地确认它们位于合法站点上。遗憾的是，这在移动应用程序中很常见，并且开发人员通常希望通过整个登录过程将用户保留在应用程序中来提供更好的用户体验。某些OAuth提供商鼓励第三方应用程序打开Web浏览器或启动提供程序的本机应用程序，而不是允许它们在Web视图中嵌入授权页面。</p>
<h5 id="对策"><a href="#对策" class="headerlink" title="对策"></a>对策</h5><p>确保通过https提供授权服务器以避免DNS欺骗。</p>
<p>授权服务器应该向开发人员介绍网络钓鱼攻击的风险，并且可以采取措施防止该页面嵌入到本机应用程序或iframe中。</p>
<p>应该让用户了解网络钓鱼攻击的危险，并且应该教导用户最佳实践，例如只访问他们信任的应用程序，并定期查看应用程序列表，对不再使用的应用程序授权撤销的访问权限。</p>
<p>该服务可能希望在允许其他用户使用该应用程序之前验证第三方应用程序。Instagram和Dropbox等服务目前都是这样做的，在初始创建应用程序时，该应用程序只能由开发人员或其他白名单用户帐户使用。应用程序提交审批并进行审核后，可以由该服务的整个用户群使用。这使服务有机会检查应用程序如何与服务交互。</p>
<h4 id="点击劫持"><a href="#点击劫持" class="headerlink" title="点击劫持"></a>点击劫持</h4><p>在点击劫持攻击中，攻击者创建了一个恶意网站，在该网站中，攻击者网页上方的透明iframe中加载了授权服务器URL。攻击者的网页堆放在iframe下方，并且有一些看似无害的按钮或链接，非常小心地放在授权服务器的确认按钮下面。当用户单击误导性可见按钮时，他们实际上是单击授权页面上的隐藏按钮，从而授予对攻击者应用程序的访问权限。这允许攻击者欺骗用户在他们不知情的情况下授予访问权限。</p>
<h5 id="对策-1"><a href="#对策-1" class="headerlink" title="对策"></a>对策</h5><p>通过确保授权URL始终直接在本机浏览器中加载，而不是嵌入在iframe中，可以防止这种攻击。较新的浏览器可以让授权服务器设置HTTP标头，X-Frame-Options旧版浏览器可以使用常见的Javascript“框架破坏”技术。</p>
<h4 id="重定向URL操作"><a href="#重定向URL操作" class="headerlink" title="重定向URL操作"></a>重定向URL操作</h4><p>攻击者可以使用属于已知正常应用程序的客户端ID构建授权URL，将重定向URL设置为攻击者控制下的URL。如果授权服务器未验证重定向URL，并且攻击者使用“令牌”响应类型，则用户将使用URL中的访问令牌返回到攻击者的应用程序。如果客户端是公共客户端，并且攻击者拦截授权码，则攻击者还可以通过授权码交换访问令牌。</p>
<p>另一个类似的攻击是攻击者可以欺骗用户的DNS，并且注册的重定向不是https URL。这将允许攻击者伪装成有效的重定向URL，并以这种方式窃取访问令牌。</p>
<p>“打开重定向”攻击是指授权服务器不需要重定向URL的完全匹配，而是允许攻击者构建将重定向到攻击者网站的URL。无论这是否最终被用于窃取授权码或访问令牌，这也是一个危险，因为它可以用于发起其他无关的攻击。有关Open Redirect攻击的更多详细信息，请访问<code>https://oauth.net/advisories/2014-1-covert-redirect/</code>。</p>
<h4 id="对策-2"><a href="#对策-2" class="headerlink" title="对策"></a>对策</h4><p>授权服务器必须要求应用程序注册一个或多个重定向URL，并且重定向到先前注册的URL必须完全匹配。</p>
<p>授权服务器还应要求所有重定向URL均为https。由于这有时会给开发人员带来负担，特别是在应用程序运行之前，在应用程序处于“开发阶段”时允许非https重定向URL并且只能由开发人员访问，然后要求在发布应用程序之前，重定向URL应更改为https URL。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--客户端注册]]></title>
      <url>/2018/07/13/oauth-guide-8/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>本章是对OAuth服务提供商的指导。</p>
<h3 id="注册新的应用程序"><a href="#注册新的应用程序" class="headerlink" title="注册新的应用程序"></a>注册新的应用程序</h3><p>当开发人员访问您的网站时，他们需要一种方法来创建新的应用程序并获取凭据。通常，您可以让他们在创建应用程序之前创建开发人员帐户，或代表其组织创建帐户。</p>
<p>虽然OAuth 2.0规范不要求您在授予凭据之前特别收集任何应用程序信息，但大多数服务会在发出client_id和client_secret之前收集有关应用程序的基本信息，例如应用程序名称和图标。但是，为了安全起见，您需要开发人员为应用程序注册一个或多个重定向URL，这一点非常重要。重定向URL中对此进行了更详细的说明。</p>
<p>通常，服务收集有关应用程序的信息，例如：</p>
<ul>
<li>应用名称</li>
<li>应用程序的图标</li>
<li>应用程序主页的URL</li>
<li>应用程序的简短描述</li>
<li>应用程序隐私策略的链接</li>
<li>重定向网址列表</li>
</ul>
<p>下面是GitHub用于注册应用程序的界面。在其中，它们收集应用程序名称，主页URL，回调URL和可选描述。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/github_create_new_application_1.png" alt="在Github上创建一个新的应用程序"><br>在GitHub上创建一个新的应用程序</p>
<p>最好向开发人员展示您从中收集的信息是显示给最终用户，还是仅供内部使用。</p>
<p>Foursquare的应用程序注册页面要求提供类似的信息，但他们还要求提供简短的标语和隐私政策URL。这些在授权提示中显示给用户。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/foursquare_create_new_application.png" alt="在Foursquare上创建一个新的应用程序"><br>在Foursquare上创建一个新的应用程序</p>
<p>由于使用隐式授权类型的安全性考虑因素，某些服务（例如Instagram）默认情况下会禁用新应用程序的此授权类型，并要求开发人员在应用程序的设置中明确启用它，如下所示。或者，该服务可以使开发人员选择他们正在创建的应用程序类型（公共或私有），并仅向私有应用程序发出密钥。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/instagram_create_new_application.png" alt="在Instagram上创建一个新的应用程序"><br>在Instagram上创建一个新的应用程序</p>
<p>Instagram还提供了一个说明，指示开发人员不要用可能使应用程序看起来来自Instagram的单词命名他们的应用程序。这也是包含API使用条款链接的优势。</p>
<h3 id="客户端ID和秘钥"><a href="#客户端ID和秘钥" class="headerlink" title="客户端ID和秘钥"></a>客户端ID和秘钥</h3><p>此时，您已构建了应用程序注册页面，您已准备好让开发人员注册该应用程序。当开发人员注册应用程序时，您需要生成客户端ID和可选的密钥。在生成这些字符串时，在安全性和美学方面需要考虑一些重要的事项。</p>
<h4 id="客户端ID"><a href="#客户端ID" class="headerlink" title="客户端ID"></a>客户端ID</h4><p>client_id是应用程序的公共标识符。即使它是公开的，最好是第三方无法猜测，因此许多实现使用类似32字符的十六进制字符串。它在授权服务器处理的所有客户端中也必须是唯一的。如果客户端ID是可猜测的，则可以更轻松地针对任意应用程序进行网络钓鱼攻击。</p>
<p>以下是来自支持OAuth 2.0的服务的客户端ID的一些示例：</p>
<ul>
<li>Foursquare： ZYDPLLBWSK3MVQJSIYHB1OR2JXCY0X2C5UJ2QAR2MAAIT5Q</li>
<li>Github： 6779ef20e75817b79602</li>
<li>Google： 292085223830.apps.googleusercontent.com</li>
<li>Instagram： f2a1ed52710d4533bde25be6da03b6e3</li>
<li>SoundCloud： 269d98e4922fb3895e9ae2108cbb5064</li>
<li>Windows Live： 00000000400ECB04</li>
</ul>
<p>如果开发人员正在创建“公共”应用程序（移动或单页应用程序），那么您根本不应该向应用程序发出client_secret。这是确保开发人员不会意外地将其包含在应用程序中的唯一方法。如果它不存在，它就不会泄露！</p>
<p>因此，您应该询问开发人员在启动时创建的应用程序类型。您可以向他们提供以下选项，并仅为“Web服务器”应用程序发出密钥。</p>
<ul>
<li>Web服务器应用程序</li>
<li>基于浏览器的应用</li>
<li>原生应用</li>
<li>移动应用</li>
</ul>
<p>当然，没有什么可以阻止开发人员选择错误的选项，但是通过主动询问开发人员将使用哪种类型的应用程序，您可以帮助减少泄露秘密的可能性。了解正在创建哪种类型的应用程序的另一个原因是您需要注册公共客户端的重定向URL，但是对于私有客户端，重定向URL的注册在技术上是可选的。有关详细信息，请参阅<a href="https://www.oauth.com/oauth2-servers/redirect-uris/redirect-uri-registration/" target="_blank" rel="noopener">重定向URI注册</a>。</p>
<h4 id="客户端密钥"><a href="#客户端密钥" class="headerlink" title="客户端密钥"></a>客户端密钥</h4><p>client_secret是只有应用程序和授权服务器知道的密钥。它必须足够随机以至于无法猜测，这意味着您应该避免使用常见的UUID库，这些库通常会考虑生成它的服务器的时间戳或MAC地址。生成安全密钥的一个好方法是使用加密安全库生成256位值并将其转换为十六进制表示。</p>
<p>在PHP中，您可以使用OpenSSL函数生成随机字节并转换为十六进制字符串：</p>
<pre><code class="php">bin2hex(openssl_random_pseudo_bytes(32));
</code></pre>
<p>或者在PHP 7及更高版本中，random_bytes可以使用内置函数。</p>
<p>在Ruby中，您可以使用SecureRandom库生成十六进制字符串：</p>
<pre><code class="ruby">require &#39;securerandom&#39;
SecureRandom.hex(32)
</code></pre>
<p>开发人员永远不要将其client_secret公开（基于移动或基于浏览器的）应用程序包含在内是至关重 为了帮助开发人员避免意外地执行此操作，最好使客户端密钥在视觉上与ID不同。这种方式当开发人员复制并粘贴ID和密钥时，很容易识别哪个是哪个。通常使用较长的字符串来表示密钥是一种很好的方式来表明这一点，或者在密钥前加上“密钥”或“私密”。</p>
<h4 id="存储和显示客户端ID和密钥"><a href="#存储和显示客户端ID和密钥" class="headerlink" title="存储和显示客户端ID和密钥"></a>存储和显示客户端ID和密钥</h4><p>对于每个注册的应用程序，您需要存储公共client_id和私有client_secret。因为这些本质上等同于用户名和密码，所以不应以纯文本格式存储密钥，而应仅存储加密或散列版本，以帮助降低秘密泄露的可能性。</p>
<p>当您发出客户端ID和密钥时，您需要将它们显示给开发人员。大多数服务为开发人员提供了一种检索现有应用程序密钥的方法，尽管有些服务只显示一次密钥并要求开发人员立即自行存储。如果您只显示一次密钥，则可以存储它的散列版本以避免存储明文密码。</p>
<p>如果您选择稍后可以向开发人员显示的方式存储密钥，则在披露密钥时应采取额外的预防措施。保护密钥的常用方法是在开发人员尝试检索密钥时插入“重新授权”提示。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/github_confirm_password.png" alt="GitHub重新授权提示"><br>GitHub在进行敏感更改时要求确认您的密码</p>
<p>该服务要求开发人员在泄密之前确认其密码。当您尝试查看或更新敏感信息时，这在Amazon或GitHub的网站中很常见。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/dropbox_show_secret.png" alt="Dropbox&#39;显示秘密&#39;确认"><br>Dropbox会隐藏秘密，直到被点击为止</p>
<p>此外，在开发人员点击“显示”之前模糊应用程序详细信息页面上的密钥是防止意外泄露秘密的好方法。</p>
<h3 id="删除应用程序和撤消秘钥"><a href="#删除应用程序和撤消秘钥" class="headerlink" title="删除应用程序和撤消秘钥"></a>删除应用程序和撤消秘钥</h3><p>开发人员需要一种方法来删除（或至少停用）他们的应用程序。为开发人员提供一种方法来撤销秘钥，并为其应用程序生成新的客户端密钥也是一个好主意。</p>
<h4 id="删除应用程序"><a href="#删除应用程序" class="headerlink" title="删除应用程序"></a>删除应用程序</h4><p>当开发人员删除应用程序时，该服务应通知开发人员删除应用程序的后果。例如，GitHub告诉开发人员将撤销所有访问令牌，以及将受影响的用户数量。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1ftfbpd4ohnj30d106e0tk.jpg" alt="GitHub删除应用程序提示"><br>GitHub要求确认删除申请</p>
<p>删除应用程序应立即撤消颁发给应用程序的所有访问令牌和其他凭据，例如待处理的授权代码和刷新令牌。</p>
<h4 id="撤销秘钥"><a href="#撤销秘钥" class="headerlink" title="撤销秘钥"></a>撤销秘钥</h4><p>该服务应该为开发人员提供重置客户端密钥的方法。在秘钥被意外暴露的情况下，开发人员需要一种方法来确保可以撤销旧秘密。撤销秘密不一定会使用户的访问令牌无效，因为如果开发人员想要使所有用户令牌无效，他们也可以随时删除该应用程序。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1ftfbqqm2vzj30d607kq40.jpg" alt="GitHub重置客户端密码提示"><br>GitHub要求确认重置应用程序的秘钥</p>
<p>重置密钥应该保持所有现有的访问令牌都处于活动状态。但是，这确实意味着使用旧秘钥的任何已部署应用程序将无法使用旧秘钥刷新访问令牌。部署的应用程序需要在能够使用刷新令牌之前更新其秘密。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--进行身份验证请求]]></title>
      <url>/2018/07/13/oauth-guide-7/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>无论您使用哪种授权类型，或者您是否使用了客户端密钥，您现在都可以使用API​​来使用OAuth 2.0 Bearer Token。</p>
<p>API服务器可以通过两种方式接受Bearer Token。一个在HTTP Authorization标头中，另一个在post body参数中。它取决于它支持的服务，因此您需要检查文档以确定。</p>
<p>在HTTP标头中传入访问令牌时，您应该发出如下请求：</p>
<pre><code class="http">POST /resource/1/update HTTP/1.1
Authorization: Bearer RsT5OjbzRn430zqMLgV3Ia&quot;
Host: api.authorization-server.com

description=Hello+World
</code></pre>
<p>如果服务接受帖子正文中的访问令牌，那么您可以发出如下请求：</p>
<pre><code class="http">POST /resource/1/ HTTP/1.1
Host: api.authorization-server.com

access_token=RsT5OjbzRn430zqMLgV3Ia
&amp;description=Hello+World
</code></pre>
<p>请注意，由于OAuth 2.0规范实际上并不需要上面的任何一个选项，因此您必须阅读与之交互的特定服务的API文档，以了解它们是否支持post body参数或HTTP标头。</p>
<p>访问令牌不应由您的应用程序解析。你应用程序唯一应该做的就是使用它来发出API请求。一些服务将使用结构化令牌（如JWT）作为其访问令牌，但客户端在这种情况下无需担心解码令牌。</p>
<p>实际上，尝试解码访问令牌是危险的，因为服务器不保证访问令牌将始终保持相同的格式。完全有可能在下次从服务获得访问令牌时，它将采用不同的格式。要记住的是，访问令牌对客户端是不透明的，并且应该仅用于发出API请求而不是自己解释。</p>
<p>如果您试图找出您的访问令牌是否已过期，您可以存储您第一次获得访问令牌时返回的过期时间，或者只是尝试发出请求查看当前令牌是否过期，并获取新的访问令牌。</p>
<p>如果您正在尝试查找有关登录用户的更多信息，您应该阅读特定服务的API文档以了解他们的建议。例如，Google的API使用OpenID Connect提供userinfo endpoint，该endpoint可以返回有关给定访问令牌的用户的信息。</p>
<h3 id="刷新访问令牌"><a href="#刷新访问令牌" class="headerlink" title="刷新访问令牌"></a>刷新访问令牌</h3><p>当您最初收到访问令牌时，它可能包含刷新令牌以及到期时间，如下例所示。</p>
<pre><code class="json">{
  &quot;access_token&quot;: &quot;AYjcyMzY3ZDhiNmJkNTY&quot;,
  &quot;refresh_token&quot;: &quot;RjY2NjM5NzA2OWJjuE7c&quot;,
  &quot;token_type&quot;: &quot;bearer&quot;,
  &quot;expires&quot;: 3600
}
</code></pre>
<p>刷新令牌的存在意味着访问令牌将过期，您将能够在没有用户交互的情况下获得新令牌。</p>
<p>“expires”值是访问令牌有效的秒数。这取决于令牌服务的提供商，并且可能取决于应用程序或组织自己的策略。您可以使用它来抢先刷新访问令牌，而不是等待带有过期令牌的请求失败。</p>
<p>如果您发出API请求并且令牌已经过期，您将收到一个指示响应。您可以检查此特定错误消息，然后刷新令牌并再次尝试请求。</p>
<p>如果您使用的是基于JSON的API，则可能会返回带有invalid_token错误的JSON错误响应。在一些情况下，WWW-Authenticate header也会出现invalid_token错误。</p>
<pre><code class="http">HTTP/1.1 401 Unauthorized
WWW-Authenticate: Bearer error=&quot;invalid_token&quot;
  error_description=&quot;The access token expired&quot;
Content-type: application/json

{
  &quot;error&quot;: &quot;invalid_token&quot;,
  &quot;error_description&quot;: &quot;The access token expired&quot;
}
</code></pre>
<p>当您的代码识别出此特定错误时，它可以使用之前收到的刷新令牌向令牌endpoint发出请求，并返回可用于重试原始请求的新访问令牌。</p>
<p>要使用刷新令牌，请向服务的令牌endpoint发出POST请求grant_type=refresh_token，并包括刷新令牌和客户端凭据。</p>
<pre><code class="http">POST /oauth/token HTTP/1.1
Host: authorization-server.com

grant_type=refresh_token
&amp;amp;refresh_token=xxxxxxxxxxx
&amp;amp;client_id=xxxxxxxxxx
&amp;amp;client_secret=xxxxxxxxxx
</code></pre>
<p>响应将是新的访问令牌，也可能包含新的刷新令牌，就像您在交换访问令牌的授权代码时收到的那样。</p>
<pre><code class="json">{
  &quot;access_token&quot;: &quot;BWjcyMzY3ZDhiNmJkNTY&quot;,
  &quot;refresh_token&quot;: &quot;Srq2NjM5NzA2OWJjuE7c&quot;,
  &quot;token_type&quot;: &quot;bearer&quot;,
  &quot;expires&quot;: 3600
}
</code></pre>
<p>如果您没有获得新的刷新令牌，那么这意味着当新的访问令牌到期时，您现有的刷新令牌将继续工作。</p>
<p>请记住，用户可以在任何时候撤销应用程序 ，因此，当刷新访问令牌也失败时，您的应用程序需要能够处理这种情况。此时，您需要再次提示用户进行授权。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--移动和原生应用]]></title>
      <url>/2018/07/13/oauth-guide-6/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>与单页应用程序一样，移动应用程序也无法保持客户机密的机密性。因此，移动应用还必须使用不需要客户端密钥的OAuth流程。当前的最佳做法是使用授权流程以及启动外部浏览器，以确保本机应用程序无法修改浏览器窗口或检查内容。</p>
<p>许多网站都提供移动SDK，为您处理授权过程。对于这些网站，你最好直接使用他们的SDK，因为他们可能用非标准的方式添加增加了他们的API。Google提供了一个名为AppAuth的开源库，它可以处理下面描述的流程的实现细节。它旨在能够与任何实现规范的OAuth 2.0服务器一起使用。如果服务不提供自己的抽象，并且您必须直接使用其OAuth 2.0的endpoint，你就可以参照本节介绍来了解如何使用授权与API进行交互。</p>
<h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><p>创建一个“登录”按钮，该按钮将打开SFSafariViewController或启动本机浏览器。您将使用与服务器端应用程序中所述相同的授权请求参数。</p>
<p>对于本机应用程序的重定向URL，在iOS上，应用程序可以注册像<code>org.example.app://</code>这样的自定义URL scheme，只要访问具有该scheme的URL，就会启动应用程序。在Android上，应用程序可以注册URL匹配模式，如果访问了与模式匹配的URL，则会启动本机应用程序。</p>
<h3 id="举个栗子🌰"><a href="#举个栗子🌰" class="headerlink" title="举个栗子🌰"></a>举个栗子🌰</h3><p>在这个例子中，我们将创建一个简单的iPhone应用程序，获取访问虚构API的授权。</p>
<h4 id="应用程序启动授权请求"><a href="#应用程序启动授权请求" class="headerlink" title="应用程序启动授权请求"></a>应用程序启动授权请求</h4><p>要开始授权过程，应用程序应该有一个“登录”按钮。该链接应构建为服务授权endpoint的完整URL。</p>
<p>授权URL通常采用以下格式：</p>
<pre><code class="http">https://authorization-server.com/authorize
?client_id=eKNjzFFjH9A1ysYd
&amp;response_type=code
&amp;redirect_uri=exampleapp://auth
&amp;state=1234zyx
</code></pre>
<p>在这种情况下请注意重定向URL的自定义方案。iOS提供了应用程序注册自定义URL方案的功能。在Android上，应用可以改为匹配特定的网址模式，以便应用在访问特定网址时在应用列表中显示并进行处理。在iOS上，您应该在应用程序的.plist文件中注册您将使用的自定义方案。这将导致设备在访问以您的自定义方案开头的URL时启动您的应用，包括移动版Safari或其他iOS应用。</p>
<p>当用户点击“登录”按钮时，应用程序应用SFSafariViewController打开共享系统cookie的嵌入式浏览器来打开登录URL。WebView在应用程序中使用嵌入式窗口被认为是非常危险的，因为这使用户无法保证他们正在查看服务自己的网站，并且是网络钓鱼攻击的简单来源。通过使用SFSafariViewController共享Safari cookie的API，您可以知道用户是否已经登录该服务。</p>
<h4 id="用户批准该请求"><a href="#用户批准该请求" class="headerlink" title="用户批准该请求"></a>用户批准该请求</h4><p>在被定向到auth服务器时，用户看到如下所示的授权请求。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/sfsafariviewcontroller-example.png" alt="内置浏览器"></p>
<p>嵌入式SFSafariViewController。右上角的“完成”按钮折叠视图并将用户返回到应用程序。</p>
<h4 id="该服务将用户重定向回应用程序"><a href="#该服务将用户重定向回应用程序" class="headerlink" title="该服务将用户重定向回应用程序"></a>该服务将用户重定向回应用程序</h4><p>当用户完成登录后，该服务将重定向回您的应用程序的重定向URL，在这种情况下，该URL具有一个自定义方案，该方案将触发您的应用程序委托的application:openURL:options:方法。Location重定向的标题将类似于以下内容，它将作为url参数传递给您的方法。</p>
<pre><code class="html">org.example.app://auth?state=1234zyx
&amp;code=lS0KgilpRsT07qT_iMOg9bBSaWqODC1g061nSLsa8gV2GYtyynB6A
</code></pre>
<p>然后，您的应用应该从URL解析授权码，交换代码以获取访问令牌，并关闭SFSafariViewController。除了不使用客户端密钥之外，交换访问令牌的代码与授权代码流中的代码相同。</p>
<h3 id="安全考虑因素"><a href="#安全考虑因素" class="headerlink" title="安全考虑因素"></a>安全考虑因素</h3><h4 id="始终打开本机浏览器或使用-SFSafariViewController"><a href="#始终打开本机浏览器或使用-SFSafariViewController" class="headerlink" title="始终打开本机浏览器或使用 SFSafariViewController"></a>始终打开本机浏览器或使用 SFSafariViewController</h4><p>您永远不应该使用OAuth提示打开嵌入式Web视图，因为它无法让用户验证他们正在查看的网页的来源。攻击者会创建一个看起来就像授权网页并将其嵌入到自己的恶意应用程序中的网页，让他们能够窃取用户名和密码。</p>
<h4 id="PKCE"><a href="#PKCE" class="headerlink" title="PKCE"></a>PKCE</h4><p>如果您使用的服务支持PKCE扩展（<a href="https://tools.ietf.org/html/rfc7636" target="_blank" rel="noopener">RFC 7636</a>），那么您应该利用它提供的额外安全性。通常，例如在使用Google OAuth API的情况下，服务提供的本机SDK将透明地处理此问题，因此您无需担心详细信息，并且无需任何额外工作即可从额外的安全性中受益。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--单页应用]]></title>
      <url>/2018/07/13/oauth-guide-5/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>从网页加载Javascript和HTML源代码后，单页应用程序（或基于浏览器的应用程序）将会完全在浏览器中运行。由于浏览器可以使用所有源代码，因此无法保持客户端密钥的机密性，因此这些应用程序不会使用该密钥。该流程与授权代码流完全相同，但在最后一步，授权码在不使用客户端密钥的情况下交换访问令牌。</p>
<p>下图是用户与浏览器进行交互的示例，该浏览器直接向服务发出API请求。在首次从客户端下载Javascript和HTML源代码之后，浏览器会直接向服务发出API请求。在这种情况下，应用程序的服务器永远不会向服务发出API请求，因为所有事情都是直接在浏览器中处理的。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/okta_oauth-diagrams.png" alt="用户的浏览器直接与API服务器通信"></p>
<h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><p>授权码是客户端交换访问令牌的临时代码。代码本身从授权服务器获得，用户可以查看客户端请求的信息，并批准或拒绝该请求。</p>
<p>Web流程的第一步是请求用户授权。这是通过为用户创建单击的授权请求链接来完成的。</p>
<p>授权URL通常采用以下格式：</p>
<pre><code class="html">https://authorization-server.com/oauth/authorize
  ?client_id=a17c21ed
  &amp;response_type=code
  &amp;state=5ca75bd30
  &amp;redirect_uri=https%3A%2F%2Fexample-app.com%2Fauth
</code></pre>
<p>用户访问授权页面后，服务会向用户显示请求的解释，包括应用程序名称，范围等。如果用户单击“批准”，服务器将重定向回网站，并附带授权码和URL查询字符串中的state值。</p>
<h3 id="授权请求参数"><a href="#授权请求参数" class="headerlink" title="授权请求参数"></a>授权请求参数</h3><p>以下参数用于发出授权请求。</p>
<blockquote>
<p><strong>client_id</strong><br>这client_id是您的应用的标识符。首次向服务注册您的应用程序时，您将收到一个client_id。</p>
<p><strong>response_type</strong><br>response_type设置为code表示您希望以授权码作为响应。</p>
<p><strong>redirect_uri （可选的）</strong><br>该redirect_uri是在规范中可选的，但是有些服务需要它。这是您希望在授权完成后将用户重定向到的URL。这必须与您先前在服务中注册的重定向URL相匹配。</p>
<p><strong>scope （可选的）</strong><br>包括一个或多个范围值以请求其他访问级别。这些值将取决于特定的服务。</p>
<p><strong>state （推荐的）</strong><br>该state参数有两个功能。当用户被重定向回您的应用程序时，您在状态中包含的任何值都将包含在重定向中。这使您的应用程序有机会在被定向到授权服务器的用户和再次返回之间保留数据，例如使用state参数作为会话密钥。这可用于指示在授权完成后应用中要执行的操作，例如，指示在授权后要重定向到应用的哪个页面。这也可以作为CSRF保护机制。当用户重定向回您的应用程序时，请仔细检查状态值是否与您最初设置的值相匹配。这将确保攻击者无法拦截授权流程。</p>
<p>请注意，缺少使用客户端密钥意味着使用state参数对单页应用程序更为重要。</p>
</blockquote>
<h3 id="举个栗子🌰"><a href="#举个栗子🌰" class="headerlink" title="举个栗子🌰"></a>举个栗子🌰</h3><p>以下分步示例说明了对单页应用程序使用授权授予类型。</p>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><h5 id="应用程序启动授权请求"><a href="#应用程序启动授权请求" class="headerlink" title="应用程序启动授权请求"></a>应用程序启动授权请求</h5><p>应用程序通过制作包含ID的URL以及可选的scope和state来启动流程。该应用程序可以将其放入<code>&lt;a href=&quot;&quot;&gt;</code>标签中。</p>
<pre><code class="html">&lt;a href=&quot;https://authorization-server.com/authorize?response_type=code
     &amp;client_id=mRkZGFjM&amp;state=TY2OTZhZGFk&quot;&gt;Connect Your Account&lt;/a&gt;
</code></pre>
<h5 id="用户批准该请求"><a href="#用户批准该请求" class="headerlink" title="用户批准该请求"></a>用户批准该请求</h5><p>在被定向到auth服务器时，用户看到授权请求。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/oauth-guide/okta_oauth-diagrams-approve.png" alt="示例授权请求"></p>
<p>用户被带到服务并看到请求后，他们将允许或拒绝该请求。如果他们允许请求，他们将被重定向回重定向URL以及查询字符串中的授权码。然后，该应用程序需要交换授权码以获得访问令牌。</p>
<pre><code class="http">https://example-app.com/cb?code=Yzk5ZDczMzRlNDEwY&amp;state=TY2OTZhZGFk
</code></pre>
<p>如果您在初始授权网址中包含“state”参数，则该服务会在用户授权您的应用后将其返回给您。你的应用程序应该将state参数与它在初始请求中创建的state餐素进行比较。这有助于确保您只交换您请求的授权码，防止攻击者使用任意或被盗的授权码重定向到您的回调URL。</p>
<h5 id="交换访问令牌的授权码"><a href="#交换访问令牌的授权码" class="headerlink" title="交换访问令牌的授权码"></a>交换访问令牌的授权码</h5><p>要交换访问令牌的授权码，应用程序会向服务的令牌endpoint发出POST请求。请求将具有以下参数。</p>
<blockquote>
<p><strong>grant_type （需要）</strong><br>该grant_type参数必须设置为“authorization_code”。</p>
<p><strong>code （需要）</strong><br>此参数用于从授权服务器接收的授权代码，该授权代码将位于此请求中的查询字符串参数“code”中。</p>
<p><strong>redirect_uri （可能需要）</strong><br>如果重定向URL包含在初始授权请求中，则它也必须包含在令牌请求中，并且必须相同。某些服务支持注册多个重定向URL，有些服务需要在每个请求上指定重定向URL。请查看服务的文档以了解具体信息。</p>
<p><strong>客户端识别ID（必填）</strong><br>尽管客户端密钥未在此流程中使用，但该请求需要发送客户端ID以识别发出请求的应用程序。这意味着客户端必须将客户端ID包含为POST主体参数，而不是像包含客户端密钥时那样使用HTTP基本认证。</p>
</blockquote>
<pre><code class="http">POST /oauth/token HTTP/1.1
  Host: authorization-endpoint.com
  grant_type=code
  &amp;code=Yzk5ZDczMzRlNDEwY
  &amp;redirect_uri=https://example-app.com/cb
  &amp;client_id=mRkZGFjM
</code></pre>
<h3 id="隐式流程"><a href="#隐式流程" class="headerlink" title="隐式流程"></a>隐式流程</h3><p>有些服务使用隐式流程用于单页面应用程序，而不是允许应用程序毫无限制地使用授权码流程。</p>
<p>隐式流程绕过代码交换步骤，而是将查询字符串片段中的访问令牌立即返回给客户端。</p>
<p>在实践中，只有非常有限的情况需要这样做。几个主要的实现（Keycloak，Deutsche Telekom，Smart Health IT）选择完全避免隐式流程并使用授权码流程。</p>
<p>为了使单页应用程序使用授权码流程，它必须能够向授权服务器发出POST请求。这意味着如果授权服务器位于不同的域上，则服务器将需要支持相应的CORS头。如果不支持CORS头，则服务可以使用隐式流程。</p>
<p>在任何情况下，对于隐式流程以及授权码流程来说，都没有客户端秘钥，服务器必须要求注册重定向URL以保持流程的安全性。</p>
<h4 id="安全考虑"><a href="#安全考虑" class="headerlink" title="安全考虑"></a>安全考虑</h4><p>通过使用“state”参数并将重定向URL限制为可认证客户端，这是授权代码授予无客户端密钥的客户端的唯一安全方法。由于没有使用密钥，除了使用注册的重定向URL之外，没有办法验证客户的身份。这就是为什么您需要使用OAuth 2.0服务预先注册您的重定向网址。</p>
<p>尽管OAuth 2.0规范并不特别要求重定向URL使用TLS加密，但强烈建议您使用它。不需要的唯一原因是因为部署SSL网站对许多开发人员来说仍然是一个障碍，这将阻碍规范的广泛采用。有些API确实需要https作为重定向端点，但许多API仍然没有。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--服务器端应用程序]]></title>
      <url>/2018/07/13/oauth-guide-4/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>服务器端应用程序是处理OAuth 2服务器时遇到的最常见的应用程序类型。这些应用程序在Web服务器上运行，其中应用程序的源代码不可供公众使用，因此他们可以保持其客户端秘钥的机密性。</p>
<p>下图说明了用户与正在与客户端通信的浏览器进行交互的典型示例。客户端和API服务器之间具有单独的安全通信通道。用户的浏览器从不直接向API服务器发出请求，所有内容都先通过客户端。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftf3o8318wj30p006edfx.jpg" alt="应用程序的服务器与API通信"></p>
<p>服务器端应用程序使用<code>authorization_code</code>授权类型。在此流程中，在用户授权应用程序之后，应用程序接收“授权码”，然后它可以交换访问令牌。</p>
<h3 id="授权码授予"><a href="#授权码授予" class="headerlink" title="授权码授予"></a>授权码授予</h3><p>授权码是客户端将为访问令牌交换的临时代码。代码本身从授权服务器获得，其中用户有机会查看客户端请求的信息，并批准或拒绝该请求。</p>
<p>授权码流程与其他授权类型相比具有一些优势。当用户授权应用程序时，会带着URL中的临时代码返回应用程序。应用程序有这个代码来交换访问令牌。当应用程序发出访问令牌请求时，该请求将使用客户端密钥进行身份验证，从而降低攻击者拦截授权码并自行使用它的风险。这也意味着访问令牌永远不会被用户看到，因此这是将令牌传递回应用程序的最安全方式，从而降低令牌泄露给其他人的风险。</p>
<p>Web流程的第一步是请求用户授权。这是通过创建用户单击的授权请求链接来完成的。</p>
<p>授权URL通常采用以下格式：</p>
<pre><code class="http">https://authorization-server.com/oauth/authorize
?client_id=a17c21ed
&amp;response_type=code
&amp;state=5ca75bd30
&amp;redirect_uri=https%3A%2F%2Fexample-app.com%2Fauth
</code></pre>
<p>确切的URL endpoint将由您要连接的服务指定，但参数名称将始终相同。</p>
<p>请注意，在接受服务之前，您很可能首先需要在服务中注册重定向URL。这也意味着您无法根据请求更改重定向网址。相反，您可以使用该state参数来自定义请求。</p>
<p>用户访问授权页面后，该服务会向用户显示请求的说明，包括应用程序名称，范围等。如果用户单击“批准”，则服务器将使用您在查询字符串参数中提供的“code”和相同的“state”参数重定向回应用程序。请务必注意，这不是访问令牌。您可以使用授权码执行的唯一操作是发出获取访问令牌的请求。</p>
<h4 id="授权授予参数"><a href="#授权授予参数" class="headerlink" title="授权授予参数"></a>授权授予参数</h4><p>以下参数用于授予授权。您应该使用以下参数构建一个查询字符串，并将其附加到从其文档中获取的应用程序的授权endpoint后。</p>
<blockquote>
<p><strong>response_type=code</strong><br>response_type设置为code表示您希望将授权码作为响应。</p>
<p><strong>client_id</strong><br>client_id是您的应用的标识符。首次向服务注册您的应用时，您将收到client_id。</p>
<p><strong>redirect_uri （可选的）</strong><br>redirect_uri是可选的，但强烈建议你添加。这是您希望在授权完成后将用户重定向到的URL。这必须与您先前在服务中注册的重定向URL相匹配。</p>
<p><strong>scope （可选的）</strong><br>包括一个或多个范围值（以空格分隔）以请求其他访问级别。它的值取决于特定服务。</p>
<p><strong>state （推荐的）</strong><br>state参数有两个功能。当用户被重定向回您的应用程序时，您在state中包含的任何值都将包含在重定向中。这使您的应用程序有机会在用户被定向到授权服务器和再次返回之间保留数据，例如使用state参数作为会话密钥。也可用于指示在授权完成后应用中要执行的操作，例如，指示在授权后应该重定向到应用的哪个页面。也可以作为CSRF保护机制。当用户重定向回您的应用程序时，请仔细检查state值是否与您最初设置的值相匹配。这将确保攻击者无法拦截授权流程。</p>
</blockquote>
<p>将所有这些查询字符串参数组合到登录URL中，并将用户的浏览器定向到那里。通常，应用程序会将这些参数放入登录按钮，或者从应用程序自己的登录URL发送重定向到此URL。</p>
<h4 id="用户批准该请求"><a href="#用户批准该请求" class="headerlink" title="用户批准该请求"></a>用户批准该请求</h4><p>在用户进入服务并看到请求后，他们将允许或拒绝该请求。如果他们允许请求，他们将带着查询字符串中的授权码，并被重定向回指定的重定向URL。然后，应用程序需要使用此授权码交换访问令牌。</p>
<h4 id="交换访问令牌的授权码"><a href="#交换访问令牌的授权码" class="headerlink" title="交换访问令牌的授权码"></a>交换访问令牌的授权码</h4><p>要使用授权码交换访问令牌，应用程序会向服务的令牌endpoint发出POST请求。请求将具有以下参数。</p>
<blockquote>
<p><strong>grant_type （需要）</strong><br>grant_type参数必须设置为“authorization_code”。</p>
<p><strong>code （需要）</strong><br>查询字符串参数“code”中存放从授权服务器接收的授权码。</p>
<p><strong>redirect_uri （可能需要）</strong><br>如果重定向URL包含在初始授权请求中，则它也必须包含在令牌请求中，并且必须相同。某些服务支持注册多个重定向URL，有些服务需要在每个请求上指定重定向URL。请查看服务的文档以了解具体信息。</p>
</blockquote>
<h4 id="客户端验证（必填）"><a href="#客户端验证（必填）" class="headerlink" title="客户端验证（必填）"></a>客户端验证（必填）</h4><p>该服务将要求客户端在发出访问令牌请求时进行身份验证。通常，服务通过HTTP Basic Auth来进行客户端身份验证，并使用客户端的client_id和client_secret。但是，某些服务通过接受client_id和client_secret作为POST body参数来支持身份验证。检查服务的文档以找出服务所期望的内容，因为OAuth 2.0规范将此决定留给了服务。</p>
<h3 id="示例流程"><a href="#示例流程" class="headerlink" title="示例流程"></a>示例流程</h3><p>以下逐步说明示例使用授权代码授予类型。</p>
<p>步骤：</p>
<ul>
<li>使用应用程序的客户端ID，重定向URL和state参数创建登录链接</li>
<li>用户看到授权提示并批准该请求</li>
<li>用户带着授权码重定向回应用程序的服务器</li>
<li>应用程序使用授权码交换访问令牌</li>
</ul>
<h4 id="应用程序启动授权请求"><a href="#应用程序启动授权请求" class="headerlink" title="应用程序启动授权请求"></a>应用程序启动授权请求</h4><p>应用程序通过制作包含ID，scope和state的URL来启动流程。该应用程序可以将其放入<code>&lt;a href=&quot;&quot;&gt;</code>标签中。</p>
<pre><code class="html">&lt;a href=&quot;https://authorization-server.com/oauth/authorize
?response_type=code&amp;client_id=mRkZGFjM&amp;state=5ca75bd30&quot;&gt;
Connect Your Account&lt;/a&gt;
</code></pre>
<h4 id="用户批准该请求-1"><a href="#用户批准该请求-1" class="headerlink" title="用户批准该请求"></a>用户批准该请求</h4><p>在被定向到auth服务器后，用户会看到下图所示的授权请求。如果用户批准该请求，他们将带着授权码和state参数重定向回应用程序。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftf5fephk0j30kw0bw0t3.jpg" alt="示例授权请求"></p>
<h4 id="服务将用户重定向回应用程序"><a href="#服务将用户重定向回应用程序" class="headerlink" title="服务将用户重定向回应用程序"></a>服务将用户重定向回应用程序</h4><p>服务将用户重定向回发出请求的应用程序。重定向将在URL中包含“code”和原始的“state”参数。</p>
<pre><code class="http">https://example-app.com/cb?code=Yzk5ZDczMzRlNDEwY&amp;state=5ca75bd30
</code></pre>
<h4 id="应用程序使用授权吗交换访问令牌"><a href="#应用程序使用授权吗交换访问令牌" class="headerlink" title="应用程序使用授权吗交换访问令牌"></a>应用程序使用授权吗交换访问令牌</h4><p>该应用程序使用授权码，通过向授权服务器发出POST请求来获取访问令牌。</p>
<pre><code class="http">POST /oauth/token HTTP/1.1
Host: authorization-server.com

code=Yzk5ZDczMzRlNDEwY
&amp;grant_type=code
&amp;redirect_uri=https://example-app.com/cb
&amp;client_id=mRkZGFjM
&amp;client_secret=ZGVmMjMz
</code></pre>
<p>auth服务器验证请求，并返回访问令牌和访问令牌过期时使用的刷新令牌。</p>
<p>响应：</p>
<pre><code class="json">{
  &quot;access_token&quot;: &quot;AYjcyMzY3ZDhiNmJkNTY&quot;,
  &quot;refresh_token&quot;: &quot;RjY2NjM5NzA2OWJjuE7c&quot;,
  &quot;token_type&quot;: &quot;bearer&quot;,
  &quot;expires&quot;: 3600
}
</code></pre>
<h3 id="可能的错误"><a href="#可能的错误" class="headerlink" title="可能的错误"></a>可能的错误</h3><p>有几种情况下，您可能会在授权期间收到错误响应。</p>
<p>错误会通过在返回的重定向URL的查询字符串提示。重定向URL总会有一个错误参数，也可能包含error_description和error_uri。</p>
<p>例如:<br><code>https://example-app.com/cb?error=invalid_scope</code></p>
<p>尽管服务器返回error_description密钥，但错误描述并不打算显示给用户。相反，您应该向用户显示您自己的错误消息。这允许您告诉用户采取适当的措施来纠正问题，并且如果您正在构建多语言网站，还可以让您有机会本地化错误消息。</p>
<h4 id="无效的重定向网址"><a href="#无效的重定向网址" class="headerlink" title="无效的重定向网址"></a>无效的重定向网址</h4><p>如果提供的重定向URL无效，则auth服务器不会重定向到它。相反，它可以向用户显示描述问题的信息。</p>
<h4 id="无法识别-client-id"><a href="#无法识别-client-id" class="headerlink" title="无法识别 client_id"></a>无法识别 client_id</h4><p>如果无法识别客户端ID，则auth服务器不会重定向用户。相反，它可能会显示一条描述问题的信息。</p>
<h4 id="用户拒绝该请求"><a href="#用户拒绝该请求" class="headerlink" title="用户拒绝该请求"></a>用户拒绝该请求</h4><p>如果用户拒绝授权请求，则服务器会将用户重定向包含error=access_denied查询字符串的重定向URL ，并且不会出现code字段。由应用程序决定此时向用户显示的内容。</p>
<h4 id="无效的参数"><a href="#无效的参数" class="headerlink" title="无效的参数"></a>无效的参数</h4><p>如果一个或多个参数无效，例如缺少必需值，或者response_type参数错误，服务器将重定向到重定向URL并包含描述问题的查询字符串参数。</p>
<p>error参数的其他可能值为：</p>
<ul>
<li>invalid_request：请求缺少必需参数，包含无效参数值，或者格式错误。</li>
<li>unauthorized_client：客户端无权使用此方法请求授权码。</li>
<li>unsupported_response_type：授权服务器不支持使用此方法获取授权码。</li>
<li>invalid_scope：请求的范围无效，未知或格式错误。</li>
<li>server_error：授权服务器遇到意外情况，导致无法完成请求。</li>
<li>temporarily_unavailable：由于服务器临时过载或维护，授权服务器当前无法处理请求。</li>
</ul>
<p>此外，服务器可以包括参数error_description和error_uri关于错误的附加信息。</p>
<h3 id="用户体验考虑事项"><a href="#用户体验考虑事项" class="headerlink" title="用户体验考虑事项"></a>用户体验考虑事项</h3><p>为了使授权代码授权生效，授权页面必须出现在用户熟悉的Web浏览器中，并且不得嵌入到iframe弹出窗口或移动到应用程序中的嵌入式浏览器中。因此，对于传统的“Web应用程序”来说，用户已经在Web浏览器中并且重定向到服务器的授权页面的这种操作，是最适用的。</p>
<h3 id="安全考虑"><a href="#安全考虑" class="headerlink" title="安全考虑"></a>安全考虑</h3><p>授权码授权是为可以保护其客户端ID和密钥的客户端设计的。因此，最适合不提供其源代码的在服务器上运行的网络应用程序。</p>
<p>如果应用程序想要使用授权代码授权但无法保护其密钥（即本机移动应用程序），则在请求交换访问令牌的授权代码时就不需要客户端密钥。但是，某些服务不接受没有客户端密钥的授权码交换，因此本机应用程序可能需要为这些服务使用备用方法。</p>
<p>尽管OAuth 2.0规范并不特别要求重定向URL使用TLS加密，但我强烈建议您使用它。不需要的唯一原因是因为部署SSL网站对许多开发人员来说仍然是一个障碍，这将阻碍规范的广泛采用。有些API确实需要https作为重定向端点，但许多API仍然没有这样要求。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--使用Google登录]]></title>
      <url>/2018/07/13/oauth-guide-3/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>尽管OAuth是<strong>授权协议</strong>而不是<strong>身份验证协议</strong>，但它通常用作身份验证工作流程的基础。许多常见OAuth API的典型用途是在登录第三方应用程序时识别当前用户。</p>
<p>身份验证和授权经常相互混淆，但如果从应用程序的角度考虑它们，则可以更容易理解。正在验证用户的应用只是验证用户是谁。授权用户的应用程序正在尝试访问或修改属于该用户的内容。</p>
<p>OAuth被设计为授权协议，因此每个OAuth流程的最终结果是应用程序获取访问令牌，以便能够访问或修改有关用户帐户的内容。访问令牌本身并未说明用户是谁。</p>
<p>有几种方法可以让不同的服务为应用程序提供一种查找用户身份的方法。一种简单的方法是API提供“用户信息”的endpoint，当使用访问令牌访问API时，该endpoint将返回经过身份验证的用户的名称和其他配置文件信息。虽然这不是OAuth标准的一部分，但它是许多服务采用的常见方法。更高级和标准化的方法是使用OAID 2.0扩展的OpenID Connect。OpenID Connect在后面有更详细的介绍。</p>
<p>本章将使用简化的OpenID Connect工作流程和Google API来识别用户并登录到您的应用程序。</p>
<h3 id="创建一个应用程序"><a href="#创建一个应用程序" class="headerlink" title="创建一个应用程序"></a>创建一个应用程序</h3><p>在我们开始之前，我们需要在Google API控制台中创建一个应用程序，以获取客户端ID和客户端秘钥，并注册重定向URL。</p>
<p>访问<code>https://console.developers.google.com/</code>并创建一个新项目。您还需要为项目创建OAuth 2.0凭据，因为Google不会自动执行此操作。在侧栏中，单击“Credentials”选项卡，然后单击“Create credentials”并从下拉列表中选择“OAuth client ID”。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1ftdy5lw1czj30sg0jwn09.jpg" alt="创建一个应用程序"></p>
<p>Google控制台会提示您提供有关您的应用程序的一些信息，例如产品名称，主页和logo。在下一页上，选择”Web application”类型，然后输入重定向URL。这样，您就会收到客户端ID和秘钥。</p>
<h3 id="建立环境"><a href="#建立环境" class="headerlink" title="建立环境"></a>建立环境</h3><p>本章节示例代码是用PHP编写的，不需要外部包，也不需要框架，这可以很容易地翻译成其他语言。要模仿此示例代码，您应该将它全部放在一个PHP文件中。</p>
<p>创建一个新文件夹并在该文件夹中创建一个空文件<code>index.php</code>。从该文件夹内部运行的命令行输入<code>php -S localhost:8000</code>，您将能够在浏览器中访问<code>http://localhost:8000</code>来运行您的代码。以下示例中的所有代码都应添加到此index.php文件中。</p>
<p>让我们为OAuth流程设置一些变量，添加我们在创建应用程序时从Google获得的客户端ID和秘钥。</p>
<pre><code class="php">// Fill these out with the values you got from Google
$googleClientID = &#39;&#39;;
$googleClientSecret = &#39;&#39;;

// This is the URL we&#39;ll send the user to first
// to get their authorization
$authorizeURL = &#39;https://accounts.google.com/o/oauth2/v2/auth&#39;;

// This is Google&#39;s OpenID Connect token endpoint
$tokenURL = &#39;https://www.googleapis.com/oauth2/v4/token&#39;;

// The URL for this script, used as the redirect URL
$baseURL = &#39;https://&#39; . $_SERVER[&#39;SERVER_NAME&#39;]
    . $_SERVER[&#39;PHP_SELF&#39;];

// Start a session so we have a place
// to store things between redirects
session_start();
</code></pre>
<p>定义了这些变量，并开始会话，让我们设置登录和注销的页面。我们将显示一个超级简单的页面，它只是指示用户是否已登录，并且具有登录或注销的链接。</p>
<pre><code class="php">// If there is a user ID in the session
// the user is already logged in
if(!isset($_GET[&#39;action&#39;])) {
  if(!empty($_SESSION[&#39;user_id&#39;])) {
    echo &#39;&lt;h3&gt;Logged In&lt;/h3&gt;&#39;;
    echo &#39;&lt;p&gt;User ID: &#39;.$_SESSION[&#39;user_id&#39;].&#39;&lt;/p&gt;&#39;;
    echo &#39;&lt;p&gt;Email: &#39;.$_SESSION[&#39;email&#39;].&#39;&lt;/p&gt;&#39;;
    echo &#39;&lt;p&gt;&lt;a href=&quot;?action=logout&quot;&gt;Log Out&lt;/a&gt;&lt;/p&gt;&#39;;

    // Fetch user info from Google&#39;s userinfo endpoint
    echo &#39;&lt;h3&gt;User Info&lt;/h3&gt;&#39;;
    echo &#39;&lt;pre&gt;&#39;;
    $ch = curl_init(&#39;https://www.googleapis.com/oauth2/v3/userinfo&#39;);
    curl_setopt($ch, CURLOPT_HTTPHEADER, [
      &#39;Authorization: Bearer &#39;.$_SESSION[&#39;access_token&#39;]
    ]);
    curl_exec($ch);
    echo &#39;&lt;/pre&gt;&#39;;

  } else {
    echo &#39;&lt;h3&gt;Not logged in&lt;/h3&gt;&#39;;
    echo &#39;&lt;p&gt;&lt;a href=&quot;?action=login&quot;&gt;Log In&lt;/a&gt;&lt;/p&gt;&#39;;
  }
  die();
}
</code></pre>
<p>已注销的页面包含指向我们的登录的URL链接，该URL用于启动OAuth流程。</p>
<h3 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h3><p>现在我们已经设置了必要的变量，让我们开始OAuth流程。</p>
<p>我们要让人们做的第一件事是,在查询字符串为<code>?action=login</code>时，访问此页面以启动该流程。</p>
<p>请注意，此请求中的scope现在是OpenID Connect的scope，“openid email”，表示我们不是要求访问用户的Google数据，只是想知道他们是谁。</p>
<p>另请注意，我们使用<code>response_type=code</code>参数来指示我们希望Google返回用来交换<code>id_token</code>的授权码。</p>
<pre><code class="php">// Start the login process by sending the user
// to Google&#39;s authorization page
if(isset($_GET[&#39;action&#39;]) &amp;&amp; $_GET[&#39;action&#39;] == &#39;login&#39;) {
  unset($_SESSION[&#39;user_id&#39;]);

  // Generate a random hash and store in the session
  $_SESSION[&#39;state&#39;] = bin2hex(random_bytes(16));

  $params = array(
    &#39;response_type&#39; =&gt; &#39;code&#39;,
    &#39;client_id&#39; =&gt; $googleClientID,
    &#39;redirect_uri&#39; =&gt; $baseURL,
    &#39;scope&#39; =&gt; &#39;openid email&#39;,
    &#39;state&#39; =&gt; $_SESSION[&#39;state&#39;]
  );

  // Redirect the user to Google&#39;s authorization page
  header(&#39;Location: &#39;.$authorizeURL.&#39;?&#39;.http_build_query($params));
  die();
}
</code></pre>
<p>生成用于保护客户端的“state”参数非常重要。这是客户端生成并存储在会话中的随机字符串。当Google将用户发送回应用时，该应用使用state参数来验证是否是它发出的请求。</p>
<p>我们建立一个授权URL，然后将用户发送到那里。该网址包含我们的公共客户ID，我们之前在Google注册的重定向网址，我们要求的scope以及state参数。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1ftdz43ass6j30se0x2wgz.jpg" alt="Google的授权请求"></p>
<p>如果用户已登录Google，他们会看到如上所示的帐户选择页面，要求他们选择现有帐户或使用其他帐户。请注意，此屏幕看起来不像典型的OAuth屏幕，因为用户没有授予应用程序任何权限，而只是尝试识别它们。</p>
<p>当用户选择一个帐户时，他们将被重定向回我们的页面，并在请求中返回code和state参数。下一步是使用Google API验证授权码。</p>
<h3 id="获取ID令牌"><a href="#获取ID令牌" class="headerlink" title="获取ID令牌"></a>获取ID令牌</h3><p>当用户被重定向回我们的应用程序时，查询字符串中将有一个code和state参数。该state参数将与我们在初始授权请求中设置的参数相同，并且在用于我们的应用程序之前，应该检查它是否匹配。这可确保我们的应用不会欺骗Google向攻击者发送授权码。</p>
<pre><code class="php">// When Google redirects the user back here, there will
// be a &quot;code&quot; and &quot;state&quot; parameter in the query string
if(isset($_GET[&#39;code&#39;])) {
  // Verify the state matches our stored state
  if(!isset($_GET[&#39;state&#39;]) || $_SESSION[&#39;state&#39;] != $_GET[&#39;state&#39;]) {
    header(&#39;Location: &#39; . $baseURL . &#39;?error=invalid_state&#39;);
    die();
  }

  // Verify the authorization code
  $ch = curl_init($tokenURL);
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
  curl_setopt($ch, CURLOPT_POSTFIELDS, http_build_query([
    &#39;grant_type&#39; =&gt; &#39;authorization_code&#39;,
    &#39;client_id&#39; =&gt; $googleClientID,
    &#39;client_secret&#39; =&gt; $googleClientSecret,
    &#39;redirect_uri&#39; =&gt; $baseURL,
    &#39;code&#39; =&gt; $_GET[&#39;code&#39;]
  ]));
  $response = json_decode(curl_exec($ch), true);

  // ... fill in from the code in the next section
}
</code></pre>
<p>此代码首先检查从Google返回的“状态”是否与我们在会话中存储的状态匹配。</p>
<p>我们向Google的令牌endpoint建立了一个POST请求，其中包含我们应用的客户端ID和密码，以及Google在查询字符串中发回给我们的授权码。</p>
<p>Google将验证我们的请求，然后使用访问令牌和ID令牌进行回复。响应将如下所示。</p>
<pre><code class="json">{
  &quot;access_token&quot;: &quot;ya29.Glins-oLtuljNVfthQU2bpJVJPTu&quot;,
  &quot;token_type&quot;: &quot;Bearer&quot;,
  &quot;expires_in&quot;: 3600,
  &quot;id_token&quot;: &quot;eyJhbGciOiJSUzI1NiIsImtpZCI6ImFmZmM2MjkwN
  2E0NDYxODJhZGMxZmE0ZTgxZmRiYTYzMTBkY2U2M2YifQ.eyJhenAi
  OiIyNzIxOTYwNjkxNzMtZm81ZWI0MXQzbmR1cTZ1ZXRkc2pkdWdzZX
  V0ZnBtc3QuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQi
  OiIyNzIxOTYwNjkxNzMtZm81ZWI0MXQzbmR1cTZ1ZXRkc2pkdWdzZX
  V0ZnBtc3QuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIi
  OiIxMTc4NDc5MTI4NzU5MTM5MDU0OTMiLCJlbWFpbCI6ImFhcm9uLn
  BhcmVja2lAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUs
  ImF0X2hhc2giOiJpRVljNDBUR0luUkhoVEJidWRncEpRIiwiZXhwIj
  oxNTI0NTk5MDU2LCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2ds
  ZS5jb20iLCJpYXQiOjE1MjQ1OTU0NTZ9.ho2czp_1JWsglJ9jN8gCg
  WfxDi2gY4X5-QcT56RUGkgh5BJaaWdlrRhhN_eNuJyN3HRPhvVA_KJ
  Vy1tMltTVd2OQ6VkxgBNfBsThG_zLPZriw7a1lANblarwxLZID4fXD
  YG-O8U-gw4xb-NIsOzx6xsxRBdfKKniavuEg56Sd3eKYyqrMA0DWnI
  agqLiKE6kpZkaGImIpLcIxJPF0-yeJTMt_p1NoJF7uguHHLYr6752h
  qppnBpMjFL2YMDVeg3jl1y5DeSKNPh6cZ8H2p4Xb2UIrJguGbQHVIJ
  vtm_AspRjrmaTUQKrzXDRCfDROSUU-h7XKIWRrEd2-W9UkV5oCg&quot;
}
</code></pre>
<p>应将访问令牌视为不透明字符串。除了能够使用它来发出API请求之外，它对您的应用程序没有重要意义。</p>
<p>ID令牌具有您的应用可以解析的特定结构，以找出登录者的用户数据。ID令牌是JWT，在OpenID Connect中有更详细的解释。您可以将Google的JWT粘贴到jsonwebtoken.io等网站，以快速向您显示内容。</p>
<h3 id="验证用户信息"><a href="#验证用户信息" class="headerlink" title="验证用户信息"></a>验证用户信息</h3><p>通常，在信任ID令牌中的任何信息之前验证ID令牌至关重要。这是因为通常您的应用会通过不受信任的渠道（例如浏览器重定向）获取ID令牌。</p>
<p>在这种情况下，您使用客户端密钥通过HTTPS连接向Google获取ID令牌，以便向Google进行身份验证，因此您可以确信您获得的ID令牌实际上来自服务商而非攻击者。考虑到这一点，我们可以不加验证的解码ID令牌。谷歌就是这样做的：<code>https://developers.google.com/identity/protocols/OpenIDConnect#obtainuserinfo</code>。</p>
<p>看看上面的JWT。它由三个部分组成，每个部分用一个句点分隔。我们可以在点上分割字符串，然后取出中间部分。中间部分是base64编码的JSON字符串，包含ID令牌数据。以下是JWT中的数据示例。</p>
<pre><code class="json">{
  &quot;azp&quot;: &quot;272196069173.apps.googleusercontent.com&quot;,
  &quot;aud&quot;: &quot;272196069173.apps.googleusercontent.com&quot;,
  &quot;sub&quot;: &quot;110248495921238986420&quot;,
  &quot;hd&quot;: &quot;okta.com&quot;,
  &quot;email&quot;: &quot;aaron.parecki@okta.com&quot;,
  &quot;email_verified&quot;: true,
  &quot;at_hash&quot;: &quot;0bzSP5g7IfV3HXoLwYS3Lg&quot;,
  &quot;exp&quot;: 1524601669,
  &quot;iss&quot;: &quot;https://accounts.google.com&quot;,
  &quot;iat&quot;: 1524598069
}
</code></pre>
<p>我们真正关心的这个演示是两个属性sub和email。sub(subject)属性包含了登录用户的唯一用户标识符。我们会提取它，并将其存储在会话中，这将向我们的应用程序表明用户已经登录。</p>
<p>我们还会在会话中存储ID令牌和访问令牌，以便我们以后可以使用它们，这也是我们获取并显示用户信息的另一种方法。</p>
<pre><code class="php">  // ... continuing from the previous code sample, insert this

  // Split the JWT string into three parts
  $jwt = explode(&#39;.&#39;, $data[&#39;id_token&#39;]);

  // Extract the middle part, base64 decode, then json_decode it
  $userinfo = json_decode(base64_decode($jwt[1]), true);

  $_SESSION[&#39;user_id&#39;] = $userinfo[&#39;sub&#39;];
  $_SESSION[&#39;email&#39;] = $userinfo[&#39;email&#39;];

  // While we&#39;re at it, let&#39;s store the access token and id token
  // so we can use them later
  $_SESSION[&#39;access_token&#39;] = $data[&#39;access_token&#39;];
  $_SESSION[&#39;id_token&#39;] = $data[&#39;id_token&#39;];

  header(&#39;Location: &#39; . $baseURL);
  die();
}
</code></pre>
<p>现在，您将被重定向回应用程序的主页，我们将使用我们在先前创建的代码向您显示用户ID和电子邮件。</p>
<pre><code class="javascript">echo &#39;&lt;p&gt;User ID: &#39;.$_SESSION[&#39;user_id&#39;].&#39;&lt;/p&gt;&#39;;
echo &#39;&lt;p&gt;Email: &#39;.$_SESSION[&#39;email&#39;].&#39;&lt;/p&gt;&#39;;
</code></pre>
<h4 id="使用ID令牌检索用户信息"><a href="#使用ID令牌检索用户信息" class="headerlink" title="使用ID令牌检索用户信息"></a>使用ID令牌检索用户信息</h4><p>Google提供了一个额外的API endpoint，称为tokeninfo endpoint，您可以使用它来查找ID令牌详细信息，而不是自己解析它。这不建议用于生产应用程序，因为它需要额外的HTTP往返，但可用于测试和故障排除。</p>
<p>Google的tokeninfo endpoint<code>https://www.googleapis.com/oauth2/v3/tokeninfo</code>位于其OpenID Connect发现文档中:<code>https://accounts.google.com/.well-known/openid-configuration</code>。要查找我们收到的ID令牌的信息，请使用查询字符串中的ID令牌向tokeninfo endpoint发出GET请求。</p>
<p><code>https://www.googleapis.com/oauth2/v3/tokeninfo?id_token=eyJ</code></p>
<p>响应将是一个JSON对象，其中包含JWT本身包含的类似属性列表。</p>
<pre><code class="json">{
 &quot;azp&quot;: &quot;272196069173.apps.googleusercontent.com&quot;,
 &quot;aud&quot;: &quot;272196069173.apps.googleusercontent.com&quot;,
 &quot;sub&quot;: &quot;110248495921238986420&quot;,
 &quot;hd&quot;: &quot;okta.com&quot;,
 &quot;email&quot;: &quot;aaron.parecki@okta.com&quot;,
 &quot;email_verified&quot;: &quot;true&quot;,
 &quot;at_hash&quot;: &quot;NUuq_yggZYi_2-13hJSOXw&quot;,
 &quot;exp&quot;: &quot;1524681857&quot;,
 &quot;iss&quot;: &quot;https://accounts.google.com&quot;,
 &quot;iat&quot;: &quot;1524678257&quot;,
 &quot;alg&quot;: &quot;RS256&quot;,
 &quot;kid&quot;: &quot;affc62907a446182adc1fa4e81fdba6310dce63f&quot;
}
</code></pre>
<h4 id="使用访问令牌来检索用户信息"><a href="#使用访问令牌来检索用户信息" class="headerlink" title="使用访问令牌来检索用户信息"></a>使用访问令牌来检索用户信息</h4><p>如前所述，许多OAuth 2.0服务还提供endpoint来检索登录用户的用户信息。这是OpenID Connect标准的一部分，endpoint将成为服务的OpenID Connect Discovery文档的一部分。</p>
<p>谷歌的userinfo endpoint是<code>https://www.googleapis.com/oauth2/v3/userinfo</code>。在这种情况下，您使用访问令牌而不是ID令牌来查找用户信息。向该 endpoint发出GET请求，并像执行OAuth 2.0 API请求时那样,在HTTP Header中添加Authorization传递访问令牌。</p>
<pre><code class="http">GET /oauth2/v3/userinfo
Host: www.googleapis.com
Authorization: Bearer ya29.Gl-oBRPLiI9IrSRA70...
</code></pre>
<p>响应将是一个JSON对象，其中包含有关用户的若干属性。响应将始终包含sub密钥，该密钥是用户的唯一标识符。Google还会返回用户的个人资料信息，例如姓名，个人资料照片网址，性别，区域设置，个人资料网址和电子邮件。服务器还可以添加自己的声明，例如Google hd在使用G Suite帐户时显示帐户的“托管域”。</p>
<pre><code class="json">{
 &quot;sub&quot;: &quot;110248495921238986420&quot;,
 &quot;name&quot;: &quot;Aaron Parecki&quot;,
 &quot;given_name&quot;: &quot;Aaron&quot;,
 &quot;family_name&quot;: &quot;Parecki&quot;,
 &quot;picture&quot;: &quot;https://lh4.googleusercontent.com/-kw-iMgD
   _j34/AAAAAAAAAAI/AAAAAAAAAAc/P1YY91tzesU/photo.jpg&quot;,
 &quot;email&quot;: &quot;aaron.parecki@okta.com&quot;,
 &quot;email_verified&quot;: true,
 &quot;locale&quot;: &quot;en&quot;,
 &quot;hd&quot;: &quot;okta.com&quot;
}
</code></pre>
<h4 id="下载示例代码"><a href="#下载示例代码" class="headerlink" title="下载示例代码"></a>下载示例代码</h4><p>您可以从GitHub下载此示例中使用的完整示例代码，网址为<code>https://github.com/aaronpk/sample-oauth2-client</code>。</p>
<p>在用户登录后，您已经看到了三种不同的方式来获取用户的个人资料信息。那么您应该使用哪个以及何时使用？</p>
<p>对于性能敏感的应用程序，您可能在每个请求上读取ID令牌或使用它们来维护会话，您绝对应该在本地验证ID令牌而不是发出网络请求。Google的API文档提供了有关离线验证ID令牌的详细信息的指南。</p>
<p>如果您所做的只是在登录后尝试查找用户的姓名和电子邮件，那么向userinfo endpoint发出API请求是最简单，最直接的选择。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--访问OAuth服务器中的数据]]></title>
      <url>/2018/07/13/oauth-guide-2/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>在本章中，我们将介绍如何在现有OAuth 2.0服务器上访问您的数据。对于此示例，我们将使用GitHub API，并构建一个简单的应用程序，该应用程序将展示出该GitHub登录用户创建的所有库。</p>
<h3 id="创建一个应用程序"><a href="#创建一个应用程序" class="headerlink" title="创建一个应用程序"></a>创建一个应用程序</h3><p>在我们开始之前，我们需要在GitHub上创建一个应用程序，以获取客户端ID和客户端密钥。</p>
<p>在GitHub.com上，从“设置”页面，单击侧栏中的“开发人员设置”链接。您最终将访问<code>https://github.com/settings/developers</code>。从那里，单击“新OAuth应用程序”，您将看到一个简短的表单，如下所示。</p>
<p>填写所需信息，包括回调URL。如果您在本地开发应用程序，则必须使用本地地址作为回调URL。由于GitHub每个应用程序只允许一个注册的回调URL，因此创建两个应用程序非常有用，一个用于开发，另一个用于生产。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1ft8d4v1w2oj318g0v40wo.jpg" alt="在GitHub上注册一个新的OAuth应用程序"></p>
<p>完成此表单后，您将进入一个页面，您可以在其中看到发布到您的应用程序的客户端ID和秘钥，如下所示。</p>
<p>客户端ID被视为公共信息，用于构建登录URL，或者可以包含在网页的Javascript源代码中。客户密钥必须保密。不要将它提交到您的git存储库！</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ft8dayhs69j316k1vdqcv.jpg" alt="GitHub应用程序已创建"></p>
<h3 id="建立环境"><a href="#建立环境" class="headerlink" title="建立环境"></a>建立环境</h3><p>此示例代码是用PHP编写的，不需要外部包，也不需要框架。这可以很容易地翻译成其他语言。您可以将它全部放在一个PHP文件中。</p>
<p>创建一个新文件夹并在该文件夹中创建一个空文件<code>index.php</code>。从该文件夹内部运行命令行，<code>php -S localhost:8000</code>，您将能够在浏览器中访问<code>http://localhost:8000</code>来运行您的代码。以下示例中的所有代码都应添加到此index.php文件中。</p>
<p>为了让我们更轻松，让我们定义一个方法，<code>apiRequest()</code>它是一个简单的cURL包装器。此函数将包含GitHub API所需的<code>Accept</code>和<code>User-Agent Header</code>，并自动解码JSON响应。如果我们在会话中有访问令牌，它也会发送带有访问令牌的正确OAuth Header，以便进行经过身份验证的请求。</p>
<pre><code class="php">function apiRequest($url, $post=FALSE, $headers=array()) {
  $ch = curl_init($url);
  curl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);

  if($post)
    curl_setopt($ch, CURLOPT_POSTFIELDS, http_build_query($post));

  $headers = [
    &#39;Accept: application/vnd.github.v3+json, application/json&#39;,
    &#39;User-Agent: https://example-app.com/&#39;
  ];

  if(isset($_SESSION[&#39;access_token&#39;]))
    $headers[] = &#39;Authorization: Bearer &#39;.$_SESSION[&#39;access_token&#39;];

  curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);

  $response = curl_exec($ch);
  return json_decode($response, true);
}
</code></pre>
<p>现在让我们设置一些OAuth流程所需的变量。</p>
<pre><code class="php">// Fill these out with the values from Github
$githubClientID = &#39;&#39;;
$githubClientSecret = &#39;&#39;;

// This is the URL we&#39;ll send the user to first
// to get their authorization
$authorizeURL = &#39;https://github.com/login/oauth/authorize&#39;;

// This is the endpoint we&#39;ll request an access token from
$tokenURL = &#39;https://github.com/login/oauth/access_token&#39;;

// This is the Github base URL for API requests
$apiURLBase = &#39;https://api.github.com/&#39;;

// The URL for this script, used as the redirect URL
$baseURL = &#39;https://&#39; . $_SERVER[&#39;SERVER_NAME&#39;]
    . $_SERVER[&#39;PHP_SELF&#39;];

// Start a session so we have a place to
// store things between redirects
session_start();
</code></pre>
<p>首先，让我们设置“登录”和“注销”视图。这将显示一条简单的消息，指示用户是登录还是注销。</p>
<pre><code class="php">// If there is an access token in the session
// the user is already logged in
if(!isset($_GET[&#39;action&#39;])) {
  if(!empty($_SESSION[&#39;access_token&#39;])) {
    echo &#39;&lt;h3&gt;Logged In&lt;/h3&gt;&#39;;
    echo &#39;&lt;p&gt;&lt;a href=&quot;?action=repos&quot;&gt;View Repos&lt;/a&gt;&lt;/p&gt;&#39;;
    echo &#39;&lt;p&gt;&lt;a href=&quot;?action=logout&quot;&gt;Log Out&lt;/a&gt;&lt;/p&gt;&#39;;
  } else {
    echo &#39;&lt;h3&gt;Not logged in&lt;/h3&gt;&#39;;
    echo &#39;&lt;p&gt;&lt;a href=&quot;?action=login&quot;&gt;Log In&lt;/a&gt;&lt;/p&gt;&#39;;
  }
  die();
}
</code></pre>
<p>已注销的视图包含指向我们的登录URL的链接，该URL启动OAuth流程。</p>
<h3 id="授权请求"><a href="#授权请求" class="headerlink" title="授权请求"></a>授权请求</h3><p>现在我们已经设置了必要的变量，让我们开始OAuth流程。</p>
<p>我们要让人们做的第一件事是,在查询字符串<code>?action=login</code>中访问此页面以启动该过程。</p>
<p>请注意，我们在此请求中要求的范围包括<code>user</code>和<code>public_repo</code>。这意味着该应用程序将能够读取用户配置文件信息以及访问公共存储库。</p>
<pre><code class="php">// Start the login process by sending the user
// to Github&#39;s authorization page
if(isset($_GET[&#39;action&#39;]) &amp;&amp; $_GET[&#39;action&#39;] == &#39;login&#39;) {
  unset($_SESSION[&#39;access_token&#39;]);

  // Generate a random hash and store in the session
  $_SESSION[&#39;state&#39;] = bin2hex(random_bytes(16));

  $params = array(
    &#39;response_type&#39; =&gt; &#39;code&#39;,
    &#39;client_id&#39; =&gt; $githubClientID,
    &#39;redirect_uri&#39; =&gt; $baseURL,
    &#39;scope&#39; =&gt; &#39;user public_repo&#39;,
    &#39;state&#39; =&gt; $_SESSION[&#39;state&#39;]
  );

  // Redirect the user to Github&#39;s authorization page
  header(&#39;Location: &#39;.$authorizeURL.&#39;?&#39;.http_build_query($params));
  die();
}
</code></pre>
<p>生成用于保护客户端的“state”参数非常重要。这是客户端生成并存储在会话中的随机字符串。我们使用state参数作为额外的安全检查，以便当Github将用户发送回查询字符串中的状态时，我们可以验证我们确实发起了此请求，并且它不是发出该请求的攻击者。</p>
<p>我们建立授权URL，然后将用户发送到那里。URL包含我们的公共客户端ID，我们之前在Github上注册的重定向URL，我们要求的范围以及“state”参数。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1ft8difjyjmj30xg1dsjx4.jpg" alt="GitHub的授权请求"></p>
<p>此时，用户将看到Github的OAuth授权提示，如上所示。</p>
<p>当用户批准该请求时，他们将被重定向回我们的页面并在请求中包含code和state参数。下一步是用授权码交换访问令牌。</p>
<h3 id="获取访问令牌"><a href="#获取访问令牌" class="headerlink" title="获取访问令牌"></a>获取访问令牌</h3><p>当用户被重定向回我们的应用程序时，查询字符串中将有一个code和state参数。该state参数将与我们在初始授权请求中设置的参数相同，在我们继续使用应用程序之前应该检查它是否匹配。这可以确保我们的应用程序不会被欺骗向GitHub发送攻击者的授权代码。</p>
<pre><code class="php">// When Github redirects the user back here,
// there will be a &quot;code&quot; and &quot;state&quot; parameter in the query string
if(isset($_GET[&#39;code&#39;])) {
  // Verify the state matches our stored state
  if(!isset($_GET[&#39;state&#39;])
    || $_SESSION[&#39;state&#39;] != $_GET[&#39;state&#39;]) {

    header(&#39;Location: &#39; . $baseURL . &#39;?error=invalid_state&#39;);
    die();
  }

  // Exchange the auth code for an access token
  $token = apiRequest($tokenURL, array(
    &#39;grant_type&#39; =&gt; &#39;authorization_code&#39;,
    &#39;client_id&#39; =&gt; $githubClientID,
    &#39;client_secret&#39; =&gt; $githubClientSecret,
    &#39;redirect_uri&#39; =&gt; $baseURL,
    &#39;code&#39; =&gt; $_GET[&#39;code&#39;]
  ));
  $_SESSION[&#39;access_token&#39;] = $token[&#39;access_token&#39;];

  header(&#39;Location: &#39; . $baseURL);
  die();
}
</code></pre>
<p>在这里，我们向Github的令牌endpoint发送请求，用授权码来交换访问令牌。该请求包含我们的公共客户端ID以及私密客户端密钥。我们还发送与之前相同的重定向URL以及授权码。</p>
<p>如果一切都检出，Github会生成一个访问令牌并在响应中返回它。我们将访问令牌存储在会话中并重定向到主页，并且用户已登录。</p>
<p>GitHub的回复如下所示。</p>
<pre><code class="json">{
  &quot;access_token&quot;: &quot;e2f8c8e136c73b1e909bb1021b3b4c29&quot;,
  &quot;token_type&quot;: &quot;bearer&quot;,
  &quot;scope&quot;: &quot;public_repo,user&quot;
}
</code></pre>
<p>我们的代码已经提取了访问令牌并将其保存在会话中。下次访问该页面时，它会识别出已存在访问令牌并显示我们之前创建的登录页面。</p>
<p>注意：为简单起见，我们在此示例中未包含任何错误处理代码。实际上，您将检查从GitHub返回的错误并向用户显示相应的消息。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OAuth教程--准备工作]]></title>
      <url>/2018/07/13/oauth-guide-1/</url>
      <content type="html"><![CDATA[<p><strong>本文是oauth.com上的教程的翻译。（<a href="https://www.oauth.com" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<blockquote>
<p>前言：</p>
<p>最近在看SSO相关的内容，发现自己对OAuth2.0只是一知半解，阮一峰的文章不错，但是真正用在开发上就远远不够了，于是决定花点时间翻译一下<a href="https://www.oauth.com/" target="_blank" rel="noopener">www.oauth.com</a>上的教程，加深理解。</p>
<p>我真是无语了，文档翻译到一半的时候，oauth.com更新了，醉了醉了，白翻译了十八个章节。</p>
</blockquote>
<p>在本书的第一部分中，我们将介绍在构建与现有OAuth 2.0 API对话的应用程序时需要了解的内容。无论您是构建网络应用程序还是移动应用程序，在开始使用时都需要记住一些事项。</p>
<p>每个OAuth 2.0服务都要求您首先注册一个新应用程序，这通常还要求您首先注册为该服务的开发人员。</p>
<h3 id="创建应用程序"><a href="#创建应用程序" class="headerlink" title="创建应用程序"></a>创建应用程序</h3><p>注册过程通常涉及在服务的网站上创建一个帐户，然后输入有关应用程序的基本信息，如名称，网站，logo等。注册申请后，您将获得client_id（在某些情况下也有client_secret），当您的应用与服务互动时，您将使用它们。</p>
<p>创建应用程序时最重要的事情之一是注册应用程序将使用的一个或多个重定向URL。重定向URL是OAuth 2.0服务在应用程序授权之后，将用户返回的位置。注册这些是至关重要的，否则很容易创建可以窃取用户数据的恶意应用程序。本书稍后将对此进行更详细的介绍。</p>
<h3 id="重定向网址和状态"><a href="#重定向网址和状态" class="headerlink" title="重定向网址和状态"></a>重定向网址和状态</h3><p>OAuth 2.0 API仅将用户重定向到已注册的URL，以防止攻击者拦截授权码或访问令牌的重定向攻击。某些服务可能允许您注册多个重定向URL，这在Web应用程序和移动应用程序使用相同的客户端ID、或者在开发和生产服务中使用相同的客户端ID时，将为开发者提供帮助。</p>
<p>为了安全起见，重定向URL必须是https端点，以防止在授权过程中拦截代码。如果您的重定向URL不是https，则攻击者可能能够拦截授权代码并使用它来劫持会话。如果服务允许使用非https重定向，则必须采取额外的预防措施以确保无法进行此类攻击。</p>
<p>大多数服务将重定向URL验证视为完全匹配。这意味着重定向网址<code>https://example.com/auth</code>不匹配<code>https://example.com/auth?destination=account</code>。最佳做法是避免在重定向URL中使用查询字符串参数，并使其仅包含路径。</p>
<p>某些应用程序可能有多个他们想要启动OAuth进程的位置，例如主页上的登录链接以及查看某些公共项目时的登录链接。对于这些应用程序，尝试注册多个重定向URL可能很诱人，或者您可能认为需要能够根据请求更改重定向URL。但请不要这么做，因为OAuth 2.0为此提供了一种机制，即“state”参数。</p>
<p>“state”参数可以用于任何你想要的服务，它是一个对OAuth 2.0服务不透明的字符串。在用户授权应用程序后，将返回您在初始授权请求期间传递的state值。其中一个常见的应用场景是包括一个随机字符串来防止CSRF攻击。您还可以使用JWT之类的技术对重定向URL进行编码，并在用户重定向回应用程序后对其进行解析，以便您在登录后将用户带回适当的位置。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[什么是OAuth？]]></title>
      <url>/2018/06/19/what-is-oauth/</url>
      <content type="html"><![CDATA[<p><strong>本文是Matt Raible的What the Heck is OAuth?的翻译。（<a href="https://developer.okta.com/blog/2017/06/21/what-the-heck-is-oauth" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<blockquote>
<p>围绕OAuth的实际情况存在很多混淆。</p>
<p>有些人认为OAuth是一种登录流程（就像当您使用Google登录登录应用程序时一样），有些人不假思索的认为OAuth是一种“安全事物”。</p>
<p>我将向您展示OAuth是什么，解释它的工作原理，并希望让您了解OAuth是如何使您的应用受益的。</p>
</blockquote>
<h3 id="什么是OAuth？"><a href="#什么是OAuth？" class="headerlink" title="什么是OAuth？"></a>什么是OAuth？</h3><p>我们先从最顶层的描述说起，OAuth 不是 API或服务：它是授权的开放标准，任何人都可以实施。</p>
<p>更具体地说，OAuth是应用程序可以用来为客户端提供“安全授权访问”的标准。OAuth通过HTTPS工作，并使用access tokens为设备，API，服务器和应用程序授权，而非credentials。</p>
<p>有两种版本的OAuth：<a href="https://tools.ietf.org/html/rfc5849" target="_blank" rel="noopener">OAuth 1.0a</a>和<a href="https://tools.ietf.org/html/rfc6749" target="_blank" rel="noopener">OAuth 2.0</a>。这些规范是完全不同的，不能一起使用：它们之间没有向后兼容性。</p>
<p>哪一个更受欢迎？如今，OAuth 2.0是最广泛使用的OAuth形式。所以从现在开始，每当我说“OAuth”时，我都在谈论OAuth 2.0–因为它很可能是您将要使用的。</p>
<h3 id="为什么使用OAuth？"><a href="#为什么使用OAuth？" class="headerlink" title="为什么使用OAuth？"></a>为什么使用OAuth？</h3><p>OAuth是对直接身份验证模式的响应。这种模式因HTTP基本认证（Basic Authentication）而闻名，用户会被提示输入用户名和密码。基本身份验证仍然是服务器端应用程序的API身份验证的基本形式：用户发送API密钥ID和密钥，而不是通过每个请求向服务器发送用户名和密码。在OAuth之前，网站会提示您直接在表单中输入用户名和密码，他们会像您一样登录您的数据（例如您的Gmail帐户）。这通常被称为<a href="https://arstechnica.com/information-technology/2010/01/oauth-and-oauth-wrap-defeating-the-password-anti-pattern/" target="_blank" rel="noopener">反密码模式(the password anti-pattern)</a>。</p>
<p>为了为网络创建更好的系统，联合身份为单点登录（SSO）的场景所创建。在这种情况下，终端用户与他们的身份提供者交谈，并且身份提供者生成一个加密签名的token，交给应用程序对用户进行身份验证。应用程序信任身份提供者。只要这种信任关系与登录的断言一起工作，你就登陆成功了。下图显示了这是如何工作的。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/browser_spa_implicit_flow-9f0d10069f4363030e4283679bd4914f9aa47e192b32a166d1e186bdb929e1d2.png" alt="oauth工作流程"></p>
<h3 id="浏览器隐式流程"><a href="#浏览器隐式流程" class="headerlink" title="浏览器隐式流程"></a>浏览器隐式流程</h3><p>联合身份因为由2005年3月15日发布的OASIS标准SAML 2.0而变得知名。它是一个很大的规范，但主要的两个组件是它的身份验证请求协议（又名Web SSO）以及它打包身份属性和签名的方式，称为SAML断言。Okta用SSO chiclets做到这一点。我们发送一条消息，我们在断言中签名，在断言中记录着用户是谁，来自Okta。再加上一个数字签名，你就登录成功了。</p>
<h3 id="SAML"><a href="#SAML" class="headerlink" title="SAML"></a>SAML</h3><p>SAML基本上是浏览器中的会话cookie，可让您访问webapps。如果您想要在Web浏览器之外的各种设备和场景中使用，它将会受到限制。</p>
<p>当SAML 2.0于2005年推出时，它是有道理的。不过，自那以后发生了很多变化。现在我们拥有现代化的网页和原生应用程序开发平台，有单页面应用程序（SPA），如Gmail / Google收件箱，Facebook和Twitter。它们与传统的Web应用程序有不同的行为，因为它们会对API进行AJAX（后台HTTP调用）。移动电话也进行API调用，电视，游戏控制台和物联网设备也一样。SAML SSO在这方面并不是特别优秀。</p>
<h3 id="OAuth和API"><a href="#OAuth和API" class="headerlink" title="OAuth和API"></a>OAuth和API</h3><p>我们构建API的方式也发生了很大变化。在2005年，人们投资于WS- *来构建Web服务。现在，大多数开发人员已经转移到REST和无状态API。简而言之，REST是通过网络推送JSON包的HTTP命令。</p>
<p>开发人员构建了很多API。API经济是您今天可能在会议室听到的常见流行词。公司需要保护其REST API，以允许许多设备访问它们。在过去，您需要输入您的用户名/密码，该应用程序将直接以您的身份登录。这引起了委托授权问题。</p>
<p>“我怎样才能允许应用程序访问我的数据，而不必给我的密码？”</p>
<p>如果您见过以下对话框之一，那就是我们正在谈论的内容。这是一个应用程序，询问您是否可以代表您访问数据。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/biketoworkday-fb-login-f00e39aabbf3e44bc3570333643cbf5d966fc27367dbffd2623ff4a3694831c3.png" alt="Facebook OAuth"></p>
<p>这是OAuth。</p>
<p>OAuth是REST / API的委托授权框架。它使应用程序可以在不泄露用户密码的情况下获取用户数据的有限访问权限（范围）。它将认证(authentication)与授权(authorization)分离开来，并支持多种用例来满足不同的设备功能。它支持服务器到服务器应用程序，基于浏览器的应用程序，移动/本机应用程序和控制台/电视。</p>
<p>对于应用程序来说，你可以把它想成酒店钥匙卡。如果你有酒店钥匙卡，你可以进入你的房间。你如何获得酒店钥匙卡？您必须在前台进行身份验证才能获得。在认证并获得钥匙卡后，您可以访问整个酒店的资源。</p>
<p>简单地说，OAuth就是：</p>
<ul>
<li>应用程序向用户请求授权</li>
<li>用户授权应用程序并提供证据</li>
<li>应用程序向服务器提供授权证明以获取令牌（token）</li>
<li>令牌（token）仅限于访问用户为特定应用程序授权的内容</li>
</ul>
<h3 id="OAuth中央组件"><a href="#OAuth中央组件" class="headerlink" title="OAuth中央组件"></a>OAuth中央组件</h3><p>OAuth建立在以下中心组件之上：</p>
<ul>
<li>作用域和同意书（Scopes and Consent）</li>
<li>扮演者（Actors）</li>
<li>客户端（Clients）</li>
<li>令牌（Tokens）</li>
<li>授权服务器（Authorization Server）</li>
<li>流程（Flows）</li>
</ul>
<h3 id="OAuth作用域"><a href="#OAuth作用域" class="headerlink" title="OAuth作用域"></a>OAuth作用域</h3><p>作用域是您在应用程序请求权限时在授权屏幕上看到的内容。它们是客户在请求令牌时所需求的权限包。这些由应用程序开发人员在编写应用程序时进行编码。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/auth-scope.png" alt="OAuth作用域"></p>
<p>作用域将授权策略的决策与执行分离。这是OAuth的第一个关键方面。权限是中心。它们不会隐藏在应用程序层后面。它们经常在API文档中列出：以下是这个应用程序需要的范围。</p>
<p>你必须获得这一同意。这被称为首次使用的信任。这是网络上非常重要的用户体验变化。OAuth之前的大多数人只是用id和密码对话框。现在你有了这个新的屏幕，你必须训练用户使用。重新调整互联网人口是困难的。从熟悉技术的年轻人到祖父母都有各种各样的用户，他们不熟悉这种流程。这是网络上的一个新概念，现在是前沿和中心。现在你必须授权并征得同意。</p>
<p>同意书可以根据应用程序而有所不同。它可以是时间敏感的作用域范围（日，周，月），但并非所有平台都允许您选择持续时间。当您同意时，需要注意的一点是，该应用程序可以代表您执行某些操作 - 例如，LinkedIn会将您网络中的每个人都发送出去。</p>
<p>OAuth是互联网规模的解决方案，因为它应用于每个应用程序。您经常可以登录到仪表板，查看您授予访问权的应用程序并撤消同意。</p>
<h3 id="OAuth扮演者"><a href="#OAuth扮演者" class="headerlink" title="OAuth扮演者"></a>OAuth扮演者</h3><p>OAuth流程中的角色如下所示：</p>
<ul>
<li>资源所有者：拥有资源服务器中的数据。例如，我是我的Facebook个人资料的资源所有者。</li>
<li>资源服务器：存储应用程序想要访问的数据的API</li>
<li>客户端：想要访问您的数据的应用程序</li>
<li>授权服务器：OAuth的主要引擎<br><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/oauth-actor.png" alt="OAuth演员"></li>
</ul>
<p>资源所有者是一个可以使用不同凭据更改的角色。它可以是最终用户，也可以是公司。</p>
<p>客户端可以公开和保密。OAuth命名法中两者之间存在显着的区别。受信任的客户端可以信任存储秘钥。它们不是在桌面上运行，或通过应用商店分发。人们无法对其进行逆向工程并获得密钥。他们在最终用户无法访问的受保护区域运行。</p>
<p>公共客户端是浏览器，移动应用程序和物联网设备。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/oauth-client.png" alt="OAuth客户端"></p>
<p>客户端注册也是OAuth的关键组件。这就像OAuth的DMV（车辆管理局）。您需要获取应用程序的牌照。这是您的应用在授权对话框中显示的方式。</p>
<h3 id="OAuth令牌"><a href="#OAuth令牌" class="headerlink" title="OAuth令牌"></a>OAuth令牌</h3><p>访问令牌是客户用来访问资源服务器（API）的令牌。他们的目的是短暂的。想象他们在几个小时和几分钟内，而不是几个月和几个月。你不需要一个机密的客户端来获得访问令牌。您可以使用公共客户端来获取访问令牌。它们旨在优化互联网规模问题。因为这些令牌可以短暂存在并扩展出来，所以它们不能被撤销，你只能等待它们超时。</p>
<p>另一个令牌是刷新令牌。这种寿命要长得多。几天，几个月，几年。这可以用来获得新的令牌。要获得刷新令牌，应用程序通常需要受信任客户端进行身份验证。</p>
<p>刷新令牌可以被撤消。当在仪表板中撤销应用程序的访问时，您正在刷新它的刷新令牌。这使您能够强制客户更新秘钥。您使用刷新令牌获取新的访问令牌，访问令牌通过线路打所有的API资源。当你每次刷新访问令牌时，都会得到一个新的加密签名令牌。更新的开关内置于系统中。</p>
<p>OAuth规范并未定义令牌的含义。它可以以任何你想要的格式。通常情况下，您希望这些令牌是JSON Web Token（一种标准）。简而言之，JWT（发音为“jot”）是令牌认证的安全可靠标准。JWT允许您使用签名对信息进行数字签名(claims)，并可以在稍后使用一个秘密的签名密钥进行验证。要了解关于JWT的更多信息，请参阅<a href="https://stormpath.com/blog/beginners-guide-jwts-in-java" target="_blank" rel="noopener">Java中的JWT初学者指南</a>。</p>
<p>令牌从授权服务器上的endpoint上取回。两个主要endpoint是授权endpoint和令牌endpoint。它们分开用于不同的用例。授权endpoint是您去哪里获得用户同意和授权的地方。这将返回一个授权，表示用户已同意。然后授权被传递给令牌端点。令牌端点处理授权并说“很好，这是您的刷新令牌和您的访问令牌”。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/oauth-server.png" alt="授权服务器"></p>
<p>您可以使用访问令牌访问API。一旦到期，您将必须返回带有刷新令牌的令牌端点以获取新的访问令牌。</p>
<p>缺点是这导致了很多开发者的反对。开发人员对OAuth最大的难点之一就是你必须管理刷新令牌。你将状态管理推给每个客户端开发者。你获得了关键轮换的好处，但是你为开发者创造了很多痛苦。这就是开发人员喜欢API密钥的原因。他们可以复制/粘贴它们，将它们放在文本文件中，然后用它们完成。API密钥对开发人员非常方便，但对安全性非常不利。</p>
<p>这是一个代价问题。让开发人员执行OAuth流程可提高安全性，但存在更多的摩擦。工具包和平台有机会简化事情并帮助进行令牌管理。幸运的是，现在OAuth已经非常成熟了，您最喜欢的语言或框架都可能用用于简化OAuth的工具。</p>
<p>我们已经谈了一些关于客户端类型，令牌类型和授权服务器的endpoint以及我们如何将其传递给资源服务器的内容。我提到了两种不同的流程：获得授权和获取令牌。这些不必在同一个通道上发生。前向通道是浏览器的内容。浏览器将用户重定向到授权服务器，用户表示同意。这发生在用户的浏览器上。一旦用户获得授权许可并将其交给应用程序，客户端应用程序就不再需要使用浏览器来完成OAuth流程以获取令牌。</p>
<p>令牌旨在被客户端应用程序使用，以便它可以代表您访问资源。我们称之为后向通道。后向的通道是直接从客户端应用程序到资源服务器的HTTP调用，用于交换令牌的授权许可。这些通道用于不同的流程，具体取决于您拥有的设备功能。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/oauth-channel.png" alt="流动通道"></p>
<p>例如，您通过用户代理进行授权的前向通道可能如下所示：</p>
<ul>
<li>资源所有者启动流程来委派对受保护资源的访问</li>
<li>客户端通过浏览器重定向到授权服务器上的授权端点，向所需范围发送授权请求</li>
<li>授权服务器返回一个同意对话框，指出“您是否允许此应用程序访问这些范围？”当然，您需要向应用程序进行身份验证，所以如果您未通过资源服务器的身份验证，它会询问你登录。如果您已经有了一个缓存的会话cookie，您只会看到同意对话框。查看同意对话框，并同意。</li>
<li>授权许可通过浏览器重定向传递回应用程序。这一切都发生在前向通道。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/front-channel.png" alt="前向通道"></p>
<p>这种流程中也存在一种称为隐式流程的变化。我们稍后再讨论。</p>
<p>这就是它在请求中的样子。</p>
<p><strong>Request</strong></p>
<blockquote>
<p>GET <a href="https://accounts.google.com/o/oauth2/auth?scope=gmail.insert" target="_blank" rel="noopener">https://accounts.google.com/o/oauth2/auth?scope=gmail.insert</a> gmail.send<br>&amp;redirect_uri=<a href="https://app.example.com/oauth2/callback" target="_blank" rel="noopener">https://app.example.com/oauth2/callback</a><br>&amp;response_type=code&amp;client_id=812741506391<br>&amp;state=af0ifjsldkj</p>
</blockquote>
<p>这是一个带有一堆查询参数的GET请求（不是出于示例目的的URL编码）。范围来自Gmail的API。redirect_uri是当授权完成时，所返回的客户端应用程序的URL。这应该与客户注册过程（在DMV处）的值相匹配。您不希望授权被退回到外部应用程序。响应类型会改变OAuth流向。客户端ID也来自注册过程。国家是一个安全标志，类似于XRSF。要了解有关XRSF的更多信息，请参阅<a href="https://dzone.com/articles/cross-site-request-forgery" target="_blank" rel="noopener">DZone的“跨站请求伪造解释”</a>。</p>
<p><strong>Response</strong></p>
<blockquote>
<p>HTTP/1.1 302 Found<br>Location: <a href="https://app.example.com/oauth2/callback?" target="_blank" rel="noopener">https://app.example.com/oauth2/callback?</a><br>code=MsCeLvIaQm6bTrgtp7&amp;state=af0ifjsldkj</p>
<p><em>code</em>返回授权认证，<em>state</em>确保它不是伪造的，即它是由同一个请求发出。</p>
</blockquote>
<p>前向通道完成后，会进行前向通道，并将授权码交换为访问令牌。</p>
<p>客户端应用程序使用受信任的客户端凭证和客户端ID访问授权服务器上的令牌endpoint，并发送访问令牌请求。该过程交换访问令牌和（可选）刷新令牌的授权代码授权。客户端使用访问令牌访问受保护的资源。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/back-channel.png" alt="后向通道流"></p>
<p>下面是其在HTTP中的样子。</p>
<p><strong>Request</strong></p>
<blockquote>
<p>POST /oauth2/v3/token HTTP/1.1<br>Host: www.googleapis.com<br>Content-Type: application/x-www-form-urlencoded</p>
<p>code=MsCeLvIaQm6bTrgtp7&amp;client_id=812741506391&amp;client_secret={client_secret}&amp;redirect_uri=<a href="https://app.example.com/oauth2/callback&amp;grant_type=authorization_code" target="_blank" rel="noopener">https://app.example.com/oauth2/callback&amp;grant_type=authorization_code</a></p>
</blockquote>
<p>grant_type是OAuth的可扩展性部分。这是来自预先获得的授权代码。它开辟了用不同方式来描述这些授权的灵活性。这是最常见的OAuth流程类型。</p>
<p><strong>Response</strong></p>
<blockquote>
<p>{<br>  “access_token”: “2YotnFZFEjr1zCsicMWpAA”,<br>  “token_type”: “Bearer”,<br>  “expires_in”: 3600,<br>  “refresh_token”: “tGzv3JOkF0XG5Qx2TlKWIA”<br>}</p>
</blockquote>
<p>响应是JSON。您可以在使用令牌时具有反应性或主动性。主动性是在你的客户端有一个计时器。反应性是捕捉一个错误，然后尝试获取新的令牌。</p>
<p>一旦获得访问令牌，就可以在验证头中使用访问令牌（使用token_type前缀）来提出受保护的资源请求。</p>
<blockquote>
<p>curl -H “Authorization: Bearer 2YotnFZFEjr1zCsicMWpAA” \<br>  <a href="https://www.googleapis.com/gmail/v1/users/1444587525/messages" target="_blank" rel="noopener">https://www.googleapis.com/gmail/v1/users/1444587525/messages</a></p>
</blockquote>
<p>所以现在你有一个前向通道，一个后向通道，不同的终端和不同的客户端。你必须为不同的用例进行混合和匹配。这增加了OAuth的复杂性，并且可能会引起混淆。</p>
<h3 id="OAuth流程"><a href="#OAuth流程" class="headerlink" title="OAuth流程"></a>OAuth流程</h3><p>第一个流程就是我们所说的<strong>隐式流程（Implicit Flow）</strong>。它被称为隐式流的原因是因为所有的通信都是通过浏览器进行的。没有后端服务器为访问令牌兑换授权许可。SPA是这个流程用例的一个很好的例子。该流程也称为2 Legged OAuth。</p>
<p>隐式流程针对仅限于浏览器的公共客户端进行了优化。访问令牌直接从授权请求中返回（仅限于前向通道）。它通常不支持刷新标记。它假定资源所有者和公共客户端位于同一设备上。由于所有事情都发生在浏览器上，它最容易受到安全威胁的影响。</p>
<p>黄金标准是<strong>授权代码流程（Authorization Code Flow）</strong>，又名3 Legged，它同时使用前向通道和后向通道。这就是我们在本文中讨论最多的内容。客户端应用程序使用前向通道流获取授权码授权。客户端应用程序使用后向通道交换访问令牌（以及可选的刷新令牌）的授权代码授权。它假定资源所有者和客户端应用程序位于不同的设备上。这是最安全的流程，因为您可以验证客户端以兑换授权授权，令牌永远不会通过用户代理。不仅有隐式流程和授权码流程，您还可以使用OAuth执行额外的流程。因此，OAuth更像是一个框架。</p>
<p>对于服务器到服务器方案，您可能需要使用<strong>客户端凭证流程（Client Credential Flow）</strong>。在这种情况下，客户端应用程序是一个受信任的客户端，它自己独立运行，而不是代表用户。它更像是一种服务帐户类型的场景。您所需要的只是客户的凭证来完成整个流程。这是一个仅使用客户凭证获取访问令牌的后向通道。它支持共享秘钥或断言，作为使用对称或非对称密钥签名的客户端凭证。</p>
<p>对称密钥算法是加密算法，只要您有密码，就可以解密任何内容。这通常在保护PDF或.zip文件时发现。</p>
<p>公钥加密或非对称加密是使用密钥对的任何加密系统：公钥和私钥。公钥可以被任何人读取，私钥对于所有者来说是神圣的。这使得数据安全无需分享密码。</p>
<p>还有一种传统模式称为<strong>资源所有者密码流程（Resource Owner Password Flow）</strong>。这与使用用户名和密码方案的直接身份验证非常相似，不推荐使用。它是原生用户名/密码应用程序（如桌面应用程序）的传统授权类型。在此流程中，您向客户端应用程序发送用户名和密码，并从授权服务器返回访问令牌。它通常不支持刷新令牌，并且假定资源所有者和公共客户端位于同一设备上。</p>
<p>对OAuth的最新补充是<strong>断言流程（Assertion Flow）</strong>，它与客户端证书流程类似。这是为了打开联合认证的想法。该流程允许授权服务器信任来自第三方的授权许可，如SAML IdP。授权服务器信任身份提供商。该断言用于从令牌endpoint获取访问令牌。这对于那些投资SAML或SAML相关技术并允许他们与OAuth集成的公司来说非常有用。由于SAML断言是短暂的，因此此流程中不存在刷新标记，并且每次断言到期时都必须继续检索访问标记。</p>
<p>不在OAuth规范中的，是<strong>设备流程（Device Flow）</strong>。没有网络浏览器，只有一个像电视一样的控制器。用户code是从授权请求返回的，必须通过浏览器上的URL访问授权请求才能进行授权。客户端应用程序使用后向通道流程来轮询访问令牌和可选刷新令牌的授权许可。这种方式也在CLI客户端中很受欢迎。</p>
<p>我们已经使用不同的角色和标记类型介绍了六种不同的流程。由于客户端的能力，我们需要获得客户端的同意书，以及了解谁正在征求同意，这些都是必要的，并且为OAuth增加了很多复杂性。</p>
<p>当人们问你是否支持OAuth时，你必须澄清他们要求的东西。他们问你是支持全部六个流程，还是只支持主流程？在所有不同的流程之间有很多可用的粒度。</p>
<h3 id="安全和企业"><a href="#安全和企业" class="headerlink" title="安全和企业"></a>安全和企业</h3><p>OAuth有很大的覆盖面。有了隐式流程，就有很多重定向和很多错误空间。有很多人试图在应用程序之间利用OAuth，如果你不遵循推荐的网络安全101准则，就很容易做到。例如：</p>
<ul>
<li>始终使用带state参数的CSRF令牌来确保流程完整性</li>
<li>始终将重定向URI列入白名单，以确保正确的URI验证</li>
<li>将同一客户端绑定到具有客户端ID的授权许可和令牌请求</li>
<li>对于受信任的客户，确保客户机密不泄露。不要把你的应用程序中的客户端秘密通过App Store分发！</li>
</ul>
<p>关于OAuth的最大抱怨一般来自安全人员。这是关于Bearer tokens，并且他们可以像会话cookie一样传递。您可以将它传递出去，而且您可以很好地进行操作，而不是以加密方式绑定到用户。使用JWT有助于避免被篡改。但是，最终，JWT只是一串字符，因此它们可以轻松复制并用于Authorization标题中。</p>
<h3 id="企业OAuth-2-0使用案例"><a href="#企业OAuth-2-0使用案例" class="headerlink" title="企业OAuth 2.0使用案例"></a>企业OAuth 2.0使用案例</h3><p>OAuth将授权策略决策与身份验证分离开来。它可以正确地混合细粒度和粗粒度的授权。它可以取代传统的Web访问管理（WAM）策略。在构建可访问特定API的应用程序时，限制和撤销权限也很好。它确保只有托管或兼容的设备才能访问特定的API。它与身份取消配置工作流程深度集成，以撤消用户或设备的所有令牌。最后，它支持与身份提供者的联合。</p>
<h3 id="OAuth不是身份验证协议"><a href="#OAuth不是身份验证协议" class="headerlink" title="OAuth不是身份验证协议"></a>OAuth不是身份验证协议</h3><p>总结一下OAuth 2.0的一些误解：它不与OAuth 1.0向后兼容。它用HTTPS替代所有通信的签名。今天人们谈论OAuth时，他们正在谈论OAuth 2.0。</p>
<p>由于OAuth是授权框架而不是协议，因此您可能会遇到互操作性问题。团队如何实施OAuth有很多差异，您可能需要自定义代码才能与供应商进行集成。</p>
<p>OAuth 2.0不是身份验证协议。它甚至在<a href="https://oauth.net/articles/authentication/" target="_blank" rel="noopener">文档</a>中都这么说。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/oauth-not-authentication.png" alt="OAuth 2.0不是身份验证协议"></p>
<p>我们一直在谈论授权。这不是关于验证用户，这是关键。仅对于OAuth 2.0来说，用户是不存在的。您只需拥有一个令牌即可访问资源。</p>
<p>在过去的几年中，OAuth发生了大量的增加。这些增加了OAuth之上的复杂性，以完成各种企业方案。例如，JWT可以用作可签名和加密的互操作令牌。</p>
<h3 id="使用OAuth-2-0进行伪身份验证"><a href="#使用OAuth-2-0进行伪身份验证" class="headerlink" title="使用OAuth 2.0进行伪身份验证"></a>使用OAuth 2.0进行伪身份验证</h3><p>Facebook Connect和Twitter让着名的OAuth登录成为了热门话题。在此流程中，客户端使用/me的endpoint访问获取令牌。它所说的是，客户端可以使用令牌访问资源。人们发明了这个假端点，作为用访问令牌取回用户配置文件的一种方式。这是获取用户信息的非标准方式。标准中没有任何人说每个人都必须实现这个端点。访问令牌意味着不透明。它们是为了API而设计的，它们不是为了包含用户信息而设计的。</p>
<p>你真正尝试验证与回答的问题应该是：这是谁的用户，有没有对用户进行认证，以及如何做的用户进行身份验证。您通常可以通过SAML断言来回答这些问题，而不是使用访问令牌和授权许可。这就是我们称之为伪认证的原因。</p>
<h3 id="输入OpenID-Connect"><a href="#输入OpenID-Connect" class="headerlink" title="输入OpenID Connect"></a>输入OpenID Connect</h3><p>为解决伪身份验证问题，将OAuth 2.0，Facebook Connect和SAML 2.0的最佳部分组合在一起，创建OpenID Connect。OpenID Connect（OIDC）扩展了OAuth 2.0，id_token为客户端和UserInfo endpoint提供了新的用户属性签名。与SAML不同，OIDC为身份提供了一套标准范围和声明。例子包括：profile，email，address，和phone。</p>
<p>OIDC的创建是为了使网络具有完全动态的可扩展性。不再需要像SAML那样下载元数据和联合认证。内置的动态联合认证可以注册，发现元数据。您可以输入您的电子邮件地址，然后它动态地发现您的OIDC提供商，动态下载元数据，动态地知道它将使用的证书，并允许BYOI(Bring Your Own Identity)。它支持企业的高保证级别和关键SAML使用案例。</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/openid-connect-protocol.png" alt="OpenID连接协议套件"></p>
<p>OIDC因谷歌和微软两大早期使用者而闻名。Okta也在OIDC上投入了大量资金。</p>
<p>初始请求中的变化就是它包含标准作用域（如openid和email）：</p>
<p><strong>Request</strong></p>
<blockquote>
<p>GET <a href="https://accounts.google.com/o/oauth2/auth?" target="_blank" rel="noopener">https://accounts.google.com/o/oauth2/auth?</a><br>scope=openid email&amp;<br>redirect_uri=<a href="https://app.example.com/oauth2/callback&amp;" target="_blank" rel="noopener">https://app.example.com/oauth2/callback&amp;</a><br>response_type=code&amp;<br>client_id=812741506391&amp;<br>state=af0ifjsldkj</p>
</blockquote>
<p><strong>Response</strong></p>
<blockquote>
<p>HTTP/1.1 302 Found<br>Location: <a href="https://app.example.com/oauth2/callback?" target="_blank" rel="noopener">https://app.example.com/oauth2/callback?</a><br>code=MsCeLvIaQm6bTrgtp7&amp;state=af0ifjsldkj</p>
<p><em>code</em>返回授权认证，<em>state</em>确保它不是伪造的，即它是由同一个请求发出。</p>
</blockquote>
<p>而授权获取令牌的响应包含一个ID令牌。</p>
<p><strong>Request</strong>    </p>
<blockquote>
<p>POST /oauth2/v3/token HTTP/1.1<br>Host: www.googleapis.com<br>Content-Type: application/x-www-form-urlencoded</p>
<p>code=MsCeLvIaQm6bTrgtp7&amp;client_id=812741506391&amp;<br>  client_secret={client_secret}&amp;<br>  redirect_uri=<a href="https://app.example.com/oauth2/callback&amp;" target="_blank" rel="noopener">https://app.example.com/oauth2/callback&amp;</a><br>  grant_type=authorization_code</p>
</blockquote>
<p><strong>Response</strong></p>
<blockquote>
<p>{<br>  “access_token”: “2YotnFZFEjr1zCsicMWpAA”,<br>  “token_type”: “Bearer”,<br>  “expires_in”: 3600,<br>  “refresh_token”: “tGzv3JOkF0XG5Qx2TlKWIA”,<br>  “id_token”: “eyJhbGciOiJSUzI1NiIsImtpZCI6IjFlOWdkazcifQ…”<br>}</p>
</blockquote>
<p>您可以看到，在OAuth之上很好地分层，将ID令牌作为结构化令牌返回。一个ID令牌是一个JSON Web令牌（JWT）。JWT（aka“jot”）比基于XML的巨大SAML断言小得多，可以在不同设备之间高效传递。JWT有三部分：标题(header)，正文(body)和签名(signature)。标题说明使用什么算法对它进行签名，声明(claims)在正文中，并且在签名中签名。</p>
<p>Open ID Connect流程涉及以下步骤：</p>
<ul>
<li>发现OIDC元数据</li>
<li>执行OAuth流程以获取id令牌和访问令牌</li>
<li>获取JWT签名密钥并可选择动态注册客户端应用程序</li>
<li>根据内置日期和签名在本地验证JWT ID令牌</li>
<li>根据需要使用访问令牌获取其他用户属性</li>
</ul>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/what-is-oauth/oidc-flow.png" alt="OIDC流程"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>OAuth 2.0是委托访问API的授权框架。它涉及请求资源所有者授权/同意的范围的客户端。授权授予交换访问令牌和刷新令牌（取决于流程）。有多种流程来解决不同的客户端和授权方案。JWT可用于授权服务器和资源服务器之间的结构化令牌。</p>
<p>OAuth具有非常大的安全覆盖面。确保使用安全工具包并验证所有输入！</p>
<p>OAuth不是身份验证协议。OpenID Connect针对身份验证方案扩展了OAuth 2.0，通常称为“带花括号的SAML”。如果您希望进一步深入了解OAuth 2.0，我建议您查看<a href="https://www.oauth.com/" target="_blank" rel="noopener">OAuth.com</a>，使用Okta的Auth SDK进行测试，然后尝试自己的OAuth流程。</p>
]]></content>
      
        <categories>
            
            <category> OAuth </category>
            
            <category> OIDC </category>
            
        </categories>
        
        
        <tags>
            
            <tag> OAuth </tag>
            
            <tag> OIDC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[用gradle构建Java 9模块化系统快速指南]]></title>
      <url>/2018/04/11/gradle-guide-java9/</url>
      <content type="html"><![CDATA[<p><strong>本文是gradle官方的构建Java 9模块化系统的入门指南的翻译。（<a href="https://guides.gradle.org/building-java-9-modules/?_ga=2.174270880.30455902.1522735364-1287880600.1513842256" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<p>Java 9最令人兴奋的特性之一是它支持开发和部署Java模块化系统。在本指南中，您将了解到如何用gradle实现模块化功能，你所要做的事情：</p>
<ol>
<li>为您的Java库生成Java 9模块。</li>
<li>使用Java 9模块作为您的依赖。</li>
<li>在Java 9模块中使用Java的ServiceLoader模式。</li>
<li>使用Java 9模块运行应用程序。</li>
<li>使用一个插件来更简单地完成以上功能。</li>
</ol>
<p>虽然Gradle 4.6版尚未对Java 9模块提供一流的支持，本指南仍将向您介绍如何在支持完成之前对Java 9进行试验性的工作。</p>
<h3 id="你需要什么"><a href="#你需要什么" class="headerlink" title="你需要什么"></a>你需要什么</h3><ol>
<li>大约41分钟</li>
<li>一个文本编辑器</li>
<li>一个命令提示符</li>
<li>Java开发工具包（JDK），版本1.9（版本174）+</li>
</ol>
<h3 id="了解示例项目"><a href="#了解示例项目" class="headerlink" title="了解示例项目"></a>了解示例项目</h3><p>本指南逐步说明，如何将不使用任何Java 9功能的Java应用程序，转换为完全模块化的Java 9应用程序。原始版本的应用程序的源代码位于src/0-original目录中。它是由六个子项目组成的gradle多项目程序：</p>
<ol>
<li>fairy - java应用程序storyteller的入口点。</li>
<li>tale - 公共Tale接口的库。</li>
<li>formula - 帮助改造Tale接口的库。</li>
<li>actors - fairy tale中所有characters的库。</li>
<li>pigs - 代表三个小猪的Tale实例的库。</li>
<li>bears - 代表金发姑娘和三只熊的Tale实例的库。</li>
</ol>
<p>六个项目之间依赖关系的项目层次结构如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/gradle_guide_java9/project-graph.png" alt="gradle-java9-1"></p>
<p>如果你对api和implementation不熟悉，请参阅在Gradle 3.5中加入的<a href="https://docs.gradle.org/current/userguide/java_library_plugin.html?_ga=2.204456536.934686470.1523424544-1287880600.1513842256" target="_blank" rel="noopener">Java Library Plugin</a></p>
<p>你可以克隆源代码来查看原始项目的输出：</p>
<pre><code class="bash">$ git clone https://github.com/gradle-guides/building-java-9-modules.git
$ cd building-java-9-modules/src/0-original
$ ./gradlew run

&gt; Task :fairy:run
Once upon a time, there lived the big bad wolf, and the 3 little pigs.

&lt;... elided ...&gt;

Goldilocks ran out of the house at top speed to escape the 3 bears.
And they all lived happily ever after.


BUILD SUCCESSFUL
</code></pre>
<p>在开始修改此项目以使其使用Java 9模块之前，您需要了解项目结构的两个重要细节，就是，它使用 ServiceLoader API来在运行时加载fairy tale，并且它包含一个测试类来显示在使用Java 9之前，软件的模块封装是多么的脆弱。</p>
<h4 id="ServiceLoader的用法"><a href="#ServiceLoader的用法" class="headerlink" title="ServiceLoader的用法"></a>ServiceLoader的用法</h4><p>Java 1.6引入了一种简单的机制，用于在运行时将一些接口（“Service”）的一组实现绑定到一个消费类。有关该特性的<a href="https://docs.oracle.com/javase/tutorial/ext/basics/spi.html" target="_blank" rel="noopener">Oracle教程</a>有点冗长，下面是它在示例应用程序中的使用方式：</p>
<pre><code class="java">public static void main(String[] args) {
        ServiceLoader&lt;Tale&gt; loader = ServiceLoader.load(Tale.class);
        if (!loader.iterator().hasNext()) {
            System.out.println(&quot;Alas, I have no tales to tell!&quot;);
        }
        for (Tale tale : loader) {
            tale.tell();
        }
    }
</code></pre>
<p>JVM中的类加载器用ServiceLoader来找出，类路径上META-INF/services文件夹中的，名为org.gradle.fairy.tale.Tale的指定Tale类。</p>
<p>ears/src/main/resources/META-INF/services/org.gradle.fairy.tale.Tale:</p>
<pre><code class="java">org.gradle.fairy.tale.bears.GoldilocksAndTheThreeBears
</code></pre>
<p>pigs/src/main/resources/META-INF/services/org.gradle.fairy.tale.Tale:</p>
<pre><code class="java">org.gradle.fairy.tale.pigs.ThreeLittlePigs
</code></pre>
<p>在运行时加载这些实例,会使StoryTeller类以松耦合的方式连接到实现该Tale接口的两个库。你可以在应用程序的build.gradle文件的dependencies块中看到它。</p>
<p>fairy/build.gradle:</p>
<pre><code class="gradle">dependencies {
    implementation project(&#39;:tale&#39;)

    runtimeOnly project(&#39;:pigs&#39;)
    runtimeOnly project(&#39;:bears&#39;)
}
</code></pre>
<p>注释掉以runtimeOnly开头的两行，并注意Gradle run任务的输出是如何改变的：</p>
<pre><code class="bash">$ ./gradlew run

&gt; Task :fairy:run
Alas, I have no tales to tell!


BUILD SUCCESSFUL
</code></pre>
<h4 id="模块化测试讨论"><a href="#模块化测试讨论" class="headerlink" title="模块化测试讨论"></a>模块化测试讨论</h4><p>在最初的项目中，有一个测试类，展现了在Java 9之前的Java版本中，未实施模块化的一些问题。<br>formula/src/test/java/org/gradle/fairy/tale/formula/ModularityTest.java：</p>
<pre><code class="java">    @Test
    public void canReachActor() {
        Actor actor = Imagination.createActor(&quot;Sean Connery&quot;);
        assertEquals(&quot;Sean Connery&quot;, actor.toString());
    }

    @Test
    public void canDynamicallyReachDefaultActor() throws Exception {
        Class clazz = ModularityTest
            .class.getClassLoader()
            .loadClass(&quot;org.gradle.actors.impl.DefaultActor&quot;);
        Actor actor = (Actor) clazz.getConstructor(String.class)
            .newInstance(&quot;Kevin Costner&quot;);
        assertEquals(&quot;Kevin Costner&quot;, actor.toString());
    }

    @Test
    public void canReachDefaultActor() {
        Actor actor = new org.gradle.actors.impl.DefaultActor(&quot;Kevin Costner&quot;);
        assertEquals(&quot;Kevin Costner&quot;, actor.toString());
    }

    /*
    @Test
    public void canReachGuavaClasses() {
        // This line would throw a compiler error because gradle has kept the implementation dependency &quot;guava&quot;
        // from leaking into the formula project.
        Set&lt;String&gt; strings = com.google.common.collect.ImmutableSet.of(&quot;Hello&quot;, &quot;Goodbye&quot;);
        assertTrue(strings.contains(&quot;Hello&quot;));
        assertTrue(strings.contains(&quot;Goodbye&quot;));
    }
    */
</code></pre>
<p>这个类的四个测试有不同的目的：</p>
<ol>
<li>canReachActor - 通过调用actors项目的公共api来表明formula项目的访问权限。</li>
<li>canDynamicallyReachDefaultActor - 尝试在运行时使用反射来加载actors子项目的私有类。这在Java 9之前是可能的，因为类路径会将应用程序的所有的实现细节暴露给其他所有的应用。</li>
<li>canReachDefaultActor - 尝试直接使用actors子项目的私有类。这只在Java 9之前可行，因为actors子项目的私有实现细节与该子项目的公共API构建在相同的位置。所以，它们在编译时和运行时都可用。</li>
<li>canReachGuavaClasses - 尝试使用actors子项目所依赖的类。需要注意的是，从Gradle 3.4开始，使用implementation关键字的依赖关系不包含在Java项目的消费者的编译类路径（compileClasspath）中。因此，这个测试被注释掉了，因为它不能用Gradle 3.4或更新的版本编译。</li>
</ol>
<p>遵循本指南，你会看到Java 9将对于模块细节的访问权限变得更加紧密，并导致测试，canDynamicallyReachDefaultActor和canReachDefaultActor在运行时或编译时失败。</p>
<p>你可以运行Gradle的check任务，来认证这三个测试是否通过了0-original项目（尽管其中两个测试 打破了良好的模块化设计。）</p>
<pre><code class="bash">$ ./gradlew check

BUILD SUCCESSFUL
</code></pre>
<p>您可以在<a href="https://scans.gradle.com/s/l76lgbuizu4pm/tests/byProject?toggled=W1sxXSxbMSwwXSxbMSwwLDBdLFsxLDAsMCwwXV0" target="_blank" rel="noopener">建构扫描</a>中查看此次调用gradle task任务的结果。</p>
<h3 id="第1步-为单个子项目生成Java-9模块"><a href="#第1步-为单个子项目生成Java-9模块" class="headerlink" title="第1步 - 为单个子项目生成Java 9模块"></a>第1步 - 为单个子项目生成Java 9模块</h3><p>如果您还不熟悉Java 9模块系统，请阅读：</p>
<ol>
<li><a href="http://openjdk.java.net/projects/jigsaw/quick-start" target="_blank" rel="noopener">模块系统快速入门指南</a> / <a href="http://seanthefish.com/2018/03/29/java9-quick-guide/">(原文翻译)</a></li>
<li><a href="http://openjdk.java.net/projects/jigsaw/spec/sotms/" target="_blank" rel="noopener">模块系统综述</a> / <a href="http://seanthefish.com/2018/03/29/module-system/">(原文翻译)</a></li>
</ol>
<p>本指南假定您已经熟悉以下概念：</p>
<ol>
<li>模块路径</li>
<li>自动模块</li>
<li>module-info.java文件的基本语法</li>
</ol>
<p>Java 9中模块系统的一个很好的功能就是可以以自下而上的方式将项目的所有代码库转换为Java 9模块。无论是从类路径还是模块路径中，我们都可以获取Java 9模块化jar包，所以我们可以在多项目构建中，转换单个叶节点以生成Java 9模块，但是在编译时使用该模块化的jar包或在类路径上使用该模块化jar包来运行该节点的输出。</p>
<p>将java-library项目转换为Java 9模块时，应该对项目进行五项更改:</p>
<ol>
<li>添加一个module-info.java文件来描述模块。</li>
<li>修改compileJava任务以生成模块。</li>
<li>修改compileTestJava任务以在本地修改模块。</li>
<li>修改test任务以使用本地更改的模块。</li>
<li>（可选）在所有其他项目的清单条目（MANIFEST.MF）中添加Automatic-Module-Name属性。</li>
</ol>
<p>我们建议为组成应用程序的所有项在META-INF/MANIFEST.MF文件中主动添加目Automatic-Module-Name清单条目 。提供Automatic-Module-Name允许库作者为未来预留模块名称，而不必将库转换为模块。这确保了库的消费者现在就可以知道模块名称将来会是什么。</p>
<p>在下面的小节中将介绍这些变化，并讨论为什么要进行变更。您还可以通过浏览src/1-single-module库中的示例项目来查看这些更改的结果。</p>
<p>我们做出以下五项改变的目标是让actors项目生成一个Java 9模块。前四项变更需要一起完成，第五项（可选）变更可以独立完成。</p>
<blockquote>
<p>提醒一下，从这一点开始，所有的构建都需要在Java 9上运行</p>
</blockquote>
<h4 id="添加一个module-info-java文件来描述模块。"><a href="#添加一个module-info-java文件来描述模块。" class="headerlink" title="添加一个module-info.java文件来描述模块。"></a>添加一个module-info.java文件来描述模块。</h4><p>将module-info.java文件添加到项目的actors/src/main/java目录。</p>
<p>actors/src/main/java/module-info.java:</p>
<pre><code class="java">module org.gradle.actors {
    exports org.gradle.actors;
    requires guava;
}
</code></pre>
<p>该文件声明org.gradle.actors模块导出org.gradle.actors包（但不org.gradle.actors.impl包），并需要guava模块。Guava jar文件还不是Java 9模块，所以当你需要它们时，你必须使用JVM通过jar文件的文件名来推断生成的自动模块的名称。对于guava来说，jar文件的名称是<a href="http://central.maven.org/maven2/com/google/guava/guava/22.0/" target="_blank" rel="noopener">guava-22.0.jar</a>，因此根据<a href="http://openjdk.java.net/projects/jigsaw/spec/sotms/#automatic-modules" target="_blank" rel="noopener">自动模块名称的规则</a>，您需要的模块叫guava。</p>
<h4 id="修改compileJava任务以生成模块。"><a href="#修改compileJava任务以生成模块。" class="headerlink" title="修改compileJava任务以生成模块。"></a>修改compileJava任务以生成模块。</h4><p>在actors子项目的build.gradle文件中添加以下内容。</p>
<p>actors/build.gradle：</p>
<pre><code class="gradle">ext.moduleName = &#39;org.gradle.actors&#39; //(1)

compileJava {
    inputs.property(&quot;moduleName&quot;, moduleName)
    doFirst {
        options.compilerArgs = [
            &#39;--module-path&#39;, classpath.asPath,
        ]
        classpath = files()  //(2)
    }
}
</code></pre>
<ol>
<li>为模块名称定义一个变量，该变量允许您稍后为其他模块重复使用相同的代码，而无需对其进行更改。</li>
<li>通过创建一个空文件集合来清除classpath属性。</li>
</ol>
<p>编译Java 9模块时，您想使用–module-path而不是 –classpath读取您的依赖关系。因此，在该doFirst块中，您将清除该任务的classpath属性并添加一个编译器参数。</p>
<blockquote>
<p>–module-path被设置为原来的值classpath。这样做是因为，classpath已经有你所依赖的库的所有jar包和类输出目录。</p>
<p>在doFirst代码块内而不是在compileJava任务中修改options.compilerArgs参数的原因是，在执行这个任务时，你只需要重构compileClasspath（编译时的类路径）的配置。</p>
</blockquote>
<h4 id="修改compileJava任务以生成模块。-1"><a href="#修改compileJava任务以生成模块。-1" class="headerlink" title="修改compileJava任务以生成模块。"></a>修改compileJava任务以生成模块。</h4><p>Java 9模块系统的一个稍微混淆的方面是如何对Java 9模块内的代码运行单元测试。推荐的方法是在测试过程中“修补”模块。修补模块意味着向组成模块的包添加额外的类。在运行测试所需要的修补模块步骤中，您将使用相同的包来把测试类添加到模块中，以便测试类可以访问被测模块中的所有其他模块。</p>
<p>将以下内容添加到您build.gradle文件中，来实现在编译时对org.gradle.actors模块的修补。</p>
<p>actors/build.gradle：</p>
<pre><code class="gradle">compileTestJava {
    inputs.property(&quot;moduleName&quot;, moduleName)
    doFirst {
        options.compilerArgs = [
            &#39;--module-path&#39;, classpath.asPath, \\(1)
            &#39;--add-modules&#39;, &#39;junit&#39;,  \\(2)
            &#39;--add-reads&#39;, &quot;$moduleName=junit&quot;, \\(3)
            &#39;--patch-module&#39;, &quot;$moduleName=&quot; + files(sourceSets.test.java.srcDirs).asPath, \\(4)
        ]
        classpath = files()
    }
}
</code></pre>
<ol>
<li>用–module-path参数来作为classpath属性的默认值。</li>
<li>显式地将junit自动模块添加为可观察模块。</li>
<li>声明junit模块读取org.gradle.actors模块。</li>
<li>将测试源文件添加到org.gradle.actors模块。</li>
</ol>
<p>这些选项的添加将会导致测试源的输出目录中的生成类文件包含合适的元数据来修补org.gradle.actors模块，这些类文件会在接下来的更改中被使用。</p>
<h4 id="修改test任务以使用本地更改的模块。"><a href="#修改test任务以使用本地更改的模块。" class="headerlink" title="修改test任务以使用本地更改的模块。"></a>修改test任务以使用本地更改的模块。</h4><p>运行测试时，我们必须配置运行测试的JVM使其发现我们的模块，并修补org.gradle.actors模块来引入测试类。</p>
<p>将以下内容添加到actors项目中的build.gradle文件中。</p>
<p>actors/build.gradle：</p>
<pre><code class="gradle">test {
    inputs.property(&quot;moduleName&quot;, moduleName)
    doFirst {
        jvmArgs = [
            &#39;--module-path&#39;, classpath.asPath, \\(1)
            &#39;--add-modules&#39;, &#39;ALL-MODULE-PATH&#39;, \\(2)
            &#39;--add-reads&#39;, &quot;$moduleName=junit&quot;, \\(3)
            &#39;--patch-module&#39;, &quot;$moduleName=&quot; + files(sourceSets.test.java.outputDir).asPath, \\(4)
        ]
        classpath = files()
    }
}
</code></pre>
<ol>
<li>这是测试运行时的classpath属性的默认值。</li>
<li>使用特殊的ALL-MODULE-PATH，因为运行测试的JVM的main class不是Java 9模块的一部分。它是Gradle的测试运行器，因此它没有声明它需要使用的模块。该参数使模块路径中的所有模块都可以被测试类访问。</li>
<li>声明junit读取org.gradle.actors模块。</li>
<li>将测试类添加到org.gradle.actors模块。</li>
</ol>
<h4 id="（可选）在所有其他项目的清单条目（MANIFEST-MF）中添加Automatic-Module-Name属性。"><a href="#（可选）在所有其他项目的清单条目（MANIFEST-MF）中添加Automatic-Module-Name属性。" class="headerlink" title="（可选）在所有其他项目的清单条目（MANIFEST.MF）中添加Automatic-Module-Name属性。"></a>（可选）在所有其他项目的清单条目（MANIFEST.MF）中添加Automatic-Module-Name属性。</h4><p>为了向后兼容，Java 9的模块系统允许非模块化的jar文件出现在模块路径中。默认情况下，这些jar文件将被转换为自动模块，其名称基于jar文件的文件名。但是这会导致一些冗杂。许多jar文件名已经创建，但没有任何规则能保证这个jar的名字是唯一的。所以当负责维护一些常用jar的开发人员在将该jar转换为Java 9模块时，他们更希望会选择一个新的模块名称，而非由自动模块转换所自动生成的名称。</p>
<p>例如，你现在可以在module-info.java文件中通过requires guava子句指定模块，但稍后负责该项目的开发人员决定为其模块命名com.google.guava。现在，任何指定requires guava或任何依赖此模块的用户，都必须改变它们依赖的模块为requires com.google.guava，如此才能使用这些新模块，因为Java 9只允许模块路径上的模块包含特定的包。</p>
<p>因此，整个情况可能会变得非常混乱。这就是为什么<a href="http://blog.joda.org/2017/05/java-se-9-jpms-automatic-modules.html" target="_blank" rel="noopener">Stephen Colebourne认为</a>我们应该立即开始更新我们发布到公共存储库的所有jar,（至少要在jar的清单中指定Automatic-Module-Name属性），而且也不要发布任何未指定Automatic-Module-Name属性并且包含需要自动模块的模块的工件。</p>
<p>因此，在每个子项目的build.gradle文件中指定一个moduleName变量。例如：</p>
<p>fairy/build.gradle:</p>
<pre><code class="gradle">ext.moduleName = &#39;org.gradle.fairy.app&#39;
</code></pre>
<p>另外，在顶层build.gradle文件中的afterEvaluate代码块中的jar任务中添加manifest属性。</p>
<pre><code class="gradle">jar {
        inputs.property(&quot;moduleName&quot;, moduleName)
        manifest {
            attributes(&#39;Automatic-Module-Name&#39;: moduleName)
        }
    }
</code></pre>
<p>现在，当您将jar文件发布到像Maven Central这样的工件存储库时，你发布的jar包的文件名就不再重要了; 你一定会（通过Automatic-Module-Name）得到你想要的Java 9模块名称。</p>
<blockquote>
<p>在下一步中，您将摆脱这些清单属性，因为您已将每个子项目都转换为适当的Java 9模块。</p>
</blockquote>
<h4 id="第1步-总结"><a href="#第1步-总结" class="headerlink" title="第1步 - 总结"></a>第1步 - 总结</h4><p>这第一步是最复杂的，但现在您已经将第一个java-library项目转换为Java 9模块。所有其他子项目都在类路径上使用该模块。我们并没有真正解决在<a href="#模块化测试讨论">模块化测试讨论</a>中演示的任何模块化违规问题 ，但是我们不必中断项目，将其逻辑体系结构转换为适当的Java 9模块。接下来，我们将根目录的build.gradle项目中来集中gradle更改，并将其应用于所有子项目中。</p>
<h3 id="第2步-为所有子项目生成Java-9模块"><a href="#第2步-为所有子项目生成Java-9模块" class="headerlink" title="第2步 - 为所有子项目生成Java 9模块"></a>第2步 - 为所有子项目生成Java 9模块</h3><p>这一步的目标是让我们的Gradle构建中的所有子项目都生成Java 9模块，并将它们的依赖作为Java 9模块使用。由于您已将actors子项目中的build.gradle文件中的moduleName变量声明与其他改变分离，因此只需将该文件中的moduleName声明以后的所有内容剪切并粘贴到根目录build.gradle文件中的afterEvaluate代码块中即可。</p>
<p>build.gradle：</p>
<pre><code class="gradle">subprojects {
    afterEvaluate {
        repositories {
            jcenter()
        }

        compileJava {
            inputs.property(&quot;moduleName&quot;, moduleName)
            doFirst {
                options.compilerArgs = [
                    &#39;--module-path&#39;, classpath.asPath,
                ]
                classpath = files()
            }
        }

        compileTestJava {
            inputs.property(&quot;moduleName&quot;, moduleName)
            doFirst {
                options.compilerArgs = [
                    &#39;--module-path&#39;, classpath.asPath,
                    &#39;--add-modules&#39;, &#39;junit&#39;,
                    &#39;--add-reads&#39;, &quot;$moduleName=junit&quot;,
                    &#39;--patch-module&#39;, &quot;$moduleName=&quot; + files(sourceSets.test.java.srcDirs).asPath,
                ]
                classpath = files()
            }
        }

        test {
            inputs.property(&quot;moduleName&quot;, moduleName)
            doFirst {
                jvmArgs = [
                    &#39;--module-path&#39;, classpath.asPath,
                    &#39;--add-modules&#39;, &#39;ALL-MODULE-PATH&#39;,
                    &#39;--add-reads&#39;, &quot;$moduleName=junit&quot;,
                    &#39;--patch-module&#39;, &quot;$moduleName=&quot; + files(sourceSets.test.java.outputDir).asPath,
                ]
                classpath = files()
            }
        }
    }
}
</code></pre>
<blockquote>
<p>如果你做了步骤1的最后一步，则应在粘贴之前删除jar代码块。</p>
</blockquote>
<p>如果您还没有为每个子项目添加moduleName变量声明，那么现在应该这样做。例如：</p>
<p>pigs/build.gradle：</p>
<pre><code class="gradle">ext.moduleName = &#39;org.gradle.fairy.tale.pigs&#39;
</code></pre>
<p>您还需要为每个子项目添加一个module-info.java文件。例如：</p>
<p>bears/src/main/java/module-info.java:</p>
<pre><code class="gradle">module org.gradle.fairy.tale.bears {
    requires org.gradle.actors;
    requires transitive org.gradle.fairy.tale;
    requires org.gradle.fairy.tale.formula;

    exports org.gradle.fairy.tale.bears;
}
</code></pre>
<blockquote>
<p>您还需要为pigs， formula，fairy，和tale子项目添加这些module-info.java文件。最终结果应该看起来像src/2-all-modules中的代码。</p>
</blockquote>
<p>现在，Gradle的test任务将无法编译，除非您已将canReachDefaultActor测试注释掉。另外，canDynamicallyReachDefaultActor测试将在测试运行时失败，除非你添加@Ignore注释。</p>
<pre><code class="bash">$ ./gradlew test

&gt; Task :formula:test

org.gradle.fairy.tale.formula.ModularityTest &gt; canDynamicallyReachDefaultActor FAILED
    java.lang.IllegalAccessException at ModularityTest.java:28

2 tests completed, 1 failed


FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task &#39;:formula:test&#39;.
&gt; There were failing tests. See the report at: &lt;link-to-report&gt;

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.

BUILD FAILED
</code></pre>
<p>如果你注释掉canReachDefaultActor测试并为canDynamicallyReachDefaultActor添加@Ignore注解，剩下的测试应该通过，你可以在src/2-all-modules中得到完整的代码。</p>
<h4 id="第2步-总结"><a href="#第2步-总结" class="headerlink" title="第2步 - 总结"></a>第2步 - 总结</h4><p>到目前为止，你已经在使用Java 9模块来编译和运行所有六个子项目和测试。这些子项目被适当地封装，并且没有一个包下的测试可以看到这个包所依赖的任何实现细节。但是，<a href="https://docs.gradle.org/4.6/userguide/application_plugin.html?_ga=2.21328251.1136812865.1523857970-1287880600.1513842256" target="_blank" rel="noopener">Gradle的应用程序插件</a>的一些特性依赖于类路径来加载和编译类，而不是模块路径。</p>
<p>此外，Java 9增加了一种更方便的方式来使用ServiceLoader功能。您将在第3步中了解如何处理这些问题。</p>
<h3 id="第3步-在run和assemble任务中使用Java-9模块"><a href="#第3步-在run和assemble任务中使用Java-9模块" class="headerlink" title="第3步 - 在run和assemble任务中使用Java 9模块"></a>第3步 - 在run和assemble任务中使用Java 9模块</h3><p>现在所有子项目都已经转化为为Java 9模块，现在该学习fairy项目中的main class（org.gradle.fairy.app.StoryTeller）在运行时是如何使用这些模块的 。</p>
<p>运行本指南中介绍的应用程序有两种方式。首先是使用由<a href="https://docs.gradle.org/4.6/userguide/application_plugin.html?_ga=2.28841596.1136812865.1523857970-1287880600.1513842256" target="_blank" rel="noopener">应用程序插件</a>添加的Gradle run任务 。</p>
<pre><code class="bash">$ ./gradlew run

&gt; Task :fairy:run
Once upon a time, there lived the big bad wolf, and the 3 little pigs.

&lt;... elided ...&gt;

Goldilocks ran out of the house at top speed to escape the 3 bears.
And they all lived happily ever after.


BUILD SUCCESSFUL
</code></pre>
<p>另一种方法是使用Gradle的assemble任务来分别打包各个应用程序，然后提取到某个目录并在那里运行。</p>
<pre><code class="bash">$ ./gradlew assemble

BUILD SUCCESSFUL
$ cp fairy/build/distributions/fair.tar /tmp
$ cd /tmp
$ tar xvf fairy.tar
x fairy/
x fairy/lib/
x fairy/lib/fairy.jar
x fairy/lib/pigs.jar
x fairy/lib/bears.jar
x fairy/lib/formula.jar
x fairy/lib/tale.jar
x fairy/lib/actors.jar
x fairy/lib/guava-22.0.jar
x fairy/lib/jsr305-1.3.9.jar
x fairy/lib/error_prone_annotations-2.0.18.jar
x fairy/lib/j2objc-annotations-1.1.jar
x fairy/lib/animal-sniffer-annotations-1.14.jar
x fairy/bin/
x fairy/bin/fairy
x fairy/bin/fairy.bat
$ ./bin/fairy
Once upon a time, there lived the big bad wolf, and the 3 little pigs.

&lt;... elided ...&gt;

Goldilocks ran out of the house at top speed to escape the 3 bears.
And they all lived happily ever after.
</code></pre>
<p>在步骤2之后，这两种机制都依赖于出现在类路径上的模块。这样也就会跳过了Java 9模块系统的模块化特性。在这一步中，您将：</p>
<ol>
<li>修改run任务以使用模块。</li>
<li>修改startScript任务来使*nix和Windows系统使用模块。</li>
<li>将ServiceLoader机制更新为Java 9语法。</li>
</ol>
<p>一旦进行了更改1和2，运行该程序的两种机制都应该能直接运行，因此请随时再次运行这些命令以确认您已正确实施每项更改。</p>
<p>您依旧可以在资源代码库中的src/3-application目录中看到所有更改 。</p>
<h3 id="修改run任务以使用模块"><a href="#修改run任务以使用模块" class="headerlink" title="修改run任务以使用模块"></a>修改run任务以使用模块</h3><p>要在run任务中使用Java 9模块，你需要将以下内容添加到fairy项目中的build.gradle文件中。</p>
<p>fairy/build.gradle</p>
<pre><code class="gradle">mainClassName = &quot;$moduleName/org.gradle.fairy.app.StoryTeller&quot; //(1)

run {
    inputs.property(&quot;moduleName&quot;, moduleName)
    doFirst {
        jvmArgs = [
            &#39;--module-path&#39;, classpath.asPath,
            &#39;--module&#39;, mainClassName //(2)
        ]
        classpath = files()
    }
}
</code></pre>
<ol>
<li>设置mainClassName属性包含moduleName。</li>
<li>明确告诉Java 9使用该模块。</li>
</ol>
<h4 id="修改startScript任务来使-nix和Windows系统使用模块。"><a href="#修改startScript任务来使-nix和Windows系统使用模块。" class="headerlink" title="修改startScript任务来使*nix和Windows系统使用模块。"></a>修改startScript任务来使*nix和Windows系统使用模块。</h4><p>在fairy/build/distributions目录中创建的tar和zip文件会包含启动脚本 ，这些脚本允许在所有支持的操作系统上，以可预测的方式启动JVM。</p>
<p>要修改已生成的startScripts，请将以下内容添加到您的fairy/build.gradle文件中：</p>
<p>fairy/build.gradle：</p>
<pre><code class="gradle">startScripts {
    inputs.property(&quot;moduleName&quot;, moduleName)
    doFirst {
        classpath = files()
        defaultJvmOpts = [
            &#39;--module-path&#39;, &#39;APP_HOME_LIBS&#39;,  \\(1)
            &#39;--module&#39;, mainClassName
        ]
    }
    doLast{
        def bashFile = new File(outputDir, applicationName)
        String bashContent = bashFile.text
        bashFile.text = bashContent.replaceFirst(&#39;APP_HOME_LIBS&#39;, Matcher.quoteReplacement(&#39;$APP_HOME/lib&#39;))

        def batFile = new File(outputDir, applicationName + &quot;.bat&quot;)
        String batContent = batFile.text
        batFile.text = batContent.replaceFirst(&#39;APP_HOME_LIBS&#39;, Matcher.quoteReplacement(&#39;%APP_HOME%\\lib&#39;))
    }
}
</code></pre>
<ol>
<li>将模块路径设置为独立于平台的占位符值，稍后将以特定于平台的方式替换*nix shell脚本和Windows .bat文件。</li>
</ol>
<h3 id="将ServiceLoader机制更新为Java-9语法。"><a href="#将ServiceLoader机制更新为Java-9语法。" class="headerlink" title="将ServiceLoader机制更新为Java 9语法。"></a>将ServiceLoader机制更新为Java 9语法。</h3><p>Java 9模块系统引入了一种更好的方式来指定哪些模块为ServiceLoader机制提供服务的实现。首先，从两个目录bears/src/main和pigs/src/main中，删除resources文件夹，因为新机制不需要META-INF/services文件。</p>
<p>然后，调整每个项目的module-info.java文件。</p>
<p>fairy/src/main/java/module-info.java:</p>
<pre><code class="java">module org.gradle.fairy.app {
    requires org.gradle.fairy.tale;
    uses org.gradle.fairy.tale.Tale;
}
</code></pre>
<p>bears/src/main/java/module-info.java:</p>
<pre><code class="java">module org.gradle.fairy.tale.bears {
    requires org.gradle.actors;
    requires transitive org.gradle.fairy.tale;
    requires org.gradle.fairy.tale.formula;

    provides org.gradle.fairy.tale.Tale
        with org.gradle.fairy.tale.bears.GoldilocksAndTheThreeBears;
}
</code></pre>
<p>pigs/src/main/java/module-info.java:</p>
<pre><code class="java">module org.gradle.fairy.tale.pigs {
    requires org.gradle.actors;
    requires transitive org.gradle.fairy.tale;
    requires org.gradle.fairy.tale.formula;

    provides org.gradle.fairy.tale.Tale
            with org.gradle.fairy.tale.pigs.ThreeLittlePigs;
}
</code></pre>
<p>由于fairy项目中的module-info.java声明它使用org.gradle.fairy.tale.Tale服务，所以该模块中的ServiceLoader实例将有权访问，所有由Java 9模块声明的在运行时提供的org.gradle.fairy.tale.Tale服务实现。</p>
<h3 id="第4步-使用experimental-jigsaw插件来做与我们之间所做的同样的事情"><a href="#第4步-使用experimental-jigsaw插件来做与我们之间所做的同样的事情" class="headerlink" title="第4步 - 使用experimental-jigsaw插件来做与我们之间所做的同样的事情"></a>第4步 - 使用experimental-jigsaw插件来做与我们之间所做的同样的事情</h3><p>虽然Gradle尚未将Java 9模块构建作为Java插件的一级特性加以支持，实验性插件也可让您在项目中尝试使用Java 9模块。</p>
<p>org.gradle.java.experimental-jigsaw插件只是一个简便的机制，可以在一个步骤中，提供本指南步骤1至3中的所有更改。它可能适用于您的项目，但您应该考虑到它是实验性的，不适合生产版本。</p>
<p>以下是如何使用插件：</p>
<p>actors/build.gradle：</p>
<pre><code class="gradle">plugins {
    id &#39;java-library&#39;
    id &#39;org.gradle.java.experimental-jigsaw&#39; version &#39;0.1.1&#39;  \\(1)
}
</code></pre>
<ol>
<li>使用插件</li>
</ol>
<p>actors/build.gradle：</p>
<pre><code class="gradle">javaModule.name = &#39;org.gradle.actors&#39;  \\(1)
</code></pre>
<ol>
<li>使用新javaModule.name设置来指定模块名称。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>此时，您的应用程序正在利用Java 9模块系统的大部分功能。本指南向您展示了如何修改常规插件java-library和application所添加的任务，来方便你使用Java 9模块进行工作。未来，Gradle团队将为模块系统添加一流的支持，但您现在就已经可以开始尝试！</p>
]]></content>
      
        <categories>
            
            <category> Java 9 </category>
            
            <category> Java module </category>
            
            <category> gradle </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java 9 </tag>
            
            <tag> Java module </tag>
            
            <tag> gradle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java模块系统综述]]></title>
      <url>/2018/03/29/module-system/</url>
      <content type="html"><![CDATA[<p><strong>本文是Mark Reinhold的The State of the Module System最新版的翻译。（<a href="http://openjdk.java.net/projects/jigsaw/spec/sotms/" target="_blank" rel="noopener">原文地址</a>）</strong></p>
<blockquote>
<p>这份文档略有过时。其基本概念没有任何改变，但requires public关键字已被重新命名为requires transitive，并增加了几项附加功能。更新正在准备中，准备就绪后会在这里发布。</p>
</blockquote>
<p>本文是对<a href="http://openjdk.java.net/projects/jigsaw/" target="_blank" rel="noopener">Jigsaw项目</a>中对Java SE平台所做的增强的一个非正式的概述，并针对<a href="http://openjdk.java.net/projects/jigsaw/spec/" target="_blank" rel="noopener">JSR 376：Java平台模块系统</a>所提出。有<a href="http://openjdk.java.net/jeps/261" target="_blank" rel="noopener">相关的文档</a>描述了对特定于JDK工具和API的增强，这些超出了JSR的范围。</p>
<p>正如JSR所述，模块系统是为了提供可靠的配置，使程序组件相互显式的声明依赖，配合其强大的封装能力，使组件允许声明其中哪些公共类型可供其他组件访问，哪些不可以，并以此来替换脆弱，容易出错的类路径机制。</p>
<p>这些功能将直接对Java SE平台本身、Java应用程序开发人员，Java类库开发人员有利，而且也会间接地实现可伸缩平台、更高的平台完整性和更高的性能。</p>
<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul>
<li><a href="#定义模块">定义模块</a><ul>
<li><a href="#模块声明">模块声明</a></li>
<li><a href="#模块打包">模块打包</a></li>
<li><a href="#模块描述符">模块描述符</a></li>
<li><a href="#平台模块">平台模块</a></li>
</ul>
</li>
<li><a href="#使用模块">使用模块</a><ul>
<li><a href="#模块路径">模块路径</a></li>
<li><a href="#解决依赖">解决依赖</a></li>
<li><a href="#可读性">可读性</a></li>
<li><a href="#可访问性">可访问性</a></li>
<li><a href="#隐含的可读性">隐含的可读性</a></li>
</ul>
</li>
<li><a href="#兼容性和迁移">兼容性和迁移</a><ul>
<li><a href="#未命名模块">未命名模块</a></li>
<li><a href="#自下而上的迁移">自下而上的迁移</a></li>
<li><a href="#自动模块">自动模块</a></li>
<li><a href="#与类路径建立联系">与类路径建立联系</a></li>
</ul>
</li>
<li><a href="#服务">服务</a></li>
<li><a href="#高级特性">高级特性</a><ul>
<li><a href="#反射">反射</a></li>
<li><a href="#反射的可读性">反射的可读性</a></li>
<li><a href="#类加载器">类加载器</a></li>
<li><a href="#未命名模块与类加载器">未命名模块与类加载器</a></li>
<li><a href="#层">层</a></li>
<li><a href="#限制性导出">限制性导出</a></li>
</ul>
</li>
<li><a href="#总结">总结</a></li>
</ul>
<p>这是本文档的第二版。相对于<a href="http://openjdk.java.net/projects/jigsaw/spec/sotms/2015-09-08" target="_blank" rel="noopener">最初版本</a>，本版引入了兼容性和迁移的解释，修改了反射可读性的描述，进行了重新排序以改善叙述的流程，并且组织了更容易定位的目录。</p>
<p>文中仍然存在许多未解决的问题，其解决方案将反映在本文档的未来版本中。</p>
<h3 id="定义模块"><a href="#定义模块" class="headerlink" title="定义模块"></a>定义模块</h3><p>为了提供可靠的配置和强大的封装，使其既能接近开发人员，又能被现有工具链支持，我们将模块视为一种基本的新型Java程序组件。一个模块是一个命名的，能自我描述的代码和数据的集合。其代码被组织为一组包（package），包中包含Java类和接口。</p>
<h4 id="模块声明"><a href="#模块声明" class="headerlink" title="模块声明"></a>模块声明</h4><p>模块的自我描述体现在它的声明中，这是一种Java编程语言的新构造。最简单的模块声明只是指定其模块的名称：</p>
<pre><code class="java">module com.foo.bar { }
</code></pre>
<p>可以添加一个或多个require子句来声明该模块在编译时和运行时依赖于其他名称的某些模块：</p>
<pre><code class="java">module com.foo.bar {
    requires org.baz.qux;
}
</code></pre>
<p>最后，可以添加exports子句来声明该模块中仅有特定包中的公共类型可供其他模块使用：</p>
<pre><code class="java">module com.foo.bar {
    requires org.baz.qux;
    exports com.foo.bar.alpha;
    exports com.foo.bar.beta;
}
</code></pre>
<p>如果一个模块的声明不包含任何exports子句，那么它将不会导出任何类型到其他模块。</p>
<p>按照惯例，模块声明的源代码放置在名为module-info.java的文件中，该文件位于模块的源文件层次结构的根目录下。 com.foo.bar模块的源文件可能包括：</p>
<pre><code class="java">module-info.java
com/foo/bar/alpha/AlphaFactory.java
com/foo/bar/alpha/Alpha.java
...
</code></pre>
<p>按照惯例，模块声明被编译成名为module-info.class的文件，并放置在.class文件输出目录中。</p>
<p>模块名称跟包名称一样，不得相互冲突。命名模块的推荐方法是使用长期用于命名软件包的反向域名模式。因此，模块的名称通常就是其导出包名称的前缀，但这种关系不是强制性的。</p>
<p>模块的声明不包括其版本号，也不包括它所依赖的子模块的版本号。这样做是<a href="http://openjdk.java.net/projects/jigsaw/spec/reqs/02#version-selection" target="_blank" rel="noopener">故意为之</a>的：模块系统的目标不是解决版本选择问题，这最好留给构建工具和容器应用程序来做。</p>
<p>模块声明是Java编程语言的一部分，这其中的原因有几个。其中最重要的一点是，模块必须在编译时和运行时都可用，以实现各个阶段的确定性，即确保模块系统在编译时和运行时都以相同的方式工作。这反过来又能防止多种错误的发生，或者至少在编译时更早地报告错误使其更容易诊断和修复。</p>
<p>源文件中的模块声明文件和模块中的其他源文件，将会一起编译为.class文件供Java虚拟机使用，这是建立确定性的自然方式。这种方法将立即为开发人员所熟悉，并且IDE和构建工具也会很容易支持。尤其是IDE，可以依照依赖需要为现有组件提供模块声明的提示。</p>
<h4 id="模块打包"><a href="#模块打包" class="headerlink" title="模块打包"></a>模块打包</h4><p>现有工具已经可以创建，操作和使用JAR文件，因此为了便于使用和迁移，我们定义了模块化JAR文件。除了根目录中还包含了一个module-info.class文件之外，模块化的JAR文件就像普通的JAR文件一样。上述com.foo.bar模块的模块化JAR文件可能具有以下内容：</p>
<pre><code>META-INF/
META-INF/MANIFEST.MF
module-info.class
com/foo/bar/alpha/AlphaFactory.class
com/foo/bar/alpha/Alpha.class
...
</code></pre><p>模块化的JAR文件可以被当作模块，在这种情况下，它的module-info.class文件被用来作为模块的声明。它也可以被放在普通的类路径上，在这种情况下，它的module-info.class文件将被忽略。模块化JAR文件允许库的维护者在所有版本上发布工件（artifacts），该工件既可作为Java SE 9及更高版本的模块，也可作为类路径上的常规JAR文件。我们期望包含jar工具的Java SE 9的实现将增强该工具，以便轻松创建模块化JAR文件。</p>
<p>为了模块化Java SE平台的JDK，我们将引入一种新的打包机制（artifact format），它将超越JAR文件来容纳原生代码、配置文件和其他类型的数据（如果这种数据真的存在）。这种机制利用了在源文件中的模块声明并将它们编译成.class文件，此.class文件与其他的打包方式都不同。这种被临时命名为“JMOD”的新格式是否应该成为标准化仍旧是一个悬而未决的问题。（已成为Java9的标准格式之一，请查看<a href="https://docs.oracle.com/javase/9/tools/jmod.htm" target="_blank" rel="noopener">oracle官方文档</a>）</p>
<h4 id="模块描述符"><a href="#模块描述符" class="headerlink" title="模块描述符"></a>模块描述符</h4><p>将模块声明编译到.class文件中的最后一个优点是.class文件已经具有精确定义和可扩展的格式。因此，我们可以将module-info.class文件视为更通用的模块描述符，其中包括源代码级模块声明的编译形式，还包括在声明最初编译之后插入的.class文件中的附加信息。</p>
<p>例如，IDE、或者记录打包时间的工具，可以插入包含文档信息的属性，例如模块的版本、标题、说明和许可证。这些信息可以在编译时和运行时通过模块系统的反射来读取，以用于写文档，程序诊断和调试。它也可以被下游工具用于构建跨操作系统的程序包。特定的属性将被标准化，但由于Java类文件格式是可扩展的，所以其他工具和框架将能够根据需要来定义附加属性。非标准的属性不会影响模块系统本身的行为。</p>
<h3 id="平台模块"><a href="#平台模块" class="headerlink" title="平台模块"></a>平台模块</h3><p>Java SE 9的平台规范，使用模块系统将平台划分为一组模块。Java SE 9平台的实现可能包含所有的平台模块，或者可能仅包含其中的一部分。</p>
<p>在任何情况下，模块系统专用的唯一模块是已命名的基础模块java.base。基本模块定义并导出所有平台的核心软件包，包括模块系统本身：</p>
<pre><code class="java">module java.base {
    exports java.io;
    exports java.lang;
    exports java.lang.annotation;
    exports java.lang.invoke;
    exports java.lang.module;
    exports java.lang.ref;
    exports java.lang.reflect;
    exports java.math;
    exports java.net;
    ...
}
</code></pre>
<p>基本模块始终存在。每个其他模块都隐式的建立在基本模块之上，而基本模块则不依赖于其他模块。</p>
<p>其余的平台模块将共享“ java.”名称前缀，并有可能包括，例如，模块java.sql用于数据库连接， 模块java.xml用于XML处理，模块java.logging进行记录日志。按照惯例，尽管没有在Java SE 9平台规范中定义，但是专用于JDK的模块将共享“ jdk.”名称前缀。</p>
<h3 id="使用模块"><a href="#使用模块" class="headerlink" title="使用模块"></a>使用模块</h3><p>单个模块可以在模块工件（artifacts）中定义，或者内嵌于编译时或运行时环境。要在任一阶段使用它们，模块系统必须定位它们，然后确定它们如何相互关联的，并以此提供可靠的配置和强大的封装。</p>
<h4 id="模块路径"><a href="#模块路径" class="headerlink" title="模块路径"></a>模块路径</h4><p>为了定位包中定义的模块，模块系统搜索由系统定义的模块路径（module path）。模块路径是一个序列，其中的每个元素都是模块工件或包含模块工件的目录。系统会按顺序搜索模块路径的元素，以找到定义合适的第一个模块工件。</p>
<p>模块路径（module path）与类路径（class path）有着很大的不同，它更加健壮。类路径的固有脆弱性是基于这样一个事实：即它是一种在所有包中通过路径来定位各个类型的工作方式，它不会在不同的包文件本身之间进行区分。这使得它无法预先知道程序什么时候缺少了某个包。它还允许不同的程序包（artifacts）在相同的包（package）中定义类型，即使这些程序包是只是版本不同，或者就是完全不同的组件（jar hell）。</p>
<p>相反，模块路径是定位整个模块、而不是某个类型的一种手段。如果模块系统无法满足来自模块路径的模块工件的特定依赖性，或者如果在同一目录中遇到定义相同名称模块的两个模块工件，则编译器或虚拟机将报告错误并退出。</p>
<p>内置于编译时或运行时环境的模块以及模块路径中的模块工件定义的模块统称为可观察模块的范围。</p>
<h4 id="解决依赖"><a href="#解决依赖" class="headerlink" title="解决依赖"></a>解决依赖</h4><p>假设我们有一个使用上述com.foo.bar模块和平台java.sql模块的应用程序。包含应用程序核心的模块声明如下：</p>
<pre><code class="java">module com.foo.app {
    requires com.foo.bar;
    requires java.sql;
}
</code></pre>
<p>鉴于这种初始应用程序模块，该模块系统可通过表达依赖性的requires来定位额外观察到的模块，以满足这些依赖关系，然后解决这些模块的依赖关系，并依此类推，直到每个模块的每一个的依赖都被满足。这个传递闭包计算的结果是一个模块图，对于每个依赖其他模块的模块，它包含从第一个模块到第二个模块的有向边。</p>
<p>要为模块com.foo.app构建模块图，模块系统将检查模块的声明java.sql，即：</p>
<pre><code class="java">module java.sql {
    requires java.logging;
    requires java.xml;
    exports java.sql;
    exports javax.sql;
    exports javax.transaction.xa;
}
</code></pre>
<p>它还会循环检查其声明的com.foo.bar模块（上面的模块定义中已经示出），包括org.baz.qux模块，java.logging模块和 java.xml模块; 为简洁起见，最后三个这里没有显示，因为它们没有声明对任何其他模块的依赖。</p>
<p>根据所有这些模块声明，为com.foo.app模块画出的模块图，包含以下节点和边：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-1.png" alt="module-pic-1"></p>
<p>在该图中，深蓝色线条表示显式依赖关系，如requires，而浅蓝色线条表示每个模块对基本模块的隐式依赖关系。</p>
<h4 id="可读性"><a href="#可读性" class="headerlink" title="可读性"></a>可读性</h4><p>当一个模块直接依赖于模块图中的另一个模块时，则第一个模块中的代码将能够引用第二个模块中的类型。因此，我们说第一个模块读取第二个模块，或者等同地，第二个模块可以被第一个模块读取。因此，在上述的曲线图中，com.foo.app模块读取com.foo.bar和 java.sql模块，但并不读取org.baz.qux模块，java.xml模块或 java.logging模块。java.logging模块可由java.sql模块读取，但不能被其他模块读取。（根据定义，每个模块都会自行读取自己本身。）</p>
<p>在模块图中定义的可读性关系是可靠配置的基础 ：模块系统能确保每个依赖是由另一个模块完成的，模块图是非循环的，每个模块最多只能读取一个包含制定包的模块，这样定义相同名称包的模块就不会相互干扰。</p>
<p>这样的配置不仅更可靠，也可以更快。当模块中的代码引用包中的某个类型时，那么该包将保证在该模块中定义，或者只在该模块读取的模块中定义一个。因此，在寻找特定类型的定义时，不需要在多个模块中搜索它，或者更糟糕的，沿着整个路径搜索它。</p>
<h4 id="可访问性"><a href="#可访问性" class="headerlink" title="可访问性"></a>可访问性</h4><p>在模块图中定义的可读性关系与exports模块声明中的子句相结合，是强封装的基础：只有当某个模块被另一个模块读取时，Java编译器和虚拟机才会将这个模块中的包中的公共类型视为只能被另一个模块所访问，同时还需要这个模块导出该包。即，如果两种类型的S和T在不同的模块中定义的，并且T是 public，则如果代码S 可以存取 T，必须满足以下条件：</p>
<ol>
<li>S的模块读取T的模块，</li>
<li>T的模块导出T包。</li>
</ol>
<p>跨越模块边界的类型引用以及私有的方法和字段在这种情况下都是不可用的：任何尝试使用它的操作都将导致编译器报告错误，或者由Java虚拟机报出的IllegalAccessError，或者由反射运行时API引发的IllegalAccessException。因此，即使声明了一个类型public，如果它的包没有在其模块的声明中导出，那么它将只能被该模块中的代码访问。</p>
<p>如果模块中的封闭类型是可访问的，并且其成员本身也被声明成允许访问，那么跨模块也可以访问并引用到其方法或字段。</p>
<p>要了解上述模块图的封装是如何工作的，我们标记出每个模块导出的包：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-2.png" alt="module-pic-2"></p>
<p>模块com.foo.app中的代码可以访问com.foo.bar.alpha包中声明的公共类型， 因为模块com.foo.app依赖于模块com.foo.bar，并且因为模块com.foo.bar导出com.foo.bar.alpha包。如果com.foo.bar包含内部程序包（internal package），即com.foo.bar.internal包，则模块com.foo.app不能访问该com.foo.bar.internal包中的任何类型，因为com.foo.bar并没有导出这个内部包。模块com.foo.app中的代码也不能引用org.baz.qux包中的类型，因为模块com.foo.app不依赖于模块org.baz.qux，因此不会读取它（在这个例子中，模块的依赖并不能传递）。</p>
<h4 id="隐含的可读性"><a href="#隐含的可读性" class="headerlink" title="隐含的可读性"></a>隐含的可读性</h4><p>如果一个模块读取另一个模块，则在某些情况下，它也能符合逻辑地读取其他一些模块。</p>
<p>例如，平台的java.sql模块依赖于java.logging模块和java.xml模块，不仅因为它包含了这些模块中的类型的代码实现，还因为它直接声明使用了这些模块中的类型。java.sql.Driver接口声明了一个公共的方法：</p>
<pre><code class="java">public Logger getParentLogger();
</code></pre>
<p>其中Logger是在java.logging模块所导出的包java.util.logging中声明的类型。</p>
<p>假设，例如，com.foo.app模块中的代码调用此方法来获取日志，然后记录一条消息：</p>
<pre><code class="java">String url = ...;
Properties props = ...;
Driver d = DriverManager.getDriver(url);
Connection c = d.connect(url, props);
d.getParentLogger().info(&quot;Connection acquired&quot;);
</code></pre>
<p>如果com.foo.app模块像为如上所述声明，那么这样的代码将不起作用：该getParentLogger方法返回另一个模块java.logging中所声明的Logger类型，而模块com.foo.app并没有读取模块java.logging ，因此调用java.logging模块中Logger类的info方法将会失败，因为该类以及该方法无法访问。</p>
<p>解决这个问题的一个方法寄希望于每一位开发者在依赖java.sql模块并使用getParentLogger方法Logger类的同时，还必须记得声明对java.logging模块的依赖。当然，这样的方式是不可靠的，因为它违反了最小意外原则（principle of least surprise）：如果一个模块依赖于第二个模块，那么很自然的我们会期望去使用第一个模块中的所有属性，包括在第二的模块中声明的属性，也会在我们依赖第一个模块是变得立即可见（即模块依赖的传递性）。</p>
<p>因此，我们扩展了模块声明，以便一个模块可以将附加模块的可读性授予依赖它的任何模块。这种隐含的可读性通过requires public子句来表达（在正式版的jdk中已经被更新为requires transitive）。java.sql模块的声明实际上是这样的：</p>
<pre><code class="java">module java.sql {
    requires public java.logging;
    requires public java.xml;
    exports java.sql;
    exports javax.sql;
    exports javax.transaction.xa;
}
</code></pre>
<p>该public关键字是指，任何依赖于模块java.sql的模块，不仅仅会读取java.sql模块，也会读取java.logging模块和java.xml模块。因此，上述com.foo.app模块的模块图，包含两个额外的深蓝色边缘，通过绿色边缘链接到java.sql模块，因为java.logging模块和java.xml模块被该模块隐性的依赖：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-moudle-3.png" alt="module-pic-3"></p>
<p>com.foo.app模块现在可以包含访问java.logging模块和java.xml模块的导出包中的所有公共类型的代码，即使其声明中没有提及这些模块。</p>
<p>一般而言，如果一个模块的导出包引用了了另一个模块中的包的类型，则第一个模块应该使用requires public子句来声明对第二个模块的依赖。这将确保依赖于第一个模块的其他模块将自动读取第二个模块，从而访问该模块的导出包中的所有类型。</p>
<h3 id="兼容性和迁移"><a href="#兼容性和迁移" class="headerlink" title="兼容性和迁移"></a>兼容性和迁移</h3><p>到目前为止，我们已经看到如何从头开始定义模块，将它们打包到模块工件中，并将它们与其他模块一起使用，这些模块既可以嵌入到平台中，也可以直接在包中定义。</p>
<p>当然，大多数Java代码是在引入模块系统之前编写的，并且必须继续像现在一样继续工作，而不用更改（向下兼容）。因此，即使平台本身由模块组成，模块系统也应该可以在类路径上编译和运行由JAR文件组成的应用程序。它还允许将现有应用程序以灵活和渐进的方式迁移到模块化形式。</p>
<h4 id="未命名模块"><a href="#未命名模块" class="headerlink" title="未命名模块"></a>未命名模块</h4><p>如果我们的需求时在加载一个其所在的包未再任何已知的模块中声明的类型，则模块系统将尝试从类路径加载它。如果成功，那么该类型会被认为成为一个，被称为未命名模块的特殊模块中的成员，以确保每个类型都与某个模块相关联。未命名模块在高层次上类似于现有概念中的未命名包。当然，所有其他模块都有名称，所以我们今后将把它们称为命名模块。</p>
<p>未命名模块读取所有的其他模块。因此，从类路径加载的任何类型的代码，都将能够访问所有其他可读模块的导出类型，默认情况下，该模块将包含所有内置的已命名平台模块。因此，编译并在Java SE 8上运行的现有类路径应用程序将在Java SE 9上以完全相同的方式进行编译和运行，只要它使用的是标准的，未弃用的Java SE API即可。</p>
<p>未命名的模块默认导出其所有软件包。这可以实现灵活的迁移。但是，它并不意味着命名模块中的代码可以访问未命名模块中的类型。实际上，命名模块甚至不能声明对未命名模块的依赖。这种限制是故意的，因为如果允许命名模块依赖于类路径的任意内容，就不可能实现可靠的配置。</p>
<p>如果在命名模块和未命名模块中都定义了同样名字的包，那么未命名模块中的包将被忽略。即使类路径十分混乱，这种可靠的配置，仍能确保每个模块最多只能读取一个模块来提供你所需要的包。如果在上面的示例中，类路径上的JAR文件，包含一个名为，com/foo/bar/alpha/AlphaFactory.class的.class文件，那么该文件将永远不会被加载，因为包com.foo.bar.alpha 是由模块com.foo.bar导出的。</p>
<h4 id="自下而上的迁移"><a href="#自下而上的迁移" class="headerlink" title="自下而上的迁移"></a>自下而上的迁移</h4><p>从类路径加载的类型作为未命名模块中的成员，这种处理将允许我们自下而上的，将现有的应用程序从JAR文件形式迁移到模块化的形式。</p>
<p>例如，上面显示的应用程序最初是为Java SE 8构建的，因为它是放置在类路径上的一组JAR文件。如果我们在Java SE 9上按原样运行它，那么JAR文件中的类型将在未命名的模块中定义。该模块将读取所有其他模块，包括所有内置平台模块; 为简单起见，假设那些被读取的模块被限制为java.sql模块，java.xml模块， java.logging模块和java.base模块。因此我们获得如下的模块图：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-4.png" alt="module-pic-4"></p>
<p>我们可以立即将org-baz-qux.jar转换为命名模块，因为我们知道它不会引用其他两个JAR文件中的任何类型，因此作为命名模块，它也不会引用未命名模块中的任何类型。（这是因为我们刚刚从最初的例子中知道了这一点。如果我们不知道它时候引用未命名模块的话，我们可以借助诸如类似jdeps的工具来发现它。）</p>
<p>我们编写一个模块声明为org.baz.qux，将其添加到模块的源代码中，编译并将结果打包为模块化JAR包。如果我们将该JAR文件放在模块路径上，并将其他类放在类路径上，我们将获得改进的模块图：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-5.png" alt="module-pic-5"></p>
<p>com-foo-bar.jar和com-foo-app.jar中的代码会继续工作，因为未命名的模块会读取每个已命名的模块，这个未命名模块现在包含新模块org.baz.qux。</p>
<p>我们可以类似地进行模块化com-foo-bar.jar，然后接着模块化com-foo-app.jar最终结束预期的模块图，如前所示：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-6.png" alt="module-pic-6"></p>
<p>如果我们了解原始JAR文件中的类型所做的工作，我们当然可以在一个步骤中将它们全部三个模块化。然而，如果 org-baz-qux.jar是独立维护的，或许由完全不同的团队或组织来维护，那么它可以在其他两个组件之前模块化，并且在com-foo-app.jar模块化之前也可以模块化com-foo-bar.jar。</p>
<h4 id="自动模块"><a href="#自动模块" class="headerlink" title="自动模块"></a>自动模块</h4><p>自下而上的迁移很简单，但并非总是可行的。即使org-baz-qux.jar的维护者尚未将其转换为适当的模块，或者可能永远不会，我们仍然可能想要将模块化com-foo-app.jar和com-foo-bar.jar。</p>
<p>我们已经知道代码是com-foo-bar.jar依赖org-baz-qux.jar。但是，如果我们转换com-foo-bar.jar为命名模块com.foo.bar，但留org-baz-qux.jar在类路径中，那么该代码将不再起作用：org-baz-qux.jar将继续在未命名模块中定义，但com.foo.bar是一个命名模块，它不能声明依赖于未命名模块。</p>
<p>那么，我们必须以某种方式安排org-baz-qux.jar作为一个命名模块出现，以便com.foo.bar可以依赖它。我们可以fork org.baz.qux的源代码并将其模块化，但是如果维护人员不愿意将该更改合并到上游存储库中，那么只要我们需要它，我们就必须维护这个分支。</p>
<p>因此，我们将把org-baz-qux.jar作为一个自动模块，不加修改地放在模块路径上，而不是类路径上。这将定义一个可观察模块，其模块名称，org.baz.qux来源于JAR文件的名称，以便其他非自动模块可以通常的方式依赖它：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-7.png" alt="module-pic-7"></p>
<p>自动模块是一个隐式定义的命名模块，因为它没有模块声明。相比之下，普通的命名模块是通过模块声明明确定义的; 我们今后将把它们称为显式模块。</p>
<p>没有方法可以预先告诉自动模块可能依赖哪些其他模块。因此，在模块图解析完成后，自动模块将读取每个其他命名模块，无论是自动模块还是显式模块：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-8.png" alt="module-pic-8"></p>
<p>（这些新的可读性边在模块图中创建了循环，这使得推理起来有些困难，但我们认为这些是可以容忍的，而且通常是为了实现更灵活迁移所导致的临时结果。）</p>
<p>类似地，没有方法可以告诉自动模块中的哪些包打算供其他模块使用，或者仍旧是通过类路径上的类继续使用。因此，即使自动模块中的每个软件包只用于内部使用，也会被视为导出：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-9.png" alt="module-pic-9"></p>
<p>现在com.foo.app中的代码可以访问org.baz.qux中的类型，尽管我们知道它实际上并没有这样做。</p>
<p>自动模块提供了混乱的类路径和显式模块规则之间的中间地带。它们允许将由JAR文件组成的现有应用程序从上到下迁移到模块，如上所示，或者以自上而下和自下而上的方法组合来迁移。通常，我们可以从类路径上的任意一组JAR文件开始，使用一个工具jdeps来分析它们之间的依赖关系，将我们控制的源代码组件转换为显式模块，然后将剩余的JAR文件按原样放在模块路径中。我们不控制源代码的JAR文件将被视为自动模块，直到它们也转换为显式模块为止。</p>
<h4 id="与类路径建立联系"><a href="#与类路径建立联系" class="headerlink" title="与类路径建立联系"></a>与类路径建立联系</h4><p>许多现有的JAR文件可以用作自动模块，但有些不能。如果类路径上的两个或多个JAR文件包含同一个包中的类型，那么最多可以有其中的一个来用作自动模块，因为模块系统仍然保证每个命名模块至多读取一个包含了需要的包的命名模块，以保证定义了相同名称包的命名模块不会相互干扰。在这种情况下，我们经常会发现实际上，我们只需要其中一个JAR文件。如果其他的JAR文件重复或接近重复，并以某种方式错误地放在类路径上，则可以将其中一个用作自动模块，其他的JAR文件就会被舍弃。但是，如果类路径上的多个JAR文件有意包含在同一个包中的类型，那么它们必须都保留在类路径中（即作为一个在类路径上的未命名模块而非在模块路径上的自动模块）。</p>
<p>因为这些JAR文件不能用作自动模块，为了启用迁移，我们会将自动模块，视为建立在显式模块和仍然处于类路径上的代码（未命名模块）之间的桥梁：自动模块除了读取其他所有命名模块之外，还将读取未命名的模块。如果我们的应用程序的原始类路径中，包含了JAR文件org-baz-fiz.jar和org-baz-fuz.jar，那么我们将有图：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-10.png" alt="module-pic-10"></p>
<p>如前所述，未命名模块导出其所有软件包，因此自动模块中的代码将能够访问所有从类路径加载的公用类型（即未命名模块中的所用公共类型）。</p>
<p>使用类路径中的类型的自动模块，不能将这些类型暴露给其他依赖于它的显式模块，因为显式模块无法声明对未命名模块的依赖关系。如果显式模块com.foo.app中的代码引用了一个自动模块com.foo.bar中的公共类型，并且自动模块com.foo.bar明确声明使用了仍在类路径上的一个JAR文件中的类型，则com.foo.app中的代码将无法访问该类路径上的类型，因为命名模块com.foo.bar不能依赖于未命名的模块。这可以通过将模块com.foo.app暂时视为自动模块来解决，以便其代码可以访问类路径中的类型，直到类路径上的相关JAR文件（未命名模块）可以被视为自动模块或转换为显式模块为止。</p>
<h3 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h3><p>利用服务接口和服务提供者的松散耦合是构建大型软件系统的强大工具。Java通过<a href="https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html" target="_blank" rel="noopener">java.util.ServiceLoader</a>类来支持服务，该类在运行时通过搜索类路径来定位服务提供者。对于在模块中定义的服务提供者，我们必须考虑如何在一组可观察模块中找到这些模块，解决它们的依赖性，并使提供者可以使用使用相应服务的代码。</p>
<p>假设，例如，我们的com.foo.app模块使用MySQL数据库，并且在具有声明的可观察模块中提供MySQL JDBC驱动程序</p>
<pre><code class="java">module com.mysql.jdbc {
    requires java.sql;
    requires org.slf4j;
    exports com.mysql.jdbc;
}
</code></pre>
<p>其中org.slf4j是驱动程序（jdbc driver）使用的日志记录库，并且com.mysql.jdbc是包含java.sql.Driver这一服务接口的具体实现的包。（实际上并不需要导出驱动程序包，我们这样做是为了使代码清晰可见。）</p>
<p>为了让java.sql模块使用这个驱动程序， ServiceLoader类必须能够通过反射来实例化驱动程序类; 为了实现这一点，模块系统必须将驱动模块添加到模块图中并解决其依赖性，因此：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-11.png" alt="module-pic-11"></p>
<p>为了实现这一点，模块系统必须能够识别所有使用服务的模块，然后从一组可观察模块中找到服务的提供者。</p>
<p>模块系统可以通过，扫描模包中的类文件并调用ServiceLoader::load方法，来识别对服务的使用，但是这样做不仅会很慢，而且并不可靠。模块使用特定服务应该是是模块的一个基本定义，所以为了效率和清晰度，我们在模块的声明中用一个uses子句来表示对服务的使用：</p>
<pre><code class="java">module java.sql {
    requires public java.logging;
    requires public java.xml;
    exports java.sql;
    exports javax.sql;
    exports javax.transaction.xa;
    uses java.sql.Driver;
}
</code></pre>
<p>模块系统可以通过扫描META-INF/services资源条目来识别服务提供者，就像现在ServiceLoader类所做的那样。但是，模块提供特定服务借口的具体实现同样很重要，所以我们在模块的声明中用一个provides子句表示模块的提供者：</p>
<pre><code class="java">module com.mysql.jdbc {
    requires java.sql;
    requires org.slf4j;
    exports com.mysql.jdbc;
    provides java.sql.Driver with com.mysql.jdbc.Driver;
}
</code></pre>
<p>现在，只要阅读这些模块的声明，就很容易看出来，其中一个m模块使用另一个提供的服务。</p>
<p>在模块声明中声明服务提供者和服务使用者的关系具有提高效率和代码清晰度的优势。这两种服务声明都可以在编译时进行解释，以确保服务提供者和服务使用者都可以访问服务接口（例如，java.sql.Driver）。服务提供者声明可以进一步解释，以确保提供者（例如，com.mysql.jdbc.Driver）确定实现其宣称的服务接口。服务使用的声明可以通过工具来提前编译，以确保在运行之前服务提供者能恰当的被编译。</p>
<p>出于迁移目的，如果定义自动模块的JAR文件包含META-INF/services资源条目，则将每个这样的条目视为该模块中的provides关键字的对应子句。自动模块被认为可以使用每一种可用的服务。</p>
<h3 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h3><p>本文档的其余部分讨论了高级特性，这些特性虽然很重要，但大多数开发人员可能并不感兴趣。</p>
<h4 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h4><p>为了使模块图在运行时反射也可用，我们在java.lang.reflect包中定义了一个叫Module类，并在一个新的包java.lang.module中定义一些相关类型。Module类的一个实例在运行时代表一个单独的模块。每个类型都在一个模块中，因此每个Class对象都有一个关联的Module对象，该对象由新Class::getModule方法返回。</p>
<p>Module对象的基本操作是：</p>
<pre><code class="java">package java.lang.reflect;

public final class Module {
    public String getName();
    public ModuleDescriptor getDescriptor();
    public ClassLoader getClassLoader();
    public boolean canRead(Module target);
    public boolean isExported(String packageName);
}
</code></pre>
<p>其中ModuleDescriptor是java.lang.module包中的类，它的实例表示模块描述符; getClassLoader方法返回模块的类加载器; canRead方法告诉模块是否可以读取目标模块; isExported方法告诉模块是否导出给定的包。</p>
<p>java.lang.reflect包并不是平台上唯一的反射工具。相似的工具也被添加到javax.lang.model模块，为了支持编译时的注释处理和文档生成工具。</p>
<h4 id="反射的可读性"><a href="#反射的可读性" class="headerlink" title="反射的可读性"></a>反射的可读性</h4><p>框架是使用反射来加载，检查，并在运行时实例化的其他类的工具。Java SE平台本身的框架示例是服务加载器，资源包，动态代理和序列化，当然还有许多流行的外部框架库，用于数据库持久性，依赖注入和测试等多种用途。</p>
<p>鉴于需要在运行时发现类，框架必须能够访问其构造函数之一以实例化它。但事实表明，情况通常不会如此。</p>
<p>Java平台的<a href="https://docs.oracle.com/javase/8/docs/api/javax/xml/stream/package-summary.html" target="_blank" rel="noopener">XML解析器</a>，如果<a href="https://docs.oracle.com/javase/8/docs/api/javax/xml/stream/XMLInputFactory.html#newFactory--" target="_blank" rel="noopener">加载和实例化</a>由系统配置命名为javax.xml.stream.XMLInputFactory的<a href="https://docs.oracle.com/javase/8/docs/api/javax/xml/stream/XMLInputFactory.html" target="_blank" rel="noopener">XMLInputFactory</a>的服务实现，它就将通过ServiceLoader类，优先于所有服务提供者发现被发现。忽略异常处理和安全检查的代码大致如下所示：</p>
<pre><code class="java">String providerName
    = System.getProperty(&quot;javax.xml.stream.XMLInputFactory&quot;);
if (providerName != null) {
    Class providerClass = Class.forName(providerName, false,
                                        Thread.getContextClassLoader());
    Object ob = providerClass.newInstance();
    return (XMLInputFactory)ob;
}
// Otherwise use ServiceLoader
...
</code></pre>
<p>在模块化设置中，只要包含的服务提供者的类为上下文类加载器所知，Class::forName就仍将继续工作。但是，通过反射的方式调用服务提供者的newInstance方法将不起作用：服务提供者可能会从类路径加载，在这种情况下，它将位于未命名的模块中，或者它可能位于某个已命名的模块中，无论是哪种情况，我们的框架本身都在java.xml模块中。该模块仅依赖于基本模块，因此也只读取基本模块，此框架将无法访问任何其他模块中的服务提供者类。</p>
<p>为了使框架可以访问服务提供者类，我们需要使框架的模块可以读取服务提供者的模块。我们可以要求每个框架在运行时都明确地，将必要的可读性边缘添加到模块图中，就像本文档的早期版本一样，但是经验表明这种方法很麻烦并且会导致迁移的障碍。</p>
<p>因此，我们需要修改反射API，我们假设任何反射其他类型的代码，都位于一个可以访问到被反射类型所在模块的模块中。这使得上面的例子和其他类似的代码可以毫无改变地工作。这种方法不会削弱强封装：公开类型仍然必须位于导出的包中，以便从其所在模块外部进行访问，无论是通过编译代码还是通过反射。</p>
<blockquote>
<p>事实上，在这种需要发射其他模块的情况下，如果我们只想要反射共有类型，那只要在模块中导出相应的包就可以；但如果我们想要通过setAccessible(true)方法来反射私有类型是，必须在模块声明时添加open关键字或者opens子句，来使模块成为一个开放模块或者开放模块中的软件包，使反射对私有类型可见，否则就会在运行报出Accessing Error。这一点原作者并未提及，我个人认为这种设计很好的保证了模块的强封装的特性</p>
</blockquote>
<h4 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h4><p>每个类型都在一个模块中，并且在运行时每个模块都有一个类加载器，但是类加载器是否只加载一个模块呢？事实上，模块系统对模块和类加载器之间的关系几乎没有限制。一个类加载器可以从一个模块或多个模块加载类型，只要这些模块不相互干扰，并且只有一个加载器加载了特定模块中的所有类型。</p>
<p>这种灵活性对于兼容性至关重要，因为它允许我们保留平台现有的内置类加载器的层次结构。引导类加载器（bootstrap classloader）和扩展类加载器（extension classloader）仍然存在，并用于从平台模块加载类型。应用程序类加载器（application classloader）仍然存在，用于从工件的模块路径中找到加载类型。</p>
<p>这种灵活性还会使模块化现有应用程序变得更加容易，这些应用程序已经构建了复杂的层次结构甚至自定义类加载器，因次我们可以将这些加载器升级到模块中的加载类型，而无需更改其委托模式。</p>
<blockquote>
<p>事实上，Java9的classloader是有改变的，这一部分我以后会单独写一篇文章来总结。如现在想了解请参考<a href="http://www.cnblogs.com/IcanFixIt/p/7131676.html" target="_blank" rel="noopener">此链接</a>中的扩展机制部分</p>
</blockquote>
<h4 id="未命名模块与类加载器"><a href="#未命名模块与类加载器" class="headerlink" title="未命名模块与类加载器"></a>未命名模块与类加载器</h4><p>我们之前了解到，如果某个类型未在命名模块中定义，那么它将被视为未命名模块的成员，但与未命名模块相关的是哪个类加载器呢？</p>
<p>事实证明，每个类加载器都有自己独特的未命名模块，它是由新ClassLoader::getUnnamedModule方法返回的。如果一个类加载器加载了一个没有在命名模块中定义的类型，那么该类型就被认为是在该加载器的未命名模块中。例如，Class类中的getModule方法将返回其加载器的未命名模块。应用加载器（application classloader）的未命名模块，会从类路径中加载不在任何模块下定义的包中的类型。</p>
<h4 id="层"><a href="#层" class="headerlink" title="层"></a>层</h4><p>模块系统并不指定模块和类加载器之间的关系，但为了加载特定的类型，它必须以某种方式能够找到合适的加载器。因此，在运行时，模块图的实例化会生成一个层（layer），这个层将图中的每个模块映射到负责加载该模块中的类型的唯一类加载器上。与可被发现的模块相反，引导层（boot layer）是由Java虚拟机在启动时通过解析应用程序的初始模块所创建的。</p>
<p>大多数应用程序以及几乎当前所有的应用程序都不会使用引导层以外的层。然而，多个层可用于带有插件的复杂应用程序或容器体系结构（如应用程序服务器，IDE和测试框架）。这样的应用程序可以使用动态的类加载和模块系统的反射API，来加载和运行由一个或多个模块组成的应用程序。然而，这通常需要添加两种额外的灵活性：</p>
<ol>
<li><p>使用模块的应用程序可能需要不同版本的已存在的模块。例如，Java EE Web应用程序可能需要java.xml.ws模块中的不同版本的JAX-WS，而不是内置于运行时环境的版本。</p>
</li>
<li><p>使用模块的应用程序可能需要已经被发现的服务提供者以外的服务提供者。应用程序甚至可能嵌入自己的首选服务提供者。Web应用程序，可能包含一个它所期望的<a href="https://github.com/FasterXML/woodstox" target="_blank" rel="noopener">Woodstox XML解析器</a>版本，在这种情况下，ServiceLoader类应优先返回它需要的服务提供者而不是任何其他的服务提供者。</p>
</li>
</ol>
<p>与可被发现的模块的环境相反，一个容器应用程序可以为一个使用模块的应用程序的初始模块，在其已有的层上创建一个新的层。这样的环境可以包含可升级平台模块的替代版本以及其他已存在于较低层的非平台模块，解析器优先解析这些备用模块。这种环境也可以在那些已经在较低层被发现的服务提供者之外发现不同的服务提供者; ServiceLoader类将在较低层返回服务提供者之前去加载这些服务提供者。</p>
<p>层可以堆叠：我们可以在引导层之上构建新层，然后再在其上创建另一个层。作为正常解析过程的结果，所指定的层中的模块可以读取该层中或下层中的模块。因此，层的模块图可以通过引用包括其下的每个层的模块图来表示。</p>
<blockquote>
<p>上面这一节翻译的不太好，事实上我也不太理解这一节的内容。以后会仔细研究一下，目前只知道现在JDK中已经有了ModuleLayer类，可以通过Module.getLayer()获得。</p>
</blockquote>
<h4 id="限制性导出"><a href="#限制性导出" class="headerlink" title="限制性导出"></a>限制性导出</h4><p>偶尔有必要安排某些类型在一组模块中可访问，但其他模块无法访问。</p>
<p>在标准JDK的java.sql模块和 java.xml模块的代码实现中，使用了java.base模块中的sun.reflect包下定义的类型 。为了让代码访问sun.reflect包中的类型，我们可以简单地从java.base模块中导出该包：</p>
<pre><code class="java">module java.base {
    ...
    exports sun.reflect;
}
</code></pre>
<p>然而，这将使得每个sun.reflect包中的类型对所有模块都可见（因为每个模块都读取java.base），而这是不合理的，因为该包中的一些类定义了有特权的，安全敏感的方法。</p>
<p>因此，我们扩展了模块声明以允许将包导出到一个或多个特定命名的模块，而不被其他模块可见。java.base模块的声明实际上只将sun.reflect包导出到特定的一组JDK模块：</p>
<pre><code class="java">module java.base {
    ...
    exports sun.reflect to
        java.corba,
        java.logging,
        java.sql,
        java.sql.rowset,
        jdk.scripting.nashorn;
}
</code></pre>
<p>通过在模块图中添加另一种类型的边缘（此处为彩色金色），可以将这些限制性的导出显示在模块图中：</p>
<p><img src="https://raw.githubusercontent.com/ShanyouYu-Sean/blog-images/master/java%20module%20system/example-module-12.png" alt="module-pic-12"></p>
<p>前面提到的可访问性规则如下所述：如果两种类型S并且T在不同模块中定义，并且T是public，则代码S可以在以下情况下访问T：</p>
<ol>
<li>S的模块读取T的模块，和</li>
<li>T的模块直接导出T的包到S的模块，亦或是导出到所有模块。</li>
</ol>
<p>我们为用于反射的Module类提供了一种方法，来确定是否将包导出到特定模块，而非所有模块：</p>
<pre><code class="java">public final class Module {
    ...
    public boolean isExported(String packageName, Module target);
}
</code></pre>
<p>限制性的导出可能会意外地将内部的类型到处到预期之外的模块，因此我们必须小心使用它们。例如命名一个名为java.corba的模块以访问sun.reflect包中的类型。为了防止这种情况，我们可以在构建时分析相关模块，并在每个模块的描述符中记录允许依赖它的模块内容的哈希值，并使用限制性导出。在分析期间，我们需要验证，那些使用限制性导出到其他命名模块的模块，其模块内容的哈希值，与引用该模块的模块中记录的该模块的哈希值匹配。只要声明和使用限制性的导出的模块以这种方式绑定在一起，限制性的导出就可以安全地在不受信任的环境中使用。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这里描述了模块系统的很多方面，但大多数开发人员只需要使用其中的一部分。我们期望在未来几年内，大多数Java开发人员都会熟悉模块声明，模块化JAR文件，模块路径，可读性，可访问性，未命名模块，自动模块和模块化服务等基本概念。相比之下，反射可读性，层和限制性的导出等更高级功能可能被使用的可能性比较小。</p>
]]></content>
      
        <categories>
            
            <category> Java 9 </category>
            
            <category> Java module </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java 9 </tag>
            
            <tag> Java module </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Project Jigsaw:Java模块系统快速入门指南]]></title>
      <url>/2018/03/29/java9-quick-guide/</url>
      <content type="html"><![CDATA[<p><strong>本文为openjdk官方java模块入门指南的翻译。(<a href="http://openjdk.java.net/projects/jigsaw/quick-start" target="_blank" rel="noopener">原文地址</a>)</strong></p>
<p>本文档提供了一些让开发者快速上手Java模块系统的简单例子。<br>例子中的文件路径用/划分，文件分隔符是：，windows开发者请用\和；替换以上分隔符。</p>
<h3 id="Greetings"><a href="#Greetings" class="headerlink" title="Greetings"></a>Greetings</h3><p>第一个例子展示了一个打印”Greetings!”字符串的简单模块。这个模块由两个源文件组成（module-info.java和Main.java）。按照惯例，模块的源文件应该在一个以模块名字为命名的目录中。</p>
<pre><code class="java">src/com.greetings/com/greetings/Main.java
src/com.greetings/module-info.java

$ cat src/com.greetings/module-info.java
module com.greetings { }

$ cat src/com.greetings/com/greetings/Main.java
package com.greetings;
public class Main {
    public static void main(String[] args) {
        System.out.println(&quot;Greetings!&quot;);
    }
}
</code></pre>
<p>以下命令会将源文件编译到mods/com.greetings目录中：</p>
<pre><code class="bash">$ mkdir -p mods/com.greetings

$ javac -d mods/com.greetings \
    src/com.greetings/module-info.java \
    src/com.greetings/com/greetings/Main.java
</code></pre>
<p>现在我们用以下命令来运行这个例子：</p>
<pre><code class="bash">$ java --module-path mods -m com.greetings/com.greetings.Main
</code></pre>
<p>–module-path 是模块的路径，他的值是包含模块的一个或多个目录。<br>-m 指定了主模块，/后面的值是模块里包含main方法的全类名。</p>
<h3 id="Greetings-world"><a href="#Greetings-world" class="headerlink" title="Greetings world"></a>Greetings world</h3><p>第二个例子更新了第一个例子中的模块声明，它声明了需要一个名为org.astro的模块的依赖。<br>模块org.astro导出了名为org.astro的api包。</p>
<pre><code class="java">src/org.astro/module-info.java
src/org.astro/org/astro/World.java
src/com.greetings/com/greetings/Main.java
src/com.greetings/module-info.java

$ cat src/org.astro/module-info.java
module org.astro {
    exports org.astro;
}

$ cat src/org.astro/org/astro/World.java
package org.astro;
public class World {
    public static String name() {
        return &quot;world&quot;;
    }
}

$ cat src/com.greetings/module-info.java
module com.greetings {
    requires org.astro;
}

$ cat src/com.greetings/com/greetings/Main.java
package com.greetings;
import org.astro.World;
public class Main {
    public static void main(String[] args) {
        System.out.format(&quot;Greetings %s!%n&quot;, World.name());
    }
}
</code></pre>
<p>依次编译这两个模块，用javac命令在编译com.greetings模块时指定模块的路径，使得org.astro模块中的引用和其导出包中的类型可以被引用。</p>
<pre><code class="bash">$ mkdir -p mods/org.astro mods/com.greetings

$ javac -d mods/org.astro \
    src/org.astro/module-info.java src/org.astro/org/astro/World.java

$ javac --module-path mods -d mods/com.greetings \
    src/com.greetings/module-info.java src/com.greetings/com/greetings/Main.java
</code></pre>
<p>使用与第一个例子相同的方式来运行这个例子：</p>
<pre><code class="bash">$ java --module-path mods -m com.greetings/com.greetings.Main
Greetings world!
</code></pre>
<h3 id="多模块编译"><a href="#多模块编译" class="headerlink" title="多模块编译"></a>多模块编译</h3><p>在上面的例子中，模块com.greetings和模块org.astro是分开编译的，我们也可以用一条javac命令来编译多个模块</p>
<pre><code class="bash">$ mkdir mods

$ javac -d mods --module-source-path src $(find src -name &quot;*.java&quot;)

$ find mods -type f
mods/com.greetings/com/greetings/Main.class
mods/com.greetings/module-info.class
mods/org.astro/module-info.class
mods/org.astro/org/astro/World.class
</code></pre>
<h3 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h3><p>在目前的实例中，编译好的模块都分散在文件系统中，为了调度和部署，我们通常会把模块打包成模块化jar包，模块化jar包就是在jar包最顶层目录包含module-info.class的普通jar包。</p>
<p>以下命令将会在mlib目录中创建org.astro@1.0.jar和com.greetings.jar</p>
<pre><code class="bash">$ mkdir mlib

$ jar --create --file=mlib/org.astro@1.0.jar \
    --module-version=1.0 -C mods/org.astro .

$ jar --create --file=mlib/com.greetings.jar \
    --main-class=com.greetings.Main -C mods/com.greetings .

$ ls mlib
com.greetings.jar   org.astro@1.0.jar
</code></pre>
<p>在这个例子中，模块org.astro在打包时被指定了其版本号1.0，模块com.greetings在打包时被制定了其main方法主类com.greetings.Main。</p>
<p>现在，我们可以直接运行模块com.greetings而无需制定其main class</p>
<pre><code class="bash">$ java -p mlib -m com.greetings
Greetings world!
</code></pre>
<p>命令可以用-p来替代–module-path。</p>
<p>jar命令拥有许多新选项，其中一个就是打印模块化jar包中声明的模块。</p>
<pre><code class="bash">$ jar --describe-module --file=mlib/org.astro@1.0.jar
org.astro@1.0 jar:file:///d/mlib/org.astro@1.0.jar/!module-info.class
exports org.astro
requires java.base mandated
</code></pre>
<h3 id="缺少requires或者exports关键字"><a href="#缺少requires或者exports关键字" class="headerlink" title="缺少requires或者exports关键字"></a>缺少requires或者exports关键字</h3><p>如果我们在com.greetings模块中遗漏了requires关键字：</p>
<pre><code class="java">$ cat src/com.greetings/module-info.java
module com.greetings {
    // requires org.astro;
}

$ javac --module-path mods -d mods/com.greetings \
    src/com.greetings/module-info.java src/com.greetings/com/greetings/Main.java
src/com.greetings/com/greetings/Main.java:2: error: package org.astro is not visible
    import org.astro.World;
                ^
    (package org.astro is declared in module org.astro, but module com.greetings does not read it)
1 error
</code></pre>
<p>如果我们在org.astro模块中遗漏了exports关键字：</p>
<pre><code class="java">$ cat src/com.greetings/module-info.java
module com.greetings {
    requires org.astro;
}
$ cat src/org.astro/module-info.java
module org.astro {
    // exports org.astro;
}

$ javac --module-path mods -d mods/com.greetings \
    src/com.greetings/module-info.java src/com.greetings/com/greetings/Main.java
$ javac --module-path mods -d mods/com.greetings \
    src/com.greetings/module-info.java src/com.greetings/com/greetings/Main.java
src/com.greetings/com/greetings/Main.java:2: error: package org.astro is not visible
    import org.astro.World;
                ^
    (package org.astro is declared in module org.astro, which does not export it)
1 error
</code></pre>
<h3 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h3><p>服务允许服务提供者和服务消费者中建立松散的耦合结构。在这个例子中，存在这一个服务提供者和一个服务消费者：模块com.socket提供了API用来做network socket；模块org.fastsocket是一个服务提供模块，它提供了com.socket.spi.NetworkSocketProvider的实现，并且不导出任何包。</p>
<p>下面是模块com.socket的代码：</p>
<pre><code class="java">$ cat src/com.socket/module-info.java
module com.socket {
    exports com.socket;
    exports com.socket.spi;
    uses com.socket.spi.NetworkSocketProvider;
}

$ cat src/com.socket/com/socket/NetworkSocket.java
package com.socket;

import java.io.Closeable;
import java.util.Iterator;
import java.util.ServiceLoader;

import com.socket.spi.NetworkSocketProvider;

public abstract class NetworkSocket implements Closeable {
    protected NetworkSocket() { }

    public static NetworkSocket open() {
        ServiceLoader&lt;NetworkSocketProvider&gt; sl
            = ServiceLoader.load(NetworkSocketProvider.class);
        Iterator&lt;NetworkSocketProvider&gt; iter = sl.iterator();
        if (!iter.hasNext())
            throw new RuntimeException(&quot;No service providers found!&quot;);
        NetworkSocketProvider provider = iter.next();
        return provider.openNetworkSocket();
    }
}


$ cat src/com.socket/com/socket/spi/NetworkSocketProvider.java
package com.socket.spi;

import com.socket.NetworkSocket;

public abstract class NetworkSocketProvider {
    protected NetworkSocketProvider() { }

    public abstract NetworkSocket openNetworkSocket();
}
</code></pre>
<p>以下是模块org.fastsocket的代码</p>
<pre><code class="java">$ cat src/org.fastsocket/module-info.java
module org.fastsocket {
    requires com.socket;
    provides com.socket.spi.NetworkSocketProvider
        with org.fastsocket.FastNetworkSocketProvider;
}

$ cat src/org.fastsocket/org/fastsocket/FastNetworkSocketProvider.java
package org.fastsocket;

import com.socket.NetworkSocket;
import com.socket.spi.NetworkSocketProvider;

public class FastNetworkSocketProvider extends NetworkSocketProvider {
    public FastNetworkSocketProvider() { }

    @Override
    public NetworkSocket openNetworkSocket() {
        return new FastNetworkSocket();
    }
}

$ cat src/org.fastsocket/org/fastsocket/FastNetworkSocket.java
package org.fastsocket;

import com.socket.NetworkSocket;

class FastNetworkSocket extends NetworkSocket {
    FastNetworkSocket() { }
    public void close() { }
}
</code></pre>
<p>为了简单化，我们同时编译两个模块，但事实上，服务提供者和服务消费者几乎总是分开编译的</p>
<pre><code class="bash">$ mkdir mods
$ javac -d mods --module-source-path src $(find src -name &quot;*.java&quot;)
</code></pre>
<p>最后我们对模块com.greetings用新的模块的api做更改</p>
<pre><code class="java">$ cat src/com.greetings/module-info.java
module com.greetings {
    requires com.socket;
}

$ cat src/com.greetings/com/greetings/Main.java
package com.greetings;

import com.socket.NetworkSocket;

public class Main {
    public static void main(String[] args) {
        NetworkSocket s = NetworkSocket.open();
        System.out.println(s.getClass());
    }
}


$ javac -d mods/com.greetings/ -p mods $(find src/com.greetings/ -name &quot;*.java&quot;)
</code></pre>
<p>最后，我们运行com.greetings模块</p>
<pre><code class="bash">$ java -p mods -m com.greetings/com.greetings.Main
class org.fastsocket.FastNetworkSocket
</code></pre>
<p>输出结果确认服务提供者已经被定位成功。</p>
<h3 id="The-linker"><a href="#The-linker" class="headerlink" title="The linker"></a>The linker</h3><p>jlink是一个用来在一组拥有传递性依赖的模块之中，建立一个自定义的模块化可运行镜像的工具。</p>
<p>此工具目前需要制定模块路径的模块化jar包或者jmod格式。jdk会将标准的或jdk指定的模块以jmod格式打包。</p>
<p>以下命令会创建一个包含模块com.greetings和其传递性依赖的可运行镜像。</p>
<pre><code class="bash">jlink --module-path $JAVA_HOME/jmods:mlib --add-modules com.greetings --output greetingsapp
</code></pre>
<p>–module-path的值是包含打包后的模块的路径。在windows下需要将’:’替换成’;’。<br>$JAVA_HOME/jmods是包含java.base.jmod和其他标准化jdk模块的路径。mlib路径包含模块com.greetings的artifact。</p>
<p>jlink工具也包含许多高级的选项来自定义镜像，详见jlink –help</p>
<h3 id="–patch-module"><a href="#–patch-module" class="headerlink" title="–patch-module"></a>–patch-module</h3><p>开发者常会从Doug Lea的CVS中checkout出java.util.concurrent下的类并用-Xbootclasspath/p来替换源文件编译。(我都不知道Doug Lea还在更新juc的代码，膜拜大神)</p>
<p>现在-Xbootclasspath/p已经被舍弃，它在模块化系统中替代是–patch-module，用来替换模块中的类，它也可以被用来增大模块的内容。</p>
<p>javac命令同样也支持–patch-module选项用来编译模块中的as if部分。</p>
<p>以下是用新版本的java.util.concurrent.ConcurrentHashMap来编译并用其运行的例子</p>
<pre><code class="bash">javac --patch-module java.base=src -d mypatches/java.base \
    src/java.base/java/util/concurrent/ConcurrentHashMap.java

java --patch-module java.base=mypatches/java.base ...
</code></pre>
<h3 id="更多链接"><a href="#更多链接" class="headerlink" title="更多链接"></a>更多链接</h3><ul>
<li><a href="http://openjdk.java.net/projects/jigsaw/spec/sotms/" target="_blank" rel="noopener">The State of the Module System</a></li>
<li><a href="http://openjdk.java.net/jeps/261" target="_blank" rel="noopener">JEP 261: Module System</a></li>
<li><a href="http://openjdk.java.net/projects/jigsaw/" target="_blank" rel="noopener">Project Jigsaw</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> Java 9 </category>
            
            <category> Java module </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java 9 </tag>
            
            <tag> Java module </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2017/12/22/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;
</code></pre>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server
</code></pre>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate
</code></pre>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy
</code></pre>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      
        
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<p>不是所有的树</p>
<p>都能在自己的家乡终老</p>
<p>不是所有的轨道</p>
<p>都通往春暖花开的地方</p>
<p>不是所有的花都会盛开</p>
<p>不是所有的约定的人都会到来</p>
<p>我知道，是流星赞美了黑夜</p>
<p>鲸鱼安慰了大海</p>
<hr>
<p><strong>Sean the Fish</strong></p>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=4882391&auto=0&height=66"></iframe>

<p>Java码农，目前供职于IBM。</p>
<p>博客刚刚建立，希望自己能坚持写下去。</p>
<p>Email：a728976009@hotmail.com</p>
<hr>
<p>想在天井里盛一只玻璃杯</p>
<p>明朝看天下雨今夜落几寸</p>
]]></content>
    </entry>
    
  
</search>
